<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">154</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (10), Neurology (7), Cardiology (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (10)</option>
                        
                        <option value="Neurology">Neurology (7)</option>
                        
                        <option value="Cardiology">Cardiology (7)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (7)</option>
                        
                        <option value="Oncology">Oncology (6)</option>
                        
                        <option value="Digital Health">Digital Health (5)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Geriatrics">Geriatrics (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (4)</option>
                        
                        <option value="Public Health">Public Health (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.01986v1"
                     data-domains="Sleep Medicine,Neurology,Pulmonology,Geriatrics,Digital Health,Cardiology"
                     data-keywords="Deep learning,Wrist accelerometry,Actigraphy,Sleep-wake detection,Polysomnography,Sleep disorders,Generalizability,Device-agnostic"
                     data-authors="Nasim Montazeri,Stone Yang,Dominik Luszczynski,John Zhang,Dharmendra Gurve,Andrew Centen,Maged Goubran,Andrew Lim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01986v1.html">A robust generalizable device-agnostic deep learning model for sleep-wake determination from triaxial wrist accelerometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nasim Montazeri, Stone Yang, Dominik Luszczynski et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel, robust deep learning model designed to accurately determine sleep-wake states from triaxial wrist accelerometry. The model demonstrated high performance and strong generalizability, effectively overcoming previous limitations related to poor wake detection and lack of cross-device compatibility, even in diverse adult populations including those with various sleep disorders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01986v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01986v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01986v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01986v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01934v1"
                     data-domains="Surgical Robotics Safety,Hospital Logistics Automation,Patient Monitoring Systems (future),Rehabilitation Robotics,Medical Imaging Analysis (tracking agents/instruments)"
                     data-keywords="Multi-Object Tracking,Adversarial Attack,Physical Attack,Trajectory Manipulation,ID-Transfer,Computer Vision Security,Autonomous Systems,Cyber-Physical Systems"
                     data-authors="Chenyi Wang,Yanmao Man,Raymond Muller,Ming Li,Z. Berkay Celik,Ryan Gerdes,Jonathan Petit">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01934v1.html">Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chenyi Wang, Yanmao Man, Raymond Muller et al.
                </div>

                <div class="paper-summary">
                    This paper introduces AdvTraj, the first online and physical ID-manipulation attack against Multi-Object Tracking (MOT) systems that operates by generating adversarial trajectories without directly attacking the object detection module. AdvTraj successfully transfers the attacker's ID to a target object, demonstrating 100% success in white-box simulations and high transferability to state-of-the-art MOT algorithms, revealing critical vulnerabilities in their object association mechanisms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgical Robotics Safety</span>
                    
                    <span class="domain-tag">Hospital Logistics Automation</span>
                    
                    <span class="domain-tag">Patient Monitoring Systems (future)</span>
                    
                    <span class="domain-tag">Rehabilitation Robotics</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis (tracking agents/instruments)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01934v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01934v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01934v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01934v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01922v1"
                     data-domains="Ophthalmology,Radiology,Pathology"
                     data-keywords="Large Vision-Language Models,LVLMs,Hallucination Mitigation,Visual Contrastive Decoding,Token Sparsification,Visual Question Answering,Report Generation,Factual Accuracy"
                     data-authors="Zahra Mahdavi,Zahra Khodakaramimaghsoud,Hooman Khaloo,Sina Bakhshandeh Taleshani,Erfan Hashemi,Javad Mirzapour Kaleybar,Omid Nejati Manzari">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01922v1.html">Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zahra Mahdavi, Zahra Khodakaramimaghsoud, Hooman Khaloo et al.
                </div>

                <div class="paper-summary">
                    Med-VCD introduces a novel sparse visual-contrastive decoding method to mitigate hallucinations in medical Large Vision-Language Models (LVLMs) without significant inference time overhead. This approach leverages a token-sparsification strategy to select visually informed tokens, thereby enhancing factual accuracy and reducing incorrect outputs in medical applications like visual question answering and report generation. Evaluations across diverse medical datasets show an average 13% increase in factual accuracy and 6% improvement in hallucination accuracy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01922v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01922v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01922v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01922v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01913v1"
                     data-domains="eess.IV"
                     data-keywords="eess.IV,cs.CV"
                     data-authors="Bailiang Jian,Jiazhen Pan,Rohit Jena,Morteza Ghahremani,Hongwei Bran Li,Daniel Rueckert,Christian Wachinger,Benedikt Wiestler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01913v1.html">Disentangling Progress in Medical Image Registration: Beyond Trend-Driven Architectures towards Domain-Specific Strategies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bailiang Jian, Jiazhen Pan, Rohit Jena et al.
                </div>

                <div class="paper-summary">
                    Medical image registration drives quantitative analysis across organs, modalities, and patient populations. Recent deep learning methods often combine low-level "trend-driven" computational blocks from computer vision, such as large-kernel CNNs, Transformers, and state-space models, with high-level ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">eess.IV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01913v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01913v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01913v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01913v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01885v1"
                     data-domains="Oncology,Cell Biology,Pharmacology,Drug Discovery,Pathology"
                     data-keywords="cell tracking,deep learning,cancer research,fluorescent microscopy,mitosis,apoptosis,drug efficacy,multi-object tracking"
                     data-authors="Florian B√ºrger,Martim Dias Gomes,Nica Gutu,Adri√°n E. Granada,No√©mie Moreau,Katarzyna Bozek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01885v1.html">TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Florian B√ºrger, Martim Dias Gomes, Nica Gutu et al.
                </div>

                <div class="paper-summary">
                    TransientTrack is a novel deep learning-based framework designed for multi-object tracking and classification of cancer cells in multi-channel microscopy videos, specifically addressing the challenge of transient fluorescent signals. It accurately identifies pivotal cellular events like mitosis and apoptosis to build complete cell trajectories and lineage information, demonstrating its utility in analyzing chemotherapeutic drug efficacy at a single-cell level.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cell Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01885v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01885v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01885v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01885v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01834v1"
                     data-domains="Psychiatry,Mental health,Clinical psychology,Digital health,Public health,Medical diagnostics"
                     data-keywords="Gender bias,Depression detection,Counterfactual inference,Causal inference,Acoustic features,Fairness in AI,Machine learning,Mental health"
                     data-authors="Mingxuan Hu,Hongbo Ma,Xinlan Wu,Ziqi Liu,Jiaqi Liu,Yangbin Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01834v1.html">Mitigating Gender Bias in Depression Detection via Counterfactual Inference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingxuan Hu, Hongbo Ma, Xinlan Wu et al.
                </div>

                <div class="paper-summary">
                    This paper addresses gender bias in audio-based depression detection models, which over-diagnose females and underperform on males due to imbalanced training data and spurious correlations. The authors propose a Counterfactual Debiasing Framework grounded in causal inference to model and subtract the direct causal effect of gender on predictions. Extensive experiments on the DAIC-WOZ dataset demonstrate that their framework significantly reduces gender bias while also improving overall detection performance compared to existing debiasing strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental health</span>
                    
                    <span class="domain-tag">Clinical psychology</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01834v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01834v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01834v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01834v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01771v1"
                     data-domains="Radiology,Oncology,Neurology,Image-guided surgery,Diagnostic imaging,Treatment planning"
                     data-keywords="medical image registration,rigid registration,non-rigid registration,learnable kernels,edge detection,deep learning,multi-modal imaging,anatomical analysis"
                     data-authors="Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01771v1.html">Robust Rigid and Non-Rigid Medical Image Registration Using Learnable Edge Kernels</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ahsan Raza Siyal, Markus Haltmeier, Ruth Steiger et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel approach for robust rigid and non-rigid medical image registration by integrating learnable edge kernels into learning-based techniques. The method adaptively optimizes edge features from perturbed predefined kernels, enabling superior capture of diverse structural information. Across extensive evaluations on various datasets and setups, it consistently outperformed state-of-the-art methods, signifying significant advancements in multi-modal image alignment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Image-guided surgery</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01771v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01771v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01771v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01771v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01769v1"
                     data-domains="Geriatrics,Assisted Living Facilities,Remote Patient Monitoring,Rehabilitation,Patient Safety,Elderly Care,Telemedicine"
                     data-keywords="Video Situation Analysis,Assisted Living,Continuous Query Processing,Relational Model,Graph Models,Domain-Independent Framework,Activity Recognition,Patient Monitoring"
                     data-authors="Hafsa Billah">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01769v1.html">VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hafsa Billah
                </div>

                <div class="paper-summary">
                    The paper introduces VideoScoop, a general-purpose, domain-independent framework for Video Situation Analysis (VSA) designed to overcome limitations of manual or custom video analysis methods. It employs a hybrid approach using extended relational (R++) and graph models to process extracted video content, enabling continuous query processing and robust detection of complex, meaningful situations across diverse domains, including Assisted Living, Civic Monitoring, and Surveillance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Assisted Living Facilities</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01702v1"
                     data-domains="Cardiology,Electrophysiology,Computational Medicine,Personalized Medicine,Medical Imaging"
                     data-keywords="cardiac electrophysiology,arrhythmias,local activation time (LAT),operator learning,neural operator,vision transformer,geometry-independent,real-time simulation,atrial fibrillation,personalized medicine"
                     data-authors="Bei Zhou,Cesare Corrado,Shuang Qian,Maximilian Balmus,Angela W. C. Lee,Cristobal Rodero,Marco J. W. Gotte,Luuk H. G. A. Hopman,Mengyun Qiao,Steven Niederer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01702v1.html">A unified framework for geometry-independent operator learning in cardiac electrophysiology simulations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bei Zhou, Cesare Corrado, Shuang Qian et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel geometry-independent operator-learning framework that uses a neural operator with a vision-transformer backbone to predict local activation time (LAT) fields in cardiac electrophysiology. It achieves a high accuracy (5.1 ms mean error) and near-instantaneous inference (0.12 ms/sample) across diverse left atrial anatomies, outperforming established methods. The framework decouples electrophysiological patterns from mesh topology using a Universal Atrium Coordinate system, enabling real-time and population-scale computational electrophysiology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01702v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01702v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01702v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01702v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01681v1"
                     data-domains="Oncology,Pathology,Thoracic Medicine,Medical AI,Prognostics"
                     data-keywords="mesothelioma,computational pathology,self-supervised learning,biopsy analysis,resection validation,survival prediction,subtype classification,AI in pathology"
                     data-authors="Farzaneh Seyedshahi,Francesca Damiola,Sylvie Lantuejoul,Ke Yuan,John Le Quesne">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01681v1.html">Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Farzaneh Seyedshahi, Francesca Damiola, Sylvie Lantuejoul et al.
                </div>

                <div class="paper-summary">
                    This research demonstrates a cross-domain validation approach where a self-supervised encoder, initially trained on large resection tissue images, effectively extracts meaningful morphological patterns from smaller mesothelioma biopsy material. This model successfully leverages these patterns to accurately predict patient survival and classify tumor subtypes, addressing a significant limitation of traditional computational pathology models in real-world clinical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Thoracic Medicine</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01681v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01681v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01681v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01681v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01675v1"
                     data-domains="Radiology,Medical Diagnostics,AI in Healthcare,Medical Image Analysis"
                     data-keywords="Diffusion Models,Long-tail Learning,Medical Imaging,Data Augmentation,Residual Adapters,Mode Collapse,Rare Pathologies,Generative AI"
                     data-authors="Felix N√ºtzel,Mischa Dombrowski,Bernhard Kainz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01675v1.html">GRASP: Guided Residual Adapters with Sample-wise Partitioning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Felix N√ºtzel, Mischa Dombrowski, Bernhard Kainz
                </div>

                <div class="paper-summary">
                    This paper introduces GRASP, a novel method addressing mode collapse in text-to-image diffusion models when generating images for rare medical pathologies, a prevalent issue in long-tail datasets. GRASP mitigates gradient conflicts between frequent and rare classes by partitioning samples into clusters and injecting cluster-specific residual adapters, leading to significantly improved generation quality and diversity for rare conditions and enhanced downstream classification performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01657v1"
                     data-domains="Ophthalmology,Diabetology,Cardiology,Neurology,Diagnostic Imaging"
                     data-keywords="Retinal Vessel Segmentation,Deep Learning,UNet,CNN-Transformer Hybrid,Kolmogorov-Arnold Network (KAN),Medical Image Analysis,Ophthalmology,Adaptive Fusion"
                     data-authors="Hongyu Xu,Panpan Meng,Meng Wang,Dayu Hu,Liming Liang,Xiaoqi Sheng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01657v1.html">DB-KAUNet: An Adaptive Dual Branch Kolmogorov-Arnold UNet for Retinal Vessel Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hongyu Xu, Panpan Meng, Meng Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DB-KAUNet, an Adaptive Dual Branch Kolmogorov-Arnold UNet, designed for precise retinal vessel segmentation. It addresses the limitations of traditional CNNs in capturing long-range dependencies and complex nonlinear relationships by employing a heterogeneous dual-branch encoder, enhanced with novel interaction and adaptive fusion modules, thereby achieving state-of-the-art performance and robustness across benchmark datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01657v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01657v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01657v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01657v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01653v1"
                     data-domains="Cardiology,Preventive Medicine,Remote Patient Monitoring,Digital Health,Critical Care"
                     data-keywords="Cuffless Blood Pressure,Wearable Sensors,Multi-modal Sensing,Photoplethysmography (PPG),Electrocardiography (ECG),Motion Artifacts,Hypertension,Mixture-of-Experts"
                     data-authors="Yiqiao Chen,Fazheng Xu,Zijian Huang,Juchi He,Zhenghui Feng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01653v1.html">Cuffless Blood Pressure Estimation from Six Wearable Sensor Modalities in Multi-Motion-State Scenarios</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiqiao Chen, Fazheng Xu, Zijian Huang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel six-modal cuffless blood pressure (BP) estimation framework designed for robust accuracy across various motion states, addressing the limitations of existing PPG/ECG-based methods under dynamic conditions. By integrating diverse wearable sensor data and advanced machine learning techniques, the proposed system achieves high clinical-grade accuracy for SBP and DBP in multi-motion scenarios. This significantly advances continuous, non-invasive BP monitoring for early screening and long-term management of hypertension.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01653v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01653v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01653v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01653v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01589v1"
                     data-domains="Otolaryngology (ENT),Radiology,Infectious Diseases,Emergency Medicine,Critical Care Medicine,Head and Neck Surgery"
                     data-keywords="Head and Neck Abscesses,CT Segmentation,Medical Imaging,Deep Learning,AbscessHeNe Dataset,Semantic Segmentation,Content-based Retrieval,Contrast-enhanced CT"
                     data-authors="Thao Thi Phuong Dao,Tan-Cong Nguyen,Trong-Le Do,Truong Hoang Viet,Nguyen Chi Thanh,Huynh Nguyen Thuan,Do Vo Cong Nguyen,Minh-Khoi Pham,Mai-Khiem Tran,Viet-Tham Huynh,Trong-Thuan Nguyen,Trung-Nghia Le,Vo Thanh Toan,Tam V. Nguyen,Minh-Triet Tran,Thanh Dinh Le">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01589v1.html">Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thao Thi Phuong Dao, Tan-Cong Nguyen, Trong-Le Do et al.
                </div>

                <div class="paper-summary">
                    This study introduces AbscessHeNe, a new publicly available dataset of 4,926 contrast-enhanced CT slices with comprehensively annotated head and neck abscesses, designed to advance semantic segmentation and content-based image retrieval in this critical medical domain. Baseline evaluations of state-of-the-art deep learning models (CNN, Transformer, Mamba-based) reveal significant challenges in accurately segmenting these lesions, with the best model achieving a Dice Similarity Coefficient of only 0.39.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Otolaryngology (ENT)</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01589v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01589v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01589v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01589v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01534v1"
                     data-domains="Neurology,Radiology,Neuroradiology,Medical Imaging,AI in Medicine"
                     data-keywords="brain imaging,unsupervised anomaly detection,MRI,deep learning,benchmarking,bias analysis,clinical translation,neuroradiology"
                     data-authors="Alexander Frotscher,Christian F. Baumgartner,Thomas Wolfers">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01534v1.html">Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alexander Frotscher, Christian F. Baumgartner, Thomas Wolfers
                </div>

                <div class="paper-summary">
                    This paper presents a comprehensive, large-scale, multi-center benchmark for deep unsupervised anomaly detection in brain MRI to assess its clinical readiness. It evaluates various algorithms on diverse datasets, revealing substantial performance variability and pervasive systematic biases related to scanners, lesion characteristics, age, and sex. The study concludes that current frameworks are limited by algorithmic capabilities rather than data availability, providing a critical foundation for future research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01534v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01534v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01534v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01534v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01510v1"
                     data-domains="abdominal imaging,cardiac imaging,prostate imaging,oncology,radiology"
                     data-keywords="domain generalization,medical image segmentation,semantic-aware random convolution,source matching,cross-modality,cross-center,deep learning,CT,MR"
                     data-authors="Franz Thaler,Martin Urschler,Mateusz Kozinski,Matthias AF Gsell,Gernot Plank,Darko Stern">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01510v1.html">Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Franz Thaler, Martin Urschler, Mateusz Kozinski et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SRCSM, a novel method addressing single-source domain generalization for medical image segmentation, enabling a model trained on one domain (e.g., CT) to directly segment images from a different domain (e.g., MR) without adaptation. SRCSM achieves this by combining semantic-aware random convolution during training with test-time intensity source matching, establishing a new state-of-the-art and often matching in-domain performance across various challenging cross-modality and cross-center scenarios.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">abdominal imaging</span>
                    
                    <span class="domain-tag">cardiac imaging</span>
                    
                    <span class="domain-tag">prostate imaging</span>
                    
                    <span class="domain-tag">oncology</span>
                    
                    <span class="domain-tag">radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01510v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01510v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01510v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01510v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01498v1"
                     data-domains="Radiology,Pathology,Diagnostic Imaging,Clinical Decision Support,Medical Device Security,Precision Medicine"
                     data-keywords="Machine Learning,Deep Learning,Anomaly Detection,Zero-Shot Learning,Image Retrieval,Model Security,Backdoor Detection,Healthcare AI"
                     data-authors="Ali Nafisi,Sina Asghari,Mohammad Saeed Arvenaghi,Hossein Shakibania">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01498v1.html">Winning Solutions for the Rayan AI Contest: Compositional Retrieval, Zero-Shot Anomaly Detection, and Backdoor Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ali Nafisi, Sina Asghari, Mohammad Saeed Arvenaghi et al.
                </div>

                <div class="paper-summary">
                    This report details winning solutions for three machine learning challenges: compositional image retrieval, zero-shot anomaly detection, and backdoored model detection. The authors achieved first place in compositional retrieval (95.38% accuracy) and zero-shot anomaly detection (73.14% accuracy), and second place in backdoor detection (78% accuracy). These methods demonstrate significant advancements in multimodal retrieval, novel abnormality identification, and AI model security, holding strong implications for various real-world applications including healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Device Security</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01497v1"
                     data-domains="epidemiology,systems biology,drug discovery,genomics,infectious disease modeling,pharmacology"
                     data-keywords="critical node detection,stochastic networks,heuristic algorithms,machine learning,epidemic control,biological networks,network vulnerability,graph theory"
                     data-authors="Tuguldur Bayarsaikhan,Altannar Chinchuluun,Ashwin Arulselvan,Panos Pardalos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01497v1.html">Heuristic algorithms for the stochastic critical node detection problem</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.DM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tuguldur Bayarsaikhan, Altannar Chinchuluun, Ashwin Arulselvan et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the stochastic critical node detection problem, identifying a subset of nodes whose probabilistic removal most effectively disrupts network connectivity. The authors propose and evaluate novel heuristic and learning-based algorithms, demonstrating their effectiveness and scalability compared to existing methods. The research provides robust computational tools for assessing network vulnerability in systems where edge existence is uncertain.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">epidemiology</span>
                    
                    <span class="domain-tag">systems biology</span>
                    
                    <span class="domain-tag">drug discovery</span>
                    
                    <span class="domain-tag">genomics</span>
                    
                    <span class="domain-tag">infectious disease modeling</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01497v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01497v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01497v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01497v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01462v1"
                     data-domains="cellular regulation,disease epidemiology,pharmacology,systems biology,infectious diseases,public health"
                     data-keywords="robustness,resilience,dynamical networks,epidemiology,bifurcation analysis,stochastic perturbations,attractors,tipping points"
                     data-authors="Daniele Proverbio,Rami Katz,Giulia Giordano">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01462v1.html">Robustness and resilience of dynamical networks in biology and epidemiology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ math-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniele Proverbio, Rami Katz, Giulia Giordano
                </div>

                <div class="paper-summary">
                    This survey paper elucidates the concepts of robustness and resilience in complex dynamical networks pertinent to biology and epidemiology. It reviews diverse definitions, presents methods for assessing structural and robust properties, and introduces novel formal probabilistic definitions of resilience to characterize system behavior under stochastic perturbations, also summarizing tools for detecting resilience loss and anticipating regime shifts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cellular regulation</span>
                    
                    <span class="domain-tag">disease epidemiology</span>
                    
                    <span class="domain-tag">pharmacology</span>
                    
                    <span class="domain-tag">systems biology</span>
                    
                    <span class="domain-tag">infectious diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01462v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01462v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01462v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01462v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01453v1"
                     data-domains="q-bio.OT"
                     data-keywords="q-bio.OT"
                     data-authors="Xiaoquan Zhi,Hongke Zhao,Likang Wu,Chuang Zhao,Hengshu Zhu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01453v1.html">Reinventing Clinical Dialogue: Agentic Paradigms for LLM Enabled Healthcare Communication</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoquan Zhi, Hongke Zhao, Likang Wu et al.
                </div>

                <div class="paper-summary">
                    Clinical dialogue represents a complex duality requiring both the empathetic fluency of natural conversation and the rigorous precision of evidence-based medicine. While Large Language Models possess unprecedented linguistic capabilities, their architectural reliance on reactive and stateless proces...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.OT</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01453v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01453v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01453v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01453v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01417v1"
                     data-domains="Hematology,Diagnostics,Cellular Biophysics,Microcirculation Disorders,Inherited Red Cell Disorders,Metabolic Disorders (e.g., Diabetes),Infectious Diseases (e.g., Malaria)"
                     data-keywords="red blood cells,optical tweezers,membrane flickering,active mechanics,biomechanical dysfunction,cellular physiology,energy dissipation,non-invasive"
                     data-authors="Arnau Dorn,Clara Luque-Rioja,Macarena Calero,Diego Herr√°ez-Aguilar,Francisco Monroy,Niccol√≤ Caselli">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01417v1.html">Active Force Dynamics in Red Blood Cells Under Non-Invasive Optical Tweezers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ physics.bio-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Arnau Dorn, Clara Luque-Rioja, Macarena Calero et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, minimally invasive optical tweezers method combined with high-speed video microscopy to simultaneously quantify local membrane forces and displacements in single red blood cells. This technique allowed for the creation of a mechano-dynamic phase space, successfully differentiating metabolic and structural states based on unique fluctuation-force signatures. Key findings include that membrane softening enhances fluctuations while elevating energy dissipation, offering a robust framework for mapping active cellular mechanics and detecting biomechanical dysfunction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Hematology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Cellular Biophysics</span>
                    
                    <span class="domain-tag">Microcirculation Disorders</span>
                    
                    <span class="domain-tag">Inherited Red Cell Disorders</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01417v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01417v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01417v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01417v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01412v1"
                     data-domains="critical care,chronic disease management,patient monitoring,epidemiology,precision medicine,pharmacovigilance,neurology (EEG/fMRI time series),cardiology (ECG time series)"
                     data-keywords="explainable AI,time series analysis,causal inference,deep learning,attention mechanisms,temporal patterns,healthcare AI,prognostics"
                     data-authors="Ziqian Wang,Yuxiao Cheng,Jinli Suo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01412v1.html">A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziqian Wang, Yuxiao Cheng, Jinli Suo
                </div>

                <div class="paper-summary">
                    This paper introduces EXCAP, a novel self-explainable AI framework designed for modeling long time series, which addresses limitations of existing methods by generating pattern-centric, causally disentangled explanations. EXCAP combines an attention-based segmenter, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism to provide robust and coherent temporal explanations. The framework achieves strong predictive accuracy in classification and forecasting while delivering interpretable insights, making it highly relevant for high-stakes domains like healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">critical care</span>
                    
                    <span class="domain-tag">chronic disease management</span>
                    
                    <span class="domain-tag">patient monitoring</span>
                    
                    <span class="domain-tag">epidemiology</span>
                    
                    <span class="domain-tag">precision medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01412v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01412v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01412v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01412v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01367v1"
                     data-domains="Neurology,Geriatrics,Dementia Research,Cognitive Neuroscience,Digital Health,Clinical Psychology"
                     data-keywords="Alzheimer's Disease,Cube Copying Test,Dynamic Handwriting,Visual Spatial Cognition,BiLSTM-Attention,Early Detection,Cognitive Assessment,Machine Learning"
                     data-authors="Xinyu Jiang,Cuiyun Gao,Wenda Huang,Yiyang Jiang,Binwen Luo,Yuxin Jiang,Mengting Wang,Haoran Wen,Yang Zhao,Xuemei Chen,Songqun Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01367v1.html">A Fine Evaluation Method for Cube Copying Test for Early Detection of Alzheimer's Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinyu Jiang, Cuiyun Gao, Wenda Huang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel fine evaluation method for the Cube Copying Test (CCT) to improve early detection of Alzheimer's Disease (AD) by addressing the limitations of traditional binary scoring. Utilizing dynamic handwriting analysis and a BiLSTM-Attention neural network, the method achieves 86.69% accuracy in classifying cognitive impairment, revealing nuanced correlations between drawing ability scores, age, and education levels. This provides a more objective and comprehensive tool for early screening and personalized intervention for visual spatial cognitive impairment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Dementia Research</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01367v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01367v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01367v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01367v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01333v1"
                     data-domains="Cardiology,Neurology,Preventive Medicine,Public Health,Internal Medicine"
                     data-keywords="Stroke prediction,Machine learning,Ensemble learning,Explainable AI (XAI),Random Over-Sampling (ROS),LIME,Cardiovascular risk,Preventive medicine"
                     data-authors="A S M Ahsanul Sarkar Akib,Raduana Khawla,Abdul Hasib">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01333v1.html">Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> A S M Ahsanul Sarkar Akib, Raduana Khawla, Abdul Hasib
                </div>

                <div class="paper-summary">
                    This paper presents an interpretable machine learning framework for stroke risk prediction, combining ROS-balanced ensembles and Explainable AI (XAI) techniques. Their optimized ensemble model, comprising Random Forest, ExtraTrees, and XGBoost, achieved an exceptional 99.09% accuracy on the Stroke Prediction Dataset. The framework also identified crucial clinical variables like age, hypertension, and glucose levels using LIME, enhancing transparency for personalized preventative strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01320v1"
                     data-domains="Personalized medicine,Precision medicine,Sports medicine,Clinical diagnostics,Physiology,Biomedical engineering"
                     data-keywords="Wearable sensors,Sweat monitoring,Biomarkers,Biosensors,Signal processing,Analog circuitry,Personalized health,Precision medicine"
                     data-authors="Yuhan Zheng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01320v1.html">A Review of Wearable Sweat Monitoring Platforms: From Biomarker Detection to Signal Processing Systems</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhan Zheng
                </div>

                <div class="paper-summary">
                    This review provides a comprehensive analysis of wearable sweat monitoring platforms, detailing advancements in biomarker detection and signal processing systems. It highlights sweat's potential for personalized health and precision medicine due to its noninvasive nature, while also addressing critical challenges such as the lack of clinically validated standards and the need to establish reliable correlations between sweat and blood analytes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Precision medicine</span>
                    
                    <span class="domain-tag">Sports medicine</span>
                    
                    <span class="domain-tag">Clinical diagnostics</span>
                    
                    <span class="domain-tag">Physiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01320v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01320v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01320v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01320v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01319v1"
                     data-domains="Neurosurgery,Neuroradiology,Neuroscience,Vascular Medicine,Biomedical Engineering"
                     data-keywords="Intracranial Aneurysm,Vessel Segmentation,Computational Fluid Dynamics (CFD),Hemodynamics,Medical Imaging,Magnetic Resonance Angiography (MRA),Deep Learning,Medical Dataset"
                     data-authors="Feiyang Xiao,Yichi Zhang,Xigui Li,Yuanye Zhou,Chen Jiang,Xin Guo,Limei Han,Yuxin Li,Fengping Zhu,Yuan Cheng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01319v1.html">Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Feiyang Xiao, Yichi Zhang, Xigui Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, a comprehensive multi-center collection of 3D MRA images with IA-Vessel annotations and detailed hemodynamic analysis outcomes. It addresses the critical gap where current segmentation methods often neglect their practical effectiveness in subsequent Computational Fluid Dynamics (CFD) applications, by establishing new benchmarks and a standardized CFD applicability evaluation system.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Vascular Medicine</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01319v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01319v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01319v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01319v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01310v1"
                     data-domains="Neurology,Radiology,Geriatrics,Neuroinformatics,Medical Imaging,AI in Medicine"
                     data-keywords="Brain imaging,Neuroimaging,Pretraining,Foundation models,Data quality,Brain age prediction,Domain gap,Data curation"
                     data-authors="Yanteng Zhang,Songheng Li,Zeyu Shen,Qizhen Lan,Lipei Zhang,Yang Liu,Vince Calhoun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01310v1.html">Lost in Distortion: Uncovering the Domain Gap Between Computer Vision and Brain Imaging - A Study on Pretraining for Age Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yanteng Zhang, Songheng Li, Zeyu Shen et al.
                </div>

                <div class="paper-summary">
                    This paper investigates how the quality heterogeneity in large-scale brain imaging datasets impacts pretraining for domain foundation models. By pretraining models on datasets with varying quality levels and fine-tuning for brain age prediction, the study reveals significant performance differences, highlighting the critical need for domain-aware data curation in neuroimaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neuroinformatics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01310v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01310v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01310v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01310v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01292v1"
                     data-domains="dermatology (skin lesions),gastroenterology (polyps),pulmonology/radiology (lung nodules)"
                     data-keywords="medical image segmentation,diffusion model,latent space,variational autoencoder (VAE),uncertainty quantification,generative models,skin lesions,lung nodules"
                     data-authors="Huynh Trinh Ngoc,Toan Nguyen Hai,Ba Luong Son,Long Tran Quoc">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01292v1.html">Diffusion Model in Latent Space for Medical Image Segmentation Task</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huynh Trinh Ngoc, Toan Nguyen Hai, Ba Luong Son et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedSegLatDiff, a novel diffusion-based framework that addresses the computational heaviness of generative models for medical image segmentation while enabling the generation of multiple plausible segmentation masks and capturing inherent uncertainty. By combining a Variational Autoencoder (VAE) with a latent diffusion model, the framework operates efficiently in a low-dimensional latent space and achieves state-of-the-art or highly competitive performance on diverse medical image datasets, providing enhanced interpretability and reliability for clinical use.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">dermatology (skin lesions)</span>
                    
                    <span class="domain-tag">gastroenterology (polyps)</span>
                    
                    <span class="domain-tag">pulmonology/radiology (lung nodules)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01292v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01292v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01292v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01292v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01273v1"
                     data-domains="Ophthalmology,Diabetology (Diabetic Retinopathy Screening),Cardiology (Hypertensive Retinopathy),Neurology (Stroke Risk Assessment),Preventive Medicine"
                     data-keywords="retinal imaging,deep learning,convolutional neural networks,transformers,hybrid networks,nnMobileNet,ocular diseases,systemic diseases,fundus images,classification,computational efficiency,lesion detection"
                     data-authors="Xin Li,Wenhui Zhu,Xuanzhao Dong,Hao Wang,Yujian Xiong,Oana Dumitrascu,Yalin Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01273v1.html">nnMobileNet++: Towards Efficient Hybrid Networks for Retinal Image Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Li, Wenhui Zhu, Xuanzhao Dong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces nnMobileNet++, a novel hybrid deep learning architecture combining convolutional and transformer networks for efficient and accurate retinal image analysis. The framework integrates dynamic snake convolution, stage-specific transformer blocks, and retinal image pretraining to overcome limitations of purely convolutional networks in capturing complex retinal patterns. Experiments demonstrate that nnMobileNet++ achieves state-of-the-art or competitive accuracy on multiple retinal classification tasks while maintaining low computational cost.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diabetology (Diabetic Retinopathy Screening)</span>
                    
                    <span class="domain-tag">Cardiology (Hypertensive Retinopathy)</span>
                    
                    <span class="domain-tag">Neurology (Stroke Risk Assessment)</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01273v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01273v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01273v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01273v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01241v1"
                     data-domains="Primary Care,Specialist Consultations,Various Medical Specialties (10 covered)"
                     data-keywords="Large Language Models (LLMs),Clinical Safety,Medical AI,Harm Assessment,NOHARM Benchmark,Medical Recommendations,Harms of Omission,AI Evaluation"
                     data-authors="David Wu,Fateme Nateghi Haredasht,Saloni Kumar Maharaj,Priyank Jain,Jessica Tran,Matthew Gwiazdon,Arjun Rustagi,Jenelle Jindal,Jacob M. Koshy,Vinay Kadiyala,Anup Agarwal,Bassman Tappuni,Brianna French,Sirus Jesudasen,Christopher V. Cosgriff,Rebanta Chakraborty,Jillian Caldwell,Susan Ziolkowski,David J. Iberri,Robert Diep,Rahul S. Dalal,Kira L. Newman,Kristin Galetta,J. Carl Pallais,Nancy Wei,Kathleen M. Buchheit,David I. Hong,Ernest Y. Lee,Allen Shih,Vartan Pahalyants,Tamara B. Kaplan,Vishnu Ravi,Sarita Khemani,April S. Liang,Daniel Shirvani,Advait Patil,Nicholas Marshall,Kanav Chopra,Joel Koh,Adi Badhwar,Liam G. McCoy,David J. H. Wu,Yingjie Weng,Sumant Ranji,Kevin Schulman,Nigam H. Shah,Jason Hom,Arnold Milstein,Adam Rodman,Jonathan H. Chen,Ethan Goh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01241v1.html">First, do NOHARM: towards clinically safe large language models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CY</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> David Wu, Fateme Nateghi Haredasht, Saloni Kumar Maharaj et al.
                </div>

                <div class="paper-summary">
                    This paper introduces NOHARM, a novel benchmark evaluating the clinical safety of 31 large language models (LLMs) using 100 real primary-care-to-specialist consultation cases. It reveals that LLMs can generate severely harmful medical recommendations in up to 22.2% of cases, primarily due to errors of omission. The study emphasizes that clinical safety is a distinct performance metric, poorly correlated with existing benchmarks, and highlights the potential of multi-agent approaches for enhanced safety.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Specialist Consultations</span>
                    
                    <span class="domain-tag">Various Medical Specialties (10 covered)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01241v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01241v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01241v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01241v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01210v1"
                     data-domains="Clinical Prediction,Medical Informatics,Diagnostic Support,Personalized Medicine"
                     data-keywords="Knowledge Graph,Large Language Models,Disease Prediction,Chain-of-Thought,Explainable AI,Electronic Health Records,Clinical Decision Support,MIMIC-III"
                     data-authors="Ruiyu Wang,Tuan Vinh,Ran Xu,Yuyin Zhou,Jiaying Lu,Carl Yang,Francisco Pasquel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01210v1.html">Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruiyu Wang, Tuan Vinh, Ran Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel knowledge graph (KG)-guided Chain-of-Thought (CoT) framework that augments Large Language Models (LLMs) to generate clinically grounded and temporally consistent reasoning for next-visit disease prediction using Electronic Health Records (EHRs). By integrating PrimeKG with lightweight LLMs, the models not only achieve superior predictive performance compared to classical baselines but also provide interpretable explanations preferred by clinicians, enhancing the utility of AI in patient-level decision making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Prediction</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Diagnostic Support</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01210v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01210v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01210v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01210v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01198v1"
                     data-domains="Traditional Chinese Medicine,Medical History,Cross-cultural Medicine"
                     data-keywords="Traditional Chinese Medicine,TCM translation,Imagistic Thinking,Prompt Engineering,Large Language Models (LLMs),Metaphor,Metonymy,Huangdi Neijing"
                     data-authors="Jiatong Han">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01198v1.html">Conveying Imagistic Thinking in Traditional Chinese Medicine Translation: A Prompt Engineering and LLM-Based Evaluation Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiatong Han
                </div>

                <div class="paper-summary">
                    This study addresses the challenge of translating Traditional Chinese Medicine (TCM) theories, which are based on imagistic thinking (metaphor and metonymy), into English without losing their underlying conceptual networks crucial for clinical application. Utilizing a human-in-the-loop framework and prompt engineering with DeepSeek V3.1, the research developed prompt-adjusted LLM translations that significantly outperformed human and baseline machine translations across five cognitive dimensions, as evaluated by simulated readers powered by ChatGPT 5 Pro and Gemini 2.5 Pro.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Traditional Chinese Medicine</span>
                    
                    <span class="domain-tag">Medical History</span>
                    
                    <span class="domain-tag">Cross-cultural Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01198v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01198v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01198v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01198v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01191v1"
                     data-domains="General Medicine,Clinical Decision Support,Medical Informatics,Diagnosis,Triage,Guideline Interpretation"
                     data-keywords="Large Language Models (LLMs),Clinical AI Tools,Medical Benchmarks,Clinical Decision Support,AI Evaluation,Patient Safety,Medical Knowledge,GPT-5"
                     data-authors="Krithik Vishwanath,Mrigayu Ghosh,Anton Alyakin,Daniel Alexander Alber,Yindalon Aphinyanaphongs,Eric Karl Oermann">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01191v1.html">Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-01</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Krithik Vishwanath, Mrigayu Ghosh, Anton Alyakin et al.
                </div>

                <div class="paper-summary">
                    This paper reveals that state-of-the-art generalist Large Language Models (LLMs) consistently outperform specialized clinical AI tools on medical benchmarks, challenging the perception that specialized tools are inherently safer or more reliable. Using a 1,000-item mini-benchmark, generalist models, with GPT-5 leading, demonstrated superior performance compared to OpenEvidence and UpToDate Expert AI, which showed deficits in completeness, communication, context awareness, and safety reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Diagnosis</span>
                    
                    <span class="domain-tag">Triage</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01191v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01191v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01191v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01191v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01116v1"
                     data-domains="Oncology,Pathology,Computational Biology,Precision Medicine,Bioinformatics"
                     data-keywords="Cancer survival prediction,Multimodal analysis,Histology images,Gene profiles,Slot attention,Prognostic events,Oncology,Machine learning"
                     data-authors="Yilan Zhang,Li Nanbo,Changchun Yang,J√ºrgen Schmidhuber,Xin Gao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01116v1.html">Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yilan Zhang, Li Nanbo, Changchun Yang et al.
                </div>

                <div class="paper-summary">
                    The paper introduces SlotSPE, a novel slot-based framework leveraging slot attention and factorial coding to effectively model structural prognostic events from multimodal cancer data (histology images and gene profiles). By compressing complex inputs into compact, distinctive slots, SlotSPE significantly enhances intra- and inter-modal interaction modeling, leading to superior survival prediction, robustness to missing data, and improved interpretability across ten cancer benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01116v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01116v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01116v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01116v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01085v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Informatics,Medical Education"
                     data-keywords="Medical Phrase Grounding,Radiological Reports,Deep Learning,Computer Vision,Natural Language Processing,Image-Text Alignment,Multi-region Grounding,Zero-shot Learning"
                     data-authors="Wenjun Zhang,Shekhar S. Chandra,Aaron Nicolson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01085v1.html">Generalized Medical Phrase Grounding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenjun Zhang, Shekhar S. Chandra, Aaron Nicolson
                </div>

                <div class="paper-summary">
                    This paper introduces Generalized Medical Phrase Grounding (GMPG) to overcome limitations of traditional Medical Phrase Grounding (MPG) systems, which struggle with multi-region findings, non-diagnostic text, and non-groundable phrases in radiological reports. Their novel model, MedGrounder, maps report sentences to zero, one, or multiple scored image regions, demonstrating superior performance on complex phrases with significantly fewer human annotations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01085v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01085v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01085v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01085v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01080v1"
                     data-domains="Drug Discovery,Precision Medicine,Diagnostic Imaging,Clinical Decision Support Systems,Medical Device Design,Public Health Analytics,Pharmacovigilance"
                     data-keywords="Trustworthy AI,AI Ethics,Machine Learning,Healthcare AI,Fairness,Interpretability,Uncertainty Quantification,Human-in-the-loop"
                     data-authors="Benhour Amirian,Ashley S. Dale,Sergei Kalinin,Jason Hattrick-Simpers">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01080v1.html">Building Trustworthy AI for Materials Discovery: From Autonomous Laboratories to Z-scores</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cond-mat.mtrl-sci</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Benhour Amirian, Ashley S. Dale, Sergei Kalinin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the GIFTERS framework (Generalizable, Interpretable, Fair, Transparent, Explainable, Robust, Stable) for evaluating Trustworthy AI (TAI) in materials discovery, highlighting its broader applicability. A literature review in materials science revealed a median GIFTERS score of 5/7, indicating a significant lack of comprehensive trustworthiness reporting, with specific omissions in fairness for Bayesian studies and interpretability for non-Bayesian methods, emphasizing the need for human-in-the-loop and integrated approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Device Design</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01080v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01080v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01080v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01080v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01074v1"
                     data-domains="Public Health,Epidemiology,Infectious Disease Management,Health Policy,Biostatistics"
                     data-keywords="COVID-19 forecasting,wastewater surveillance,epidemic modeling,n-sub-epidemic framework,ARIMA,GAM,public health,retrospective study"
                     data-authors="Faharudeen Alhassan,Hamed Karami,Amanda Bleichrodt,James M. Hyman,Isaac C. H. Fung,Ruiyan Luo,Gerardo Chowell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01074v1.html">COVID-19 Forecasting from U.S. Wastewater Surveillance Data: A Retrospective Multi-Model Study (2022-2024)</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Faharudeen Alhassan, Hamed Karami, Amanda Bleichrodt et al.
                </div>

                <div class="paper-summary">
                    This retrospective multi-model study evaluated 11 different forecasting models using U.S. COVID-19 wastewater surveillance data from March 2022 to September 2024 across national and regional levels. It identified that n-sub-epidemic unweighted ensembles excelled at 3-4-week forecasting horizons, particularly nationally and in the Midwest and West, while ARIMA and GAM performed best for shorter 1-2-week forecasts. The research highlights the critical need for region-specific modeling strategies to optimize public health responses during pandemics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Disease Management</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01074v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01074v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01074v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01074v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01062v1"
                     data-domains="Disaster Preparedness and Response,Public Health Epidemiology,Environmental Health,Global Health Equity,Emergency Medicine,Infectious Disease Control"
                     data-keywords="precipitation nowcasting,physics-informed neural networks,neural operators,advection-diffusion,satellite imagery,generative models,early warning systems,climate change adaptation"
                     data-authors="Seokhyun Chin,Junghwan Park,Woojin Cho">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01062v1.html">PIANO: Physics-informed Dual Neural Operator for Precipitation Nowcasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Seokhyun Chin, Junghwan Park, Woojin Cho
                </div>

                <div class="paper-summary">
                    This paper introduces PIANO, a novel physics-informed dual neural operator, designed to improve precipitation nowcasting by integrating fundamental advection-diffusion physics into a deep learning framework. By leveraging satellite imagery and a generative model to produce radar images, PIANO achieves superior accuracy in predicting moderate and short-term heavy precipitation events with robust generalization across seasons, addressing the limitations of computationally expensive traditional methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Disaster Preparedness and Response</span>
                    
                    <span class="domain-tag">Public Health Epidemiology</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Global Health Equity</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01062v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01062v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01062v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01062v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.01037v1"
                     data-domains="Clinical Decision Support,Patient Education,Medical Informatics,Pharmacovigilance,Telemedicine,Mental Health Support"
                     data-keywords="LLM safety,semantic confusion,paraphrase consistency,false rejection,AI in healthcare,model auditing,natural language processing,refusal rates"
                     data-authors="Riad Ahmed Anonto,Md Labid Al Nahiyan,Md Tanvir Hassan,Ch. Md. Rakin Haider">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.01037v1.html">When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riad Ahmed Anonto, Md Labid Al Nahiyan, Md Tanvir Hassan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the concept of "semantic confusion" to measure local inconsistency in safety-aligned LLM refusals, where models accept one phrasing of an intent but reject close paraphrases. It proposes a framework with novel token-level metrics and a 10k-prompt corpus, ParaGuard, to reveal hidden structures of inconsistency that global false-rejection rates often mask, offering a practical signal for developers to enhance LLM safety alignments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.01037v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.01037v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.01037v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.01037v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00999v1"
                     data-domains="Diagnostic Imaging,Radiology,Clinical Diagnosis,AI in Healthcare,Medical Data Integrity"
                     data-keywords="Medical Image Reconstruction,Semantic AI,U-Net,Blockchain,Provenance,Image Restoration,Anatomical Fidelity,Diagnostic Confidence"
                     data-authors="Mohsin Rasheed,Abdullah Al-Mamun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00999v1.html">Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohsin Rasheed, Abdullah Al-Mamun
                </div>

                <div class="paper-summary">
                    This paper introduces a semantic-aware medical image reconstruction framework that utilizes high-level latent embeddings and a hybrid U-Net architecture to restore corrupted medical images while preserving clinically relevant anatomical structures. To ensure trust and accountability, it incorporates a lightweight blockchain-based provenance layer, enabling verifiable recording of each reconstruction event with minimal overhead. The solution significantly improves structural consistency, restoration accuracy, and provenance integrity, thereby advancing dependable AI for medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Clinical Diagnosis</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                    <span class="domain-tag">Medical Data Integrity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00999v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00999v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00999v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00999v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00989v1"
                     data-domains="Sleep Medicine,Cardiology,Pulmonology,Medical Devices,Digital Health"
                     data-keywords="sleep apnea,sleep disordered breathing,wearable device,Mamba deep learning,polysomnography,AHI,ECG,PPG,diagnosis,non-intrusive"
                     data-authors="Dominik Luszczynski,Richard Fei Yin,Nicholas Afonin,Andrew S. P. Lim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00989v1.html">Sleep Apnea Detection on a Wireless Multimodal Wearable Device Without Oxygen Flow Using a Mamba-based Deep Learning Approach</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dominik Luszczynski, Richard Fei Yin, Nicholas Afonin et al.
                </div>

                <div class="paper-summary">
                    This paper presents a Mamba-based deep learning model for accurately detecting sleep disordered breathing (SDB) using a non-intrusive, wireless wearable device, ANNE One, without requiring oxygen flow measurement. The model demonstrated a high correlation (R=0.95) with PSG-derived AHI and strong diagnostic performance at clinically relevant thresholds, along with good epoch-level event identification and promise for detailed event characterization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Devices</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00989v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00989v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00989v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00989v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00976v1"
                     data-domains="Cardiology,Medical Imaging,Diagnostic Medicine,Health Equity Research,Public Health"
                     data-keywords="Echocardiography,Machine Learning,Subgroup Validity,Health Equity,Demographic Bias,Deep Learning,Cardiac Ultrasound,Aortic Stenosis"
                     data-authors="Cynthia Feeney,Shane Williams,Benjamin S. Wessler,Michael C. Hughes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00976v1.html">Subgroup Validity in Machine Learning for Echocardiogram Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cynthia Feeney, Shane Williams, Benjamin S. Wessler et al.
                </div>

                <div class="paper-summary">
                    This paper reveals critical deficiencies in subgroup validity for machine learning models trained on open echocardiogram datasets. The authors demonstrate pervasive underreporting of patient demographics and insufficient representation of diverse groups, including a complete lack of gender-diverse patients, in current datasets. Through improved reporting and exploratory analysis of aortic stenosis models, they find insufficient evidence to support subgroup validity across sex, racial, and ethnic groups, highlighting a significant barrier to equitable AI deployment in cardiology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Health Equity Research</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00976v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00976v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00976v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00976v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00949v1"
                     data-domains="Oncology,Digital Health,Telemedicine,Palliative Care"
                     data-keywords="Multi-modal AI,Remote Patient Monitoring (RPM),Cancer Care,Adverse Events,Wearable Sensors,Machine Learning,Oncology,Predictive Analytics"
                     data-authors="Yansong Liu,Ronnie Stafford,Pramit Khetrapal,Huriye Kocadag,Gra√ßa Carvalho,Patricia de Winter,Maryam Imran,Amelia Snook,Adamos Hadjivasiliou,D. Vijay Anand,Weining Lin,John Kelly,Yukun Zhou,Ivana Drobnjak">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00949v1.html">Multi-Modal AI for Remote Patient Monitoring in Cancer Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yansong Liu, Ronnie Stafford, Pramit Khetrapal et al.
                </div>

                <div class="paper-summary">
                    This paper presents a multi-modal AI framework for remote patient monitoring (RPM) in cancer care, aiming to bridge the gap of unmonitored side effects between clinic visits. Developed and prospectively trialed on 84 patients, the system integrates diverse data from the HALO-X platform, achieving 83.9% accuracy (AUROC=0.70) in forecasting adverse events. The findings establish the feasibility of AI-powered RPM for proactive patient support in oncology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Palliative Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00949v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00949v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00949v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00949v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00919v1"
                     data-domains="Epidemiology,Health Outcomes Research,Drug Discovery,Clinical Trials,Public Health,Personalized Medicine,Health Policy"
                     data-keywords="Causal Inference,Instrumental Variables,Nonparametric Regression,Spectral Feature Learning,Hidden Confounders,Outcome-Aware,Machine Learning,Treatment Effects"
                     data-authors="Dimitri Meunier,Jakub Wornbard,Vladimir R. Kostic,Antoine Moulin,Alek Fr√∂hlich,Karim Lounici,Massimiliano Pontil,Arthur Gretton">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00919v1.html">Outcome-Aware Spectral Feature Learning for Instrumental Variable Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitri Meunier, Jakub Wornbard, Vladimir R. Kostic et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Augmented Spectral Feature Learning (ASFL), a novel framework for nonparametric instrumental variable (IV) regression that addresses causal effect estimation in the presence of hidden confounders. ASFL makes the feature learning process outcome-aware by minimizing a contrastive loss derived from an augmented operator incorporating outcome information, thereby remaining effective even when standard spectral features fail due to spectral misalignment. This approach provides robust causal inference by learning task-specific features that accurately represent the true causal function.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Outcomes Research</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00919v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00919v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00919v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00919v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00905v1"
                     data-domains="Pulmonology,Internal Medicine,Epidemiology,Clinical Informatics,Health Equity"
                     data-keywords="demographic adjustments,race,clinical equations,spirometry,proxies,sitting height,personalized medicine,lung function"
                     data-authors="Aashna P. Shah,James A. Diao,Emma Pierson,Chirag J. Patel,Arjun K. Manrai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00905v1.html">Disentangling Proxies of Demographic Adjustments in Clinical Equations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aashna P. Shah, James A. Diao, Emma Pierson et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ARC (Approach for identifying pRoxies of demographic Correction), a novel framework to identify explanatory factors for group-level differences in clinical equations, specifically addressing the debate around race-based adjustments. Applying ARC to spirometry tests across two large cohorts, the authors found that anthropometric measures like sitting height and waist circumference, rather than coarse sociodemographic factors, explain significant portions of observed lung function differences. The resulting $ARC_{PFT}$ equations, incorporating these factors, surpassed current race-neutral and race-stratified models in predictive performance and reduced vulnerability to domain shift.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Equity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00905v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00905v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00905v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00905v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00873v1"
                     data-domains="Interventional Radiology,Oncology,Diagnostic Imaging,Medical Physics"
                     data-keywords="CBCT reconstruction,Sparse-view,Deep learning,Low-dose imaging,Radiation reduction,Thoracic puncture,Multicenter validation,Prospective trial"
                     data-authors="Haoshen Wang,Lei Chen,Wei-Hua Zhang,Linxia Wu,Yong Luo,Zengmao Wang,Yuan Xiong,Chengcheng Zhu,Wenjuan Tang,Xueyi Zhang,Wei Zhou,Xuhua Duan,Lefei Zhang,Gao-Jun Teng,Bo Du,Huangxuan Zhao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00873v1.html">Neural Discrete Representation Learning for Sparse-View CBCT Reconstruction: From Algorithm Design to Prospective Multicenter Clinical Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haoshen Wang, Lei Chen, Wei-Hua Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DeepPriorCBCT, a three-stage deep learning framework designed to achieve diagnostic-grade CBCT reconstruction using only one-sixth of the conventional radiation dose. The framework was extensively validated using a large-scale multicenter retrospective dataset of 4102 patients and further confirmed its clinical applicability in a prospective cross-over trial with 138 patients, demonstrating comparable image quality and diagnostic performance to standard methods while significantly reducing radiation exposure.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00873v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00873v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00873v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00873v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.00872v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Artificial Intelligence"
                     data-keywords="Foundation Models,Computed Tomography,Self-supervised Learning,Vision Transformers,DINOv2,3D Medical Imaging,Task-agnostic Pretraining,Medical AI"
                     data-authors="Tim Veenboer,George Yiasemis,Eric Marcus,Vivien Van Veldhuizen,Cees G. M. Snoek,Jonas Teuwen,Kevin B. W. Groot Lipman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.00872v1.html">TAP-CT: 3D Task-Agnostic Pretraining of Computed Tomography Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tim Veenboer, George Yiasemis, Eric Marcus et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TAP-CT, a suite of task-agnostic pretraining methods for 3D Computed Tomography (CT) foundation models, adapting Vision Transformers (ViTs) and DINOv2 for volumetric data. By employing scalable self-supervised pretraining on a large dataset of 105K CT volumes with targeted architectural modifications, TAP-CT achieves stable, robust frozen representations that generalize strongly across diverse downstream tasks. This approach aims to reduce the need for extensive fine-tuning and reliance on task-biased objectives in medical AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.00872v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.00872v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.00872v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.00872v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-02 06:27:03</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>