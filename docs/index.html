<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">12</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">12</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">50</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Medical Imaging (2), Radiology (2), Drug Discovery (2)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (2)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (2)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (2)</option>
                        
                        <option value="Pharmacology">Pharmacology (2)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (2)</option>
                        
                        <option value="Clinical informatics">Clinical Informatics (1)</option>
                        
                        <option value="Electronic Health Records (EHR) management">Electronic Health Records (Ehr) Management (1)</option>
                        
                        <option value="Medical research data analysis">Medical Research Data Analysis (1)</option>
                        
                        <option value="Public health surveillance">Public Health Surveillance (1)</option>
                        
                        <option value="Healthcare regulatory compliance">Healthcare Regulatory Compliance (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.22060v1"
                     data-domains="Clinical informatics,Electronic Health Records (EHR) management,Medical research data analysis,Public health surveillance,Healthcare regulatory compliance,Clinical decision support systems"
                     data-keywords="NLP,AI governance,security,privacy,compliance,lifecycle management,healthcare AI,terminology drift"
                     data-authors="Sunil Arora,John Hastings">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.22060v1.html">Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sunil Arora, John Hastings
                </div>

                <div class="paper-summary">
                    This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a comprehensive six-phase model addressing the security, privacy, and regulatory compliance risks of NLP systems in sensitive domains like healthcare. Developed through a PRISMA-based review and aligned with leading AI governance standards, the framework provides a practical, lifecycle-wide structure for developing, deploying, and maintaining secure and accountable NLP systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical informatics</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) management</span>
                    
                    <span class="domain-tag">Medical research data analysis</span>
                    
                    <span class="domain-tag">Public health surveillance</span>
                    
                    <span class="domain-tag">Healthcare regulatory compliance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.22060v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.22060v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.22060v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.22060v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.22046v1"
                     data-domains="Digital Pathology,Medical Imaging,Oncology,Histopathology,Radiology"
                     data-keywords="Backdoor Attack,Video Segmentation,Foundation Models,Digital Pathology,Prompt-driven,Adversarial Machine Learning,Computer Vision,AI Security"
                     data-authors="Zongmin Zhang,Zhen Sun,Yifan Liao,Wenhan Dong,Xinlei He,Xingshuo Han,Shengmin Xu,Xinyi Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.22046v1.html">Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zongmin Zhang, Zhen Sun, Yifan Liao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces BadVSFM, the first backdoor attack framework specifically designed for prompt-driven Video Segmentation Foundation Models (VSFMs), which are increasingly used in critical applications like digital pathology. It demonstrates that classic backdoor attacks are ineffective, but BadVSFM successfully injects controllable backdoors by manipulating both the encoder and decoder through a novel two-stage process, leading to missegmentation under specific triggers while bypassing existing defenses. The research reveals an underexplored vulnerability in VSFMs, necessitating urgent development of tailored defense mechanisms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.22046v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.22046v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.22046v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.22046v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.22031v1"
                     data-domains="Drug Discovery,Pharmacology,Medicinal Chemistry,Pharmaceutical Sciences,Computational Biology"
                     data-keywords="generative models,drug discovery,hit identification,deep learning,molecular generation,in silico,in vitro,virtual screening,GSK-3Œ≤"
                     data-authors="Nagham Osman,Vittorio Lembo,Giovanni Bottegoni,Laura Toni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.22031v1.html">From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nagham Osman, Vittorio Lembo, Giovanni Bottegoni et al.
                </div>

                <div class="paper-summary">
                    This study investigates the novel application of deep learning generative models specifically for hit-like molecule generation, a critical and resource-intensive step in drug discovery. The research demonstrates that autoregressive and diffusion models can produce valid, diverse, and biologically relevant compounds, with selected GSK-3Œ≤ inhibitors experimentally validated in vitro, proving their potential to accelerate drug discovery pipelines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmaceutical Sciences</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.22031v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.22031v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.22031v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.22031v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.22026v1"
                     data-domains="Radiation Oncology,Medical Physics,Diagnostic Imaging,Neuro-oncology,Head and Neck Oncology"
                     data-keywords="proton therapy,range uncertainty,photon-counting CT,stopping power ratio,TissueXplorer,virtual imaging,dose distribution,radiation oncology"
                     data-authors="S. Vrba≈°ki,G. Staniƒá,S. Mollineli,M. Bhattarai,E. Abadi,M. Ciocca,E. Samei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.22026v1.html">Proton therapy range uncertainty reduction using vendor-agnostic tissue characterization on a virtual photon-counting CT head scan</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> S. Vrba≈°ki, G. Staniƒá, S. Mollineli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces virtual imaging simulators as a novel approach to validate proton therapy range uncertainty in complex patient geometries using a computational head model and photon-counting CT. It demonstrates that a prototype software, TissueXplorer, leveraging spectral CT information, significantly improves stopping power ratio (SPR) estimation and subsequent dose distribution accuracy compared to conventional methods, thereby reducing range uncertainty.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Head and Neck Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.22026v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.22026v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.22026v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.22026v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.22007v1"
                     data-domains="Immunology,Pharmacology,Drug Discovery,Vaccinology,Biotechnology"
                     data-keywords="Antigen-Antibody Affinity,Deep Learning,Sequence-Only Prediction,Protein Language Models,ESM-2,Drug Discovery,Vaccine Development,High-throughput Screening"
                     data-authors="Aicha Boutorh,Soumia Bouyahiaoui,Sara Belhadj,Nour El Yakine Guendouz,Manel Kara Laouar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.22007v1.html">DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj et al.
                </div>

                <div class="paper-summary">
                    DuaDeep-SeqAffinity introduces a novel dual-stream deep learning framework that accurately predicts antigen-antibody binding affinity solely from amino acid sequences, circumventing the need for expensive 3D structures. Leveraging pre-trained ESM-2 embeddings with a hybrid CNN-Transformer architecture, the model significantly outperforms state-of-the-art methods and even structure-sequence hybrids, demonstrating sequence data's capacity to capture crucial binding patterns. This innovation enables highly scalable and efficient high-throughput screening, accelerating therapeutic discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.22007v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.22007v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.22007v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.22007v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21997v1"
                     data-domains="Diagnostics,Point-of-care testing,Health monitoring,Clinical laboratory,Global health"
                     data-keywords="affinity biosensors,sample volume,mathematical model,mass transport,Langmuir kinetics,biosensor optimization,point-of-care testing,quantitative design rules"
                     data-authors="Daan Beijersbergen,J√©r√¥me Charmet">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21997v1.html">Sample volume as a key design parameter in affinity-based biosensors</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daan Beijersbergen, J√©r√¥me Charmet
                </div>

                <div class="paper-summary">
                    This paper addresses the critical yet underexplored role of sample volume in affinity-based biosensor design, where performance hinges on the absolute number of target molecules, not just concentration. The authors developed a tractable two-compartment mathematical model that integrates mass transport, Langmuir kinetics, and mass conservation to accurately predict assay time and minimum required sample volume. This model, validated experimentally and computationally, drastically reduces design optimization time and provides quantitative rules to enhance biosensor sensitivity and performance, particularly for point-of-care applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Point-of-care testing</span>
                    
                    <span class="domain-tag">Health monitoring</span>
                    
                    <span class="domain-tag">Clinical laboratory</span>
                    
                    <span class="domain-tag">Global health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21997v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21997v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21997v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21997v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21988v1"
                     data-domains="Dermatology,Telemedicine,Digital Health,Diagnostic Imaging,Medical Device Validation"
                     data-keywords="Smartphone dermatology,Tele-dermatology,Colorimetric calibration,Clinical biomarkers,Color-clinical decoupling,Individual Typology Angle (ITA),Melanin Index,Inter-device agreement,Fitzpatrick skin types"
                     data-authors="Sungwoo Kang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21988v1.html">The Color-Clinical Decoupling: Why Perceptual Calibration Fails Clinical Biomarkers in Smartphone Dermatology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sungwoo Kang
                </div>

                <div class="paper-summary">
                    This paper reveals that standard colorimetric calibration, while achieving perceptual accuracy (Delta E < 2.3) in smartphone dermatology, fails to ensure reliability for clinical biomarker extraction, particularly for underrepresented skin types (Fitzpatrick III-IV). It introduces the concept of "color-clinical decoupling," demonstrating that despite accurate color reproduction, clinical biomarkers like the Individual Typology Angle (ITA) show poor inter-device agreement due to inherent formula sensitivities and significant anatomical variances.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Device Validation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21988v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21988v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21988v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21988v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21984v1"
                     data-domains="Spine Surgery,Neurosurgery,Orthopedic Surgery,Minimally Invasive Surgery,Endoscopy"
                     data-keywords="instance segmentation,spinal endoscopy,real-time AI,lightweight deep learning,multi-scale attention,surgical navigation,PELD dataset,medical image analysis"
                     data-authors="Qi Lai,JunYan Li,Qiang Cai,Lei Wang,Tao Yan,XiaoKun Liang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21984v1.html">A Lightweight Multi-Scale Attention Framework for Real-Time Spinal Endoscopic Instance Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qi Lai, JunYan Li, Qiang Cai et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LMSF-A, a lightweight multi-scale attention framework designed for real-time instance segmentation in spinal endoscopy, addressing challenges like limited visibility and hardware constraints. By co-designing the backbone, neck, and head for efficiency and accuracy, the framework achieves competitive performance with minimal computational cost. The authors also release a new clinically reviewed PELD dataset and demonstrate the model's exceptional lightness, stability under small-batch training, and strong generalization capabilities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Spine Surgery</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Orthopedic Surgery</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery</span>
                    
                    <span class="domain-tag">Endoscopy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21984v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21984v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21984v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21984v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21975v1"
                     data-domains="diagnostic imaging,interventional radiology,ultrasound imaging,endoscopy,mobile health,telemedicine,surgical guidance"
                     data-keywords="image deblurring,real-time processing,lightweight model,edge computing,motion blur,deep learning,U-shaped network,medical imaging"
                     data-authors="Zhuoyu Wu,Wenhui Ou,Qiawei Zheng,Jiayan Yang,Quanjun Wang,Wenqi Fang,Zheng Wang,Yongkui Yang,Heshan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21975v1.html">RT-Focuser: A Real-Time Lightweight Model for Edge-side Image Deblurring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhuoyu Wu, Wenhui Ou, Qiawei Zheng et al.
                </div>

                <div class="paper-summary">
                    RT-Focuser is a novel lightweight U-shaped deep learning model designed for real-time image deblurring, specifically targeting edge devices. It effectively mitigates motion blur, which degrades image quality in real-time applications like medical imaging, by utilizing specialized blocks for edge-aware feature extraction, encoder integration, and progressive decoder refinement. The model achieves high accuracy and exceptional speed with minimal computational resources, demonstrating strong potential for edge deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">diagnostic imaging</span>
                    
                    <span class="domain-tag">interventional radiology</span>
                    
                    <span class="domain-tag">ultrasound imaging</span>
                    
                    <span class="domain-tag">endoscopy</span>
                    
                    <span class="domain-tag">mobile health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21975v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21975v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21975v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21975v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21964v1"
                     data-domains="Radiology,Pathology,Clinical Decision Support,Medical Imaging,Medical Informatics"
                     data-keywords="Medical MLLMs,Robustness,Input Perturbations,Denoising,Multi-modal Calibration,Vision Encoder,Multi-agent System,Clinical Applicability"
                     data-authors="Dunyuan XU,Xikai Yang,Yaoqian Li,Juzheng Miao,Jinpeng Li,Pheng-Ann Heng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21964v1.html">Perceive and Calibrate: Analyzing and Enhancing Robustness of Medical Multi-Modal Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dunyuan XU, Xikai Yang, Yaoqian Li et al.
                </div>

                <div class="paper-summary">
                    Medical Multi-modal Large Language Models (MLLMs) are significantly hampered by their sensitivity to real-world input perturbations like imaging artifacts and textual errors, which critically undermines their clinical applicability. This paper systematically analyzes the impact of such noise and introduces a training-free Inherent-enhanced Multi-modal Calibration (IMC) framework. IMC leverages MLLMs' intrinsic capabilities for cross-modal robustness enhancement through a Perturbation-aware Denoising Calibration (PDC) for visuals and a Self-instantiated Multi-agent System (SMS) for text, demonstrating state-of-the-art performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21964v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21964v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21964v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21964v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21895v1"
                     data-domains="q-bio.QM"
                     data-keywords="q-bio.QM"
                     data-authors="Hao-Yu Zhu,Shi-Jie Du,Lu Xu,Wei Shi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21895v1.html">Drug discovery guided by maximum drug likeness</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao-Yu Zhu, Shi-Jie Du, Lu Xu et al.
                </div>

                <div class="paper-summary">
                    To overcome the high attrition rate and limited clinical translatability in drug discovery, we introduce the concept of Maximum Drug-Likeness (MDL) and develop an applicable Fivefold MDL strategy (5F-MDL) to reshape the screening paradigm. The 5F-MDL strategy integrates an ensemble of 33 deep learni...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.QM</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21895v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21895v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21895v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21895v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.21890v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Juyoung Bae,Moo Hyun Son,Jiale Peng,Wanting Qu,Wener Chen,Zelin Qiu,Kaixin Li,Xiaojuan Chen,Yifan Lin,Hao Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.21890v1.html">CrownGen: Patient-customized Crown Generation via Point Diffusion Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Juyoung Bae, Moo Hyun Son, Jiale Peng et al.
                </div>

                <div class="paper-summary">
                    Digital crown design remains a labor-intensive bottleneck in restorative dentistry. We present \textbf{CrownGen}, a generative framework that automates patient-customized crown design using a denoising diffusion model on a novel tooth-level point cloud representation. The system employs two core com...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.21890v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.21890v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.21890v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.21890v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-29 06:17:33</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>