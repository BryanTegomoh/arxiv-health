<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">152</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (11), Neurology (7), Diagnostic Imaging (6)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (11)</option>
                        
                        <option value="Neurology">Neurology (7)</option>
                        
                        <option value="Oncology">Oncology (6)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (6)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (5)</option>
                        
                        <option value="Clinical Decision Support Systems">Clinical Decision Support Systems (4)</option>
                        
                        <option value="Artificial Intelligence in Medicine">Artificial Intelligence In Medicine (4)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                        <option value="Digital Health">Digital Health (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.04655v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04655v1.html">Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ellis Brown, Jihan Yang, Shusheng Yang et al.
                </div>

                <div class="paper-summary">
                    Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-cen...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04637v1"
                     data-domains="Neurodevelopmental disorders,Psychiatric disorders,Cancer,Aging"
                     data-keywords="Genetic risk factors,Allele frequency spectrum,Missing middle,Variant discovery,Variant annotation,Joint modeling,Phenotype refinement,Network inference"
                     data-authors="Madison Caballero,Behrang Mahjani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04637v1.html">Advancing Risk Gene Discovery Across the Allele Frequency Spectrum</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Madison Caballero, Behrang Mahjani
                </div>

                <div class="paper-summary">
                    This paper addresses the critical challenge of stalled genetic risk factor discovery for variants of intermediate allele frequency and effect size, dubbed the "missing middle," which are poorly characterized by current methods optimized for rare or common variants. It reviews existing strategies by variant frequency class and proposes innovative methodological advancements‚Äîincluding variant annotation, joint modeling, phenotype refinement, and network-based inference‚Äîto extend discovery into this understudied range across diverse disease areas. The overarching goal is to provide a conceptual map for more comprehensive risk gene identification across the entire allele frequency spectrum.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurodevelopmental disorders</span>
                    
                    <span class="domain-tag">Psychiatric disorders</span>
                    
                    <span class="domain-tag">Cancer</span>
                    
                    <span class="domain-tag">Aging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04637v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04637v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04637v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04637v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04619v1"
                     data-domains="Neurology,Geriatrics,Dementia Research,Neuroscience,Biomarker Development"
                     data-keywords="Alzheimer's disease,Causal Discovery,Latent Pseudotime,Dynamic Interactions,Biomarkers,Disease Trajectory,Neurodegeneration,Machine Learning"
                     data-authors="Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04619v1.html">Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Natalia Glazman, Jyoti Mangal, Pedro Borges et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel application of an existing latent variable model to uncover dynamic causal relationships in Alzheimer's disease (AD) by inferring a 'pseudotime' that reflects a data-driven disease trajectory. This pseudotime significantly outperforms chronological age in predicting AD diagnosis and, when combined with minimal background knowledge, enables the discovery of evolving causal interactions between AD biomarkers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Dementia Research</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Biomarker Development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04574v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Biostatistics,Vaccine Policy"
                     data-keywords="COVID-19,Reproduction Number,R_0,R_t,Serial Interval,Presymptomatic Transmission,Lotka-Euler Equation,Renewal Equation,Gaussian Distribution,Epidemiological Modeling"
                     data-authors="Derek Marsh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04574v1.html">Reproduction Numbers R_0, R_t for COVID-19 Infections with Gaussian Distribution of Generation Times, and of Serial Intervals including Presymptomatic Transmission</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Derek Marsh
                </div>

                <div class="paper-summary">
                    This paper addresses inconsistencies in calculating COVID-19 reproduction numbers (R_0, R_t) when accounting for presymptomatic transmission, which leads to negative serial intervals. It formulates the Lotka-Euler equation with an explicit lower cut-off for Gaussian-distributed serial intervals, contrasting it with the discretized renewal equation, to accurately explore the consequences of presymptomatic transmission.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Vaccine Policy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04557v1"
                     data-domains="Clinical Decision Support Systems,Electronic Health Record (EHR) Analysis,Predictive Analytics in Healthcare,Patient Trajectory Modeling,Personalized Medicine"
                     data-keywords="Graph Transformers,Relational Deep Learning,Temporal Graphs,Multi-task Learning,Latent Bottleneck,Healthcare AI,Graph Neural Networks,State-of-the-art"
                     data-authors="Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04557v1.html">Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Divyansha Lachi, Mahmoud Mohammadi, Joe Meyer et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Relational Graph Perceiver (RGP), a novel graph transformer architecture designed to effectively integrate long-range temporal and structural dependencies in complex relational data, particularly in domains like healthcare. RGP employs a temporal subgraph sampler and a cross-attention-based latent bottleneck to build global context across diverse entities, alongside a flexible decoder for multi-task learning. It achieves state-of-the-art performance on various benchmarks, offering a general and scalable solution for relational deep learning with diverse predictive tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Electronic Health Record (EHR) Analysis</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="domain-tag">Patient Trajectory Modeling</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04557v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04557v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04557v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04557v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04556v1"
                     data-domains="Public Health,Environmental Health,Disaster Preparedness,Preventive Medicine"
                     data-keywords="Sparse Sensing,Sensor Placement Optimization,Urban Flooding,Stormwater Management,Data-Driven,EPA-SWMM,Peak Flowrate,Public Health"
                     data-authors="Zihang Ding,Kun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04556v1.html">Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihang Ding, Kun Zhang
                </div>

                <div class="paper-summary">
                    This research paper introduces a Data-Driven Sparse Sensing (DSS) framework, integrated with EPA-SWMM, to optimize sensor placement and accurately reconstruct peak flowrates in urban stormwater systems. Utilizing a simulated dataset, the framework demonstrated that merely three optimally placed sensors among 77 nodes could achieve high-accuracy flow reconstruction with Nash-Sutcliffe Efficiency values of 0.92-0.95, while also showing good robustness to measurement uncertainty and location-dependent resilience to sensor failures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Disaster Preparedness</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04556v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04556v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04556v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04556v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04525v1"
                     data-domains="General Surgery,Gastrointestinal Surgery,Medical Education,Medical Informatics,Artificial Intelligence in Medicine"
                     data-keywords="Laparoscopic Cholecystectomy,Surgical Complexity,Parkland Grading Scale,Weak Temporal Supervision,Deep Learning,Video Analysis,Computer Vision,AI in Surgery"
                     data-authors="Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04525v1.html">Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios Anastasiou, Santiago Barbarisi, Lucy Culshaw et al.
                </div>

                <div class="paper-summary">
                    This paper introduces STC-Net, a novel deep learning framework for automated, single-timestamp-based complexity estimation in Laparoscopic Cholecystectomy (LC) using the Parkland Grading Scale (PGS). Operating directly on full surgical videos with weak temporal supervision, STC-Net jointly performs temporal localization and grading, achieving 62.11% accuracy and 61.42% F1-score and outperforming non-localized baselines by over 10%.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Gastrointestinal Surgery</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04510v1"
                     data-domains="eess.IV"
                     data-keywords="eess.IV,cs.CV,physics.optics,68T07, 78A46, 78A70, 92C55,I.2.10; I.4.5"
                     data-authors="Shihan Zhao,Jianru Zhang,Yanan Wu,Linlin Li,Siyuan Shen,Xingjun Zhu,Guoyan Zheng,Jiahua Jiang,Wuwei Ren">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04510v1.html">$Œº$NeuFMT: Optical-Property-Adaptive Fluorescence Molecular Tomography via Implicit Neural Representation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shihan Zhao, Jianru Zhang, Yanan Wu et al.
                </div>

                <div class="paper-summary">
                    Fluorescence Molecular Tomography (FMT) is a promising technique for
non-invasive 3D visualization of fluorescent probes, but its reconstruction
remains challenging due to the inherent ill-posedness and reliance on
inaccurate or often-unknown tissue optical properties. While deep learning
methods ha...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">eess.IV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04510v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04510v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04510v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04510v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04506v1"
                     data-domains="Radiology,Diagnostic Imaging,Clinical Decision Support,Medical Natural Language Processing,Artificial Intelligence in Medicine"
                     data-keywords="radiology reports,clinical uncertainty,explicit uncertainty,implicit uncertainty,large language models,diagnostic pathways,medical NLP,uncertainty quantification"
                     data-authors="Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04506v1.html">Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paloma Rabaey, Jong Hak Moon, Jung-Oh Lee et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel two-part framework to systematically model both explicit and implicit clinical uncertainty found in radiology reports, addressing limitations of current automated analysis methods. It quantifies explicit uncertainty using an LLM-based, expert-validated ranking of hedging phrases and models implicit uncertainty by expanding reports with characteristic sub-findings derived from expert-defined diagnostic pathways. The work culminates in the release of Lunguage++, an enriched, uncertainty-aware benchmark dataset designed to enable improved image classification and faithful diagnostic reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04506v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04506v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04506v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04506v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04476v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology,Digital Health,Behavioral Health"
                     data-keywords="Depression detection,PHQ-8,Natural Language Processing,Deep Learning,Probabilistic Modeling,Time Series Analysis,Clinical Interviews,Uncertainty Quantification"
                     data-authors="Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04476v1.html">Probabilistic Textual Time Series Depression Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fabian Schmidt, Seyedehmoniba Ravan, Vladimir Vlassov
                </div>

                <div class="paper-summary">
                    This paper introduces PTTSD, a novel Probabilistic Textual Time Series Depression Detection framework that predicts PHQ-8 scores from clinical interview utterances while explicitly modeling temporal uncertainty. Leveraging advanced deep learning architectures with probabilistic output heads, PTTSD achieves state-of-the-art performance among text-only systems and provides well-calibrated prediction intervals, enhancing clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04476v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04476v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04476v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04476v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04458v1"
                     data-domains="Oncology,Neurology,Alzheimer's Disease Research,Diagnostic Imaging,Clinical Research"
                     data-keywords="PET imaging,Preprocessing,Statistical modeling,Neuroimaging,Alzheimer's disease,Cancer,Data harmonization,TRAECR,Medical imaging"
                     data-authors="Akhil Ambekar,Robert Zielinski,Ani Eloyan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04458v1.html">TRAECR: A Tool for Preprocessing Positron Emission Tomography Imaging for Statistical Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Akhil Ambekar, Robert Zielinski, Ani Eloyan
                </div>

                <div class="paper-summary">
                    This paper introduces TRAECR (Template registration, MRI-PET co-Registration, Anatomical brain Extraction and COMBAT/RAVEL harmonization), a novel tool designed to preprocess and visualize Positron Emission Tomography (PET) imaging data. TRAECR aims to facilitate the preparation of PET datasets for robust statistical modeling, addressing complex scientific questions in clinical applications such as cancer and Alzheimer's disease (AD) research. It integrates essential preprocessing steps to enhance data quality and consistency for advanced analyses.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Alzheimer's Disease Research</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04458v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04458v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04458v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04458v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04334v1"
                     data-domains="Radiology,Oncology,Urology,Diagnostic Imaging,Medical Physics"
                     data-keywords="Kidney segmentation,Kidney tumors,Computed Tomography,Submanifold Sparse Convolutional Networks,Deep learning,Medical image analysis,Automated segmentation,KiTS23"
                     data-authors="Sa√∫l Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04334v1.html">Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sa√∫l Alonso-Monsalve, Leigh H. Whitehead, Adam Aurisano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel two-stage methodology combining voxel sparsification and Submanifold Sparse Convolutional Networks (SSCNs) for automated, high-resolution 3D segmentation of kidneys and kidney tumors in Computed Tomography (CT) images. This approach achieves state-of-the-art competitive accuracy on the KiTS23 challenge while significantly reducing computational resources, offering substantial improvements in inference time and GPU memory usage.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04334v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04334v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04334v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04334v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04333v1"
                     data-domains="Intensive Care Medicine,Critical Care,Clinical Decision Support,Longitudinal Patient Data Analysis"
                     data-keywords="Dynamic Bayesian Networks,Missing Data Imputation,Full Bayesian Inference,Gibbs Sampling,Intensive Care,Temporal Models,Uncertainty Quantification,Clinical Decision-Making"
                     data-authors="Federico Pirola,Fabio Stella,Marco Grzegorczyk">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04333v1.html">LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Federico Pirola, Fabio Stella, Marco Grzegorczyk
                </div>

                <div class="paper-summary">
                    This paper introduces LUME-DBN, a novel full Bayesian framework utilizing Gibbs sampling to learn Dynamic Bayesian Networks (DBNs) from incomplete longitudinal clinical data, specifically addressing the limitations of existing missing data handling methods that neglect temporal dependencies. By treating missing values as Gaussian-distributed unknown parameters sampled from their full conditional distributions, the approach enables principled imputation and temporal uncertainty quantification. Evaluated on simulated and real-world intensive care unit (ICU) data, LUME-DBN demonstrates superior reconstruction accuracy and convergence compared to standard model-agnostic techniques like MICE.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Longitudinal Patient Data Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04328v1"
                     data-domains="Pharmacology,Clinical Informatics,Patient Safety,Drug Management,Medical AI"
                     data-keywords="Medication Safety,Large Language Models,Clinical Decision Support,Drug Interactions,Contraindications,AI Evaluation,Benchmark,Patient Safety"
                     data-authors="Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04328v1.html">RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiahao Zhao, Luxin Xu, Minghuan Tan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces RxSafeBench, a novel framework and benchmark designed to rigorously evaluate Large Language Models' medication safety capabilities within simulated clinical consultations. It reveals that current LLMs significantly struggle to integrate medication contraindication and interaction knowledge, particularly when risks are implied rather than explicitly stated. The work highlights critical challenges for ensuring safer, more trustworthy AI-driven clinical decision support systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Drug Management</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04328v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04328v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04328v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04328v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04276v1"
                     data-domains="Infectious Disease Epidemiology,Medical Entomology,Public Health,Vector Control,Mathematical Biology in Medicine"
                     data-keywords="Dengue,Vector Competence,Predator-Prey Model,Disease Persistence,Aedes Mosquitoes,Endemic Stability,Innate Immunity,Evolutionary Trade-off"
                     data-authors="Piyumi Chathurangika,Tharushika Peiris,Lakmini S. Premadasa,S. S. N. Perera,Kushani De Silva">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04276v1.html">Vector Traits Shape Disease Persistence: A Predator Prey Approach to Dengue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Piyumi Chathurangika, Tharushika Peiris, Lakmini S. Premadasa et al.
                </div>

                <div class="paper-summary">
                    This study models dengue transmission using a predator-prey framework, demonstrating that endemic conditions naturally arise from vector-pathogen interactions and are globally stable. It identifies vector competence (vc) as a key driver of disease persistence, revealing a fundamental biological trade-off where vectors cannot enhance immune capacity to offset high vc in endemic tropical/subtropical environments, leading to unstable transmission dynamics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Medical Entomology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Vector Control</span>
                    
                    <span class="domain-tag">Mathematical Biology in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04255v1"
                     data-domains="Radiology,Medical Imaging Analysis,Anatomy,Diagnostic Imaging,Surgical Planning,Radiation Oncology"
                     data-keywords="Medical Imaging,Anatomical Landmark Detection,Foundation Models,Human-Centric Models,Pose Estimation,Deep Learning,State-of-the-Art,Few-Shot Learning"
                     data-authors="Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04255v1.html">MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marawan Elbatel, Anbang Wang, Keyuan Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedSapiens, a novel approach that adapts human-centric foundation models, specifically Sapiens (designed for pose estimation), for anatomical landmark detection in medical imaging. By leveraging multi-dataset pretraining, MedSapiens achieves a new state-of-the-art performance across various datasets, demonstrating the significant and previously overlooked potential of such models to provide strong spatial priors for medical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04255v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04255v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04255v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04255v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04190v1"
                     data-domains="Medical imaging,Diagnostic imaging,Computer-aided diagnosis,Radiology,Pathology"
                     data-keywords="Covariance descriptors,Riemannian deep learning,SPDNet,Medical image classification,General Vision Encoders,DINOv2,MedSAM,Second-order statistics"
                     data-authors="Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04190v1.html">Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Josef Mayr, Anna Reithmeir, Maxime Di Folco et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the effectiveness of covariance descriptors, which capture second-order image statistics, for medical image classification, particularly when integrated with SPDNet, a classification network designed for symmetric positive definite (SPD) matrices. The authors propose constructing these descriptors from features extracted by powerful pre-trained General Vision Encoders (GVEs) like DINOv2 and MedSAM. Their findings demonstrate that GVE-derived covariance descriptors consistently outperform handcrafted alternatives, and critically, the combination of SPDNet with DINOv2 features achieves superior performance compared to state-of-the-art methods on diverse medical image datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Computer-aided diagnosis</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04190v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04190v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04190v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04190v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04174v1"
                     data-domains="Neurology,Neurogenetics,Molecular Medicine,Neuropharmacology,Pathology"
                     data-keywords="Huntington's disease,protein aggregation,polyglutamine,huntingtin,hydrogen bonds,covalent bonds,transglutaminase,neuronal death"
                     data-authors="Guylaine Hoffner,Philippe Djian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04174v1.html">Protein aggregation in Huntington's disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guylaine Hoffner, Philippe Djian
                </div>

                <div class="paper-summary">
                    This paper analyzes protein aggregation in Huntington's disease (HD), driven by expanded polyglutamine in huntingtin, as a likely cause of neuronal death. It outlines two proposed aggregation mechanisms ‚Äì hydrogen bonding (polar-zipper) and covalent bonding (transglutaminase-catalyzed cross-linking) ‚Äì noting that cell culture models show aggregates mostly stabilized by hydrogen bonds, with some covalent involvement. Critically, the authors highlight a significant knowledge gap regarding the nature of these stabilizing bonds *in vivo* in patient brains, emphasizing its importance for guiding therapeutic approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurogenetics</span>
                    
                    <span class="domain-tag">Molecular Medicine</span>
                    
                    <span class="domain-tag">Neuropharmacology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04174v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04174v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04174v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04174v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04171v1"
                     data-domains="Digital Pathology,Histopathology,Cancer Diagnostics,Biomarker Discovery,Medical Imaging"
                     data-keywords="Digital Pathology,Image Registration,Color Transformation,Preprocessing,CycleGAN,H&E Stains,Multimodal Imaging,VALIS"
                     data-authors="Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04171v1.html">Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemehzahra Darzi, Rodrigo Escobar Diaz Guerrero, Thomas Bocklitz
                </div>

                <div class="paper-summary">
                    This study systematically evaluates various preprocessing techniques, focusing on color transformations, to enhance image registration accuracy between H&E stained and non-linear multimodal images in digital pathology. It conclusively demonstrates that CycleGAN color transformation significantly reduces registration errors, leading to improved spatial alignment for downstream applications like biomarker analysis and tissue reconstruction. The findings highlight the critical role of appropriate preprocessing in achieving reliable image integration across different imaging modalities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Cancer Diagnostics</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04171v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04171v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04171v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04171v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04158v1"
                     data-domains="Predictive Analytics,Clinical Decision Support Systems,Population Health Management,Chronic Disease Management,Personalized Medicine,Health Informatics"
                     data-keywords="Deep Learning,Transformers,Clinical Risk Identification,Electronic Health Records (EHR),Heterogeneous Data,Longitudinal Modeling,Multi-head Self-Attention,Semantic-Weighted Pooling"
                     data-authors="Anzhuo Xie,Wei-Chen Chang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04158v1.html">Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anzhuo Xie, Wei-Chen Chang
                </div>

                <div class="paper-summary">
                    This study introduces a novel Transformer-based deep learning model designed for clinical risk identification from heterogeneous Electronic Health Record (EHR) data. The model effectively addresses challenges like irregular temporal patterns, large modality differences, and complex semantic structures by employing specialized embedding, temporal encoding, and attention mechanisms. Experimental results demonstrate its superior performance over existing models, offering a robust framework for intelligent clinical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04084v1"
                     data-domains="Radiology,Oncology,Anatomy,Diagnostics,Surgery,Medical Imaging"
                     data-keywords="Medical Image Segmentation,Swin Transformer,Kolmogorov-Arnold Networks (KANs),U-Net,Deep Learning,Data Efficiency,Computer Vision,Artificial Intelligence"
                     data-authors="Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04084v1.html">When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nishchal Sapkota, Haoyan Shi, Yejia Zhang et al.
                </div>

                <div class="paper-summary">
                    UKAST is a novel U-Net-like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders for medical image segmentation. This approach addresses the limitations of standard CNNs and Transformers by achieving state-of-the-art performance on four diverse medical benchmarks, particularly excelling in data-scarce environments. By leveraging Group Rational KANs, UKAST offers a more expressive, data-efficient, and computationally optimized framework, significantly advancing medical image analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04084v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04084v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04084v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04084v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04079v1"
                     data-domains="Radiology,Medical Informatics,Clinical Research,Data Privacy,Artificial Intelligence in Medicine"
                     data-keywords="Radiology Reports,De-identification,Protected Health Information (PHI),Transformers,Natural Language Processing (NLP),Machine Learning,Benchmarking,Clinical Text"
                     data-authors="Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04079v1.html">Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eva Prakash, Maayane Attias, Pierre Chambon et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel transformer-based model significantly enhancing the automated de-identification of radiology reports by leveraging large-scale, diverse training data and incorporating an 'AGE' PHI category. The model achieves superior performance (F1 scores up to 0.996) for Protected Health Information (PHI) detection, outperforming both prior academic models and leading commercial cloud vendor systems. This work establishes a new benchmark for secure and accurate clinical text processing.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Data Privacy</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04079v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04079v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04079v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04079v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04071v1"
                     data-domains="Cardiology,Electrophysiology,Diagnostic Radiology,Medical Imaging,Biomedical Engineering"
                     data-keywords="Left Atrial Segmentation,nnU-Net,Cardiac MRI,Atrial Fibrillation,Deep Learning,Medical Image Segmentation,Dice Similarity Coefficient,Electrophysiology"
                     data-authors="Fatemeh Hosseinabadi,Seyedhassan Sharifi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04071v1.html">Left Atrial Segmentation with nnU-Net Using MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemeh Hosseinabadi, Seyedhassan Sharifi
                </div>

                <div class="paper-summary">
                    This paper presents the application of the nnU-Net deep learning framework for accurate left atrial (LA) segmentation from cardiac MRI scans, a critical step for atrial fibrillation (AF) ablation guidance and biophysical cardiac modeling. The self-configuring nnU-Net model achieved a high mean Dice similarity coefficient of 93.5 on the Left Atrial Segmentation Challenge 2013 dataset, demonstrating superior performance and robust generalization compared to traditional methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04071v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04071v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04071v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04071v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04069v1"
                     data-domains="Pediatrics,Emergency Medicine,Diagnostic Imaging,Radiology,Gastroenterology"
                     data-keywords="Pediatric Appendicitis,Ultrasound Imaging,Deep Learning,ResNet,Automated Detection,Diagnosis,Acute Abdominal Pain,Medical Imaging"
                     data-authors="Fatemeh Hosseinabadi,Seyedhassan Sharifi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04069v1.html">Pediatric Appendicitis Detection from Ultrasound Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemeh Hosseinabadi, Seyedhassan Sharifi
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a deep learning model, based on a fine-tuned ResNet architecture, for automated detection of pediatric appendicitis from ultrasound images. Leveraging the Regensburg Pediatric Appendicitis Dataset, the model achieved high performance metrics (93.44% accuracy, 91.53% precision, 89.8% recall) in identifying appendicitis, demonstrating its ability to handle challenging pediatric ultrasound characteristics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04069v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04069v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04069v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04069v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04070v1"
                     data-domains="Surgery,Therapy (Psychology),Clinical Decision Support,Medical Diagnostics"
                     data-keywords="LLMs,Explainable AI,Expert Alignment,Benchmarking,Clinical Decision Support,Trustworthy AI,Evaluation Metrics,Medical AI"
                     data-authors="Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04070v1.html">T-FIX: Text-Based Explanations with Features Interpretable to eXperts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shreya Havaldar, Helen Jin, Chaehyeon Kim et al.
                </div>

                <div class="paper-summary">
                    This paper introduces T-FIX, a novel benchmark and evaluation framework designed to assess the 'expert alignment' of explanations generated by Large Language Models (LLMs) in knowledge-intensive domains. Recognizing the inadequacy of current evaluation metrics that focus primarily on plausibility or internal faithfulness, T-FIX formalizes the criterion of whether an LLM's explanation truly reflects and aligns with expert-level reasoning and intuition.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Therapy (Psychology)</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04070v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04070v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04070v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04070v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04016v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04016v1.html">MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahmoud Soliman, Islam Osman, Mohamed S. Shehata et al.
                </div>

                <div class="paper-summary">
                    The performance of vision models in medical imaging is often hindered by the
prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain
natural images. To address this fundamental domain gap, we propose MedDChest, a
new foundational Vision Transformer (ViT) model optimized specificall...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04016v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04016v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04016v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04016v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04000v1"
                     data-domains="Clinical Decision Support Systems,Medical Diagnostics,Prognostic Modeling,Risk Stratification,Explainable AI in Medicine"
                     data-keywords="Decision Trees,Meta-Learning,Interpretable Models,Synthetic Data Generation,Scalability,Healthcare AI,Pre-training,Computational Efficiency"
                     data-authors="Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04000v1.html">Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kyaw Hpone Myint, Zhe Wu, Alexandre G. R. Day et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an efficient and scalable method for meta-learning interpretable decision trees by generating synthetic pre-training data. The approach samples near-optimal decision trees to create large-scale datasets, which, when used with the MetaTree transformer, achieve performance comparable to pre-training on real-world data or with computationally expensive optimal trees. This strategy significantly reduces computational costs and enhances data generation flexibility, enabling scalable development of interpretable models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Prognostic Modeling</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                    <span class="domain-tag">Explainable AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04000v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04000v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04000v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04000v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03976v1"
                     data-domains="Virology,Infectious Diseases,Public Health,Epidemiology,Vaccinology,Genomics,Bioinformatics"
                     data-keywords="SARS-CoV-2,mutation prediction,evolutionary transformer,phylogenetic trees,viral evolution,public health,vaccine development,deep learning,genomics,bioinformatics"
                     data-authors="Xu Zou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03976v1.html">PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xu Zou
                </div>

                <div class="paper-summary">
                    PETRA introduces a novel Pretrained Evolutionary Transformer for predicting future SARS-CoV-2 mutations by analyzing evolutionary trajectories derived from phylogenetic trees, rather than noisy raw RNA sequences. This method, enhanced by a weighted training framework, significantly outperforms existing baselines in predicting both nucleotide and critical spike amino-acid mutations. PETRA offers a powerful tool to aid real-time mutation prediction for emerging clades, thereby supporting public health and vaccine development efforts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Virology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03976v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03976v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03976v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03976v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03912v1"
                     data-domains="Radiology,Pulmonology,Neurology,Chest X-ray (CXR),Brain MRI"
                     data-keywords="Anomaly Detection,Medical Imaging,Incremental Learning,Unsupervised Learning,Stochastic Weight Averaging-Gaussian (SWAG),Convolutional Adapters,Oracle-Free,Label Scarcity"
                     data-authors="Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03912v1.html">I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nand Kumar Yadav, Rodrigue Rizk, William CW Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an unsupervised, oracle-free framework for incremental anomaly learning in medical imaging, designed to identify unknown anomalies despite scarce labeled data. It achieves this by iteratively expanding a trusted set of normal samples through lightweight adapter updates and a robust dual probabilistic gating mechanism, significantly improving anomaly detection performance across various medical imaging tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Chest X-ray (CXR)</span>
                    
                    <span class="domain-tag">Brain MRI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03912v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03912v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03912v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03912v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03897v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Health Disparities,Biostatistics"
                     data-keywords="infectious disease modelling,social contact surveys,perception bias,sociodemographics,SIR model,cumulative incidence,health equity,epidemiology"
                     data-authors="Thomas J. Harris,Prescott C. Alexander,Anh B. D. Pham,Joseph Tuccillo,Nicholas Geard,Cameron Zachreson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03897v1.html">Simulating the impact of perception bias on social contact surveys for infectious disease modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thomas J. Harris, Prescott C. Alexander, Anh B. D. Pham et al.
                </div>

                <div class="paper-summary">
                    This study simulates social contact surveys on a synthetic network to investigate how perception biases in estimating others' sociodemographic attributes (age, race) impact derived contact patterns and infectious disease model projections. It found that such biases significantly reduce survey accuracy, leading to a systematic underestimation of cumulative disease incidence in older populations and racial minority groups when used in Susceptible-Infectious-Recovered (SIR) models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Health Disparities</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03897v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03897v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03897v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03897v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03891v1"
                     data-domains="Ophthalmology,Medical Imaging Diagnostics,Retinal Disease Diagnosis,Artificial Intelligence in Medicine"
                     data-keywords="Class-Based Image Composition,Optical Coherence Tomography,Deep Learning,Medical Imaging,Diagnostic Performance,Class Imbalance,Retinal Diseases,Computer Vision"
                     data-authors="Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03891v1.html">Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hlali Azzeddine, Majid Ben Yakhlef, Soulaiman El Hazzat
                </div>

                <div class="paper-summary">
                    This paper introduces Class-Based Image Composition (CoImg) to address challenges of small and imbalanced datasets in deep learning diagnostics. By fusing multiple images of the same class into composite inputs, the method enhances intra-class variance and information density, leading to significantly improved diagnostic performance on an Optical Coherence Tomography (OCT) retina dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnostics</span>
                    
                    <span class="domain-tag">Retinal Disease Diagnosis</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03891v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03891v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03891v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03891v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03890v1"
                     data-domains="Cardiovascular Imaging,Cardiology,Cardiovascular Surgery,Medical Biomechanics,Radiology"
                     data-keywords="Aortic valve,Finite Element Meshing,Deep Learning,Shape Deformation Networks,CT imaging,Quadrilateral meshes,Biomechanical analysis,Patient-specific simulation"
                     data-authors="Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03890v1.html">Shape Deformation Networks for Automated Aortic Valve Finite Element Meshing from 3D CT Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Linchen Qian, Jiasong Chen, Ruonan Gong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning-based template-fitting pipeline to generate structured quadrilateral meshes of aortic valves directly from 3D CT images. By employing a common quad mesh template, the method ensures uniform mesh topology and consistent correspondence across patients, leading to high-quality meshes and simplifying network training for biomechanical analysis and preoperative planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiovascular Imaging</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Medical Biomechanics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03890v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03890v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03890v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03890v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03873v1"
                     data-domains="Oncology,Immunology,Cellular Therapy,Cancer Therapy,Systems Biology in Medicine"
                     data-keywords="CAR T cells,mathematical modeling,immunotherapy,translational research,predictive design,multiscale modeling,synthetic biology,precision oncology"
                     data-authors="Lucas E Sant'Anna,Rohita Roy,Janella C Schwab,Julian I Perez,Micha√´lle N Mayalu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03873v1.html">CAR T Cells from Code to Clinic: Framing Modeling Approaches with Current Translational Research Goals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.CB</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lucas E Sant'Anna, Rohita Roy, Janella C Schwab et al.
                </div>

                <div class="paper-summary">
                    This perspective paper advocates for mathematical modeling as a critical framework to overcome translational bottlenecks in CAR T cell therapy, linking mechanistic understanding to design optimization and clinical application. It systematically evaluates current modeling approaches within the context of therapeutic challenges, highlighting their strengths, limitations, and data gaps while emphasizing their role in developing safer and more effective therapies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Cellular Therapy</span>
                    
                    <span class="domain-tag">Cancer Therapy</span>
                    
                    <span class="domain-tag">Systems Biology in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03873v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03873v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03873v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03873v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03855v1"
                     data-domains="Radiology,Medical Imaging,Infectious Diseases (COVID-19),Diagnostic AI"
                     data-keywords="Deep Learning,Out-of-Distribution Generalization,Noise Injection,Chest X-ray,COVID-19 Detection,Distribution Shift,Shortcut Learning,Medical Imaging"
                     data-authors="Duong Mai,Lawrence Hall">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03855v1.html">Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Duong Mai, Lawrence Hall
                </div>

                <div class="paper-summary">
                    This paper addresses the critical issue of Deep Learning (DL) models failing to generalize to out-of-distribution (OOD) medical imaging data, particularly for COVID-19 detection from Chest X-rays (CXRs), due to learning source-specific artifacts. The study proposes and empirically demonstrates that injecting fundamental noise (Gaussian, Speckle, Poisson, Salt and Pepper) during model training significantly improves OOD generalization, drastically reducing the performance gap between in-distribution and OOD evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Infectious Diseases (COVID-19)</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03855v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03855v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03855v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03855v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03831v1"
                     data-domains="Genomics,Systems Biology,Pharmacology,Epidemiology,Precision Medicine,Immunology,Disease Pathogenesis"
                     data-keywords="Causal structure learning,Higher-order interactions,Additive models,Causal additive model (CAM),Hypergraph,Identifiability,Causal inference,Machine learning"
                     data-authors="James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03831v1.html">Higher-Order Causal Structure Learning with Additive Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> James Enouen, Yujia Zheng, Ignavier Ng et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the gap in causal structure learning by explicitly treating higher-order interactions, extending the Causal Additive Model (CAM) to additive models with these complex mechanisms. It introduces a novel Directed Acyclic Hypergraph (Hyper DAG) representation and provides theoretical tools, identifiability results, and an extended greedy algorithm for learning these structures, demonstrating its empirical utility in synthetic experiments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03831v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03831v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03831v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03831v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03806v1"
                     data-domains="Intensive Care Unit (ICU),Sepsis,Clinical Natural Language Processing (NLP),Biomedical Informatics,Patient Privacy,Medical Machine Learning"
                     data-keywords="Differential Privacy,Foundation Models,Feature Imputation,Privacy-Preserving Machine Learning,Sepsis Prediction,Clinical Notes,Privacy-Utility Trade-off,Medical Data Privacy"
                     data-authors="Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03806v1.html">FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Linghui Zeng, Ruixuan Liu, Atiquer Rahman Sarkar et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FusionDP, a novel two-step framework designed to enhance model utility in differentially private learning when only a subset of features are sensitive. It leverages large foundation models to impute sensitive features as external priors, followed by a modified DP-SGD algorithm that trains models on both original and imputed features while formally preserving privacy. FusionDP significantly improves model performance and the privacy-utility trade-off on tasks like sepsis prediction and clinical note classification compared to existing privacy-preserving baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Sepsis</span>
                    
                    <span class="domain-tag">Clinical Natural Language Processing (NLP)</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                    <span class="domain-tag">Patient Privacy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03806v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03806v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03806v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03806v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03771v1"
                     data-domains="Breast histopathology,Diagnostic pathology,General medical image analysis,Oncology"
                     data-keywords="Medical imaging,Contrastive learning,Self-supervised learning,Hierarchical classification,Label taxonomy,Representation learning,Histopathology,Deep learning"
                     data-authors="Alif Elham Khan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03771v1.html">Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alif Elham Khan
                </div>

                <div class="paper-summary">
                    This paper introduces a novel hierarchy-preserving contrastive learning framework that explicitly integrates taxonomic label structures into self-supervised learning for medical imaging. By employing Hierarchy-Weighted Contrastive (HWC) and Level-Aware Margin (LAM) objectives, the approach consistently improves representation quality and ensures better alignment with medical taxonomies across various benchmarks, including breast histopathology. The framework offers a simple and general recipe for learning high-performance and interpretable medical image representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Breast histopathology</span>
                    
                    <span class="domain-tag">Diagnostic pathology</span>
                    
                    <span class="domain-tag">General medical image analysis</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03771v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03771v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03771v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03771v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03693v1"
                     data-domains="Oncology,Pathology,Gastroenterology,Medical Imaging,Digital Health"
                     data-keywords="Federated Learning,Colorectal Cancer,Histopathological Grading,Deep Learning,Multi-Scale Analysis,Digital Pathology,Privacy-Preserving AI,Prognosis"
                     data-authors="Md Ahasanul Arafath,Abhijit Kumar Ghosh,Md Rony Ahmed,Sabrin Afroz,Minhazul Hosen,Md Hasan Moon,Md Tanzim Reza,Md Ashad Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03693v1.html">Colorectal Cancer Histopathological Grading using Multi-Scale Federated Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md Ahasanul Arafath, Abhijit Kumar Ghosh, Md Rony Ahmed et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a privacy-preserving federated learning framework for colorectal cancer (CRC) histopathological grading. It leverages a dual-stream ResNetRS50 architecture for multi-scale feature learning and FedProx for stable distributed training, achieving 83.5% overall accuracy and significantly improving Grade III tumor identification with an 87.5% recall, thus enhancing prognostic accuracy while adhering to data privacy regulations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03693v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03693v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03693v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03693v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03677v1"
                     data-domains="q-bio.PE"
                     data-keywords="q-bio.PE,math.DS,34C25, 34D23, 92D25"
                     data-authors="Ailin Zhang,Shigui Ruan,Xi Huo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03677v1.html">Impact of Resistance Development Mechanisms on Antibiotic Treatment Outcomes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ailin Zhang, Shigui Ruan, Xi Huo
                </div>

                <div class="paper-summary">
                    Bacteria develop resistance to antibiotics through various mechanisms, with
the specific mechanism depending on the drug-bacteria pair. It remains unclear,
however, which resistance mechanism best supports favorable treatment outcomes,
specifically in clearing infections and inhibiting further resis...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.PE</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03677v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03677v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03677v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03677v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03675v1"
                     data-domains="Telemedicine,Electronic Health Records (EHR) systems,Clinical decision support,Patient privacy and data security,Mental health support (AI chatbots),Medical research data analytics"
                     data-keywords="side-channel attack,Large Language Models,privacy,metadata leakage,network surveillance,TLS encryption,packet analysis,healthcare security"
                     data-authors="Geoff McDonald,Jonathan Bar Or">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03675v1.html">Whisper Leak: a side-channel attack on Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Geoff McDonald, Jonathan Bar Or
                </div>

                <div class="paper-summary">
                    This paper introduces Whisper Leak, a side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. It achieves near-perfect classification (>98% AUPRC) across 28 popular LLMs, even identifying sensitive topics with 100% precision. The attack highlights a significant, industry-wide metadata leakage vulnerability, posing risks for users under network surveillance, with evaluated mitigation strategies proving incomplete.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) systems</span>
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                    <span class="domain-tag">Patient privacy and data security</span>
                    
                    <span class="domain-tag">Mental health support (AI chatbots)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03671v1"
                     data-domains="Neurology,Computational Neuroscience,Neurophysiology,Psychiatry (Computational)"
                     data-keywords="Chialvo neurons,neural coupling,chaotic dynamics,fractal basin boundaries,multistability,synchronization,final state sensitivity,neurological disease"
                     data-authors="Bennett Lamb,Brandon B. Le">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03671v1.html">Final state sensitivity and fractal basin boundaries from coupled Chialvo neurons</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ nlin.CD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bennett Lamb, Brandon B. Le
                </div>

                <div class="paper-summary">
                    This paper investigates the basin geometry and final state uncertainty in a system of two identical electrically asymmetrically coupled Chialvo neurons. It identifies that despite individual neurons being nonchaotic, the coupled system exhibits multistability with two qualitatively different attractors, predominantly chaotic, separated by a fractal basin boundary. This fractal boundary leads to extreme final state sensitivity, having significant implications for understanding neuronal synchronization, human behavior, and neurological disease.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Neurophysiology</span>
                    
                    <span class="domain-tag">Psychiatry (Computational)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03661v1"
                     data-domains="Digital Health,Medical Device Security,Hospital Information Systems,Patient Safety,Telemedicine"
                     data-keywords="Healthcare IoT,Anomaly Detection,Cyberattack Detection,Machine Learning,XGBoost,K-NN,Medical Device Security,Patient Safety"
                     data-authors="Mahek Desai,Apoorva Rumale,Marjan Asadinia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03661v1.html">SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahek Desai, Apoorva Rumale, Marjan Asadinia
                </div>

                <div class="paper-summary">
                    This study proposes SHIELD, a machine learning framework designed to detect both malicious cyberattacks and faulty device anomalies in healthcare IoT environments. By evaluating eight diverse machine learning models on a 200,000-record dataset, the research identifies highly efficient and accurate techniques for enhancing IoT-enabled healthcare security. The findings highlight XGBoost and KNN as top performers for anomaly and attack detection respectively, offering significant potential for safeguarding patient health and data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Medical Device Security</span>
                    
                    <span class="domain-tag">Hospital Information Systems</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03661v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03661v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03661v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03661v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03656v1"
                     data-domains="Medical Treatment,Healthcare Informatics,Clinical Natural Language Processing,Medical Knowledge Management"
                     data-keywords="Chinese NLP,Question Answering,Multi-Document QA,Medical Treatment,Document Comprehension,Knowledge Extraction,Fine-grained Evaluation,Dataset"
                     data-authors="Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03656v1.html">ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu et al.
                </div>

                <div class="paper-summary">
                    ChiMDQA introduces a novel Chinese Multi-Document Question Answering Dataset designed for various downstream NLP applications, encompassing six diverse domains including medical treatment. This dataset features 6,068 rigorously curated, high-quality QA pairs derived from long-form documents, further classified into ten fine-grained categories. It aims to provide a robust foundation for advancing Chinese QA, document comprehension, and knowledge extraction systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Treatment</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                    <span class="domain-tag">Clinical Natural Language Processing</span>
                    
                    <span class="domain-tag">Medical Knowledge Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03656v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03656v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03769v1"
                     data-domains="Surgery,Surgical Oncology,Medical Informatics,Artificial Intelligence in Healthcare,Surgical Data Science,Minimally Invasive Surgery"
                     data-keywords="Surgical AI,AI validation,Surgical video analysis,Delphi process,Validation pitfalls,Temporal dynamics,Hierarchical data,Clinical translation"
                     data-authors="Annika Reinke,Ziying O. Li,Minu D. Tizabi,Pascaline Andr√©,Marcel Knopp,Mika M. Rother,Ines P. Machado,Maria S. Altieri,Deepak Alapatt,Sophia Bano,Sebastian Bodenstedt,Oliver Burgert,Elvis C. S. Chen,Justin W. Collins,Olivier Colliot,Evangelia Christodoulou,Tobias Czempiel,Adrito Das,Reuben Docea,Daniel Donoho,Qi Dou,Jennifer Eckhoff,Sandy Engelhardt,Gabor Fichtinger,Philipp Fuernstahl,Pablo Garc√≠a Kilroy,Stamatia Giannarou,Stephen Gilbert,Ines Gockel,Patrick Godau,Jan G√∂deke,Teodor P. Grantcharov,Tamas Haidegger,Alexander Hann,Makoto Hashizume,Charles Heitz,Rebecca Hisey,Hanna Hoffmann,Arnaud Huaulm√©,Paul F. J√§ger,Pierre Jannin,Anthony Jarc,Rohit Jena,Yueming Jin,Leo Joskowicz,Luc Joyeux,Max Kirchner,Axel Krieger,Gernot Kronreif,Kyle Lam,Shlomi Laufer,Jo√´l L. Lavanchy,Gyusung I. Lee,Robert Lim,Peng Liu,Hani J. Marcus,Pietro Mascagni,Ozanan R. Meireles,Beat P. Mueller,Lars M√ºndermann,Hirenkumar Nakawala,Nassir Navab,Abdourahmane Ndong,Juliane Neumann,Felix Nickel,Marco Nolden,Chinedu Nwoye,Namkee Oh,Nicolas Padoy,Thomas Pausch,Micha Pfeiffer,Tim R√§dsch,Hongliang Ren,Nicola Rieke,Dominik Rivoir,Duygu Sarikaya,Samuel Schmidgall,Matthias Seibold,Silvia Seidlitz,Lalith Sharan,Jeffrey H. Siewerdsen,Vinkle Srivastav,Raphael Sznitman,Russell Taylor,Thuy N. Tran,Matthias Unberath,Fons van der Sommen,Martin Wagner,Amine Yamlahi,Shaohua K. Zhou,Aneeq Zia,Amin Madani,Danail Stoyanov,Stefanie Speidel,Danail A. Hashimoto,Fiona R. Kolbinger,Lena Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03769v1.html">Current validation practice undermines surgical AI development</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Annika Reinke, Ziying O. Li, Minu D. Tizabi et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical issue of inadequate validation practices in surgical AI development, which severely limits clinical adoption. It introduces the first comprehensive, expert-consensus-driven catalog of validation pitfalls in AI-based surgical video analysis, spanning data, metrics, and reporting. The study empirically demonstrates that current practices often neglect the temporal and hierarchical structure of surgical videos, leading to misleading results, and establishes a foundational framework for rigorous validation essential for safe clinical translation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Surgical Oncology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Healthcare</span>
                    
                    <span class="domain-tag">Surgical Data Science</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03595v1"
                     data-domains="Personalized Medicine,Clinical Decision Support Systems,Medical Robotics,Treatment Planning,Disease Management,Drug Discovery Optimization"
                     data-keywords="Reinforcement Learning,Q-learning,Tensor Decomposition,High-Dimensional,Sample Efficiency,Exploration Strategy,Regularization,Healthcare AI"
                     data-authors="Junyi Wu,Dan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03595v1.html">Tensor-Efficient High-Dimensional Q-learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junyi Wu, Dan Li
                </div>

                <div class="paper-summary">
                    This paper introduces Tensor-Efficient Q-Learning (TEQL), an algorithm designed to overcome challenges in high-dimensional reinforcement learning, particularly the curse of dimensionality and low sample efficiency in Q-learning. TEQL enhances low-rank tensor decomposition with novel exploration strategies and regularization mechanisms. Empirical results demonstrate TEQL's superior performance in sample efficiency and total rewards compared to conventional and deep RL methods, making it suitable for resource-constrained applications like healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Treatment Planning</span>
                    
                    <span class="domain-tag">Disease Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03595v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03595v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03595v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03595v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03767v1"
                     data-domains="Neurology,Neurosurgery,Traumatology,Radiology,Rehabilitation Medicine,Computational Neuroscience"
                     data-keywords="Traumatic Brain Injury,Phenotype Discovery,MRI,Brain Segmentation,Heterogeneity,Independent Component Analysis,Biomarkers,FITBIR"
                     data-authors="Adam M. Saunders,Michael E. Kim,Gaurav Rudravaram,Lucas W. Remedios,Chloe Cho,Elyssa M. McMaster,Daniel R. Gillis,Yihao Liu,Lianrui Zuo,Bennett A. Landman,Tonia S. Rex">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03767v1.html">Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Adam M. Saunders, Michael E. Kim, Gaurav Rudravaram et al.
                </div>

                <div class="paper-summary">
                    This research addresses the intrinsic heterogeneity of traumatic brain injury (TBI) by identifying shared structural injury patterns from a large, multi-site neuroimaging dataset. Utilizing T1-weighted MRI data from the FITBIR repository, the study harmonized images, segmented 132 brain regions, and identified significant volume differences in 37 regions between TBI patients and controls. Subsequent analysis revealed three distinct phenotype clusters of injury, providing objective imaging-based characterizations of TBI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Traumatology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03767v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03767v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03767v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03767v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03488v1"
                     data-domains="Sleep Medicine,Neurology,Clinical Neurophysiology,Diagnostic Imaging"
                     data-keywords="Automatic sleep staging,Polysomnography,Attention mechanism,Multimodal deep learning,Late fusion,Zero-shot generalization,Neural networks,Sleep disorders"
                     data-authors="Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03488v1.html">NAP: Attention-Based Late Fusion for Automatic Sleep Staging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvise Dei Rossi, Julia van der Meer, Markus H. Schmidt et al.
                </div>

                <div class="paper-summary">
                    This paper introduces NAP (Neural Aggregator of Predictions), an attention-based deep learning model designed for automatic sleep staging from heterogeneous polysomnography (PSG) data. NAP employs a novel tri-axial attention mechanism to intelligently combine prediction streams from frozen, pretrained single-channel models, achieving state-of-the-art zero-shot generalization across diverse datasets. This approach addresses the variability in PSG signal composition, channel availability, and acquisition protocols, enhancing the robustness and adaptability of automated sleep staging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03488v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03488v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03488v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03488v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-08 06:25:03</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>