<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">149</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Diagnostic Imaging (10), Oncology (9), Radiology (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (10)</option>
                        
                        <option value="Oncology">Oncology (9)</option>
                        
                        <option value="Radiology">Radiology (9)</option>
                        
                        <option value="Neurology">Neurology (7)</option>
                        
                        <option value="Geriatrics">Geriatrics (6)</option>
                        
                        <option value="Cardiology">Cardiology (6)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Neuroscience">Neuroscience (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (4)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.15640v1"
                     data-domains="Oncology,Gastroenterology,Diagnostic Radiology,Hepatology,Urology"
                     data-keywords="Ultrasound Strain Elastography,Unsupervised Deep Learning,Strain Estimation,Tissue Mechanics,Noise Suppression,Medical Imaging,Residual Learning,Deep Learning"
                     data-authors="Shourov Joarder,Tushar Talukder Showrav,Md. Kamrul Hasan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15640v1.html">Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shourov Joarder, Tushar Talukder Showrav, Md. Kamrul Hasan
                </div>

                <div class="paper-summary">
                    MUSSE-Net is a novel multi-stage, residual-aware unsupervised deep learning framework designed to improve Ultrasound Strain Elastography (USE) by robustly and consistently estimating tissue strain. It addresses key limitations like decorrelation noise, lack of ground truth, and inconsistent strain, achieving state-of-the-art performance with enhanced lesion-to-background contrast and noise suppression across diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15640v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15640v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15640v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15640v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15632v1"
                     data-domains="Cardiology,Telemedicine,Diagnostic Medicine,Medical Informatics,Preventive Cardiology"
                     data-keywords="ECG analysis,artificial intelligence,deep learning,cardiology,large-scale dataset,telehealth,diagnostic criteria,transfer learning"
                     data-authors="Petrus E. O. G. B. Abreu,Gabriela M. M. Paix√£o,Jiawei Li,Paulo R. Gomes,Peter W. Macfarlane,Ana C. S. Oliveira,Vinicius T. Carvalho,Thomas B. Sch√∂n,Antonio Luiz P. Ribeiro,Ant√¥nio H. Ribeiro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15632v1.html">CODE-II: A large-scale dataset for artificial intelligence in ECG analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Petrus E. O. G. B. Abreu, Gabriela M. M. Paix√£o, Jiawei Li et al.
                </div>

                <div class="paper-summary">
                    CODE-II is a new, large-scale, real-world dataset comprising over 2.7 million 12-lead ECGs from 2 million adult patients, featuring 66 cardiologist-validated, clinically meaningful diagnostic classes. AI models pre-trained on CODE-II demonstrated superior transfer performance on external benchmarks, outperforming alternatives trained on other, even larger, datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Preventive Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15632v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15632v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15632v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15632v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15617v1"
                     data-domains="Musculoskeletal Radiology,Orthopedics,Sports Medicine,Rheumatology,Emergency Medicine,Point-of-Care Imaging"
                     data-keywords="MRI,Zero Echo Time (ZTE),portable MRI,Halbach scanner,hard tissue imaging,musculoskeletal,quantitative imaging,low-field MRI,T1 mapping"
                     data-authors="Jose Borreguero,Luiz G. C. Santos,Lorena Vega Cid,Elisa Casta√±√≥n,Marina Fern√°ndez-Garc√≠a,Pablo Benlloch,Rub√©n Bosch,Jes√∫s Conejero,Pablo Garc√≠a-Crist√≥bal,Alba Gonz√°lez-Cebri√°n,Teresa Guallart-Naval,Eduardo Pall√°s,Laia Porcar,Lucas Swistunow,Jose Miguel Algar√≠n,Fernando Galve,Joseba Alonso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15617v1.html">Qualitative and quantitative hard-tissue MRI with portable Halbach scanners</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jose Borreguero, Luiz G. C. Santos, Lorena Vega Cid et al.
                </div>

                <div class="paper-summary">
                    This paper demonstrates the feasibility of performing high-quality in vivo imaging and quantitative relaxation mapping of both soft and hard tissues using low-cost, portable Halbach MRI scanners. It establishes a comprehensive methodological framework for artifact-free Zero Echo Time (ZTE) imaging in systems with strong field inhomogeneities, enabling clear visualization of musculoskeletal structures previously invisible at low fields and providing quantitative T1 measurements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Musculoskeletal Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15617v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15617v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15617v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15617v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15603v1"
                     data-domains="Radiology,Diagnostic Imaging,Anatomy,Oncology,Surgery"
                     data-keywords="Medical Image Segmentation,Deep Learning,Transformer,Deformable Attention,Semantic Segmentation,Decoupled Head,Object Queries,MaskMed"
                     data-authors="Bin Xie,Gady Agam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15603v1.html">MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bin Xie, Gady Agam
                </div>

                <div class="paper-summary">
                    MaskMed introduces a novel medical image segmentation method featuring a unified decoupled segmentation head that separates class-agnostic mask prediction from class label prediction using shared object queries. It also incorporates a Full-Scale Aware Deformable Transformer for efficient, spatially aligned fusion of multi-resolution features. This approach achieves state-of-the-art performance, significantly outperforming nnUNet on AMOS 2022 and BTCV datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15603v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15603v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15603v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15603v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15600v1"
                     data-domains="Spine Surgery,Neurosurgery,Orthopedic Surgery,Interventional Radiology,Diagnostic Imaging"
                     data-keywords="Ultrasound,X-ray,Multi-modal imaging,Deep learning,Vertebral reconstruction,Spinal procedures,Anatomical completion,Acoustic shadowing"
                     data-authors="Miruna-Alexandra Gafencu,Yordanka Velikova,Nassir Navab,Mohammad Farid Azampour">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15600v1.html">US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Miruna-Alexandra Gafencu, Yordanka Velikova, Nassir Navab et al.
                </div>

                <div class="paper-summary">
                    This paper introduces US-X Complete, a novel multi-modal deep learning method designed to overcome ultrasound's inherent limitation in visualizing complete vertebral anatomy due to acoustic shadowing. By leveraging complementary morphological information from a single X-ray image and 3D partial ultrasound data, the method significantly improves vertebral reconstruction, providing a more accurate and complete volumetric lumbar spine visualization without requiring preoperative CT registration.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Spine Surgery</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Orthopedic Surgery</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15600v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15600v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15600v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15600v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15599v1"
                     data-domains="Neuromuscular Diseases,Muscular Dystrophies,Regenerative Medicine,Immunology,Computational Biology"
                     data-keywords="muscular dystrophy,kinetic modeling,mean-field theory,Fokker-Planck equations,integro-differential equations,cell dynamics,regeneration,inflammation,inverse Gamma distribution"
                     data-authors="Tommaso Lorenzi,Horacio Tettamanti,Mattia Zanella">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15599v1.html">Kinetic and mean-field modeling of muscular dystrophies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ math.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tommaso Lorenzi, Horacio Tettamanti, Mattia Zanella
                </div>

                <div class="paper-summary">
                    This paper introduces a novel class of multi-scale models for understanding the cellular dynamics underlying muscular dystrophies. It develops a framework that progresses from integro-differential equations for statistical cell distributions to mean-field Fokker-Planck equations, and subsequently to a macroscopic model for mean cell densities and their variances. The research identifies quasi-equilibrium cell distribution functions as inverse Gamma distributions and proves long-time convergence to these states, offering new insights into the balance between muscle degeneration and regeneration.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuromuscular Diseases</span>
                    
                    <span class="domain-tag">Muscular Dystrophies</span>
                    
                    <span class="domain-tag">Regenerative Medicine</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15599v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15599v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15599v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15599v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15485v1"
                     data-domains="Neurology,Neuroscience,Speech Pathology,Diagnostic Medicine,Biomarker Discovery"
                     data-keywords="Parkinson's Disease,neurodegenerative disorder,voice analysis,spectral features,CustNetGC,Convolutional Neural Network,Grad-CAM,CatBoost,early diagnosis,biomarkers"
                     data-authors="Abishek Karthik,Pandiyaraju V,Dominic Savio M,Rohit Swaminathan S">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15485v1.html">A Novel CustNetGC Boosted Model with Spectral Features for Parkinson's Disease Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.SD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abishek Karthik, Pandiyaraju V, Dominic Savio M et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CustNetGC, a novel classification and visualization model combining a Convolutional Neural Network (CNN) with Custom Network Grad-CAM and CatBoost, for early Parkinson's Disease (PD) prediction. Utilizing spectral features (L-mHP and Spectral Slopes) extracted from voice recordings, the model achieved high diagnostic accuracy (99.06%) and provided interpretability for its predictions. The findings suggest a potential improvement in diagnostic accuracy and interpretability for PD detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Speech Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15485v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15485v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15485v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15485v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15481v1"
                     data-domains="Radiology,Pulmonology,Diagnostic Imaging,Oncology (lung cancer screening/diagnosis)"
                     data-keywords="Explainable AI,xAI,Medical Imaging,Synthetic Data,Lung Nodules,Attribute-based Reasoning,Diagnostic AI,Model Evaluation"
                     data-authors="Luisa Gall√©e,Yiheng Xiong,Meinrad Beer,Michael G√∂tz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15481v1.html">FunnyNodules: A Customizable Medical Dataset Tailored for Evaluating Explainable AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Luisa Gall√©e, Yiheng Xiong, Meinrad Beer et al.
                </div>

                <div class="paper-summary">
                    FunnyNodules introduces a novel, fully parameterized synthetic medical dataset designed to address the scarcity of reasoning-annotated datasets crucial for Explainable AI (xAI). It generates customizable lung nodule-like shapes with controllable visual attributes and predefined decision rules linking these attributes to diagnostic classes. This dataset enables systematic evaluation of whether AI models learn correct attribute-target relations and align their attention with relevant regions, thereby fostering the development of more trustworthy medical AI systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (lung cancer screening/diagnosis)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15481v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15481v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15481v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15481v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15464v1"
                     data-domains="Computational Pathology,Oncology,Tissue Biology,Molecular Diagnostics,Precision Medicine"
                     data-keywords="Histopathology,Spatial Transcriptomics,Multi-modal Learning,Contrastive Learning,Graph Neural Networks,Hierarchical Representations,Cell-Cell Interactions,Gene Expression Prediction"
                     data-authors="Dabin Jeong,Amirhossein Vahidi,Ciro Ram√≠rez-Su√°stegui,Marie Moullet,Kevin Ly,Mohammad Vali Sanian,Sebastian Birk,Yinshui Chang,Adam Boxall,Daniyal Jafree,Lloyd Steele,Vijaya Baskar MS,Muzlifah Haniffa,Mohammad Lotfollahi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15464v1.html">SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dabin Jeong, Amirhossein Vahidi, Ciro Ram√≠rez-Su√°stegui et al.
                </div>

                <div class="paper-summary">
                    SIGMMA proposes a novel multi-modal contrastive alignment framework to learn hierarchical representations of histopathology images and spatial transcriptome profiles across multiple scales, overcoming the limitations of single-scale approaches. By integrating multi-scale contrastive alignment and graph-based modeling of cell interactions, the framework significantly improves gene-expression prediction and cross-modal retrieval tasks, demonstrating better capture of cross-modal correspondences.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Tissue Biology</span>
                    
                    <span class="domain-tag">Molecular Diagnostics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15464v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15464v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15464v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15464v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15406v1"
                     data-domains="Gastroenterology (endoscopy),Radiology,Pathology (microscopy analysis),Surgery (pre-operative planning),Oncology"
                     data-keywords="Conformal prediction,semantic segmentation,false positives,confidence masks,medical imaging,risk-aware AI,polyp segmentation,statistical guarantees"
                     data-authors="Luca Mossina,Corentin Friedrich">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15406v1.html">Controlling False Positives in Image Segmentation via Conformal Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Luca Mossina, Corentin Friedrich
                </div>

                <div class="paper-summary">
                    This paper introduces a novel post-hoc framework for medical image segmentation that uses conformal prediction to construct confidence masks with distribution-free, image-level control of false-positive predictions. It provides explicit statistical guarantees on the proportion of false positives, enabling reliable and risk-aware segmentation without requiring retraining of the underlying deep learning model, as demonstrated on a polyp-segmentation benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology (endoscopy)</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology (microscopy analysis)</span>
                    
                    <span class="domain-tag">Surgery (pre-operative planning)</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15406v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15406v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15406v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15406v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15393v1"
                     data-domains="Neurology,Geriatrics,Neuroscience,Diagnostic Imaging,Artificial Intelligence in Medicine"
                     data-keywords="EEG,Brain Age,Anomaly Detection,Deep Learning,Interpretable AI,Alzheimer's Disease,Mild Cognitive Impairment,Transformer"
                     data-authors="Kunyu Zhang,Mingxuan Wang,Xiangjie Shi,Haoxing Xu,Chao Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15393v1.html">EVA-Net: Interpretable Brain Age Prediction via Continuous Aging Prototypes from EEG</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kunyu Zhang, Mingxuan Wang, Xiangjie Shi et al.
                </div>

                <div class="paper-summary">
                    EVA-Net is a novel framework designed for interpretable brain age prediction from EEG, addressing the challenges of imperfect medical data and the black-box nature of existing models. It recasts brain age as an anomaly detection problem, leveraging a Transformer for long EEG sequences, a Variational Information Bottleneck for robust representations, and a continuous prototype network to explicitly learn the normative healthy aging manifold. The model achieves state-of-the-art accuracy in healthy subjects and accurately identifies deviations in MCI and AD patients through elevated brain-age gaps and a novel Prototype Alignment Error.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15393v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15393v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15393v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15393v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15357v1"
                     data-domains="Cardiology,Geriatrics,Home Healthcare,Health Economics,Clinical Decision Support"
                     data-keywords="Heart Failure,Mortality Prediction,Machine Learning,LLM,Cost-Benefit Analysis,Decision Support System,Clinical Impact,Interpretability"
                     data-authors="Yinan Yu,Falk Dippel,Christina E. Lundberg,Martin Lindgren,Annika Rosengren,Martin Adiels,Helen Sj√∂land">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15357v1.html">Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline and Decision Support System for Heart Failure Mortality Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yinan Yu, Falk Dippel, Christina E. Lundberg et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Cost-Aware Prediction (CAP), a novel framework that integrates machine learning (ML) models with cost-benefit analysis, enhanced by Large Language Model (LLM) agents, to provide transparent and interpretable decision support for heart failure mortality prediction. It leverages Clinical Impact Projection (CIP) curves for population-level cost visualization and LLM agents for generating patient-specific cost-benefit descriptions, aiming to explicitly communicate value trade-offs in clinical practice. The system was developed using an XGBoost model predicting 1-year mortality in heart failure patients and was well-received by clinicians for its decision support value.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Home Healthcare</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15357v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15357v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15357v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15357v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15355v1"
                     data-domains="General Medicine,Clinical Informatics,Medical Education,Diagnostic Reasoning"
                     data-keywords="healthcare reasoning,medical QA,LLM benchmarking,medical datasets,biomedical NLP,Spanish language,multilingual AI,clinical decision support"
                     data-authors="Alexis Correa-Guill√©n,Carlos G√≥mez-Rodr√≠guez,David Vilares">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15355v1.html">HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alexis Correa-Guill√©n, Carlos G√≥mez-Rodr√≠guez, David Vilares
                </div>

                <div class="paper-summary">
                    HEAD-QA v2 is an expanded and updated multilingual healthcare multiple-choice reasoning dataset, now comprising over 12,000 questions derived from a decade of Spanish professional exams. This resource serves as a robust benchmark for evaluating Large Language Models (LLMs), demonstrating that model scale and intrinsic reasoning ability are the primary drivers of performance, with complex inference strategies yielding only limited additional gains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Diagnostic Reasoning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15355v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15355v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15355v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15355v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15312v1"
                     data-domains="Healthcare Logistics,Emergency Medical Services (EMS),Hospital Security,Public Health Preparedness,Disaster Response"
                     data-keywords="UAV detection,multimodal fusion,Transformer,aerial object recognition,radar,infrared,audio,deep learning"
                     data-authors="Mauro Larrat,Claudomiro Sales">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15312v1.html">A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognition Using Radar, Audio, and Video Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mauro Larrat, Claudomiro Sales
                </div>

                <div class="paper-summary">
                    This research introduces a novel multimodal Transformer model integrating radar, visual, infrared, and audio data for highly accurate UAV detection and aerial object recognition. The model achieves state-of-the-art performance in classification, demonstrating exceptional accuracy, precision, and recall while maintaining computational efficiency suitable for real-time applications. This offers a robust solution for complex airspace monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Logistics</span>
                    
                    <span class="domain-tag">Emergency Medical Services (EMS)</span>
                    
                    <span class="domain-tag">Hospital Security</span>
                    
                    <span class="domain-tag">Public Health Preparedness</span>
                    
                    <span class="domain-tag">Disaster Response</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15312v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15312v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15312v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15312v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15211v1"
                     data-domains="Clinical Informatics,Medical Natural Language Processing,Electronic Health Record Management,Biomedical Research,Public Health,Clinical Decision Support"
                     data-keywords="Clinical Named Entity Recognition,Zero-Shot Learning,Multi-Agent Systems,Ontology (SNOMED CT),Large Language Models (LLMs),Electronic Health Records (EHRs),Natural Language Processing (NLP),Medical Informatics"
                     data-authors="Xinli Tao,Xin Dong,Xuezhong Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15211v1.html">OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinli Tao, Xin Dong, Xuezhong Zhou
                </div>

                <div class="paper-summary">
                    OEMA is a novel zero-shot clinical Named Entity Recognition (NER) framework utilizing multi-agent collaboration and ontology-guided reasoning to overcome limitations of existing large language model (LLM) approaches. By integrating a self-annotator, an SNOMED CT-enhanced discriminator, and a predictor, OEMA achieves state-of-the-art exact-match performance on clinical datasets. It demonstrates near-supervised performance under related-match, offering an efficient solution for clinical information extraction without extensive manual annotation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                    <span class="domain-tag">Electronic Health Record Management</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15211v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15211v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15211v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15211v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15188v1"
                     data-domains="Neurology,Geriatrics,Psychiatry,Neuroimaging,Alzheimer's Disease,Cognitive Impairment,Autism Spectrum Disorder"
                     data-keywords="Brain Age Estimation,Structural MRI,Vision Transformer,Residual CNN,Neurodegeneration,Alzheimer's Disease,Explainable AI,Biomarker"
                     data-authors="Wasif Jalal,Md Nafiu Rahman,M. Sohel Rahman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15188v1.html">BrainRotViT: Transformer-ResNet Hybrid for Explainable Modeling of Brain Aging from 3D sMRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wasif Jalal, Md Nafiu Rahman, M. Sohel Rahman
                </div>

                <div class="paper-summary">
                    This paper introduces BrainRotViT, a novel hybrid Transformer-ResNet architecture for highly accurate and explainable brain age estimation from 3D structural MRI. The model achieves state-of-the-art performance and strong generalization, revealing significant associations between brain age gap and neurodegenerative/neurodevelopmental conditions, while providing interpretability through attention maps. It bridges the gap between CNN and transformer approaches for robust brain age prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Alzheimer's Disease</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15188v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15188v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15188v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15188v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15174v1"
                     data-domains="Rare Disease Research,Pharmacovigilance (Adverse Event Monitoring),Critical Care Medicine (ICU Monitoring),Medical Diagnostics (for rare conditions),Personalized Medicine,Neuroscience (e.g., rare seizure patterns in EEG)"
                     data-keywords="diffusion models,few-shot learning,time-series generation,synthetic data generation,anomaly detection,rare event modeling,predictive maintenance,medical data synthesis"
                     data-authors="Yi Xu,Zhigang Chen,Rui Wang,Yangfan Li,Fengxiao Tang,Ming Zhao,Jiaqi Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15174v1.html">FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yi Xu, Zhigang Chen, Rui Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FaultDiffusion, a novel diffusion model-based framework for few-shot fault time-series generation, primarily in industrial equipment monitoring. It addresses the critical challenge of data scarcity for rare fault events by employing a positive-negative difference adapter and a diversity loss, enabling the synthesis of highly authentic and diverse fault samples that significantly outperform traditional methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Disease Research</span>
                    
                    <span class="domain-tag">Pharmacovigilance (Adverse Event Monitoring)</span>
                    
                    <span class="domain-tag">Critical Care Medicine (ICU Monitoring)</span>
                    
                    <span class="domain-tag">Medical Diagnostics (for rare conditions)</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15174v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15174v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15174v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15174v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15159v1"
                     data-domains="Surgical Training,Medical Education,Minimally Invasive Surgery (implied by instrument tracking),Performance Assessment"
                     data-keywords="surgical training,natural language generation,surgical feedback,Instrument-Action-Target (IAT),GPT-4o,video analysis,medical education,AI in medicine"
                     data-authors="Firdavs Nasriddinov,Rafal Kocielnik,Anima Anandkumar,Andrew J. Hung">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15159v1.html">Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel structure-aware pipeline to automate natural-language surgical feedback generation, crucial for trainee skill development. By leveraging Instrument-Action-Target (IAT) triplets mined from real surgical transcripts to condition GPT-4o, the system significantly improves feedback fidelity and clinical relevance compared to generating feedback from video alone.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgical Training</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery (implied by instrument tracking)</span>
                    
                    <span class="domain-tag">Performance Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15159v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15159v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15159v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15159v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15151v1"
                     data-domains="Neurology,Neuro-oncology,Diagnostic Imaging,Radiology,Geriatrics"
                     data-keywords="Neuroimaging,Spatiotemporal Encoding,Dynamic Curriculum Learning,Brain Imaging,Alzheimer's Disease,Brain Tumor,Medical Diagnosis,Approximate Rank Pooling"
                     data-authors="Meihua Zhou,Xinyu Tong,Jiarui Zhao,Min Cheng,Li Yang,Lei Tian,Nan Wan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15151v1.html">DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Meihua Zhou, Xinyu Tong, Jiarui Zhao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DCL-SE, an end-to-end framework designed to overcome limitations in high-dimensional neuroimaging analysis for clinical diagnosis. It utilizes a novel Data-driven Spatiotemporal Encoding (DaSE) with Approximate Rank Pooling (ARP) to efficiently transform 3D brain data into compact 2D representations, combined with a dynamic curriculum learning strategy for refined feature extraction. Evaluated across diverse brain imaging tasks, DCL-SE consistently demonstrates superior accuracy, robustness, and interpretability, highlighting the value of compact, task-specific architectures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15151v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15151v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15151v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15151v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15132v1"
                     data-domains="Ophthalmology,Radiology,Dermatology,Pathology (implied for general medical image analysis)"
                     data-keywords="Active Learning,Medical Imaging,Multi-Strategy Fusion,Annotation Cost Reduction,Adaptive Learning,Deep Learning,Computer-Aided Diagnosis,Cyclical Learning"
                     data-authors="Nishchala Thakur,Swati Kochhar,Deepti R. Bathula,Sukrit Gupta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15132v1.html">WaveFuse-AL: Cyclical and Performance-Adaptive Multi-Strategy Active Learning for Medical Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nishchala Thakur, Swati Kochhar, Deepti R. Bathula et al.
                </div>

                <div class="paper-summary">
                    This paper introduces WaveFuse-AL, a novel active learning framework that adaptively fuses multiple established acquisition strategies (BALD, BADGE, Entropy, CoreSet) throughout the learning cycle. By integrating cyclical temporal priors with performance-driven adaptation, WaveFuse-AL dynamically adjusts strategy importance to reduce annotation costs. It consistently outperforms both single-strategy and alternating-strategy baselines across diverse medical imaging tasks, achieving statistically significant performance improvements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Pathology (implied for general medical image analysis)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15132v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15132v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15132v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15132v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15083v1"
                     data-domains="Cardiology (ECG/PPG anomaly detection),Neurology (EEG/EMG pattern analysis),Intensive Care Unit (ICU) Monitoring,Remote Patient Monitoring (RPM),Wearable Health Devices,Diabetes Management (glucose trends),Medical Device Fault Diagnosis"
                     data-keywords="time-series anomaly detection,Mamba,Kolmogorov-Arnold Network,Fourier transform,state-space model,patient monitoring,physiological data,predictive health analytics"
                     data-authors="Xiancheng Wang,Lin Wang,Rui Wang,Zhibo Zhang,Minghang Zhao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15083v1.html">Fourier-KAN-Mamba: A Novel State-Space Equation Approach for Time-Series Anomaly Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiancheng Wang, Lin Wang, Rui Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Fourier-KAN-Mamba, a novel hybrid state-space model designed for enhanced time-series anomaly detection, addressing the limitations of direct Mamba application in capturing complex temporal and nonlinear dynamics. The architecture integrates a Fourier layer for multi-scale frequency feature extraction, Kolmogorov-Arnold Networks (KAN) for superior nonlinear representation, and the Mamba selective state-space model for efficient long-sequence processing, augmented by a temporal gating mechanism. Extensive experiments on MSL, SMAP, and SWaT datasets demonstrate that Fourier-KAN-Mamba significantly outperforms current state-of-the-art approaches in anomaly detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology (ECG/PPG anomaly detection)</span>
                    
                    <span class="domain-tag">Neurology (EEG/EMG pattern analysis)</span>
                    
                    <span class="domain-tag">Intensive Care Unit (ICU) Monitoring</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring (RPM)</span>
                    
                    <span class="domain-tag">Wearable Health Devices</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15083v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15083v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15083v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15083v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15070v1"
                     data-domains="Epidemiology,Immunology,Public Health,Infectious Diseases,Healthcare Systems Management"
                     data-keywords="Respiratory Viruses,Seasonality,Antibody-Mediated Immunity,Antigenic Drift,Epidemiological Modeling,Hopf Bifurcation,Chaos,Resonance"
                     data-authors="Ruarai Tobin,James McCaw,Freya Shearer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15070v1.html">The role of antibody-mediated immunity in shaping the seasonality of respiratory viruses</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruarai Tobin, James McCaw, Freya Shearer
                </div>

                <div class="paper-summary">
                    This paper investigates how antibody waning and antigenic variation interact with seasonal forcing to shape the recurrent epidemics of respiratory viruses. Using an SIS immuno-epidemiological model, the authors reveal complex dynamics including multi-year periodicity, quasiperiodicity, and chaos when seasonal forcing is introduced, significantly influencing epidemic timing, magnitude, and cumulative infection burden.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Healthcare Systems Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15070v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15070v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15070v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15070v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15067v1"
                     data-domains="Oncology,Pathology,Gastroenterology,Precision Medicine,Bioinformatics"
                     data-keywords="Colorectal Cancer,Prognosis,Deep Learning,Histopathology,Multi-omics,Biomarker,MRPL37,Nomogram"
                     data-authors="Zisong Wang,Xuanyu Wang,Hang Chen,Haizhou Wang,Yuxin Chen,Yihang Xu,Yunhe Yuan,Lihuan Luo,Xitong Ling,Xiaoping Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15067v1.html">Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zisong Wang, Xuanyu Wang, Hang Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TDAM-CRC, a novel multiple instance learning model utilizing histopathological whole-slide images to significantly improve prognostic stratification in colorectal cancer (CRC), outperforming conventional clinical staging and state-of-the-art models. It further integrates multi-omics data to uncover underlying molecular mechanisms, identifying metabolic reprogramming and an immunosuppressive tumor microenvironment in high-risk subtypes, and validating MRPL37 as a key prognostic biomarker.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15067v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15067v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15067v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15067v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15062v1"
                     data-domains="Cardiology,Electrophysiology,Clinical Decision Support Systems,Medical Informatics"
                     data-keywords="arrhythmia classification,ECG,clinical decision support,temporal fusion network,attention mechanism,deep learning,cardiology,MIT-BIH database"
                     data-authors="Yun Kwan Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15062v1.html">Interpretable temporal fusion network of multi- and multi-class arrhythmia classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yun Kwan Kim
                </div>

                <div class="paper-summary">
                    This paper proposes an interpretable temporal fusion network designed to overcome challenges in arrhythmia classification from electrocardiograms (ECGs) due to varying arrhythmia lengths and onset times. The framework integrates local and global information extraction with attention-based fusion, achieving high accuracy in multi- and multi-class arrhythmia detection, classification, and precise timing of episodes on MIT-BIH databases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15062v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15062v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15062v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15062v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15057v1"
                     data-domains="Radiology,Diagnostic Imaging,Sonography,Medical AI,Anatomy"
                     data-keywords="Ultrasound Image Segmentation,Semi-Supervised Learning,Prompt Learning,Universal Segmentation,Medical Imaging,Deep Learning,Pseudo-Labeling,Multi-Task Learning"
                     data-authors="Yaxiong Chen,Qicong Wang,Chunlei Li,Jingliang Hu,Yilei Shi,Shengwu Xiong,Xiao Xiang Zhu,Lichao Mou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15057v1.html">ProPL: Universal Semi-Supervised Ultrasound Image Segmentation via Prompt-Guided Pseudo-Labeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yaxiong Chen, Qicong Wang, Chunlei Li et al.
                </div>

                <div class="paper-summary">
                    Existing ultrasound image segmentation methods are often highly specialized for specific anatomical structures, limiting their broad applicability in clinical settings. ProPL introduces a pioneering universal semi-supervised framework that addresses multiple organs and segmentation tasks simultaneously, leveraging both labeled and unlabeled data. It achieves this through prompt-guided dual decoders and an uncertainty-driven pseudo-label calibration module, outperforming state-of-the-art methods and establishing a new benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Sonography</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15057v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15057v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15057v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15057v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15048v1"
                     data-domains="Infectious Diseases,Critical Care Medicine,Hospital Management,Clinical Informatics,Public Health"
                     data-keywords="COVID-19,Length of Stay,Electronic Health Records,Imbalanced Classification,Oversampling,Artificial Neural Network,Bayesian Optimization,F1 Score"
                     data-authors="Zachariah Farahany,Jiawei Wu,K M Sajjadul Islam,Praveen Madiraju">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15048v1.html">Oversampling techniques for predicting COVID-19 patient length of stay</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zachariah Farahany, Jiawei Wu, K M Sajjadul Islam et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of predicting COVID-19 patient length of stay (LOS) as a measure of disease severity, particularly focusing on the inherent data imbalance where short stays are more common. The proposed methodology leverages synthetic oversampling techniques to balance the training data, subsequently employing an Artificial Neural Network (ANN) whose hyperparameters are optimized using Bayesian optimization, with the final model selected based on its F1 score.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Hospital Management</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15048v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15048v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15048v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15048v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14971v1"
                     data-domains="Radiation Oncology,Cardiology,Medical Physics,Oncology,Diagnostic Radiology"
                     data-keywords="Deep Learning,Cardiac Segmentation,Radiation Oncology,Cardiac Toxicity,LAD V15,Lung Cancer,Prospective Surveillance,AI in Medicine"
                     data-authors="Christian V. Guthier,Christopher E Kehayias,Cosmin Ciausu,Jordan O. Gasho,John He,Maria Oorloff,Samuel C. Zhang,Danielle S. Bitterman,Jeremy S. Bredfeldt,Kelly Fitzgerald,Benjamin H. Kann,David E. Kozono,Jennifer Steers,Marion Tonneau,Anju Nohria,Hugo J. W. L. Aerts,Katelyn M. Atkins,Raymond H. Mak">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14971v1.html">Clinical Validation and Prospective Deployment of an Automated Deep Learning-Based Coronary Segmentation and Cardiac Toxicity Risk Prediction System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christian V. Guthier, Christopher E Kehayias, Cosmin Ciausu et al.
                </div>

                <div class="paper-summary">
                    This paper presents the clinical validation and real-world deployment of an automated deep learning-based system for precise segmentation of cardiac substructures from CT scans and subsequent prediction of cardiac toxicity risk. The AI system demonstrated high geometric accuracy and dose-volume concordance, successfully reproduced known dose-outcome relationships for cardiac events, and proved effective in large-scale retrospective analysis and prospective real-time surveillance for identifying high-risk patients.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14971v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14971v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14971v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14971v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14962v1"
                     data-domains="Hematology,Pathology,Diagnostics,Geriatrics,Cell Biology"
                     data-keywords="Multi-fidelity neural networks,Red blood cell morphology,3D reconstruction,Erythrocyte disorders,Dissipative particle dynamics,Image analysis,Machine learning,Cellular aging"
                     data-authors="Haizhou Wen,He Li,Zhen Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14962v1.html">Reconstruction of three-dimensional shapes of normal and disease-related erythrocytes from partial observations using multi-fidelity neural networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.comp-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haizhou Wen, He Li, Zhen Li
                </div>

                <div class="paper-summary">
                    This study introduces a multi-fidelity neural network (MFNN) for reconstructing full three-dimensional (3D) erythrocyte (RBC) shapes from partial two-dimensional observations, such as microscope cross-sections. By fusing high-fidelity cross-sections with a low-fidelity reference and incorporating physical constraints, the MFNN achieves over 95% coordinate accuracy across diverse RBC morphologies. This capability enables precise quantitative analysis of RBC morphological parameters crucial for understanding aging and various blood disorders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Hematology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Cell Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14962v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14962v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14962v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14962v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14948v1"
                     data-domains="Surgery,Medical Robotics,Image-Guided Surgery,Rehabilitation,Biomechanics,Medical Imaging"
                     data-keywords="temporal synchronization,heterogeneous cameras,LED Clock,millisecond accuracy,multi-view 3D reconstruction,pose estimation,surgical recording,infrared imaging"
                     data-authors="Jaro Meyer,Fr√©d√©ric Giraud,Joschua W√ºthrich,Marc Pollefeys,Philipp F√ºrnstahl,Lilian Calvet">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14948v1.html">RocSync: Millisecond-Accurate Temporal Synchronization for Heterogeneous Camera Systems</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jaro Meyer, Fr√©d√©ric Giraud, Joschua W√ºthrich et al.
                </div>

                <div class="paper-summary">
                    RocSync addresses the critical challenge of spatiotemporal synchronization in heterogeneous multi-camera systems, particularly in unconstrained environments where traditional hardware synchronization is infeasible. It proposes a low-cost, general-purpose method leveraging a custom LED Clock with red and infrared LEDs to achieve millisecond-level temporal alignment, significantly improving downstream computer vision tasks like pose estimation and 3D reconstruction. The system was validated in large-scale surgical recordings, demonstrating superior performance and expanding access to advanced vision-based sensing in clinical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Image-Guided Surgery</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14948v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14948v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14948v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14948v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14939v1"
                     data-domains="Infectious Diseases,Public Health,Respiratory Medicine,Diagnostic Artificial Intelligence,Biomedical Engineering"
                     data-keywords="COVID-19 detection,audio models,deep learning,fine-tuning,generalization failure,demographic bias,AI in medicine,diagnostic tools"
                     data-authors="Daniel Oliveira de Brito,Let√≠cia Gabriella de Souza,Marcelo Matheus Gauy,Marcelo Finger,Arnaldo Candido Junior">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14939v1.html">Fine-tuning Pre-trained Audio Models for COVID-19 Detection: A Technical Report</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.SD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Oliveira de Brito, Let√≠cia Gabriella de Souza, Marcelo Matheus Gauy et al.
                </div>

                <div class="paper-summary">
                    This technical report evaluates pre-trained audio models (Audio-MAE, PANNs) for COVID-19 detection, employing strict demographic stratification on Coswara and COUGHVID datasets. It reveals moderate intra-dataset performance but severe cross-dataset generalization failure, highlighting that demographic leakage inflates performance metrics and balanced dataset sizes are currently insufficient for robust deep learning models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Respiratory Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Artificial Intelligence</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14939v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14939v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14939v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14939v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14936v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,cs.CL"
                     data-authors="Mathieu Dufour,Andrew Duncan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14936v1.html">How to Train Private Clinical Language Models: A Comparative Study of Privacy-Preserving Pipelines for ICD-9 Coding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mathieu Dufour, Andrew Duncan
                </div>

                <div class="paper-summary">
                    Large language models trained on clinical text risk exposing sensitive patient information, yet differential privacy (DP) methods often severely degrade the diagnostic accuracy needed for deployment. Despite rapid progress in DP optimisation and text generation, it remains unclear which privacy-pres...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14936v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14936v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14936v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14936v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14922v1"
                     data-domains="Neurology,Alzheimer's Disease,Neuroimaging,Computational Neuroscience,Geriatrics"
                     data-keywords="Causal Inference,Graph Neural Networks,Alzheimer's Disease,Structural Connectome,Do-calculus,Neuroimaging,Brain Regions,Confounders"
                     data-authors="Pranay Kumar Peddi,Dhrubajyoti Ghosh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14922v1.html">Integrating Causal Inference with Graph Neural Networks for Alzheimer's Disease Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pranay Kumar Peddi, Dhrubajyoti Ghosh
                </div>

                <div class="paper-summary">
                    This paper introduces Causal-GCN, a novel interventional graph convolutional framework that integrates do-calculus-based causal inference with deep graph learning for Alzheimer's disease (AD) analysis. It aims to identify brain regions exerting stable causal influence on AD progression by adjusting for confounders, providing interpretable causal effect rankings consistent with established AD neuropathology while achieving performance comparable to baseline GNNs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Alzheimer's Disease</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14922v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14922v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14922v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14922v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14918v1"
                     data-domains="Radiology,Pulmonology,Diagnostic Imaging,Medical AI"
                     data-keywords="Chest X-ray,Computed Tomography,World Model,Predictive Sensing,3D Reconstruction,Contrastive Learning,Representation Learning,Medical Imaging AI"
                     data-authors="Zefan Yang,Ge Wang,James Hendler,Mannudeep K. Kalra,Pingkun Yan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14918v1.html">X-WIN: Building Chest Radiograph World Model via Predictive Sensing</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zefan Yang, Ge Wang, James Hendler et al.
                </div>

                <div class="paper-summary">
                    This paper introduces X-WIN, a novel chest radiograph (CXR) world model designed to overcome the 2D limitations of CXRs by internalizing 3D volumetric knowledge from chest CT scans. X-WIN learns to predict latent 2D projections of CTs, incorporates real CXRs via masked image modeling, and demonstrates superior performance over existing foundation models on diverse downstream diagnostic tasks. Crucially, it also shows the capability to render 2D projections for reconstructing 3D CT volumes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14918v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14918v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14918v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14918v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14907v1"
                     data-domains="Anatomic Pathology,Oncology,Histopathology,Prognostics,Diagnostics,Molecular Pathology"
                     data-keywords="Computational Pathology,Multiple Instance Learning (MIL),Whole-Slide Images (WSIs),Pathology Foundation Models,Generalizability,Uncertainty Quantification,Clinical Inference,AI in Medicine"
                     data-authors="Xiangde Luo,Jinxi Xiang,Yuanfeng Ji,Ruijiang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14907v1.html">nnMIL: A generalizable multiple instance learning framework for computational pathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiangde Luo, Jinxi Xiang, Yuanfeng Ji et al.
                </div>

                <div class="paper-summary">
                    nnMIL is a novel multiple-instance learning (MIL) framework designed to overcome generalizability and reliability limitations of existing methods in computational pathology. It effectively aggregates rich patch-level features from foundation models into robust, slide-level clinical predictions. This framework demonstrates superior performance and strong cross-model generalization across 35 diverse clinical tasks, enhancing the practical deployment of AI in real-world settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Anatomic Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14907v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14907v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14907v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14907v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14900v1"
                     data-domains="Dermatology,Diagnostic Imaging,Artificial Intelligence in Medicine,Clinical Decision Support"
                     data-keywords="Dermatological Diagnosis,Vision-Language Models (VLMs),Clinical Reasoning,Reinforcement Learning (RL),Supervised Fine-Tuning (SFT),Differential Diagnosis (DDx),Trustworthy AI,Medical Imaging"
                     data-authors="Zehao Liu,Wejieying Ren,Jipeng Zhang,Tianxiang Zhao,Jingxi Zhu,Xiaoting Li,Vasant G. Honavar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14900v1.html">Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zehao Liu, Wejieying Ren, Jipeng Zhang et al.
                </div>

                <div class="paper-summary">
                    SkinR1 introduces a novel vision-language model designed for dermatological diagnosis, specifically addressing key limitations of existing models such as data heterogeneity, lack of reasoning rationales, and poor generalization. It integrates deep, textbook-based reasoning with reinforcement learning to provide trustworthy, grounded clinical reasoning. The model demonstrates superior diagnostic accuracy across multiple dermatology datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14900v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14900v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14900v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14900v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14872v1"
                     data-domains="Neuroscience,Neurology,Computational Neuroscience,Psychiatry"
                     data-keywords="Neuronal avalanches,Brain criticality,Maximum entropy models,Thermodynamics,Subcritical,Supercritical,Neuroscience,Computational neuroscience"
                     data-authors="T. S. A. N. Sim√µes,F. Lombardi,D. Plenz,H. J. Herrmann,L. de Arcangelis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14872v1.html">Maximum entropy models of neuronal populations at and off criticality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> T. S. A. N. Sim√µes, F. Lombardi, D. Plenz et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the relationship between neuronal avalanche criticality and thermodynamic signatures in Maximum Entropy (ME) models, finding that ME models can distinguish subcritical brain states from critical/supercritical ones. However, thermodynamic signatures of criticality derived from ME models are indistinguishable between critical and supercritical conditions, despite significant differences in underlying neuronal dynamics and functional performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14872v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14872v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14872v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14872v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14860v1"
                     data-domains="Dentistry,Oral and Maxillofacial Radiology,Diagnostic Imaging,Preventive Dentistry"
                     data-keywords="Dental Caries Segmentation,Panoramic Radiographs,Convolutional Neural Networks (CNNs),Vision Transformers,State-Space Models (Mamba),Medical Image Segmentation,Deep Learning Benchmarking,Early Diagnosis"
                     data-authors="Aashish Ghimire,Jun Zeng,Roshan Paudel,Nikhil Kumar Tomar,Deepak Ranjan Nayak,Harshith Reddy Nalla,Vivek Jha,Glenda Reynolds,Debesh Jha">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14860v1.html">When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aashish Ghimire, Jun Zeng, Roshan Paudel et al.
                </div>

                <div class="paper-summary">
                    This study performed the first comprehensive benchmarking of CNN, Vision Transformer, and State-Space Mamba architectures for automated dental caries segmentation on panoramic radiographs using the DC1000 dataset. Contrary to the growing trend towards complex attention-based models, the CNN-based DoubleU-Net significantly outperformed all Transformer and Mamba variants, achieving the highest segmentation metrics. These findings underscore that architecture-task alignment and domain-specific considerations are more critical than model complexity for effective medical image segmentation, particularly with limited data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Oral and Maxillofacial Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Dentistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14860v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14860v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14860v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14860v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14753v1"
                     data-domains="Remote Patient Monitoring,Wearable Health Technology,Smart Hospitals,Medical IoT (Internet of Things),Predictive Healthcare Analytics,Personalized Medicine"
                     data-keywords="Spatiotemporal modeling,Efficient AI,Data sparsity,ConvLSTM,Edge computing,Healthcare,Predictive analytics,Multi-objective optimization"
                     data-authors="Junfeng Wu,Hadjer Benmeziane,Kaoutar El Maghraoui,Liu Liu,Yinan Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14753v1.html">SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junfeng Wu, Hadjer Benmeziane, Kaoutar El Maghraoui et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SparseST, a novel framework designed to address the high computational cost of state-of-the-art spatiotemporal models like ConvLSTM, particularly for resource-constrained edge devices. SparseST pioneers in exploiting inherent data and feature sparsity to achieve computational efficiency while preserving model performance, a strategy largely overlooked in previous efficient AI research. The framework also features a multi-objective composite loss function to approximate the Pareto front, offering practitioners a guide to balance performance and efficiency based on specific deployment constraints.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Wearable Health Technology</span>
                    
                    <span class="domain-tag">Smart Hospitals</span>
                    
                    <span class="domain-tag">Medical IoT (Internet of Things)</span>
                    
                    <span class="domain-tag">Predictive Healthcare Analytics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14753v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14753v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14753v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14753v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14744v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG"
                     data-authors="Antonia Ebner,Christoph Bartmann,Sonja Topf,Sohvi Luukkonen,Johannes Schimunek,G√ºnter Klambauer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14744v1.html">Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Antonia Ebner, Christoph Bartmann, Sonja Topf et al.
                </div>

                <div class="paper-summary">
                    Deep learning's rise since the early 2010s has transformed fields like computer vision and natural language processing and strongly influenced biomedical research. For drug discovery specifically, a key inflection - akin to vision's "ImageNet moment" - arrived in 2015, when deep neural networks surp...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14744v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14744v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14744v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14744v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14826v1"
                     data-domains="Public Health,Infectious Disease Epidemiology,Microbiology,Genomics,Zoonoses,Food Safety"
                     data-keywords="NCBI,Genomic Metadata,Epidemiology,Enterobacterales,Surveillance,Outbreak Detection,Cross-species Transmission,EpiNCBI_V1"
                     data-authors="Bryan Harris,Majid Bani-Yaghoub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14826v1.html">Leveraging NCBI Genomic Metadata for Epidemiological Insights: Example of Enterobacterales</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bryan Harris, Majid Bani-Yaghoub
                </div>

                <div class="paper-summary">
                    This study demonstrates the underexplored epidemiological potential of NCBI genomic metadata by analyzing over 477,000 Enterobacterales records. It shows how NCBI data, compared to CDC NORS, offers broader host species insights, greater isolate diversity, and finer spatial-temporal resolution for infectious disease surveillance. These insights are facilitated by a newly developed open-source Python tool, EpiNCBI_V1, highlighting the value of integrating genomic repositories into public health analytics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Microbiology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Zoonoses</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14826v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14826v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14826v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14826v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14702v1"
                     data-domains="Cardiology,Cardiac Imaging,Radiology,Electrophysiology"
                     data-keywords="myocardial scar segmentation,LGE-MRI,ECG,multimodal deep learning,cardiac imaging,anatomical priors,Temporal Aware Feature Fusion,tissue viability"
                     data-authors="Farheen Ramzan,Yusuf Kiberu,Nikesh Jathanna,Meryem Jabrane,Vicente Grau,Shahnaz Jamil-Copley,Richard H. Clayton,Chen,Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14702v1.html">Seeing Beyond the Image: ECG and Anatomical Knowledge-Guided Myocardial Scar Segmentation from Late Gadolinium-Enhanced Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Farheen Ramzan, Yusuf Kiberu, Nikesh Jathanna et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel multimodal deep learning framework for accurate myocardial scar segmentation from late gadolinium-enhanced (LGE) cardiac MRI. It integrates ECG-derived electrophysiological information and anatomical priors with LGE-MRI data, utilizing a Temporal Aware Feature Fusion (TAFF) mechanism to handle non-simultaneous data acquisition. The method achieved substantial gains over image-only baselines, significantly improving Dice scores for scar segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiac Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14702v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14702v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14702v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14702v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14682v1"
                     data-domains="Preventive Medicine,Cardiology,Nephrology,Hepatology,Endocrinology,Public Health,Internal Medicine"
                     data-keywords="Machine Learning,Smoking Risk,Health Decline,Biomarkers,Random Forest,SHAP Analysis,Preventive Health,Early Detection"
                     data-authors="Vaskar Chakma,MD Jaheid Hasan Nerab,Abdur Rouf,Abu Sayed,Hossem MD Saim,Md. Nournabi Khan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14682v1.html">Machine Learning Models for Predicting Smoking-Related Health Decline and Disease Risk</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vaskar Chakma, MD Jaheid Hasan Nerab, Abdur Rouf et al.
                </div>

                <div class="paper-summary">
                    This study systematically evaluated machine learning models to assess smoking-related health risk using routine health screening data, aiming for earlier identification of health decline. The Random Forest model emerged as the most accurate (AUC 0.926), reliably distinguishing individuals based on health biomarkers, with blood pressure, triglycerides, liver enzymes, and serum creatinine identified as key predictive indicators.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14682v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14682v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14682v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14682v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14676v1"
                     data-domains="Drug Discovery,Immunotherapy,Oncology,Biologics Development,Structural Biology"
                     data-keywords="AlphaFold 3,Antibody-Antigen,CD47,Binding Affinity,Molecular Docking,Drug Development,Reverse Docking,AI for Structural Prediction"
                     data-authors="Yiyang Xu,Ziyou Shen,Yanqing Lv,Shutong Tan,Chun Sun,Juan Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14676v1.html">Exploring AlphaFold 3 for CD47 Antibody-Antigen Binding Affinity: An Unexpected Discovery of Reverse docking</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiyang Xu, Ziyou Shen, Yanqing Lv et al.
                </div>

                <div class="paper-summary">
                    This study investigates AlphaFold 3's (AF3) potential for predicting CD47 antibody-antigen complex structures and assessing binding affinity, aiming to facilitate antibody candidate pre-screening in drug development. While AF3 demonstrated promising capabilities for reliable structure and binding energy predictions for most subjects, an unexpected and nonrandom "reverse docking" phenomenon was discovered in a subset of antibodies, attributed to its revolutionary AI model architectures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Immunotherapy</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Biologics Development</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14676v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14676v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14676v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14676v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14669v1"
                     data-domains="Infectious Diseases,Pharmacology,Drug Development,Immunology,Systems Biology,Structural Biology"
                     data-keywords="Host-pathogen interactions,Hyperbolic graph embeddings,Deep learning,Graph neural networks,G-protein-coupled receptors (GPCRs),AlphaFold 3,Drug discovery,Interactome"
                     data-authors="Xiaoqiong Xia,Cesar de la Fuente-Nunez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14669v1.html">Hyperbolic Graph Embeddings Reveal the Host-Pathogen Interactome</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.MN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoqiong Xia, Cesar de la Fuente-Nunez
                </div>

                <div class="paper-summary">
                    This research introduces ApexPPI, a novel deep learning framework that utilizes hyperbolic graph embeddings and multi-task hyperbolic graph neural networks to map host-pathogen protein interactions. By integrating multimodal biological data, the model achieved significantly higher accuracy than previous methods, identifying thousands of high-confidence interactions, including many involving human GPCRs, which were partially validated by AlphaFold 3 structural modeling.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14669v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14669v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14669v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14669v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14663v1"
                     data-domains="Drug Discovery,Structural Biology,Pharmacology,Therapeutics,Biotechnology"
                     data-keywords="Peptide design,AI,Protein-peptide interaction,Drug discovery,Computational biology,Flow-matching,Therapeutics,Structural biology"
                     data-authors="Xiaoqiong Xia,Cesar de la Fuente-Nunez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14663v1.html">ApexGen: Simultaneous design of peptide binder sequence and structure for target proteins</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoqiong Xia, Cesar de la Fuente-Nunez
                </div>

                <div class="paper-summary">
                    ApexGen is a novel AI-based framework designed to simultaneously determine both the amino-acid sequence and the three-dimensional structure of peptide binders for specific protein targets. This unified approach generates tightly fitting, naturally-shaped peptides with strong predicted binding affinity, significantly accelerating the discovery of new peptide-based therapeutics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Therapeutics</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14663v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14663v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14663v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14663v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14649v1"
                     data-domains="Pulmonology,Radiology,Respiratory Medicine,Diagnostic Imaging,Computational Anatomy,Thoracic Surgery"
                     data-keywords="airway segmentation,CT,deep learning,nnU-Net,topology correction,discontinuity correction,lung analysis,biomarker extraction"
                     data-authors="John M. Oyer,Ali Namvar,Benjamin A. Hoff,Wassim W. Labaki,Ella A. Kazerooni,Charles R. Hatt,Fernando J. Martinez,MeiLan K. Han,Craig J. Galb√°n,Sundaresh Ram">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14649v1.html">RepAir: A Framework for Airway Segmentation and Discontinuity Correction in CT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> John M. Oyer, Ali Namvar, Benjamin A. Hoff et al.
                </div>

                <div class="paper-summary">
                    RepAir is a novel three-stage framework addressing the critical challenge of disconnected airway segmentations from CT scans, combining an nnU-Net with anatomically informed topology correction. It significantly improves airway tree completeness and consistency compared to existing U-Net methods, demonstrating superior performance on both healthy and pathological datasets. This framework resolves common issues of automated methods, providing more reliable anatomical models for quantitative analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Respiratory Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14649v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14649v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14649v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14649v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14638v1"
                     data-domains="Rare Diseases,Clinical Genetics,Diagnostic Medicine,Medical Informatics,Precision Medicine"
                     data-keywords="Rare Diseases,Large Language Models,Clinical Reasoning,Diagnosis,Electronic Health Records,Instruction Tuning,Graph-Grounded Retrieval,Decision Support"
                     data-authors="Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14638v1.html">A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tao Yang, Dandan Huang, Yunting Lin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces RareSeek R1, a specialized Large Language Model (LLM) designed for clinical reasoning and diagnosis of rare diseases, addressing the challenges of prolonged diagnostic odysseys and limitations of existing LLMs. RareSeek R1 achieves state-of-the-art accuracy on multicenter EHRs and public benchmarks, performing on par with experienced physicians, by integrating a domain-specific corpus, staged instruction tuning, chain-of-thought learning, and graph-grounded retrieval.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Genetics</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14638v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14638v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14638v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14638v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14619v1"
                     data-domains="Neurology,Rare Diseases,Clinical Decision Support,Personalized Medicine,Medical Diagnostics,Treatment Planning"
                     data-keywords="POMDP,Fuzzy Logic,EM Algorithm,Machine Learning,Healthcare,Limited Data,Myasthenia Gravis,MAP Estimation"
                     data-authors="Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14619v1.html">Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marco Locatelli, Arjen Hommersom, Roberto Clemens Cerioli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Fuzzy MAP EM algorithm, a novel approach that integrates expert knowledge into POMDP parameter learning through fuzzy pseudo-counts, reformulating the problem as a Maximum A Posteriori (MAP) estimation. It significantly outperforms the standard EM algorithm in medical simulations with limited and noisy data and successfully recovers a clinically coherent POMDP for Myasthenia Gravis. This method offers a data-efficient solution for robust modeling in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.14613v1"
                     data-domains="Oncology,Pathology,Neuroscience,Developmental Biology,Immunology,Personalized Medicine"
                     data-keywords="spatial transcriptomics,3D reconstruction,gene expression,histology,flow matching,deep learning,biomarker discovery,tissue organization"
                     data-authors="Mohammad Vali Sanian,Arshia Hemmat,Amirhossein Vahidi,Jonas Maaskola,Jimmy Tsz Hang Lee,Stanislaw Makarchuk,Yeliz Demirci,Nana-Jane Chipampe,Omer Bayraktar,Lassi Paavolainen,Mohammad Lotfollahi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.14613v1.html">3D-Guided Scalable Flow Matching for Generating Volumetric Tissue Spatial Transcriptomics from Serial Histology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-18</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Vali Sanian, Arshia Hemmat, Amirhossein Vahidi et al.
                </div>

                <div class="paper-summary">
                    HoloTea is a novel 3D-aware flow-matching framework that accurately infers spot-level gene expression to generate volumetric tissue spatial transcriptomics from serial H&E histology. It overcomes limitations of existing methods by explicitly using cross-section information through a ControlNet and a 3D-consistent prior, demonstrating improved accuracy and generalization across diverse tissue types and resolutions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Developmental Biology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.14613v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.14613v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.14613v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.14613v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-20 06:28:29</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>