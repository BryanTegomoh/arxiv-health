<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">146</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (14), Oncology (11), Diagnostic Imaging (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (14)</option>
                        
                        <option value="Oncology">Oncology (11)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (7)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (7)</option>
                        
                        <option value="Epidemiology">Epidemiology (5)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (5)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (4)</option>
                        
                        <option value="Medical Image Analysis">Medical Image Analysis (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.26783v1"
                     data-domains="Epidemiology,Clinical Trials,Pharmacoepidemiology,Health Policy Research,Public Health,Comparative Effectiveness Research,Precision Medicine"
                     data-keywords="Causal Inference,Average Treatment Effect,Riesz Regression,Density-Ratio Estimation,Targeted Maximum Likelihood Estimation,Balancing Weights,Debiased Machine Learning,Observational Studies"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26783v1.html">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper introduces a unified theoretical framework for causal inference, integrating various methods such as Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and matching estimators. It elucidates their interrelationships and equivalences, particularly in the context of Average Treatment Effect (ATE) estimation, by emphasizing the central roles of balancing weights (Riesz representers) and outcome regression functions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Health Policy Research</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26783v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26783v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26759v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Oncology"
                     data-keywords="CT reconstruction,deep learning,medical imaging,generalization,multi-organ,dataset,robustness,optimization-based methods"
                     data-authors="Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26759v1.html">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Multi-Organ Medical Image REconstruction (MORE) dataset, designed to overcome the poor generalization of current deep learning CT reconstruction methods to diverse anatomies and lesions. The dataset facilitates robust model training and rigorous generalization evaluation, demonstrating that comprehensive data and optimization-based methods significantly enhance model performance for unseen anatomical structures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26723v1"
                     data-domains="Personalized medicine,Precision health,Clinical decision support systems,Treatment optimization,Pharmacogenomics,Public health interventions"
                     data-keywords="Policy learning,Causal inference,Personalized medicine,Conditional Average Treatment Effect,Empirical Welfare Maximization,Machine learning,Treatment optimization,Convex optimization"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26723v1.html">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper unifies the two primary approaches in policy learning ‚Äì Empirical Welfare Maximization (EWM) and the plug-in approach based on Conditional Average Treatment Effect (CATE) estimation ‚Äì by demonstrating their exact mathematical equivalence through a reparameterization of the policy class. This unification yields shared theoretical guarantees and enables the development of a novel, convex, and computationally efficient regularization method for policy learning that bypasses the typically NP-hard combinatorial steps of EWM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Precision health</span>
                    
                    <span class="domain-tag">Clinical decision support systems</span>
                    
                    <span class="domain-tag">Treatment optimization</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26723v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26723v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26715v1"
                     data-domains="Diagnostics,Biomarker Discovery,Personalized Medicine,Metabolomics,Proteomics,Oncology,Pathology"
                     data-keywords="mass spectrometry,deep learning,foundation model,spectral identification,biological interpretation,spectral embeddings,disease diagnosis,clinical outcomes"
                     data-authors="Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26715v1.html">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Asher, Devesh Shah, Amy A. Caudy et al.
                </div>

                <div class="paper-summary">
                    LSM-MS2 is a large-scale deep learning foundation model trained on millions of mass spectrometry spectra, designed to learn a semantic chemical space. It achieves state-of-the-art performance in spectral identification, significantly improving accuracy for challenging compounds and increasing identifications in complex biological samples. Furthermore, LSM-MS2 generates rich spectral embeddings that facilitate direct biological interpretation, enabling differentiation of disease states and prediction of clinical outcomes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Metabolomics</span>
                    
                    <span class="domain-tag">Proteomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26703v1"
                     data-domains="Urology,Oncology,Diagnostic Imaging,Medical Artificial Intelligence,Radiology"
                     data-keywords="Prostate Cancer,Micro-ultrasound,Medical Foundation Models,AI,Diagnostic Systems,Prospective Study,Clinical Biomarkers,Machine Learning"
                     data-authors="Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26703v1.html">ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To et al.
                </div>

                <div class="paper-summary">
                    ProstNFound+ introduces a novel medical foundation model specifically adapted for prostate cancer detection using micro-ultrasound, demonstrating robust generalization in its initial prospective clinical validation. The model effectively integrates clinical biomarkers to provide interpretable heatmaps and risk scores for clinically significant PCa, showing consistent performance and strong alignment with established clinical protocols.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26703v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26703v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26703v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26703v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26700v1"
                     data-domains="Epidemiology,Pharmacoepidemiology,Health Informatics,Clinical Decision Support,Personalized Medicine,Outcomes Research"
                     data-keywords="Causal Machine Learning,Individualized Treatment Effects,Conditional Exchangeability,Negative Control Outcomes,Unmeasured Confounding,Observational Studies,Simulation Study,Personalized Medicine"
                     data-authors="Gerard T. Portela,Jason B. Gibbons,Sebastian Schneeweiss,Rishi J. Desai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26700v1.html">Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss et al.
                </div>

                <div class="paper-summary">
                    This simulation study evaluated causal machine learning (ML) models' performance for individualized treatment effect (ITE) prediction under violations of the conditional exchangeability assumption. It demonstrated that Causal Forest and X-learner models fail to accurately estimate ITEs and can produce misleading heterogeneity signals when this crucial assumption is violated. The research validated negative control outcomes (NCOs) as an effective diagnostic tool for detecting subgroup-specific unmeasured confounding, recommending their routine incorporation into causal ML workflows.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26700v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26700v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26700v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26700v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26685v1"
                     data-domains="Oncology,Immunotherapy,Vaccinology,Precision Medicine,Bioinformatics,Health Economics"
                     data-keywords="AI-to-clinical translation,Algorithm-to-Outcome Concordance (AOC),personalized neoantigen vaccines,melanoma,tumor mutational burden (TMB),clinical efficacy,regulatory standardization,cost-effectiveness"
                     data-authors="Xiyao Yu,Kai Fu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26685v1.html">A Proposed Framework for Quantifying AI-to-Clinical Translation: The Algorithm-to-Outcome Concordance (AOC) Metric</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiyao Yu, Kai Fu
                </div>

                <div class="paper-summary">
                    This paper proposes the Algorithm-to-Outcome Concordance (AOC) metric, a novel quantitative framework designed to evaluate the translational fidelity between AI-based neoantigen prediction models and observed clinical outcomes in personalized vaccines. Through simulated data from melanoma vaccine trials, the study demonstrates AOC's utility, revealing heterogeneous concordance and correlations with biomarkers, while offering a reproducible metric for future validation and regulatory standardization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunotherapy</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26685v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26685v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26685v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26685v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26683v1"
                     data-domains="Healthcare,Medical Question Answering,Clinical Decision Support (implied),Knowledge Management in Medicine"
                     data-keywords="Large Language Models (LLMs),Ontology Rules,Domain Adaptation,Healthcare AI,Medical QA,Self-Evolution,Knowledge Distillation,Low-Resource Learning"
                     data-authors="Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26683v1.html">Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingchen Tu, Zhiqiang Liu, Juan Li et al.
                </div>

                <div class="paper-summary">
                    Evontree proposes a novel framework for domain adaptation of Large Language Models (LLMs) in data-sensitive fields like healthcare by leveraging a small set of high-quality ontology rules. It systematically extracts, validates, and enhances domain knowledge within LLMs through a three-step process: ontology extraction, inconsistency detection, and self-distilled fine-tuning. This approach significantly improves LLM performance on medical QA benchmarks (up to 3.7% accuracy) without requiring extensive external datasets, proving effective for low-resource adaptation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare</span>
                    
                    <span class="domain-tag">Medical Question Answering</span>
                    
                    <span class="domain-tag">Clinical Decision Support (implied)</span>
                    
                    <span class="domain-tag">Knowledge Management in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26683v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26683v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26668v1"
                     data-domains="Cardiovascular Medicine,Neurology,Diagnostic Imaging,Preventive Medicine"
                     data-keywords="Zoeppritz equations,medical ultrasound,angle-dependent reflection,density-speed separation,subwavelength imaging,cerebrovascular accident,arterial plaque,AI in diagnosis"
                     data-authors="Harry G. Saavedra,Ramiro Moro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26668v1.html">Zoeppritz equations: from seismology to medical exploration</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Harry G. Saavedra, Ramiro Moro
                </div>

                <div class="paper-summary">
                    This paper investigates the application of Zoeppritz equations, traditionally used in seismology, to medical ultrasound for extracting richer information about tissue properties. It demonstrates the potential to differentiate between density and speed of sound mismatches using angle-dependent reflection coefficients and to detect subwavelength layer thicknesses by analyzing critical angles and waveform distortion at interfaces.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiovascular Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26668v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26668v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26668v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26668v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26635v1"
                     data-domains="Radiology,Oncology,Anatomy,Neurology,Cardiology,Diagnostic Imaging"
                     data-keywords="MRI segmentation,Segment Anything Model (SAM),deep learning,fine-tuning,medical imaging,generalization,diagnostic imaging,convolutional neural networks"
                     data-authors="Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26635v1.html">SAMRI: Segment Anything Model for MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhao Wang, Wei Dai, Thuy Thanh Dao et al.
                </div>

                <div class="paper-summary">
                    SAMRI introduces an MRI-specialized adaptation of the Segment Anything Model (SAM) for accurate and efficient medical image segmentation. By fine-tuning only SAM's mask decoder with a two-stage strategy on a large MRI dataset, SAMRI achieves state-of-the-art accuracy and robust generalization across diverse anatomical regions and pathologies. This approach significantly reduces training time and trainable parameters compared to full-model retraining.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26582v1"
                     data-domains="Medical Imaging,Radiology,Medical Diagnosis (potential for aiding)"
                     data-keywords="VQA,Cross-domain Adaptation,Medical Imaging,Deep Learning,Plug-and-Play,Domain Adaptation,LLMs,Hook Interface"
                     data-authors="Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26582v1.html">CATCH: A Modular Cross-domain Adaptive Template with Hook</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinjin Li, Yulie Lu, Jinghan Cao et al.
                </div>

                <div class="paper-summary">
                    CATCH is a novel plug-and-play framework designed to overcome the significant performance degradation of Visual Question Answering (VQA) models, such as LLaVA, when applied to out-of-domain data like medical imaging. It achieves this by decoupling visual and linguistic adaptation through a lightweight domain classifier and a dual adapter mechanism (Prompt and Visual Adapters), dynamically injected via a hook interface. The framework demonstrates consistent and substantial performance gains across diverse domain-specific VQA benchmarks, notably +2.6 VQA on MedVQA-RAD, without requiring retraining of the backbone VQA model.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Diagnosis (potential for aiding)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26568v1"
                     data-domains="Orthopedics,Pediatric Orthopedics,Radiology,Diagnostic Imaging,Medical Image Analysis,Artificial Intelligence in Medicine"
                     data-keywords="Spine segmentation,Ultrasound VPI,Scoliosis diagnosis,SA$^{2}$Net,Deep learning,Transformers,Medical imaging,Structure-affinity transformation"
                     data-authors="Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26568v1.html">SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao Xie, Zixun Huang, Yushen Zuo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SA$^{2}$Net (Scale-Adaptive Structure-Aware Network), a novel deep learning architecture designed for robust and accurate spine segmentation from ultrasound Volume Projection Imaging (VPI), which is critical for intelligent scoliosis diagnosis. SA$^{2}$Net addresses challenges in capturing global contextual knowledge and rich structural information of spine bones by incorporating a scale-adaptive complementary strategy and a structure-affinity transformation with a Transformer decoder. The proposed method demonstrates superior segmentation performance and adaptability across various backbones, enhancing its utility for advanced spinal image analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Pediatric Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26568v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26568v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26568v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26568v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26566v1"
                     data-domains="Diagnostic imaging,Personalized medicine,Rare disease diagnosis,Clinical decision support systems,Medical risk assessment,Predictive analytics in healthcare"
                     data-keywords="Multiclass classification,Machine Learning calibration,Local calibration,Proximity bias,Jensen-Shannon distance,Neural Networks,Healthcare AI,Trustworthy AI"
                     data-authors="Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26566v1.html">Multiclass Local Calibration With the Jensen-Shannon Distance</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cesare Barbera, Lorenzo Perini, Giovanni De Toni et al.
                </div>

                <div class="paper-summary">
                    This paper addresses a significant limitation in current multiclass machine learning calibration methods: 'proximity bias,' where predictions in sparse regions of the feature space are systematically miscalibrated, posing a major risk in high-stakes fields like healthcare. It introduces the formal concept of multiclass local calibration and proposes a novel method for Neural Networks that utilizes the Jensen-Shannon distance to align predicted probabilities with local estimates of class frequencies, empirically demonstrating its effectiveness in enhancing trustworthiness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Rare disease diagnosis</span>
                    
                    <span class="domain-tag">Clinical decision support systems</span>
                    
                    <span class="domain-tag">Medical risk assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26563v1"
                     data-domains="Radiation Oncology,Medical Physics,Gynecology Oncology,Head and Neck Oncology,Radiation Therapy Planning"
                     data-keywords="Volumetric Modulated Arc Therapy,VMAT,Fraction-variant,Direct Aperture Optimization,Dosimetric Quality,Delivery Efficiency,Gynecological Cancer,Head-and-Neck Cancer,Radiation Oncology"
                     data-authors="Nathan Torelli,Madalyne Day,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26563v1.html">Fraction-variant VMAT planning for patients with complex gynecological and head-and-neck cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Madalyne Day, Jan Unkelbach
                </div>

                <div class="paper-summary">
                    This paper introduces a novel fraction-variant VMAT planning approach where different optimal treatment plans are delivered in different fractions, optimized simultaneously based on their cumulative physical dose. The study demonstrates that this method significantly improves dosimetric quality, achieving better target coverage and reduced organ-at-risk dose for complex gynecological and head-and-neck cancers. Crucially, it achieves this while also reducing per-fraction delivery times compared to conventional fraction-invariant VMAT, addressing patient discomfort and motion concerns.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Gynecology Oncology</span>
                    
                    <span class="domain-tag">Head and Neck Oncology</span>
                    
                    <span class="domain-tag">Radiation Therapy Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26525v1"
                     data-domains="regenerative medicine,drug discovery,diagnostics,therapeutics,medical device development,precision medicine"
                     data-keywords="biological engineering,bioinspired engineering,biohybrid systems,artificial intelligence,data-driven discovery,healthcare innovation,regenerative medicine,biomedical education"
                     data-authors="Ulrike A. Nuber,Viktor Stein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26525v1.html">Biological Engineering: What does it mean? Where does it -- need to -- go?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ulrike A. Nuber, Viktor Stein
                </div>

                <div class="paper-summary">
                    This paper provides a comprehensive overview of biological engineering, an interdisciplinary field merging engineering and biology, and structures it into bioinspired, biological, and biohybrid approaches. It analyzes inherent challenges and opportunities, proposing data-driven discovery and artificial intelligence as crucial tools to overcome the lack of reductionist models. Furthermore, it addresses the necessary educational frameworks for a new generation of biological engineers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">regenerative medicine</span>
                    
                    <span class="domain-tag">drug discovery</span>
                    
                    <span class="domain-tag">diagnostics</span>
                    
                    <span class="domain-tag">therapeutics</span>
                    
                    <span class="domain-tag">medical device development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26501v1"
                     data-domains="Cardiology,Telemedicine,Preventive Medicine,Digital Health,Wearable Technology"
                     data-keywords="ECG classification,Out-of-Distribution detection,Unsupervised Anomaly Detection,Deep SVDD,Wearables,Cardiovascular Disease,Machine Learning,Resource-constrained devices"
                     data-authors="Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26501v1.html">Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mustafa Fuad Rifet Ibrahim, Maurice Meijer, Alexander Schlaefer et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical reliability challenges of deep learning-based ECG analysis on resource-constrained wearables, particularly concerning Out-of-Distribution (OOD) data such as unseen pathologies or noise. It proposes and evaluates lightweight Unsupervised Anomaly Detection (UAD) filters as an independent, upstream mechanism to robustly detect and mitigate OOD inputs. The study demonstrates that an optimized Deep SVDD filter, when integrated with a diagnostic classifier, significantly enhances classification accuracy by filtering OOD inputs, thus enabling safer and more reliable continuous cardiovascular monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Wearable Technology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26501v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26501v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26501v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26501v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26498v1"
                     data-domains="Radiology,Emergency Medicine,Neurology,Medical AI/Machine Learning,Clinical Informatics"
                     data-keywords="Large Language Model,LLM Ensemble,Clinical AI,Intracranial Hemorrhage,CT Head,AI Triage,Performance Assessment,Ground Truth"
                     data-authors="Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26498v1.html">A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Adam E. Flanders, Yifan Peng, Luciano Prevedello et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a multi-agent Large Language Model (LLM) framework designed to automatically assess the performance of a clinical AI triage tool for intracranial hemorrhage (ICH) detection. The study demonstrated that an ensemble of LLMs provides a more consistent and reliable method for retrospective evaluation of clinical AI tools compared to using a single LLM alone, suggesting a scalable approach for AI performance validation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical AI/Machine Learning</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26494v1"
                     data-domains="Public Health,Health Communication,Behavioral Health,Digital Health,Epidemiology,Health Policy"
                     data-keywords="Social media,Agent-based modeling,LLM agents,Social influence,Health communication,Public health campaigns,Digital epidemiology,Simulation"
                     data-authors="Sadegh Shirani,Mohsen Bayati">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26494v1.html">Simulating and Experimenting with Social Media Mobilization Using LLM Agents</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.SI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sadegh Shirani, Mohsen Bayati
                </div>

                <div class="paper-summary">
                    This research paper introduces an agent-based simulation framework that uses heterogeneous LLM agents, realistic demographics, and authentic social network topology to model political mobilization on social media. The framework successfully reproduces qualitative patterns of mobilization observed in landmark field experiments, particularly demonstrating stronger effects from social messaging and measurable peer spillovers. It offers a controlled, reproducible environment for exploring counterfactual designs in social influence research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Health Communication</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26494v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26494v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26494v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26494v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26444v1"
                     data-domains="Pulmonology,Precision Medicine,Rare Diseases,Clinical Decision Support,Medical Informatics"
                     data-keywords="Personalized medicine,treatment outcome prediction,knowledge distillation,scarce data,precision medicine,chronic obstructive pulmonary disease,deep learning,adaptive fusion"
                     data-authors="Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26444v1.html">Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenjie Chen, Li Zhuang, Ziying Luo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Cross-Fidelity Knowledge Distillation and Adaptive Fusion Network (CFKD-AFN) to improve personalized treatment outcome prediction, particularly for small-sample and rare patient groups. CFKD-AFN addresses the scarcity of high-fidelity trial data by leveraging abundant low-fidelity simulation data through a dual-channel knowledge distillation and attention-guided fusion approach. The method demonstrates significant improvements in prediction accuracy and robustness, exemplified in chronic obstructive pulmonary disease (COPD) treatment outcomes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26444v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26444v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26444v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26411v1"
                     data-domains="Radiology,Medical Imaging,Chest Imaging,Diagnostic AI"
                     data-keywords="Medical AI,Interpretability,Sparse Autoencoders,MedCLIP,Vision-Language Models,Chest Radiographs,Mechanistic Interpretability,MedGEMMA"
                     data-authors="Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26411v1.html">MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riccardo Renzulli, Colas Lepoutre, Enrico Cassano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Medical Sparse Autoencoders (MedSAEs) to dissect the latent space of MedCLIP, a medical vision-language model, enhancing its interpretability. By applying MedSAEs, the authors achieve higher monosemanticity and interpretability of neurons compared to raw MedCLIP features, bridging high-performing medical AI with transparency for clinically reliable representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Chest Imaging</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26411v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26411v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26411v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26411v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26390v1"
                     data-domains="Radiology,Diagnostic Imaging,Oncology,Medical Image Analysis,Anatomy"
                     data-keywords="Multi-organ segmentation,Deep learning,Spatial prior,Cross dual encoder,Computer-aided diagnosis,Medical imaging,Attention mechanism,Semantic segmentation"
                     data-authors="Xizhi Tian,Changjun Zhou,Yulin. Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26390v1.html">SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xizhi Tian, Changjun Zhou, Yulin. Yang
                </div>

                <div class="paper-summary">
                    This paper introduces SPG-CDENet, a novel two-stage deep learning framework for multi-organ segmentation that addresses challenges posed by significant organ size and shape variations. It combines a spatial prior network for coarse localization with a cross dual encoder network featuring global and local encoders, symmetric cross-attention, and a flow-based decoder. The method demonstrates superior segmentation accuracy on public datasets, enhancing computer-aided diagnosis capabilities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26390v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26390v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26390v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26388v1"
                     data-domains="Nuclear Medicine,Medical Imaging,Neurology,Oncology"
                     data-keywords="PET imaging,Head motion correction,Positron emission tomography,Brain imaging,Motion tracking,22Na,Medical physics,Image quality"
                     data-authors="Machiel Kolstein,Mokhtar Chmeissani,Andreu Pacheco">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26388v1.html">Monitoring Head Movement in a Brain PET Scanner</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Machiel Kolstein, Mokhtar Chmeissani, Andreu Pacheco
                </div>

                <div class="paper-summary">
                    This paper presents a simulation study of CrowN@22, a novel head monitoring device designed to mitigate patient head movement artifacts during brain PET imaging. By utilizing crown-like rings of low-activity non-pure positron emitter sources (e.g., 22Na) and uniquely tagging their additional gamma photon emissions, the device aims to precisely track head movements with a superb signal-to-noise ratio. The simulation demonstrates the ability to detect movements with high precision (< 0.3 degrees or 0.5 mm) at a 1 Hz sampling rate, even in the presence of high brain activity, significantly improving PET image quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26388v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26388v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26388v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26388v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26350v1"
                     data-domains="Radiology,Pathology,Medical Image Classification,Medical Image Segmentation,Digital Health"
                     data-keywords="Federated Learning,Architectural Heterogeneity,Statistical Heterogeneity,Graph Neural Networks,Medical Imaging,Privacy-Preserving AI,Deep Learning,Equitable Federation"
                     data-authors="Furkan Pala,Islem Rekik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26350v1.html">UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Furkan Pala, Islem Rekik
                </div>

                <div class="paper-summary">
                    UnifiedFL introduces a novel dynamic federated learning framework designed to overcome significant limitations in existing FL approaches, particularly architectural heterogeneity, statistical heterogeneity, and domain-fracture across clients. It achieves this by representing diverse local neural networks as a directed model graph optimized by a shared graph neural network (GNN), incorporating distance-driven clustering and a two-tier aggregation policy. Experiments on MedMNIST and hippocampus segmentation benchmarks demonstrate UnifiedFL's superior performance in fostering equitable federation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Image Classification</span>
                    
                    <span class="domain-tag">Medical Image Segmentation</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26350v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26350v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26350v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26350v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26342v1"
                     data-domains="Pharmacology,Systems Biology,Drug Discovery,Personalized Medicine,Diagnostics,Disease Modeling"
                     data-keywords="Causal Discovery,Interventional Constraints,Linear Causal Models,Constrained Optimization,Causal Effects,Treatment Design,Biological Networks,Explainable AI"
                     data-authors="Zhigao Guo,Feng Dong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26342v1.html">Linear Causal Discovery with Interventional Constraints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhigao Guo, Feng Dong
                </div>

                <div class="paper-summary">
                    This paper introduces 'interventional constraints,' a novel concept in causal discovery that leverages high-level causal knowledge as inequality constraints on total causal effects between variable pairs. This approach aims to refine linear causal models by ensuring learned relationships are consistent with established scientific findings, thereby improving model accuracy and facilitating the discovery of new, otherwise costly, causal connections. The method proposes a metric for total causal effects and utilizes a two-stage constrained optimization to integrate these constraints.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26342v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26342v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26342v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26339v1"
                     data-domains="Diagnostic Imaging,Digital Pathology,Telemedicine,Pharmaceutical Information Systems,Health Informatics,Medical Device Labeling,Clinical Documentation"
                     data-keywords="Super-resolution,Scene-text,Optical Character Recognition (OCR),Diffusion Models,Vision-Language Models (VLM),Latent Diffusion,Image Enhancement,Medical Imaging"
                     data-authors="Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26339v1.html">GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingyu Sung, Seungjae Ham, Kangwoo Kim et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GLYPH-SR, a novel VLM-guided latent diffusion framework designed for image super-resolution that simultaneously optimizes for high visual quality and high-fidelity scene-text recovery. Addressing the common failure of previous SR models to accurately reconstruct text within natural images, GLYPH-SR leverages a Text-SR Fusion ControlNet and a ping-pong scheduler to achieve significant improvements in OCR F1 scores while maintaining competitive perceptual quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Pharmaceutical Information Systems</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26339v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26339v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26339v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26315v1"
                     data-domains="Ophthalmology,Diabetic Retinopathy,Medical Imaging,Diagnostic AI"
                     data-keywords="Diabetic Retinopathy,CNN,Vision Transformer,Hybrid Model,Feature Fusion,Theory of Evidence,Medical Image Analysis,Interpretability"
                     data-authors="Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26315v1.html">A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng et al.
                </div>

                <div class="paper-summary">
                    This research addresses the performance bottleneck of single-backbone automated Diabetic Retinopathy (DR) diagnosis systems by proposing a novel hybrid framework that combines Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). It introduces an evidential fusion paradigm, based on the theory of evidence, to adaptively integrate local and global features from different backbones. The proposed model achieves improved DR grading accuracy and enhanced interpretability on public datasets, surpassing existing state-of-the-art methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diabetic Retinopathy</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26272v1"
                     data-domains="Radiation Oncology,Medical Physics,Thoracic Oncology,Pulmonology"
                     data-keywords="NSCLC,Reirradiation,Non-coplanar radiotherapy,Beam orientation optimization,EQD2,OAR sparing,VMAT,Thoracic radiotherapy"
                     data-authors="Nathan Torelli,Jonas Willmann,Katja Daehler,Madalyne Day,Nicolaus Andratschke,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26272v1.html">Simultaneous optimization of non-coplanar beam orientations and cumulative EQD2 distribution for high-dose reirradiation of locoregionally recurrent non-small cell lung cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Jonas Willmann, Katja Daehler et al.
                </div>

                <div class="paper-summary">
                    This study developed an EQD2-based direct aperture optimization algorithm for non-coplanar beam orientation in high-dose reirradiation of locoregionally recurrent non-small cell lung cancer (NSCLC). It showed that non-coplanar planning could reduce maximum cumulative equivalent dose in 2 Gy fractions (EQD2) to critical organs-at-risk (OARs) like the bronchial tree, esophagus, thoracic wall, and trachea by at least 5 Gy2 in challenging cases. This was achieved without compromising target coverage or lung EQD2, suggesting an improved therapeutic window for these complex treatments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Thoracic Oncology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26272v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26272v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26272v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26272v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26188v1"
                     data-domains="Healthcare Quality Management,Health Economics,Hospital Administration,Population Health Management,Clinical Risk Stratification,Public Health Policy"
                     data-keywords="Hospital Readmissions,Machine Learning,Medical Claims Data,Random Forest,Principal Component Analysis,Area Under Curve,Predictive Analytics,Healthcare Quality"
                     data-authors="Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26188v1.html">Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Avinash Kadimisetty, Arun Rajagopalan, Vijendra SK
                </div>

                <div class="paper-summary">
                    This paper leverages machine learning techniques, including Logistic Regression, Random Forest, and Support Vector Machines, to predict all-cause hospital readmissions using high-dimensional medical claims data. The study employed Principal Component Analysis (PCA) for dimensionality reduction and identified Random Forest as the best-performing model based on the Area Under Curve (AUC) metric.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Quality Management</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                    <span class="domain-tag">Hospital Administration</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                    <span class="domain-tag">Clinical Risk Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26188v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26188v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26188v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26151v1"
                     data-domains="Radiology,Oncology,Medical Imaging,Diagnostic Medicine"
                     data-keywords="mammography,breast cancer,vision-language model,multi-view,self-supervision,risk prediction,synthetic reports,CAD"
                     data-authors="Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26151v1.html">MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MV-MLM, a novel Multi-View Mammography and Language Model, designed to enhance breast cancer diagnosis and risk prediction. By utilizing multi-view mammograms paired with synthetic radiology reports, and employing cross-modal self-supervision and joint visual-textual learning, MV-MLM achieves state-of-the-art performance. The model demonstrates high data efficiency across malignancy classification, subtype classification, and image-based cancer risk prediction without requiring actual expert-annotated reports.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26151v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26151v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26151v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26148v1"
                     data-domains="Geriatrics,Telemedicine,Rehabilitation,Remote Patient Monitoring,Smart Home Healthcare,Preventive Care"
                     data-keywords="Human Activity Recognition,Wi-Fi CSI,Edge AI,Privacy-Preserving,Energy-Efficient,Gated Recurrent Unit (GRU),Healthcare Monitoring,Embedded Systems"
                     data-authors="Kexing Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26148v1.html">STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kexing Liu
                </div>

                <div class="paper-summary">
                    STAR is an edge-AI framework designed for real-time, energy-efficient Human Activity Recognition (HAR) using Wi-Fi Channel State Information (CSI) on low-power embedded devices. It integrates a lightweight Gated Recurrent Unit (GRU)-based neural network, multi-stage signal processing, and hardware-aware co-optimization, achieving high accuracy (93.52% for activities, 99.11% for presence) with significant computational efficiency and privacy preservation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Smart Home Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26148v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26148v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26148v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26148v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26083v1"
                     data-domains="Magnetic Resonance Imaging (MRI),Radiology,Medical Diagnostics,Medical Imaging"
                     data-keywords="Specialized Generalist Models (SGM),Large Language Models (LLM),Task-Aware Memory,Magnetic Resonance Imaging (MRI),Image Reconstruction,Clinical Reports,Deep Learning,Domain Adaptation"
                     data-authors="Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26083v1.html">Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhua Jiang, Shuang Cheng, Yihao Liu et al.
                </div>

                <div class="paper-summary">
                    Nirvana is a Specialized Generalist Model (SGM) that introduces a novel task-aware memory mechanism for enhanced adaptability and performance. It achieves competitive results on general language tasks and demonstrates superior performance in challenging medical domains, specifically high-quality MRI reconstruction and accurate preliminary clinical report generation, even with a frozen foundational backbone.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26083v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26083v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26083v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26083v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26049v1"
                     data-domains="Pediatric Orthopedics,Diagnostic Radiology,Emergency Medicine,Musculoskeletal Imaging"
                     data-keywords="Ultrasound Segmentation,In-Context Learning (ICL),Pediatric Fractures,Deep Learning,Bony Region Segmentation,Data Efficiency,Medical Imaging,Musculoskeletal Ultrasound"
                     data-authors="Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26049v1.html">FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuyue Zhou, Jessica Knight, Shrimanti Ghosh et al.
                </div>

                <div class="paper-summary">
                    FlexICL introduces a novel and flexible in-context learning (ICL) framework for highly efficient segmentation of bony regions in pediatric elbow and wrist ultrasound (US) images. It significantly reduces the need for expert annotations, requiring only 5% of training images, while robustly outperforming state-of-the-art ICL and conventional deep learning models by 1-27% Dice coefficient across multiple datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatric Orthopedics</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Musculoskeletal Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26049v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26049v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26049v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26049v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26032v1"
                     data-domains="Endocrinology,Radiology,Oncology,Public Health,Internal Medicine,Clinical Informatics"
                     data-keywords="Artificial Intelligence,Natural Language Processing,Incidental Thyroid Findings,Radiology Reports,Thyroid Cancer,Overdiagnosis,Epidemiology,Clinical Cascade"
                     data-authors="Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26032v1.html">Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Felipe Larios, Mariana Borras-Osorio, Yuqi Wu et al.
                </div>

                <div class="paper-summary">
                    This study developed an AI-enabled natural language processing (NLP) pipeline to analyze radiology reports for incidental thyroid findings (ITFs). It found ITFs in 7.8% of over 115,000 patients, showing these findings often trigger a cascade of investigations leading to the diagnosis of small, low-risk thyroid cancers, contributing significantly to overdiagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26032v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26032v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26032v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26032v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26014v1"
                     data-domains="Oncology,Prognostics,Clinical Research,Biomedical Research"
                     data-keywords="Survival Analysis,Mixture-of-Experts,Deep Learning,Discrete-Time,Patient Heterogeneity,Temporal Dynamics,Breast Cancer,C-index"
                     data-authors="Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26014v1.html">Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hyeonjun Lee, Hyungseob Shin, Gunhee Nam et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel dual Mixture-of-Experts (MoE) framework designed for discrete-time survival analysis, aiming to precisely model patient heterogeneity and temporal risk dynamics. The framework integrates a feature-encoder MoE for subgroup-aware representation learning with a hazard MoE that leverages time embeddings to capture temporal patterns. Evaluated on breast cancer datasets, the method significantly boosts the time-dependent C-index by up to 0.04, demonstrating consistent performance improvements and further gains when integrated into the Consurv framework.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26014v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26014v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26014v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26014v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26004v1"
                     data-domains="Emergency Medicine,Public Health,Trauma Surgery,Prehospital Care,Critical Care Transport"
                     data-keywords="Drone,AI,Traffic Incident Detection,Real-time,Deep Learning,Thermal Imaging,Emergency Response,Public Health,Trauma Care"
                     data-authors="Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26004v1.html">DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.RO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bai Li, Achilleas Kourtellis, Rong Cao et al.
                </div>

                <div class="paper-summary">
                    DARTS is a novel drone-based, AI-powered system for real-time traffic incident detection, addressing the limitations of conventional methods like slow response times and infrastructure dependency. It integrates drone mobility, thermal imaging, and a lightweight deep learning framework to achieve high detection accuracy and provide rapid incident verification, severity assessment, and congestion monitoring. A field test demonstrated DARTS detected a collision 12 minutes earlier than existing systems, offering significant potential for faster emergency response and reducing crash-related injuries and fatalities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Trauma Surgery</span>
                    
                    <span class="domain-tag">Prehospital Care</span>
                    
                    <span class="domain-tag">Critical Care Transport</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26004v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26004v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26004v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25998v1"
                     data-domains="Neurology,Neurocritical Care,Anesthesiology,Rehabilitation Medicine,Developmental Neuroscience"
                     data-keywords="Integrated Information Theory,Consciousness,Phenomenal Experience,Cause-Effect Structure,Qualia,Disorders of Consciousness,Neuroscience,Clinical Assessment"
                     data-authors="Giulio Tononi,Melanie Boly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25998v1.html">Integrated Information Theory: A Consciousness-First Approach to What Exists</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Giulio Tononi, Melanie Boly
                </div>

                <div class="paper-summary">
                    Integrated Information Theory (IIT) posits a "consciousness-first" approach, deriving operational postulates of physical existence from the essential properties of phenomenal experience. It proposes that intrinsic existence, and thus consciousness, arises from an entity's specific, unitary, definite, and structured cause-effect power upon itself, with this underlying structure accounting for all aspects of experience, including qualia and spatio-temporal properties. This theoretical framework provides a principled method for understanding and assessing consciousness across biological and potentially artificial systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurocritical Care</span>
                    
                    <span class="domain-tag">Anesthesiology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Developmental Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25998v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25998v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25998v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25998v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25962v1"
                     data-domains="medical imaging,radiology,diagnostics,personalized medicine,computational biology,rare diseases"
                     data-keywords="neural networks,dataless training,optimization,medical image reconstruction,data scarcity,inverse problems,combinatorial optimization,machine learning"
                     data-authors="Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25962v1.html">On the Dataless Training of Neural Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvaro Velasquez, Susmit Jha, Ismail R. Alkhouri
                </div>

                <div class="paper-summary">
                    This paper surveys the emerging field of "dataless training" for neural networks, focusing on their application to optimization problems without requiring traditional training datasets. It examines how various NN architectures (MLP, CNN, GNN, QNN) re-parameterize problems, driven by the limitations of data-driven methods and inherent data scarcity in critical applications like medical image reconstruction. The paper defines and categorizes dataless settings, clarifying their distinctions from related machine learning paradigms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">medical imaging</span>
                    
                    <span class="domain-tag">radiology</span>
                    
                    <span class="domain-tag">diagnostics</span>
                    
                    <span class="domain-tag">personalized medicine</span>
                    
                    <span class="domain-tag">computational biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25962v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25962v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25962v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25962v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25954v1"
                     data-domains="Public Health,Epidemiology,Health Information Systems,Infectious Diseases (HIV, TB),Maternal and Child Health,Health Policy and Management"
                     data-keywords="Geospatial Foundation Models,Health Data Prediction,Low- and Middle-Income Countries,Malawi,XGBoost,Routine Health Information Systems,HIV,Child Vaccinations"
                     data-authors="Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25954v1.html">Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lynn Metz, Rachel Haggard, Michael Moszczynski et al.
                </div>

                <div class="paper-summary">
                    This study validated Geospatial Foundation Models (GeoFMs) for predicting 15 routine health programmatic outputs in Malawi, addressing the challenges of unreliable health data in low- and middle-income countries (LMICs). The research demonstrated that embedding-based GeoFM approaches, particularly a multi-source integration model, significantly improved prediction accuracy over traditional geostatistical methods for most indicators, offering a novel tool to strengthen constrained health information systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Information Systems</span>
                    
                    <span class="domain-tag">Infectious Diseases (HIV, TB)</span>
                    
                    <span class="domain-tag">Maternal and Child Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25954v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25954v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25954v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25954v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25944v1"
                     data-domains="Radiation Oncology,Urology,Medical Education,Medical Physics,Oncology"
                     data-keywords="virtual reality,HDR brachytherapy,prostate cancer,medical simulation,radiation oncology,surgical training,confidence assessment,Unreal Engine"
                     data-authors="Anton Varlukhin,Mackenzie Smith,Fahad Alam,Amandeep Tagger,Gerard Morton,Moti Paudel,Andrew Loblaw,Lucas Mendez,Douglas Hoover,Raffi Karshafian,Humza Nusrat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25944v1.html">Development and pilot evaluation of a virtual reality simulator for HDR prostate brachytherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anton Varlukhin, Mackenzie Smith, Fahad Alam et al.
                </div>

                <div class="paper-summary">
                    This paper details the development and pilot evaluation of a virtual reality (VR) simulator designed for High Dose Rate (HDR) prostate brachytherapy. The simulator, comprising patient preparation and template-guided needle insertion modules, significantly increased self-reported confidence among oncology staff and trainees across various procedural and equipment-related knowledge domains immediately after training.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25944v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25944v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25944v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25944v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25924v1"
                     data-domains="Epidemiology,Public Health Research,Pharmacovigilance,Clinical Trials,Precision Medicine,Comparative Effectiveness Research"
                     data-keywords="Causal Inference,Confounding,Proxy Variables,Domain Adaptation,Identifiability,Epidemiology,Transfer Learning,Estimation"
                     data-authors="Manuel Iglesias-Alonso,Felix Schur,Julius von K√ºgelgen,Jonas Peters">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25924v1.html">Transferring Causal Effects using Proxies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manuel Iglesias-Alonso, Felix Schur, Julius von K√ºgelgen et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenging problem of estimating a causal effect in multi-domain settings where the true confounder is unobserved and the causal effect may vary across domains. It proposes a novel methodology that leverages a proxy variable of the hidden confounder to achieve identifiability and consistent estimation of the causal effect in a target domain, even when only the proxy is observable there.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health Research</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25924v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25924v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25924v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25924v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25908v1"
                     data-domains="Clinical Decision Support,Drug Discovery,Biomedical Research,Public Health Informatics,Medical Ethics,Pathogen Genomics,Toxicology"
                     data-keywords="LLMs,Trustworthiness,Scientific Applications,Truthfulness,Adversarial Robustness,Scientific Safety,Scientific Ethics,Biosecurity,Benchmarking"
                     data-authors="Emily Herron,Junqi Yin,Feiyi Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25908v1.html">SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Emily Herron, Junqi Yin, Feiyi Wang
                </div>

                <div class="paper-summary">
                    This paper introduces SciTrust 2.0, a comprehensive framework designed to evaluate the trustworthiness of Large Language Models (LLMs) in scientific applications across four key dimensions: truthfulness, adversarial robustness, scientific safety, and scientific ethics. The evaluation of seven prominent LLMs revealed that general-purpose industry models significantly outperformed science-specialized models, which exhibited critical deficiencies in logical reasoning, ethical understanding, and safety, particularly in high-risk scientific domains like biosecurity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Public Health Informatics</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25908v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25908v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25908v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25908v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25867v1"
                     data-domains="Radiology,Pathology,Medical Imaging,Clinical Reasoning,Biomedical Literature Analysis,Medical Education"
                     data-keywords="Medical VQA,Large Multimodal Models,Data Synthesis,Generator-Verifier,PubMed Central,Medical Imaging,Reinforcement Learning,Open-source AI"
                     data-authors="Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25867v1.html">MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoke Huang, Ningsen Wang, Hui Liu et al.
                </div>

                <div class="paper-summary">
                    MedVLSynther introduces a rubric-guided generator-verifier framework for synthesizing high-quality, multiple-choice medical Visual Question Answering (VQA) items directly from open biomedical literature. Addressing the critical lack of large, high-quality training corpora, this framework produced MedSynVQA, a diverse dataset that significantly improved the accuracy of open-weight Large Multimodal Models (LMMs) on six medical VQA benchmarks, outperforming strong existing medical LMMs. The auditable, reproducible, and privacy-preserving methodology offers a scalable solution for medical AI data generation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Reasoning</span>
                    
                    <span class="domain-tag">Biomedical Literature Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25867v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25867v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25867v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25867v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25759v1"
                     data-domains="Radiology,Digital Pathology,Histopathology,Medical Image Analysis,Computational Pathology"
                     data-keywords="Multiple Instance Learning (MIL),Correlated MIL,Medical Imaging,Generalization Gaps,Contextual Information,Synthetic Data,Digital Pathology,Radiology"
                     data-authors="Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25759v1.html">Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ethan Harvey, Dennis Johan Loevlie, Michael C. Hughes
                </div>

                <div class="paper-summary">
                    This paper addresses a critical limitation in Multiple Instance Learning (MIL) for medical imaging, where contextual relationships between instances (e.g., adjacent patches or slices) are often ignored. By designing a synthetic classification task where context is crucial, the authors demonstrate that both conventional MIL and even newer correlated MIL methods struggle to generalize effectively compared to an optimal Bayes estimator.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25758v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Health,Telemedicine,Digital Therapeutics"
                     data-keywords="psychological counseling,large language models,AI agents,longitudinal therapy,emotional understanding,adaptive strategies,dual-loop architecture,therapeutic attunement"
                     data-authors="He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25758v1.html">TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> He Hu, Yucheng Zhou, Chiyuan Ma et al.
                </div>

                <div class="paper-summary">
                    TheraMind introduces a novel strategic and adaptive AI agent for longitudinal psychological counseling, addressing critical limitations of current large language models such as lack of emotional understanding, adaptive strategies, and multi-session memory. Its core innovation is a dual-loop architecture that separates tactical dialogue management from strategic therapeutic planning, enabling superior performance in simulated multi-session clinical scenarios. This design allows for dynamic response selection based on patient emotions and long-term adaptation of therapeutic methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25758v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25758v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25758v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25758v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25816v1"
                     data-domains="Clinical Informatics,Medical Documentation,Healthcare Analytics,EHR Systems,Clinical Decision Support"
                     data-keywords="Electronic Health Records,Clinical Natural Language Processing,Question Answering,Entity Aware Retrieval,Semantic Search,FHIR,Computational Efficiency,Large Language Models"
                     data-authors="Tarun Kumar Chawdhury,Jon D. Duke">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25816v1.html">Beyond Long Context: When Semantics Matter More than Tokens</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tarun Kumar Chawdhury, Jon D. Duke
                </div>

                <div class="paper-summary">
                    This paper introduces a Clinical Notes QA Evaluation Platform to validate the Clinical Entity Augmented Retrieval (CLEAR) method for semantic question answering over Electronic Health Records (EHR). It demonstrates that CLEAR significantly improves both efficiency and accuracy, achieving a 58.3% win rate and 78% token reduction compared to traditional methods, especially on long clinical notes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Documentation</span>
                    
                    <span class="domain-tag">Healthcare Analytics</span>
                    
                    <span class="domain-tag">EHR Systems</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25816v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25816v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25816v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25816v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25628v1"
                     data-domains="Clinical Informatics,Medical Artificial Intelligence,Health Data Science,Clinical Decision Support,Translational Medicine"
                     data-keywords="EHR,LLM,Reasoning,Foundational Model,Clinical Decision-Making,Instruction Dataset,Benchmark,Multi-stage Training"
                     data-authors="Yusheng Liao,Chaoyi Wu,Junwei Liu,Shuyang Jiang,Pengcheng Qiu,Haowen Wang,Yun Yue,Shuai Zhen,Jian Wang,Qianrui Fan,Jinjie Gu,Ya Zhang,Yanfeng Wang,Yu Wang,Weidi Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25628v1.html">EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yusheng Liao, Chaoyi Wu, Junwei Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EHR-R1, a reasoning-enhanced foundational language model designed for comprehensive Electronic Health Record (EHR) analysis, addressing limitations of current LLMs in clinical workflows. It leverages EHR-Ins, a novel, large-scale instruction dataset generated by a thinking-graph framework, and employs a multi-stage training paradigm. EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs, including GPT-4o and DeepSeek-V3, on a new benchmark, EHR-Bench, demonstrating significantly improved accuracy and reasoning capabilities for clinical tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Health Data Science</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Translational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25628v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25628v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25628v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25588v1"
                     data-domains="Psychiatry,Mental Health,Clinical Diagnostics,Digital Health"
                     data-keywords="Psychiatric Diagnosis,Large Language Models (LLMs),Decision Support System,Mental Health,AI in Medicine,Diagnostic Standardization,Consensus-based AI,eHealth"
                     data-authors="Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25588v1.html">Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eranga Bandara, Ross Gore, Atmaram Yarlagadda et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel AI-powered decision support system to standardize psychiatric diagnoses, addressing the subjectivity and variability inherent in current dialogue-based evaluations. It integrates a consortium of fine-tuned Large Language Models (LLMs) trained on psychiatrist-patient interactions with an OpenAI-gpt-oss reasoning LLM to achieve robust and highly accurate mental health assessments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25588v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25588v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25588v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25588v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-02 06:28:23</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>