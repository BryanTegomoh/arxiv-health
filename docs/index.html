<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">8</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">8</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">34</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (2), Diagnostic Imaging (2), Medical Informatics (2)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (2)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (2)</option>
                        
                        <option value="Medical Informatics">Medical Informatics (2)</option>
                        
                        <option value="Biomedical Engineering">Biomedical Engineering (2)</option>
                        
                        <option value="Public Health">Public Health (2)</option>
                        
                        <option value="Medical Imaging AI">Medical Imaging Ai (1)</option>
                        
                        <option value="Type 1 Diabetes">Type 1 Diabetes (1)</option>
                        
                        <option value="Endocrinology">Endocrinology (1)</option>
                        
                        <option value="Computational Medicine">Computational Medicine (1)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2601.11522v1"
                     data-domains="Radiology,Medical Imaging AI,Diagnostic Imaging,Medical Informatics"
                     data-keywords="Chest X-ray,Medical Foundation Model,Autoregression,Diffusion Models,Image Understanding,Image Generation,Cross-modal Attention,Deep Learning"
                     data-authors="Ruiheng Zhang,Jingfeng Yao,Huangxuan Zhao,Hao Yan,Xiao He,Lei Chen,Zhou Wei,Yong Luo,Zengmao Wang,Lefei Zhang,Dacheng Tao,Bo Du">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11522v1.html">UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruiheng Zhang, Jingfeng Yao, Huangxuan Zhao et al.
                </div>

                <div class="paper-summary">
                    UniX is a novel medical foundation model designed for chest X-ray understanding and generation, addressing the inherent conflict between semantic abstraction and pixel-level reconstruction tasks. It achieves this by decoupling the tasks into distinct autoregressive (understanding) and diffusion (generation) branches, synergistically linked by a cross-modal self-attention mechanism. This architecture, combined with rigorous data processing and multi-stage training, significantly improves both understanding and generation performance compared to prior unified models, establishing a scalable paradigm for medical imaging AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging AI</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11522v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11522v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11522v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11522v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.11505v1"
                     data-domains="Type 1 Diabetes,Endocrinology,Medical Informatics,Computational Medicine,Biomedical Engineering"
                     data-keywords="Type 1 Diabetes,Continuous Glucose Monitoring,Insulin Pump,Dataset,Algorithm Development,Machine Learning,Data Standardization,Glycemic Control"
                     data-authors="Miriam K. Wolff,Peter Calhoun,Eleonora Maria Aiello,Yao Qin,Sam F. Royston">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11505v1.html">MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MetaboNet, the largest publicly available consolidated dataset designed to overcome the fragmentation and lack of standardization in existing Type 1 Diabetes (T1D) management datasets. By unifying continuous glucose monitoring (CGM) and insulin pump data from 3135 subjects, MetaboNet aims to facilitate the development of more generalizable and comparable T1D algorithms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Type 1 Diabetes</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11505v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11505v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11505v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11505v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.11488v1"
                     data-domains="Radiology,Diagnostic Imaging,Clinical Informatics,Medical AI"
                     data-keywords="radiology report generation,CT reports,clinical validity,metric assessment,generative AI,LLMs,BERTScore,GREEN Score"
                     data-authors="Vanshali Sharma,Andrea Mia Bejar,Gorkem Durak,Ulas Bagci">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11488v1.html">CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vanshali Sharma, Andrea Mia Bejar, Gorkem Durak et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CTest-Metric, a novel unified framework designed to assess the clinical validity and robustness of metrics used for automated radiology report generation (RRG) in CT imaging. By evaluating eight common metrics across three modules focusing on writing style generalizability, synthetic error injection, and expert correlation, the study found that lexical metrics are sensitive to style, GREEN Score best correlates with expert judgments, and BERTScore-F1 is robust to factual errors. The framework aims to address the current reliance on suboptimal metrics by providing a systematic assessment tool.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11488v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11488v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11488v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11488v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.11479v1"
                     data-domains="Public Health,Health Systems Management,Global Health,Health Policy,Healthcare Access,Health Economics (indirectly through resource allocation)"
                     data-keywords="Health facility location,LLMs,Algorithmic planning,Optimization,Expert knowledge integration,Population coverage,Ethiopia,Health systems planning"
                     data-authors="Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,St√©phane Verguet,Milind Tambe">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11479v1.html">Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yohai Trabelsi, Guojun Xiong, Fentabil Getnet et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Large language model and Extended Greedy (LEG) framework to address the challenge of prioritizing health facility upgrades in Ethiopia, integrating expert qualitative knowledge into algorithmic planning. The framework combines a provable approximation algorithm for maximizing population coverage with LLM-driven iterative refinement, ensuring solutions reflect expert guidance while preserving coverage guarantees. Experiments on real-world Ethiopian data demonstrate its effectiveness in supporting equitable, data-driven health system planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Health Systems Management</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Healthcare Access</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11479v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11479v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11479v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11479v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.11451v1"
                     data-domains="Public Health,Environmental Health,Infectious Disease Epidemiology,Veterinary Public Health,Food Safety"
                     data-keywords="Concentrated Animal Feeding Operations (CAFOs),Remote Sensing,Computer Vision,Deep Learning,Explainable AI,Public Health,Environmental Health,Infectious Disease Monitoring"
                     data-authors="Oishee Bintey Hoque,Nibir Chandra Mandal,Kyle Luong,Amanda Wilson,Samarth Swarup,Madhav Marathe,Abhijin Adiga">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11451v1.html">PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong et al.
                </div>

                <div class="paper-summary">
                    PRISM-CAFO introduces an infrastructure-first, explainable AI pipeline for accurately identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. The method leverages advanced computer vision techniques to detect key infrastructure components and achieves state-of-the-art performance, significantly improving mapping capabilities for these critical sites.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Veterinary Public Health</span>
                    
                    <span class="domain-tag">Food Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11451v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11451v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11451v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11451v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.11433v1"
                     data-domains="Cardiology,Medical Devices,Wearable Health Technology,Biomedical Engineering,Preventive Medicine"
                     data-keywords="ECG classification,arrhythmia detection,LGNs,LUTNs,inter-patient,low-power,wearable devices,MIT-BIH"
                     data-authors="Wout Mommen,Lars Keuninckx,Paul Detterer,Achiel Colpaert,Piet Wambacq">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.11433v1.html">Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-16</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wout Mommen, Lars Keuninckx, Paul Detterer et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) for inter-patient ECG arrhythmia classification, demonstrating their suitability with extremely low computational cost. The models achieve high accuracy on the MIT-BIH dataset, leveraging novel preprocessing, MUX-based LUT training, and rate coding, making them ideal for highly efficient, low-power medical devices.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Devices</span>
                    
                    <span class="domain-tag">Wearable Health Technology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.11433v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.11433v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.11433v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.11433v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.10520v1"
                     data-domains="Mental Health,Digital Therapeutics,Medical Ethics,Autonomous Healthcare Systems,Clinical Decision Support"
                     data-keywords="AI alignment,ethical AI,neuro-symbolic AI,deontic logic,reason-based AI,containment architecture,LLM therapy assistant,safety"
                     data-authors="Felix Jahn,Yannic Muskalla,Lisa Dargasz,Patrick Schramowski,Kevin Baum">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.10520v1.html">Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-15</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Felix Jahn, Yannic Muskalla, Lisa Dargasz et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GRACE (Governor for Reason-Aligned ContainmEnt), a neuro-symbolic reason-based containment architecture designed to ensure safe and ethical AI alignment by decoupling normative reasoning from instrumental decision-making. GRACE facilitates interpretability, contestability, and justifiability of AI actions through a Moral Module, a Decision-Making Module, and a Guard. The architecture offers formal verification and statistical guarantees of alignment, demonstrated using an LLM therapy assistant as an example.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                    <span class="domain-tag">Autonomous Healthcare Systems</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.10520v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.10520v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.10520v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.10520v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2601.10406v1"
                     data-domains="Medical education,Clinical decision support,Patient information systems,Health informatics,Medical research data analysis"
                     data-keywords="Question Generation (QG),AI evaluation,Error detection,LLM evaluators,Factual hallucination,Answer mismatch,Diagnostic AI,Medical informatics"
                     data-authors="Weiping Fu,Bifan Wei,Jingyi Hao,Yushun Zhang,Jian Zhang,Jiaxin Wang,Bo Li,Yu He,Lingling Zhang,Jun Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2601.10406v1.html">ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2026-01-15</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Weiping Fu, Bifan Wei, Jingyi Hao et al.
                </div>

                <div class="paper-summary">
                    ErrEval is an error-aware evaluation framework designed to improve automatic Question Generation (QG) assessment by explicitly diagnosing critical defects like factual hallucinations and answer mismatches. It employs a two-stage process involving a dedicated error identifier and subsequent informed LLM-based scoring, demonstrating enhanced alignment with human judgments and effectively mitigating the overestimation of low-quality generated questions. This approach addresses the limitations of existing black-box evaluation methods that often overlook significant errors.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical education</span>
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                    <span class="domain-tag">Patient information systems</span>
                    
                    <span class="domain-tag">Health informatics</span>
                    
                    <span class="domain-tag">Medical research data analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2601.10406v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2601.10406v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2601.10406v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2601.10406v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2026-01-20 06:16:56</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>