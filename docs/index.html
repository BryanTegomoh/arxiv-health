<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">142</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (13), Neurology (8), Clinical Decision Support (5)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (13)</option>
                        
                        <option value="Neurology">Neurology (8)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (5)</option>
                        
                        <option value="Oncology">Oncology (5)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (5)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (5)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                        <option value="Clinical Decision Support Systems">Clinical Decision Support Systems (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.04655v1"
                     data-domains="Radiology,Pathology,Medical Imaging Analysis,Clinical Decision Support,Diagnostic AI"
                     data-keywords="MLLM,Multimodal AI,Benchmark Design,Bias Detection,Shortcut Learning,Robustness,Medical Imaging AI,Diagnostic AI"
                     data-authors="Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04655v1.html">Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ellis Brown, Jihan Yang, Shusheng Yang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a critical framework for designing robust Multimodal Large Language Model (MLLM) benchmarks by proactively identifying and mitigating non-visual biases that allow models to achieve high scores without genuine visual understanding. The authors propose a diagnostic principle where benchmark designers should actively try to "game" their own benchmarks using a "Test-set Stress-Test" (TsT) methodology and then debias them with "Iterative Bias Pruning" (IBP). Applying this framework, they uncover pervasive non-visual biases in several prominent MLLM benchmarks, demonstrating how their debiasing process leads to more reliable evaluations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04637v1"
                     data-domains="Neurodevelopmental disorders,Psychiatric disorders,Cancer,Aging"
                     data-keywords="Genetic risk factors,Allele frequency spectrum,Missing middle,Gene discovery,Variant annotation,Joint modeling,Phenotype refinement,Network-based inference,Human genetics"
                     data-authors="Madison Caballero,Behrang Mahjani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04637v1.html">Advancing Risk Gene Discovery Across the Allele Frequency Spectrum</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Madison Caballero, Behrang Mahjani
                </div>

                <div class="paper-summary">
                    This review identifies a critical gap in genetic risk factor discovery, termed the 'missing middle,' which comprises variants of intermediate allele frequency and effect size that are poorly addressed by current methods. It analyzes the limitations of existing approaches optimized for rare or common variants and proposes innovative strategies to enable comprehensive risk gene identification across the entire allele frequency spectrum.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurodevelopmental disorders</span>
                    
                    <span class="domain-tag">Psychiatric disorders</span>
                    
                    <span class="domain-tag">Cancer</span>
                    
                    <span class="domain-tag">Aging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04637v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04637v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04637v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04637v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04619v1"
                     data-domains="Neurology,Geriatrics,Biomarker Research,Computational Medicine,Neuroscience"
                     data-keywords="Alzheimer's disease,causal discovery,pseudotime,dynamic modelling,biomarkers,neurodegeneration,latent variables,NfL,GFAP"
                     data-authors="Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04619v1.html">Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Natalia Glazman, Jyoti Mangal, Pedro Borges et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel dynamic causal discovery framework for Alzheimer's disease (AD) that addresses the limitations of static models by incorporating a latent disease pseudotime. By inferring a data-driven pseudotime, the framework orders patients along a disease trajectory and learns how causal relationships between biomarkers evolve, demonstrating superior diagnostic prediction compared to chronological age and revealing dynamic interactions among AD markers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Biomarker Research</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04574v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Vaccine Science"
                     data-keywords="Reproduction Number,R0,Rt,COVID-19,Generation Time,Serial Interval,Presymptomatic Transmission,Lotka-Euler Equation,Renewal Equation,Gaussian Distribution"
                     data-authors="Derek Marsh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04574v1.html">Reproduction Numbers R_0, R_t for COVID-19 Infections with Gaussian Distribution of Generation Times, and of Serial Intervals including Presymptomatic Transmission</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Derek Marsh
                </div>

                <div class="paper-summary">
                    This paper addresses inconsistencies in calculating COVID-19 reproduction numbers (R0, Rt) using the Lotka-Euler equation when considering presymptomatic transmission and Gaussian-distributed serial intervals. It formulates a new Lotka-Euler equation that explicitly incorporates a lower cut-off for these serial intervals, thereby resolving discrepancies with predictions from the discretized renewal equation and improving the accuracy of R number estimation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Vaccine Science</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04557v1"
                     data-domains="Healthcare Informatics,Personalized Medicine,Disease Progression Modeling,Clinical Decision Support Systems,Patient Management,Pharmacovigilance"
                     data-keywords="Relational Deep Learning,Graph Transformers,Temporal Graph Networks,Multi-task Learning,Healthcare Analytics,Latent Bottleneck,Cross-attention,State-of-the-art"
                     data-authors="Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04557v1.html">Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Divyansha Lachi, Mahmoud Mohammadi, Joe Meyer et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Relational Graph Perceiver (RGP), a novel graph transformer architecture designed for relational deep learning that robustly integrates long-range spatial and temporal dependencies. RGP leverages a temporal subgraph sampler and a cross-attention-based latent bottleneck to build global context from diverse entity interactions and supports multiple predictive tasks through a flexible cross-attention decoder. The model achieves state-of-the-art performance on various benchmarks, offering a general and scalable solution for complex relational data. 
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Patient Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04557v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04557v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04557v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04557v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04525v1"
                     data-domains="General Surgery,Minimally Invasive Surgery,Surgical Education,Medical AI,Surgical Risk Assessment"
                     data-keywords="Laparoscopic Cholecystectomy,Surgical Complexity Estimation,Parkland Grading Scale,Weak Temporal Supervision,Surgical Video Analysis,Deep Learning,Computer Vision,Surgical Training"
                     data-authors="Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04525v1.html">Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios Anastasiou, Santiago Barbarisi, Lucy Culshaw et al.
                </div>

                <div class="paper-summary">
                    This paper introduces STC-Net, a novel framework for automated surgical complexity estimation in Laparoscopic Cholecystectomy (LC) using the Parkland Grading Scale (PGS), designed to analyze full surgical videos with weak temporal supervision. STC-Net achieves 62.11% accuracy and 61.42% F1-score on a dataset of 1,859 LC videos, significantly outperforming non-localized baselines by over 10%. This scalable approach holds promise for enhancing post-operative analysis and surgical training by providing objective complexity assessments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery</span>
                    
                    <span class="domain-tag">Surgical Education</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Surgical Risk Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04506v1"
                     data-domains="Radiology,Diagnostic Imaging,Pulmonology,Clinical Decision Support,Medical Natural Language Processing"
                     data-keywords="radiology reports,clinical uncertainty,hedging phrases,LLM,diagnostic reasoning,Lunguage++,natural language processing,medical informatics"
                     data-authors="Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04506v1.html">Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paloma Rabaey, Jong Hak Moon, Jung-Oh Lee et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel two-part framework to model and quantify both explicit and implicit uncertainty present in radiology reports, critical for improving automated analysis. It addresses the challenges of interpreting hedging phrases and reconstructing omitted diagnostic reasoning pathways, culminating in the release of Lunguage++, an uncertainty-aware benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04506v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04506v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04506v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04506v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04476v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology,Digital Therapeutics,Telemedicine"
                     data-keywords="Depression Detection,PHQ-8 Scores,Natural Language Processing,Time Series Analysis,Probabilistic Modeling,Uncertainty Quantification,Clinical Decision Support,Deep Learning"
                     data-authors="Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04476v1.html">Probabilistic Textual Time Series Depression Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fabian Schmidt, Seyedehmoniba Ravan, Vladimir Vlassov
                </div>

                <div class="paper-summary">
                    This paper introduces PTTSD (Probabilistic Textual Time Series Depression Detection), a novel framework for predicting PHQ-8 depression severity scores from utterance-level clinical interview text. PTTSD innovatively models uncertainty over time, offering well-calibrated prediction intervals in addition to point estimates. It achieves state-of-the-art performance among text-only systems on E-DAIC and DAIC-WOZ datasets, demonstrating high interpretability and clinical relevance of its uncertainty-aware forecasting.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04476v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04476v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04476v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04476v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04458v1"
                     data-domains="Neuroscience,Oncology,Neurology,Radiology,Medical Imaging Informatics"
                     data-keywords="PET imaging,preprocessing,statistical modeling,Alzheimer's disease,cancer,TRAECR,image harmonization,neuroimaging"
                     data-authors="Akhil Ambekar,Robert Zielinski,Ani Eloyan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04458v1.html">TRAECR: A Tool for Preprocessing Positron Emission Tomography Imaging for Statistical Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Akhil Ambekar, Robert Zielinski, Ani Eloyan
                </div>

                <div class="paper-summary">
                    This paper introduces TRAECR, a novel preprocessing and visualization tool designed to prepare Positron Emission Tomography (PET) imaging data for rigorous statistical modeling. It addresses the critical challenge statisticians face in robustly preparing PET data, which is essential for advancing research in clinical fields like Alzheimer's disease and cancer diagnosis, monitoring, and treatment evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04458v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04458v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04458v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04458v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04334v1"
                     data-domains="Radiology,Oncology,Urology,Medical Imaging Informatics"
                     data-keywords="3D Segmentation,Submanifold Sparse Convolutional Networks,Kidney Tumours,Computed Tomography,Medical Imaging,Deep Learning,Renal Cancer,Automated Segmentation"
                     data-authors="Sa√∫l Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04334v1.html">Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sa√∫l Alonso-Monsalve, Leigh H. Whitehead, Adam Aurisano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel two-stage methodology employing voxel sparsification and Submanifold Sparse Convolutional Networks (SSCNs) for automated, high-resolution 3D segmentation of kidneys and kidney tumors in CT scans. The method achieves state-of-the-art accuracy competitive with KiTS23 challenge winners while significantly reducing computational resource demands, addressing a key bottleneck in routine quantitative clinical analyses.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04334v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04334v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04334v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04334v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04333v1"
                     data-domains="Intensive Care Medicine,Critical Care,Clinical Decision Support Systems,Prognostics in Healthcare"
                     data-keywords="Dynamic Bayesian Networks,Full Bayesian Learning,Missing Data Imputation,Gibbs Sampling,Intensive Care,Temporal Models,Uncertainty Quantification,Clinical Decision Support"
                     data-authors="Federico Pirola,Fabio Stella,Marco Grzegorczyk">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04333v1.html">LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Federico Pirola, Fabio Stella, Marco Grzegorczyk
                </div>

                <div class="paper-summary">
                    This paper introduces LUME-DBN, a novel Gibbs sampling-based full Bayesian method designed for learning Dynamic Bayesian Networks (DBNs) directly from incomplete longitudinal clinical data. It addresses the critical limitation of existing missing data imputation techniques that fail to properly account for the temporal nature of medical datasets, especially in intensive care. By treating missing values as unknown Gaussian parameters sampled from their full conditional distributions, the approach achieves superior reconstruction accuracy and convergence compared to standard model-agnostic methods like MICE, leading to more reliable imputations and supporting safer clinical decisions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Prognostics in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04328v1"
                     data-domains="Pharmacology,Clinical Medicine,Patient Safety,Medical Informatics,Clinical Pharmacy"
                     data-keywords="Medication Safety,Large Language Models (LLMs),Clinical Decision Support,Drug Interactions,Contraindications,Benchmark,AI in Healthcare,Patient Safety"
                     data-authors="Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04328v1.html">RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiahao Zhao, Luxin Xu, Minghuan Tan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces RxSafeBench, a novel framework and comprehensive benchmark for systematically evaluating the medication safety capabilities of Large Language Models (LLMs) in simulated clinical consultations. It addresses critical gaps in real-world data and realistic evaluation by generating inquiry-diagnosis dialogues with embedded medication risks, supported by the RxRisk DB knowledge base. The findings reveal that current LLMs significantly struggle to integrate contraindication and drug interaction knowledge, particularly when risks are implied rather than explicit, underscoring major challenges for AI-driven clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical Medicine</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Pharmacy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04328v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04328v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04328v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04328v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04276v1"
                     data-domains="Infectious Diseases,Epidemiology,Public Health,Vector-Borne Diseases,Tropical Medicine"
                     data-keywords="Dengue,Vector Competence,Aedes,Predator-Prey Model,Disease Persistence,Endemic,Vector Control,Biological Trade-off"
                     data-authors="Piyumi Chathurangika,Tharushika Peiris,Lakmini S. Premadasa,S. S. N. Perera,Kushani De Silva">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04276v1.html">Vector Traits Shape Disease Persistence: A Predator Prey Approach to Dengue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Piyumi Chathurangika, Tharushika Peiris, Lakmini S. Premadasa et al.
                </div>

                <div class="paper-summary">
                    This study employs a predator-prey mathematical framework to model the interactions between Aedes vectors and dengue pathogens, demonstrating how vector competence (vc) drives endemic disease persistence. It reveals a fundamental biological trade-off where vectors, particularly under tropical pressures, cannot enhance their immune capacity to offset high transmission potential, leading to instability in dengue transmission dynamics. The research also proves the global stability of these endemic conditions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Vector-Borne Diseases</span>
                    
                    <span class="domain-tag">Tropical Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04255v1"
                     data-domains="Radiology,Diagnostic Imaging,Orthopedics,Anatomy,Surgical Planning,Medical Image Analysis"
                     data-keywords="medical imaging,anatomical landmark detection,foundation models,human-centric AI,pose estimation,deep learning,pretraining,few-shot learning"
                     data-authors="Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04255v1.html">MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marawan Elbatel, Anbang Wang, Keyuan Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedSapiens, a novel approach that adapts Sapiens, a human-centric foundation model for pose estimation, to anatomical landmark detection in medical imaging through multi-dataset pretraining. By revisiting this overlooked baseline, MedSapiens establishes a new state of the art, leveraging the inherent spatial pose localization capabilities of human-centric models to provide strong priors for medical landmark detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04255v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04255v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04255v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04255v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04190v1"
                     data-domains="Medical Imaging,Diagnostic Imaging,Radiology,Pathology"
                     data-keywords="covariance descriptors,SPDNet,medical image classification,general vision encoders,DINOv2,MedSAM,Riemannian deep learning,second-order statistics"
                     data-authors="Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04190v1.html">Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Josef Mayr, Anna Reithmeir, Maxime Di Folco et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the effectiveness of covariance descriptors for medical image classification, focusing on their combination with features extracted from pre-trained General Vision Encoders (GVEs) and processed by SPDNet. The study demonstrates that covariance descriptors derived from GVE features (DINOv2, MedSAM) consistently outperform handcrafted features. Notably, SPDNet combined with DINOv2 features achieves superior performance compared to state-of-the-art methods on the MedMNSIT benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04190v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04190v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04190v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04190v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04174v1"
                     data-domains="Neurology,Neurogenetics,Molecular Medicine,Pharmacology,Neuroscience"
                     data-keywords="Huntington's disease,protein aggregation,polyglutamine,huntingtin,hydrogen bonding,covalent bonding,transglutaminase,neuronal death"
                     data-authors="Guylaine Hoffner,Philippe Djian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04174v1.html">Protein aggregation in Huntington's disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guylaine Hoffner, Philippe Djian
                </div>

                <div class="paper-summary">
                    This paper investigates protein aggregation in Huntington's disease (HD), proposing two primary mechanisms: hydrogen bonding via polar-zipper formation and covalent bonding catalyzed by transglutaminase. While cell culture models indicate hydrogen bonds are the main stabilizers with likely covalent contributions, the crucial nature of these bonds in the brains of HD patients remains unknown, posing a significant challenge for therapeutic development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurogenetics</span>
                    
                    <span class="domain-tag">Molecular Medicine</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04174v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04174v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04174v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04174v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04171v1"
                     data-domains="Pathology,Histology,Oncology,Diagnostic Imaging,Computational Pathology"
                     data-keywords="Digital Pathology,Image Registration,Color Transformation,Preprocessing,CycleGAN,Hematoxylin & Eosin,Multimodal Imaging,Target Registration Error"
                     data-authors="Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04171v1.html">Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemehzahra Darzi, Rodrigo Escobar Diaz Guerrero, Thomas Bocklitz
                </div>

                <div class="paper-summary">
                    This study systematically evaluated various preprocessing techniques, specifically color transformations, to improve the accuracy of image registration between Hematoxylin and Eosin (H&E) stained and non-linear multimodal images in digital pathology. The research found that applying CycleGAN color transformation significantly reduced registration errors compared to other methods, thereby enabling more reliable integration and analysis of multi-modal pathological data. These findings underscore the importance of optimal preprocessing for accurate multi-modal alignment in computational pathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04171v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04171v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04171v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04171v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04158v1"
                     data-domains="Clinical Decision Support,Predictive Analytics,Health Informatics,Personalized Medicine,Risk Stratification,Medical AI"
                     data-keywords="Deep Learning,Transformer,EHR,Clinical Risk Identification,Longitudinal Modeling,Heterogeneous Data,Self-Attention,Temporal Encoding"
                     data-authors="Anzhuo Xie,Wei-Chen Chang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04158v1.html">Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anzhuo Xie, Wei-Chen Chang
                </div>

                <div class="paper-summary">
                    This study proposes a novel Transformer-based deep learning model designed to address the complexities of clinical risk classification using heterogeneous Electronic Health Record (EHR) data. The method effectively handles irregular temporal patterns and diverse data modalities through specialized embedding, temporal encoding, multi-head self-attention, and a semantic-weighted pooling module. Experimental results demonstrate its superior performance over traditional machine learning and temporal deep learning models, offering a stable and precise framework for clinical risk identification.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04084v1"
                     data-domains="Radiology,Pathology (image analysis),Anatomy (segmentation),Oncology (tumor segmentation),Neurology (brain segmentation)"
                     data-keywords="Medical Image Segmentation,Swin Transformer,Kolmogorov-Arnold Networks (KANs),U-Net,Data-efficient,Deep Learning,Computer Vision,Healthcare AI"
                     data-authors="Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04084v1.html">When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nishchal Sapkota, Haoyan Shi, Yejia Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces UKAST, a novel U-Net like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders for medical image segmentation. UKAST achieves state-of-the-art performance across four diverse medical imaging benchmarks, particularly excelling in data-scarce environments while addressing the data-hungry and computational limitations of traditional Transformers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology (image analysis)</span>
                    
                    <span class="domain-tag">Anatomy (segmentation)</span>
                    
                    <span class="domain-tag">Oncology (tumor segmentation)</span>
                    
                    <span class="domain-tag">Neurology (brain segmentation)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04084v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04084v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04084v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04084v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04079v1"
                     data-domains="Radiology,Medical Imaging,Chest Radiology,Abdominal Radiology,Neuroradiology"
                     data-keywords="radiology report,de-identification,PHI,transformer model,natural language processing,deep learning,patient privacy,clinical text mining"
                     data-authors="Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04079v1.html">Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eva Prakash, Maayane Attias, Pierre Chambon et al.
                </div>

                <div class="paper-summary">
                    This paper significantly improves automated de-identification of radiology reports using a transformer-based model fine-tuned on large, diverse datasets, achieving superior performance over previous state-of-the-art academic models and commercial cloud vendor systems. The approach demonstrates robust cross-institutional generalization and establishes a new benchmark for secure processing of sensitive clinical text. It ensures patient privacy while preserving data utility for research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Chest Radiology</span>
                    
                    <span class="domain-tag">Abdominal Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04079v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04079v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04079v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04079v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04071v1"
                     data-domains="Cardiology,Electrophysiology,Medical Imaging,Radiology"
                     data-keywords="Left Atrium,Segmentation,nnU-Net,MRI,Atrial Fibrillation,Deep Learning,Dice Similarity Coefficient,Cardiac Imaging"
                     data-authors="Fatemeh Hosseinabadi,Seyedhassan Sharifi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04071v1.html">Left Atrial Segmentation with nnU-Net Using MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemeh Hosseinabadi, Seyedhassan Sharifi
                </div>

                <div class="paper-summary">
                    This paper leverages the nnU-Net deep learning framework for accurate left atrial (LA) segmentation from cardiac MRI, a crucial step for guiding atrial fibrillation ablation and cardiac modeling. The self-configuring nnU-Net achieved a mean Dice similarity coefficient of 93.5 on the Left Atrial Segmentation Challenge 2013 dataset, demonstrating robust performance comparable to and often surpassing traditional expert annotations and previous methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04071v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04071v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04071v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04071v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04069v1"
                     data-domains="Pediatrics,Emergency Medicine,Radiology,Gastroenterology"
                     data-keywords="Pediatric appendicitis,Ultrasound,Deep learning,ResNet,Automated detection,Image classification,Diagnostic accuracy,Artificial intelligence"
                     data-authors="Fatemeh Hosseinabadi,Seyedhassan Sharifi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04069v1.html">Pediatric Appendicitis Detection from Ultrasound Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fatemeh Hosseinabadi, Seyedhassan Sharifi
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a deep learning model, based on a fine-tuned ResNet architecture, for automated detection of pediatric appendicitis from ultrasound images. Utilizing the Regensburg Pediatric Appendicitis Dataset, the model achieved high diagnostic performance metrics, demonstrating its ability to learn crucial discriminative features despite common imaging challenges like low contrast, speckle noise, and anatomical variability in pediatric patients.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04069v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04069v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04069v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04069v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04070v1"
                     data-domains="Surgery,Therapy,Clinical Decision Support"
                     data-keywords="LLMs,Explainable AI (XAI),Expert Alignment,Medical AI,Clinical Decision Support,Interpretability,Benchmarking,Knowledge-Intensive Systems"
                     data-authors="Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04070v1.html">T-FIX: Text-Based Explanations with Features Interpretable to eXperts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shreya Havaldar, Helen Jin, Chaehyeon Kim et al.
                </div>

                <div class="paper-summary">
                    T-FIX introduces a novel benchmark and metrics to evaluate the "expert alignment" of Large Language Model (LLM) explanations, addressing the critical need for explanations that resonate with domain experts in knowledge-intensive fields like medicine. This work formalizes expert alignment as a crucial evaluation criterion, moving beyond current schemes that primarily focus on plausibility or internal faithfulness, to ensure AI explanations reflect sophisticated expert-level reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Therapy</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04070v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04070v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04070v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04070v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04016v1"
                     data-domains="Radiology,Pulmonology,Cardiology,Diagnostic Imaging"
                     data-keywords="foundational model,Vision Transformer,thoracic imaging,Chest X-ray,Computed Tomography,multimodal,in-domain pre-training,data augmentation"
                     data-authors="Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04016v1.html">MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahmoud Soliman, Islam Osman, Mohamed S. Shehata et al.
                </div>

                <div class="paper-summary">
                    MedDChest is a novel foundational Vision Transformer (ViT) model specifically designed for thoracic imaging, pre-trained from scratch on a massive multimodal dataset of over 1.2 million Chest X-ray and CT images. It introduces a content-aware data augmentation strategy called Guided Random Resized Crops, which significantly improves performance. The model demonstrably outperforms traditional ImageNet-pretrained models on various downstream diagnostic tasks, providing a superior starting point for AI in thoracic medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04016v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04016v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04016v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04016v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04000v1"
                     data-domains="Clinical Decision Support Systems,Diagnostics,Prognostics,Personalized Medicine,Medical Risk Assessment,Treatment Planning"
                     data-keywords="Meta-learning,Decision Trees,Interpretability,Synthetic Data Generation,Healthcare AI,Scalability,Pre-training,Clinical Decision Support"
                     data-authors="Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04000v1.html">Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kyaw Hpone Myint, Zhe Wu, Alexandre G. R. Day et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an efficient and scalable method for meta-learning interpretable decision trees by generating large-scale synthetic pre-training data from near-optimal decision trees. Utilizing a MetaTree transformer architecture, the approach achieves performance comparable to pre-training on real-world data or with computationally expensive optimal decision trees. This strategy significantly reduces computational costs and enhances data generation flexibility, paving the way for scalable development of interpretable models in high-stakes fields like healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Risk Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04000v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04000v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04000v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04000v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03976v1"
                     data-domains="Virology,Infectious Diseases,Epidemiology,Public Health,Vaccinology,Genomics"
                     data-keywords="SARS-CoV-2,mutation prediction,evolutionary transformer,phylogenetic trees,viral evolution,machine learning,public health,vaccine development"
                     data-authors="Xu Zou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03976v1.html">PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xu Zou
                </div>

                <div class="paper-summary">
                    PETRA addresses the challenge of predicting SARS-CoV-2 evolution by introducing a novel transformer model that analyzes evolutionary trajectories derived from phylogenetic trees rather than noisy raw RNA sequences. This innovative approach, coupled with a weighted training framework, significantly outperforms baselines in predicting future nucleotide and spike amino-acid mutations, providing a critical tool for public health and vaccine development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Virology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03976v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03976v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03976v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03976v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03966v1"
                     data-domains="Neuropsychology,Psychiatry,Neurology,Rehabilitation Medicine,Geriatrics,Medical Education"
                     data-keywords="Cognitive Diagnosis,Data Unlearning,Privacy Preservation,Right to be Forgotten,Hierarchical Forgetting,Machine Learning,AI in Healthcare,Patient Privacy"
                     data-authors="Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03966v1.html">PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingliang Hou, Yinuo Wang, Teng Guo et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical need for effective data unlearning mechanisms in Cognitive Diagnosis (CD) models to protect student privacy and comply with 'right to be forgotten' requests. It introduces a novel algorithm, Hierarchical Importance-guided Forgetting (HIF), which leverages the unique layer-wise characteristics of parameter importance in CD models. HIF significantly outperforms existing baselines, offering the first effective solution for deploying high-performance, privacy-preserving AI systems in cognitive assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuropsychology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03966v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03966v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03966v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03966v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03950v1"
                     data-domains="Surgical planning,Medical imaging (e.g., 3D reconstruction from CT/MRI/ultrasound),Prosthetics and Orthotics design,Anatomy education and training,Telemedicine (e.g., remote visual diagnostics),Medical Augmented/Virtual Reality"
                     data-keywords="Multi-view reconstruction,3D reconstruction,Gaussian-mesh optimization,Differentiable rendering,Geometry optimization,Appearance optimization,Photorealistic rendering,Texture-guided"
                     data-authors="Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03950v1.html">Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhejia Cai, Puhua Jiang, Shiwei Mao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework for multi-view 3D reconstruction that unifies geometry and appearance optimization, addressing the common issue of decoupling these aspects in existing methods. It proposes a Gaussian-guided mesh differentiable rendering approach to simultaneously optimize mesh geometry (vertex positions and faces) and vertex colors, achieving high-quality 3D reconstructions suitable for downstream editing tasks. The core contribution lies in its joint optimization strategy, which improves the fidelity and editability of 3D models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgical planning</span>
                    
                    <span class="domain-tag">Medical imaging (e.g., 3D reconstruction from CT/MRI/ultrasound)</span>
                    
                    <span class="domain-tag">Prosthetics and Orthotics design</span>
                    
                    <span class="domain-tag">Anatomy education and training</span>
                    
                    <span class="domain-tag">Telemedicine (e.g., remote visual diagnostics)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03950v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03950v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03950v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03950v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03912v1"
                     data-domains="Radiology,Pulmonology,Neurology,Chest X-ray (CXR),Brain MRI,COVID-19,Pneumonia"
                     data-keywords="Incremental Learning,Anomaly Detection,Medical Imaging,Unsupervised Learning,Epistemic Uncertainty,Stochastic Weight Averaging-Gaussian (SWAG),Oracle-Free,K-Nearest Neighbor (k-NN)"
                     data-authors="Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03912v1.html">I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nand Kumar Yadav, Rodrigue Rizk, William CW Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an unsupervised, oracle-free incremental learning framework for unknown anomaly detection in medical imaging, addressing the challenge of scarce labeled anomalies. The method iteratively expands a trusted set of normal samples by combining lightweight adapter updates with a dual probabilistic uncertainty-gated admission mechanism, utilizing a frozen pretrained backbone and a compact coreset for efficient k-NN scoring. This approach significantly improves anomaly detection performance across various medical imaging datasets, including COVID-CXR, Pneumonia CXR, and Brain MRI, by continually refining the notion of normality without relying on anomaly labels.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Chest X-ray (CXR)</span>
                    
                    <span class="domain-tag">Brain MRI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03912v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03912v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03912v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03912v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03897v1"
                     data-domains="Infectious Disease Epidemiology,Public Health,Health Equity and Disparities,Biostatistics and Modeling"
                     data-keywords="Infectious disease modeling,Social contact surveys,Perception bias,Epidemiology,Disease transmission,Health disparities,SIR model,Contact patterns"
                     data-authors="Thomas J. Harris,Prescott C. Alexander,Anh B. D. Pham,Joseph Tuccillo,Nicholas Geard,Cameron Zachreson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03897v1.html">Simulating the impact of perception bias on social contact surveys for infectious disease modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thomas J. Harris, Prescott C. Alexander, Anh B. D. Pham et al.
                </div>

                <div class="paper-summary">
                    This paper investigates how perception biases in social contact surveys, specifically concerning the estimation of others' age and race, impact the accuracy of derived contact patterns and subsequent infectious disease model projections. The study found that such biases significantly reduce the accuracy of contact patterns, leading to a systematic underestimation of cumulative disease incidence in older individuals (65+) and racial minority populations when these biased patterns are used in transmission models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Health Equity and Disparities</span>
                    
                    <span class="domain-tag">Biostatistics and Modeling</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03897v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03897v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03897v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03897v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03891v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.AI,cs.DB"
                     data-authors="Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03891v1.html">Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hlali Azzeddine, Majid Ben Yakhlef, Soulaiman El Hazzat
                </div>

                <div class="paper-summary">
                    Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combin...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03891v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03891v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03891v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03891v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03890v1"
                     data-domains="Cardiology,Cardiovascular Surgery,Biomedical Engineering,Medical Imaging,Preoperative Planning"
                     data-keywords="Aortic Valve,Finite Element Meshing,3D CT Images,Deep Learning,Shape Deformation Networks,Quadrilateral Meshes,Biomechanical Analysis,Patient-Specific Simulations"
                     data-authors="Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03890v1.html">Shape Deformation Networks for Automated Aortic Valve Finite Element Meshing from 3D CT Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Linchen Qian, Jiasong Chen, Ruonan Gong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a deep learning-based template-fitting pipeline that generates structured quadrilateral (quad) meshes of aortic valves from 3D CT images. By using a common quad mesh template, the method ensures consistent mesh topology and correspondence across patients, leading to high-quality meshes for biomechanical analysis while simplifying the neural network training process.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Preoperative Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03890v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03890v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03890v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03890v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03873v1"
                     data-domains="Oncology,Immunotherapy,Cell and Gene Therapy,Systems Biology in Medicine"
                     data-keywords="CAR T cells,immunotherapy,mathematical modeling,cancer therapy,translational research,multiscale modeling,predictive design,cell therapy optimization"
                     data-authors="Lucas E Sant'Anna,Rohita Roy,Janella C Schwab,Julian I Perez,Micha√´lle N Mayalu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03873v1.html">CAR T Cells from Code to Clinic: Framing Modeling Approaches with Current Translational Research Goals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.CB</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lucas E Sant'Anna, Rohita Roy, Janella C Schwab et al.
                </div>

                <div class="paper-summary">
                    This perspective paper critically evaluates how mathematical modeling can address major translational challenges in CAR T cell therapy, such as lack of persistence, toxicity, and antigen-negative relapse, by linking mechanistic understanding to design optimization. It frames modeling methodologies around therapeutic problems, highlighting emerging approaches like multiscale and data-driven methods to guide predictive design and enhance clinical performance from genetic to patient levels.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunotherapy</span>
                    
                    <span class="domain-tag">Cell and Gene Therapy</span>
                    
                    <span class="domain-tag">Systems Biology in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03873v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03873v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03873v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03873v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03855v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.AI"
                     data-authors="Duong Mai,Lawrence Hall">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03855v1.html">Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Duong Mai, Lawrence Hall
                </div>

                <div class="paper-summary">
                    Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not cove...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03855v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03855v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03855v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03855v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03831v1"
                     data-domains="Systems Biology,Genomics,Pharmacogenomics,Epidemiology,Personalized Medicine,Drug Discovery,Disease Etiology"
                     data-keywords="Causal Inference,Higher-Order Interactions,Directed Acyclic Hypergraph,Causal Additive Models (CAM),Structure Learning,Identifiability,Machine Learning,Complex Systems"
                     data-authors="James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03831v1.html">Higher-Order Causal Structure Learning with Additive Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> James Enouen, Yujia Zheng, Ignavier Ng et al.
                </div>

                <div class="paper-summary">
                    This paper extends the Causal Additive Model (CAM) to explicitly learn higher-order causal interactions, which are prevalent in complex real-world systems but often overlooked in causal discovery. It introduces the Directed Acyclic Hypergraph (hyper-DAG) as a novel representational structure for these interactions, providing theoretical tools, identifiability results, and an adapted greedy algorithm for its discovery, demonstrating improved empirical usefulness in synthetic experiments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03831v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03831v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03831v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03831v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03806v1"
                     data-domains="Intensive Care Unit (ICU),Sepsis Management,Clinical Informatics,Electronic Health Records (EHR) Analysis,Medical Natural Language Processing"
                     data-keywords="Differential Privacy,Foundation Models,Feature-Level Privacy,Sepsis Prediction,Clinical Notes,Privacy-Preserving Machine Learning,Data Imputation,Healthcare AI"
                     data-authors="Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03806v1.html">FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Linghui Zeng, Ruixuan Liu, Atiquer Rahman Sarkar et al.
                </div>

                <div class="paper-summary">
                    FusionDP is a novel two-step framework designed to improve model utility while preserving feature-level differential privacy, especially when only a subset of features is sensitive. It leverages large foundation models to impute sensitive features, then applies a modified DP-SGD algorithm to train models on both original and imputed data, demonstrating significant performance gains in medical tasks like sepsis prediction and clinical note classification.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Sepsis Management</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Analysis</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03806v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03806v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03806v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03806v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03771v1"
                     data-domains="breast histopathology,pathology,general medical imaging diagnostics"
                     data-keywords="medical imaging,self-supervised learning,contrastive learning,label hierarchy,taxonomy,representation learning,histopathology,deep learning"
                     data-authors="Alif Elham Khan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03771v1.html">Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alif Elham Khan
                </div>

                <div class="paper-summary">
                    This paper introduces a novel hierarchy-preserving contrastive learning framework for medical imaging, which leverages the inherent taxonomic structure of medical labels (e.g., organ-tissue-subtype) that standard self-supervised learning often overlooks. By incorporating two plug-in objectives, Hierarchy-Weighted Contrastive (HWC) and Level-Aware Margin (LAM), the method consistently improves representation quality over strong baselines, better respects label taxonomies, and enhances both performance and interpretability in hierarchy-rich medical domains like breast histopathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">breast histopathology</span>
                    
                    <span class="domain-tag">pathology</span>
                    
                    <span class="domain-tag">general medical imaging diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03771v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03771v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03771v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03771v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03693v1"
                     data-domains="Oncology,Pathology,Gastroenterology,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Federated Learning,Colorectal Cancer,Histopathological Grading,Multi-Scale Analysis,Deep Learning,Digital Pathology,Privacy-Preserving AI,ResNetRS50"
                     data-authors="Md Ahasanul Arafath,Abhijit Kumar Ghosh,Md Rony Ahmed,Sabrin Afroz,Minhazul Hosen,Md Hasan Moon,Md Tanzim Reza,Md Ashad Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03693v1.html">Colorectal Cancer Histopathological Grading using Multi-Scale Federated Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md Ahasanul Arafath, Abhijit Kumar Ghosh, Md Rony Ahmed et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a privacy-preserving federated learning (FL) framework for colorectal cancer (CRC) histopathological grading, overcoming inter-observer variability and data sharing constraints. The system integrates a dual-stream ResNetRS50 for multi-scale feature extraction and uses FedProx for stability, achieving 83.5% overall accuracy and crucially, an 87.5% recall for aggressive Grade III tumors, outperforming centralized models while preserving patient privacy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03693v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03693v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03693v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03693v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03677v1"
                     data-domains="Infectious Diseases,Clinical Pharmacology,Antimicrobial Stewardship,Public Health"
                     data-keywords="Antibiotic resistance,Plasmid-mediated resistance,Mutation-induced resistance,Treatment outcomes,ODE models,Dosing schedules,Infection clearance,Missed dose strategies"
                     data-authors="Ailin Zhang,Shigui Ruan,Xi Huo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03677v1.html">Impact of Resistance Development Mechanisms on Antibiotic Treatment Outcomes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ailin Zhang, Shigui Ruan, Xi Huo
                </div>

                <div class="paper-summary">
                    This study utilized periodic ordinary differential equation models to investigate how different bacterial antibiotic resistance mechanisms (plasmid-induced vs. mutation-induced) impact treatment outcomes and the efficacy of various dosing strategies. It found that fixed-dosing antibiotic treatments are more effective against plasmid-mediated resistance, while mutation-driven mechanisms promote the selection of fully resistant strains upon treatment failure. The research also demonstrated that twice-daily regimens surpass once-daily for infection clearance and that a "catch-up" strategy is superior for missed doses of short half-life antibiotics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Antimicrobial Stewardship</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03677v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03677v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03677v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03677v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03675v1"
                     data-domains="Telemedicine,Clinical Decision Support,Patient Consultation AI,Medical Research,Mental Health Support via AI"
                     data-keywords="LLM,side-channel attack,metadata leakage,privacy,healthcare AI,TLS bypass,network surveillance,packet analysis"
                     data-authors="Geoff McDonald,Jonathan Bar Or">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03675v1.html">Whisper Leak: a side-channel attack on Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Geoff McDonald, Jonathan Bar Or
                </div>

                <div class="paper-summary">
                    Whisper Leak is a novel side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. This attack achieves near-perfect classification (often >98% AUPRC) across 28 popular LLMs, even identifying specific sensitive content with 100% precision for certain topics. The findings highlight a significant industry-wide vulnerability that poses severe privacy risks for users in sensitive domains like healthcare, despite TLS encryption.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Patient Consultation AI</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                    <span class="domain-tag">Mental Health Support via AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03671v1"
                     data-domains="Neuroscience,Neurology,Computational Neuroscience,Neurophysiology,Biophysics,Computational Psychiatry"
                     data-keywords="Chialvo neurons,coupled oscillators,nonlinear dynamics,chaos theory,fractal basin boundaries,multistability,neuronal synchronization,neurological disease"
                     data-authors="Bennett Lamb,Brandon B. Le">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03671v1.html">Final state sensitivity and fractal basin boundaries from coupled Chialvo neurons</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ nlin.CD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bennett Lamb, Brandon B. Le
                </div>

                <div class="paper-summary">
                    This paper investigates the complex dynamics of two asymmetrically coupled Chialvo neurons, revealing multistability with predominantly chaotic behavior despite individual non-chaotic neurons. A critical finding is the fractal nature of the basin boundaries, leading to extreme final state sensitivity that could profoundly impact synchronization patterns in biological neural networks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Neurophysiology</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03661v1"
                     data-domains="Digital Health,Telemedicine,Medical Device Management,Hospital IT Security,Patient Monitoring"
                     data-keywords="Healthcare IoT,Anomaly Detection,Cyberattack Detection,Machine Learning,XGBoost,K-Nearest Neighbors,Medical Device Security,Cybersecurity"
                     data-authors="Mahek Desai,Apoorva Rumale,Marjan Asadinia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03661v1.html">SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahek Desai, Apoorva Rumale, Marjan Asadinia
                </div>

                <div class="paper-summary">
                    This study proposes SHIELD, a machine learning-driven framework to enhance healthcare IoT security by detecting both malicious cyberattacks and faulty device anomalies. Evaluating eight diverse models across supervised, semi-supervised, and unsupervised learning, it identifies XGBoost as highly effective for anomaly detection (99% accuracy, 0.04s) and K-Nearest Neighbors (KNN) for attack detection (near-perfect metrics, 0.05s). These findings provide strategies for improving early threat and failure detection, safeguarding patient health and critical medical infrastructure.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Medical Device Management</span>
                    
                    <span class="domain-tag">Hospital IT Security</span>
                    
                    <span class="domain-tag">Patient Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03661v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03661v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03661v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03661v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03656v1"
                     data-domains="Medical Treatment"
                     data-keywords="Chinese NLP,Question Answering,Multi-Document QA,Medical Treatment,Dataset,Fine-grained Evaluation,Knowledge Extraction,Document Comprehension"
                     data-authors="Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03656v1.html">ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu et al.
                </div>

                <div class="paper-summary">
                    ChiMDQA introduces a new Chinese Multi-Document Question Answering Dataset specifically designed for diverse business scenarios, including medical treatment. Comprising 6,068 rigorously curated, high-quality question-answer pairs from long-form documents across six distinct fields, this dataset provides a robust foundation for advancing NLP tasks like document comprehension, knowledge extraction, and intelligent QA systems in Chinese.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Treatment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03656v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03656v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03769v1"
                     data-domains="Surgery,Surgical Data Science,Medical Artificial Intelligence,Clinical Informatics,Medical Device Regulation"
                     data-keywords="Surgical AI,AI Validation,Intraoperative video analysis,Temporal stability,Hierarchical data,Delphi process,Clinical translation,Surgical data science"
                     data-authors="Annika Reinke,Ziying O. Li,Minu D. Tizabi,Pascaline Andr√©,Marcel Knopp,Mika M. Rother,Ines P. Machado,Maria S. Altieri,Deepak Alapatt,Sophia Bano,Sebastian Bodenstedt,Oliver Burgert,Elvis C. S. Chen,Justin W. Collins,Olivier Colliot,Evangelia Christodoulou,Tobias Czempiel,Adrito Das,Reuben Docea,Daniel Donoho,Qi Dou,Jennifer Eckhoff,Sandy Engelhardt,Gabor Fichtinger,Philipp Fuernstahl,Pablo Garc√≠a Kilroy,Stamatia Giannarou,Stephen Gilbert,Ines Gockel,Patrick Godau,Jan G√∂deke,Teodor P. Grantcharov,Tamas Haidegger,Alexander Hann,Makoto Hashizume,Charles Heitz,Rebecca Hisey,Hanna Hoffmann,Arnaud Huaulm√©,Paul F. J√§ger,Pierre Jannin,Anthony Jarc,Rohit Jena,Yueming Jin,Leo Joskowicz,Luc Joyeux,Max Kirchner,Axel Krieger,Gernot Kronreif,Kyle Lam,Shlomi Laufer,Jo√´l L. Lavanchy,Gyusung I. Lee,Robert Lim,Peng Liu,Hani J. Marcus,Pietro Mascagni,Ozanan R. Meireles,Beat P. Mueller,Lars M√ºndermann,Hirenkumar Nakawala,Nassir Navab,Abdourahmane Ndong,Juliane Neumann,Felix Nickel,Marco Nolden,Chinedu Nwoye,Namkee Oh,Nicolas Padoy,Thomas Pausch,Micha Pfeiffer,Tim R√§dsch,Hongliang Ren,Nicola Rieke,Dominik Rivoir,Duygu Sarikaya,Samuel Schmidgall,Matthias Seibold,Silvia Seidlitz,Lalith Sharan,Jeffrey H. Siewerdsen,Vinkle Srivastav,Raphael Sznitman,Russell Taylor,Thuy N. Tran,Matthias Unberath,Fons van der Sommen,Martin Wagner,Amine Yamlahi,Shaohua K. Zhou,Aneeq Zia,Amin Madani,Danail Stoyanov,Stefanie Speidel,Danail A. Hashimoto,Fiona R. Kolbinger,Lena Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03769v1.html">Current validation practice undermines surgical AI development</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Annika Reinke, Ziying O. Li, Minu D. Tizabi et al.
                </div>

                <div class="paper-summary">
                    This paper identifies and categorizes widespread validation pitfalls hindering surgical AI adoption, stemming from the neglect of temporal and hierarchical structures inherent in intraoperative videos. Through a multi-stage Delphi process, systematic review, and empirical experiments, it demonstrates how current validation practices lead to unreliable results, ultimately proposing a robust framework for rigorous and clinically relevant AI validation in surgery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Surgical Data Science</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Device Regulation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03595v1"
                     data-domains="Clinical Decision Support Systems,Personalized Medicine,Rehabilitation Robotics,Drug Discovery,Critical Care Management,Patient Monitoring"
                     data-keywords="Reinforcement Learning,Q-learning,Tensor Decomposition,High-Dimensional,Sample Efficiency,Exploration-Exploitation,Healthcare AI,Resource-Constrained"
                     data-authors="Junyi Wu,Dan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03595v1.html">Tensor-Efficient High-Dimensional Q-learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junyi Wu, Dan Li
                </div>

                <div class="paper-summary">
                    This paper introduces Tensor-Efficient Q-Learning (TEQL), an enhancement to tensor-based reinforcement learning designed to overcome the curse of dimensionality in high-dimensional state-action spaces. TEQL improves low-rank tensor decomposition with novel exploration and regularization mechanisms, resulting in superior sample efficiency and total rewards compared to conventional and deep RL methods. It is particularly suited for resource-constrained applications like healthcare where data collection (sampling) is costly.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Rehabilitation Robotics</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Critical Care Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03595v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03595v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03595v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03595v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03767v1"
                     data-domains="Neurology,Neurosurgery,Radiology,Rehabilitation Medicine,Traumatology"
                     data-keywords="Traumatic Brain Injury,MRI,Phenotype Discovery,Brain Segmentation,Multi-site Data,Volumetric Analysis,Neuroimaging,Heterogeneity"
                     data-authors="Adam M. Saunders,Michael E. Kim,Gaurav Rudravaram,Lucas W. Remedios,Chloe Cho,Elyssa M. McMaster,Daniel R. Gillis,Yihao Liu,Lianrui Zuo,Bennett A. Landman,Tonia S. Rex">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03767v1.html">Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Adam M. Saunders, Michael E. Kim, Gaurav Rudravaram et al.
                </div>

                <div class="paper-summary">
                    This study addressed the intrinsic heterogeneity of Traumatic Brain Injury (TBI) by analyzing a large-scale, multi-site MRI dataset from the FITBIR repository to discover shared structural injury phenotypes. By harmonizing T1-weighted images, segmenting 132 brain regions, and controlling for confounding factors, the researchers identified significant volumetric differences in 37 ROIs between TBI patients and controls, clustering into three distinct injury patterns encompassing the brainstem, subcortical gray matter, insular cortex, and cerebral/cerebellar white matter.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Traumatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03767v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03767v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03767v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03767v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03488v1"
                     data-domains="Sleep Medicine,Neurology,Pulmonology,Clinical Neurophysiology"
                     data-keywords="Sleep staging,Polysomnography,Attention mechanism,Multimodal data fusion,Deep learning,Zero-shot generalization,Physiological signals,Neural networks"
                     data-authors="Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03488v1.html">NAP: Attention-Based Late Fusion for Automatic Sleep Staging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvise Dei Rossi, Julia van der Meer, Markus H. Schmidt et al.
                </div>

                <div class="paper-summary">
                    This paper introduces NAP (Neural Aggregator of Predictions), an attention-based deep learning model designed for robust automatic sleep staging from polysomnography (PSG) signals. NAP addresses the inherent heterogeneity of PSG data by learning to combine prediction streams from frozen, pretrained single-channel models, achieving state-of-the-art zero-shot generalization across diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03488v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03488v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03488v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03488v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-07 06:31:31</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>