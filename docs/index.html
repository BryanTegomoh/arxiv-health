<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">146</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (11), Oncology (8), Diagnostic Imaging (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (11)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (7)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Cardiology">Cardiology (5)</option>
                        
                        <option value="Pharmacology">Pharmacology (5)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (4)</option>
                        
                        <option value="Computational Biology">Computational Biology (4)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.27680v1"
                     data-domains="Oncology,Diagnostic Radiology,Nuclear Medicine,Medical Imaging Informatics,AI in Healthcare"
                     data-keywords="PET/CT,Vision-Language Model,3D Medical Imaging,Automated Reporting,Lesion Segmentation,Deep Learning,Multimodal AI,Radiology"
                     data-authors="Danyal Maqbool,Changhee Lee,Zachary Huemann,Samuel D. Church,Matthew E. Larson,Scott B. Perlman,Tomas A. Romero,Joshua D. Warner,Meghan Lubner,Xin Tie,Jameson Merkow,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27680v1.html">PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Danyal Maqbool, Changhee Lee, Zachary Huemann et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PETAR-4B, a 3D mask-aware vision-language model designed for automated generation of localized findings in PET/CT radiology reports. It addresses the challenge of applying VLMs to complex 3D medical imaging by creating a large-scale dataset of over 11,000 lesion-level descriptions with 3D segmentations and integrating PET, CT, and lesion contours into a unified model, demonstrating significant improvements in report generation quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27680v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27680v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27680v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27680v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27679v1"
                     data-domains="Oncology,Pulmonology,Diagnostic Radiology,Biomedical Imaging,Public Health"
                     data-keywords="Dark-field X-ray imaging,Lung cancer screening,Deep learning,U-Net,Early tumor detection,Low-dose radiography,Preclinical models,Medical imaging"
                     data-authors="Joyoni Dey,Hunter C. Meyer,Murtuza S. Taqi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27679v1.html">Dark-Field X-Ray Imaging Significantly Improves Deep-Learning based Detection of Synthetic Early-Stage Lung Tumors in Preclinical Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Joyoni Dey, Hunter C. Meyer, Murtuza S. Taqi
                </div>

                <div class="paper-summary">
                    This paper proposes X-ray dark-field imaging (DFI) combined with deep learning as a superior alternative to standard attenuation radiography for early-stage lung tumor detection. It demonstrates that DFI significantly improves detection sensitivity, achieving an 83.7% true-positive rate compared to 51% for attenuation-only models, while offering potential as an accessible, low-cost, and low-dose screening method.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Biomedical Imaging</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27679v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27679v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27679v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27679v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27671v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Discovery,Structural Biology,Computational Biology"
                     data-keywords="Structure-based drug design,Protein-ligand alignment,Drug discovery,Generative AI,Deep learning,NatureLM,Direct Preference Optimization,Medicinal chemistry"
                     data-authors="Wei Zhang,Zekun Guo,Yingce Xia,Peiran Jin,Shufang Xie,Tao Qin,Xiang-Yang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27671v1.html">MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei Zhang, Zekun Guo, Yingce Xia et al.
                </div>

                <div class="paper-summary">
                    MolChord is a novel deep learning framework for structure-based drug design (SBDD) that aligns protein and molecule structures with their sequential and textual representations to generate drugs with desired pharmacological properties. It integrates the NatureLM autoregressive model as a molecule generator and a diffusion-based structure encoder, refining the alignment process using Direct Preference Optimization (DPO) on a property-aware dataset. The approach achieves state-of-the-art performance on the CrossDocked2020 benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27663v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Nuclear Medicine,Interventional Radiology,Oncology Imaging"
                     data-keywords="Bayesian imaging,model selection,misspecification testing,cross-validation,data fission,image reconstruction,medical imaging,inverse problems,machine learning priors"
                     data-authors="Tom Sprunck,Marcelo Pereyra,Tobias Liaudat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27663v1.html">Bayesian model selection and misspecification testing in imaging inverse problems only from noisy and partial measurements</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tom Sprunck, Marcelo Pereyra, Tobias Liaudat
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, general methodology for the unsupervised evaluation of Bayesian statistical models in computational imaging, focusing on model selection and misspecification testing when ground truth is unavailable. By combining Bayesian cross-validation with data fission, the approach efficiently and accurately assesses imaging models, including those with implicitly defined machine learning priors. This advancement is crucial for ensuring the reliability and robustness of image reconstruction and restoration techniques across various modern imaging samplers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27663v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27663v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27663v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27663v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27646v1"
                     data-domains="Ophthalmology,Neurology,Cardiology,Radiology,Vascular Surgery,Oncology"
                     data-keywords="Blood vessel segmentation,Few-shot learning,Zero-shot learning,Synthetic data,Shape priors,Medical image analysis,Deep learning,Generalization"
                     data-authors="Cesar H. Comin,Wesley N. Galv√£o">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27646v1.html">VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cesar H. Comin, Wesley N. Galv√£o
                </div>

                <div class="paper-summary">
                    This paper introduces VessShape, a novel methodology for generating large-scale 2D synthetic datasets designed to instill a strong shape bias in blood vessel segmentation models. By leveraging procedurally generated tubular geometries with diverse textures, VessShape enables models to learn geometric priors rather than texture-based features, leading to robust few-shot and zero-shot segmentation performance on real-world medical images across different modalities. The research demonstrates that pre-training with this shape bias effectively overcomes data scarcity and improves model generalization in a critical medical imaging task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27646v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27646v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27646v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27646v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27552v1"
                     data-domains="Clinical NLP,Medical Informatics,Public Health (multilingual support),Patient Care"
                     data-keywords="Multilingual BERT,NLP,Domain Adaptation,Medical Tasks,Low-resource Languages,Cross-lingual Transfer,Clinical Notes,Named Entity Recognition"
                     data-authors="Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27552v1.html">Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yinghao Luo, Lang Zhou, Amrish Jhingoer et al.
                </div>

                <div class="paper-summary">
                    This study investigates the impact of domain adaptation on multilingual BERT models for medical Natural Language Processing (NLP) tasks, particularly in low-resource languages. By further pre-training multilingual BERT on domain-specific corpora, the authors demonstrate significant performance enhancements on medical tasks and observe promising cross-lingual transferability, offering a strategy to address the scarcity of NLP tools in diverse healthcare settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical NLP</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Public Health (multilingual support)</span>
                    
                    <span class="domain-tag">Patient Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27552v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27552v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27552v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27552v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27535v1"
                     data-domains="Cardiology,Clinical Informatics,Primary Care,Patient Engagement,Medical Communication"
                     data-keywords="Patient-centered care,AI clinical summarization,Large Language Models (LLMs),Patient-Centered Summaries (PCS),Mixed-methods,Atrial fibrillation,Clinical utility,Healthcare informatics"
                     data-authors="Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27535v1.html">Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Maria Lizarazo Jimenez, Ana Gabriela Claros, Kieran Green et al.
                </div>

                <div class="paper-summary">
                    This study introduces a novel framework for Patient-Centered Summaries (PCS) generated by AI from patient-clinician conversations, aiming to capture patient preferences, values, and concerns beyond mere biology. Using a mixed-methods approach involving patient and clinician input, the research developed annotation guidelines and evaluated five open-source Large Language Models. While LLMs showed promise in completeness and fluency, human-generated PCS significantly outperformed them in correctness and true patient-centeredness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Patient Engagement</span>
                    
                    <span class="domain-tag">Medical Communication</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27535v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27535v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27535v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27535v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27508v1"
                     data-domains="Oncology,Radiology,Medical Imaging,Pulmonology"
                     data-keywords="Lung Tumor Segmentation,PET-CT,Multimodal Imaging,Visual Mamba,Context-Gated Perception,Deep Learning,Medical Image Analysis,Lung Cancer"
                     data-authors="Elena Mulero Ayll√≥n,Linlin Shen,Pierangelo Veltri,Fabrizia Gelardi,Arturo Chiti,Paolo Soda,Matteo Tortora">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27508v1.html">Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elena Mulero Ayll√≥n, Linlin Shen, Pierangelo Veltri et al.
                </div>

                <div class="paper-summary">
                    This study introduces vMambaX, a lightweight multimodal framework that integrates PET and CT images using a Context-Gated Cross-Modal Perception Module (CGM) built on Visual Mamba for accurate lung tumor segmentation. The framework adaptively enhances inter-modality feature interaction, leading to improved performance over baseline models on the PCLT20K dataset while maintaining lower computational complexity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27508v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27508v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27508v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27508v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27497v1"
                     data-domains="Drug Discovery,Medicinal Chemistry,Pharmacology,Computational Biology,Bioinformatics"
                     data-keywords="3D Molecule Generation,Autoregressive Models,Transformer,Inertial Frames,Geometric Deep Learning,Drug Discovery,Controllable Generation,Molecular Design"
                     data-authors="Haorui Li,Weitao Du,Yuqiang Li,Hongyu Guo,Shengchao Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27497v1.html">InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haorui Li, Weitao Du, Yuqiang Li et al.
                </div>

                <div class="paper-summary">
                    InertialAR introduces a transformer-based autoregressive model for 3D molecule generation, addressing challenges of canonical tokenization and hybrid atom-based tokens by utilizing inertial frames and geometric positional encoding. It employs a hierarchical approach to predict atom types and 3D coordinates, achieving state-of-the-art performance in both unconditional and controllable molecule generation, particularly for targeted chemical functionality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27497v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27497v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27497v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27497v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27442v1"
                     data-domains="Medical image analysis,Diagnostics,Pathology,Radiology,Dermatology,Ophthalmology"
                     data-keywords="Vision Transformers,medical imaging,efficient AI,deep learning,classification,MedMNIST,interpretability,resource-constrained"
                     data-authors="Aon Safdar,Mohamed Saadeldin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27442v1.html">CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aon Safdar, Mohamed Saadeldin
                </div>

                <div class="paper-summary">
                    CoMViT is a novel, compact, and generalizable Vision Transformer architecture designed to overcome the computational demands and overfitting tendencies of traditional ViTs in medical imaging. It achieves robust classification performance across twelve MedMNIST datasets with a lightweight design (~4.5M parameters), offering significant parameter reduction (5-20x) without sacrificing accuracy, while also demonstrating clinical interpretability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical image analysis</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27442v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27442v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27442v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27442v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27421v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Medical AI,Public Health,Health Disparities"
                     data-keywords="Deep learning,image segmentation,breast cancer,bias,fairness,age bias,ethnic bias,MAMA-MIA,AI in medicine,health equity"
                     data-authors="Aditya Parikh,Sneha Das,Aasa Feragen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27421v1.html">Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aditya Parikh, Sneha Das, Aasa Feragen
                </div>

                <div class="paper-summary">
                    This paper audits the fairness of automated tumor segmentation within the MAMA-MIA breast cancer dataset, uncovering significant age-related bias against younger patients that persists even after accounting for data source. It also reveals how aggregating data influences site-specific ethnic biases, emphasizing the critical need for granular data analysis in fairness evaluations. The findings highlight potential disparities in diagnostic quality for specific demographic groups if such biases remain unaddressed.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27421v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27421v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27421v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27421v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27403v1"
                     data-domains="Medical Imaging Analysis (e.g., radiology, pathology),Clinical Decision Support Systems,Drug Discovery and Development,Personalized Medicine,Public Health Surveillance,Genomics and Proteomics"
                     data-keywords="Federated Learning,Matrix Orthogonalization,Communication Efficiency,Deep Learning Optimizer,Client Drift,Non-IID Data,Convergence Rate,Medical AI,Privacy-Preserving AI"
                     data-authors="Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27403v1.html">FedMuon: Accelerating Federated Learning with Matrix Orthogonalization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junkang Liu, Fanhua Shang, Junchao Zhou et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FedMuon, a novel optimizer for Federated Learning (FL) that addresses the core communication bottleneck by leveraging matrix orthogonalization. FedMuon overcomes the challenges of client drift and moment reinitialization encountered when applying matrix optimizers in non-IID FL settings, primarily through momentum aggregation and local-global alignment. The approach significantly reduces communication rounds and improves model accuracy across various tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging Analysis (e.g., radiology, pathology)</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27403v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27403v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27403v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27403v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27354v1"
                     data-domains="Infectious Diseases,Public Health,Veterinary Medicine,Food Safety,Environmental Health,Zoonoses"
                     data-keywords="aquaculture,streptococcosis,Streptococcus iniae,Streptococcus agalactiae,disease control,One-Health,vaccine development,genetic engineering,biosecurity,big data"
                     data-authors="Hussein Aliu Sule,Abdulwakil Olawale Saba,Choo Yee Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27354v1.html">Streptococcosis in aquaculture: Advances, challenges, and future directions in disease control and prevention</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hussein Aliu Sule, Abdulwakil Olawale Saba, Choo Yee Yu
                </div>

                <div class="paper-summary">
                    This comprehensive review synthesizes current knowledge on streptococcal infections (Streptococcus iniae, S. agalactiae) in aquaculture, which pose significant threats to global food security due to high fish morbidity and mortality. It details advancements in disease control and prevention strategies, monitoring technologies, and advocates for a holistic One-Health approach to foster sustainable and productive aquaculture systems. The paper consolidates insights on epidemiology, pathogenesis, and clinical manifestations, offering a roadmap for future research and collaborative efforts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Veterinary Medicine</span>
                    
                    <span class="domain-tag">Food Safety</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27354v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27354v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27354v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27354v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27326v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Preventive Medicine"
                     data-keywords="Breast Cancer,MRI,Classification,Early Detection,Screening,Medical Imaging,Deep Learning,Robustness"
                     data-authors="Benjamin Hamm,Yannick Kirchhoff,Maximilian Rokuss,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27326v1.html">MeisenMeister: A Simple Two Stage Pipeline for Breast Cancer Classification on MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Benjamin Hamm, Yannick Kirchhoff, Maximilian Rokuss et al.
                </div>

                <div class="paper-summary">
                    This paper introduces "MeisenMeister," a simple two-stage pipeline designed for breast cancer classification on MRI, developed for the ODELIA Breast MRI Challenge 2025. The approach aims to address the critical need for improving early detection by providing robust classification-based methods that mitigate the challenges posed by limited high-quality segmentation labels, particularly suitable for large-scale screening applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27326v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27326v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27326v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27326v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27321v1"
                     data-domains="Cardiology,Critical Care Medicine,Hospital Medicine,Predictive Analytics,Clinical Informatics"
                     data-keywords="Electronic Health Records,ECG,Multimodal Learning,Time Series Analysis,Deep Learning,Clinical Prediction,Cardiovascular Disease,Mortality Prediction"
                     data-authors="Yu-Chen Kuo,Yi-Ju Tseng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27321v1.html">MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu-Chen Kuo, Yi-Ju Tseng
                </div>

                <div class="paper-summary">
                    MedM2T is a novel time-aware multimodal framework designed to integrate heterogeneous Electronic Health Record (EHR) and Electrocardiogram (ECG) data, addressing complexities arising from their distinct temporal structures and multimodality. It demonstrates superior predictive performance over state-of-the-art models across critical clinical tasks, highlighting its robustness for both chronic and acute disease dynamics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Hospital Medicine</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27321v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27321v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27321v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27321v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27315v1"
                     data-domains="Cardiology,Interventional Radiology,Medical Imaging,Diagnostic Imaging"
                     data-keywords="coronary artery segmentation,deep learning,X-ray angiogram,CAD,UNet,DenseNet,Self-ONN,image processing"
                     data-authors="Alvee Hassan,Rusab Sarmun,Muhammad E. H. Chowdhury,M. Murugappan,Md. Sakib Abrar Hossain,Sakib Mahmud,Abdulrahman Alqahtani,Sohaib Bassam Zoghoul,Amith Khandakar,Susu M. Zughaier,Somaya Al-Maadeed,Anwarul Hasan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27315v1.html">CASR-Net: An Image Processing-focused Deep Learning-based Coronary Artery Segmentation and Refinement Network for X-ray Coronary Angiogram</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvee Hassan, Rusab Sarmun, Muhammad E. H. Chowdhury et al.
                </div>

                <div class="paper-summary">
                    CASR-Net is a novel deep learning pipeline designed for automated coronary artery segmentation and refinement from X-ray coronary angiograms, specifically addressing challenges posed by poor image quality and narrow vessel continuity. This three-stage network integrates advanced preprocessing, a UNet-based segmentation model with a DenseNet121 encoder and Self-ONN decoder, and a contour refinement module. The system demonstrates superior performance compared to state-of-the-art models, making it a robust tool for supporting clinical diagnosis and treatment planning for Coronary Artery Disease (CAD).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27307v1"
                     data-domains="Radiology,Pathology,Telemedicine,Medical Informatics,Digital Health,Medical Research Data Management"
                     data-keywords="Zero-watermarking,Dual quaternions,Matrix decomposition,Medical image security,Copyright protection,Tampering detection,Fragile watermarking,Image integrity"
                     data-authors="Mingcui Zhang,Zhigang Jia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27307v1.html">A fragile zero-watermarking method based on dual quaternion matrix decomposition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingcui Zhang, Zhigang Jia
                </div>

                <div class="paper-summary">
                    This paper introduces a novel fragile zero-watermarking method designed to protect medical images from copyright infringement and content tampering. The proposed model leverages dual quaternion matrix decomposition, utilizing the operational relationship between the standard and dual parts of dual quaternions to correlate the original medical image with a watermark. This approach generates zero-watermarking information without modifying the original carrier, thereby enabling robust copyright protection and sensitive content tampering detection for medical images.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27307v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27307v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27307v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27307v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27296v1"
                     data-domains="Ultrasound,Optical Coherence Tomography (OCT),Magnetic Resonance Imaging (MRI),Computed Tomography (CT),Endoscopic Imaging"
                     data-keywords="Medical Image Super-Resolution,Mamba,State-Space Models,Frequency-Gated,Deep Learning,Diagnostic Imaging,Image Enhancement,Computational Efficiency"
                     data-authors="Wenfeng Huang,Xiangyun Liao,Wei Cao,Wenjing Jia,Weixin Si">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27296v1.html">Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenfeng Huang, Xiangyun Liao, Wei Cao et al.
                </div>

                <div class="paper-summary">
                    FGMamba introduces a novel frequency-aware gated state-space model designed for versatile and efficient medical image super-resolution. It unifies global dependency modeling and fine-detail enhancement into a lightweight architecture, addressing the challenge of capturing both long-range anatomical structures and fine-grained frequency details with low computational overhead. The method achieves superior PSNR/SSIM scores across five diverse medical imaging modalities while maintaining a compact parameter footprint, outperforming existing CNN-based and Transformer-based SOTAs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ultrasound</span>
                    
                    <span class="domain-tag">Optical Coherence Tomography (OCT)</span>
                    
                    <span class="domain-tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="domain-tag">Computed Tomography (CT)</span>
                    
                    <span class="domain-tag">Endoscopic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27296v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27296v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27296v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27296v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27282v1"
                     data-domains="Biomedical research,Disease diagnostics,Histopathology,Physiological imaging,Tissue engineering"
                     data-keywords="X-ray microtomography,phase imaging,photon-counting detector,X-ray waveguide,native tissue,radiation dose,multimodal imaging,biological specimens"
                     data-authors="Dominik John,Gregor Breitenhuber,Sami Wirtensohn,Franziska Hinterdobler,Luka Gaetani,Sara Savatoviƒá,Jens Lucht,Markus Osterhoff,Marina Eckermann,Tim Salditt,Julia Herzen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27282v1.html">Near-perfect efficiency in X-ray phase microtomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.optics</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dominik John, Gregor Breitenhuber, Sami Wirtensohn et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel X-ray microtomography setup that achieves near-perfect efficiency in both X-ray detection and phase modulation visibility. By integrating an X-ray waveguide, a structured phase modulator, and a photon-counting detector, the system enables dose-efficient, multimodal imaging at single-micrometer resolution, overcoming the limitations of high radiation dose in conventional methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical research</span>
                    
                    <span class="domain-tag">Disease diagnostics</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Physiological imaging</span>
                    
                    <span class="domain-tag">Tissue engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27282v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27282v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27282v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27282v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27281v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Discovery,Computational Biology,Bioinformatics"
                     data-keywords="Drug-Target Affinity,DTA prediction,deep learning,hierarchical features,multi-scale features,drug discovery,computational pharmacology,sequence-based prediction"
                     data-authors="Minghui Li,Yuanhang Wang,Peijin Guo,Wei Wan,Shengshan Hu,Shengqing Hu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27281v1.html">HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Minghui Li, Yuanhang Wang, Peijin Guo et al.
                </div>

                <div class="paper-summary">
                    HiF-DTA is a novel hierarchical deep learning network designed to improve Drug-Target Affinity (DTA) prediction by simultaneously modeling global sequence semantics and local topological features from drug and protein sequences. It also represents drugs using multi-scale features (atomic, substructural, molecular) fused via bilinear attention. The model outperforms state-of-the-art baselines on benchmark datasets, confirming the importance of its global-local extraction and multi-scale fusion strategies for accelerating drug discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27281v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27281v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27281v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27281v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27274v1"
                     data-domains="Clinical Pharmacology,Medical Informatics,Artificial Intelligence in Medicine,Clinical Decision Support Systems,Patient Safety,Precision Medicine"
                     data-keywords="Drug Recommendation,Medical Knowledge Graph,Traceability,Explainable AI,Multi-task Learning,Clinical Decision Support,Patient Safety,Healthcare AI"
                     data-authors="Yu Lin,Zhen Jia,Philipp Christmann,Xu Zhang,Shengdong Du,Tianrui Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27274v1.html">Traceable Drug Recommendation over Medical Knowledge Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.IR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu Lin, Zhen Jia, Philipp Christmann et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TraceDR, a novel drug recommendation system built on a medical knowledge graph (MKG) that addresses the critical lack of traceability in existing deep learning approaches. Through a multi-task learning framework, TraceDR simultaneously predicts drug recommendations and their supporting evidence, enhancing transparency and trust in high-stakes clinical applications. The authors also release DrugRec, a new large-scale testbed constructed via an automated patient health record generation framework, to support more diverse disease and drug coverage.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27274v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27274v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27274v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27274v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27267v1"
                     data-domains="Internal Medicine,Surgery,Pediatrics,Cardiology,General Clinical Practice"
                     data-keywords="LLMs,medical calculation,quantitative reasoning,benchmark,reinforcement learning,clinical decision-making,MedCalc-Eval,MedCalc-Env"
                     data-authors="Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27267v1.html">MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kangkun Mao, Jinru Ding, Jiayuan Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedCalc-Eval, the largest benchmark for evaluating Large Language Models' (LLMs) medical quantitative reasoning, addressing a critical gap in existing assessments. Furthermore, it develops MedCalc-Env, a reinforcement learning environment that significantly enhances an LLM's capabilities in multi-step clinical calculation and reasoning, achieving state-of-the-art performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">General Clinical Practice</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27267v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27267v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27267v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27267v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27265v1"
                     data-domains="Medical Imaging (various unspecified modalities),Diagnostic Radiology,Clinical Decision Support"
                     data-keywords="Vision-Language Models,Medical Imaging,Model Merging,Test-Time Adaptation,Jensen-Shannon Divergence,Zero-Shot Learning,Modality Shift,Diagnostic Accuracy"
                     data-authors="Raza Imam,Hu Wang,Dwarikanath Mahapatra,Mohammad Yaqub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27265v1.html">T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Raza Imam, Hu Wang, Dwarikanath Mahapatra et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Test-Time Task adaptive merging (T^3), a novel, backpropagation-free framework for Vision-Language Models (VLMs) in medical imaging that dynamically merges a robust generalist model with a precise expert model. T^3 computes per-sample interpolation coefficients using Jensen-Shannon divergence between model output distributions, addressing the challenge of maintaining accuracy across diverse medical modalities and under modality shift. An efficient batch-wise extension, T^3_B, is also proposed to reduce computational costs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging (various unspecified modalities)</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27265v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27265v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27265v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27265v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27247v1"
                     data-domains="Neurology,Rehabilitation Medicine,Assistive Technology,Neuroscience,Communication Disorders"
                     data-keywords="Brain-to-speech (BTS),Electroencephalography (EEG),Electromyography (EMG),Phoneme decoding,Open-vocabulary communication,Neural communication,Speech synthesis,Assistive technology"
                     data-authors="Deok-Seon Kim,Seo-Hyun Lee,Kang Yin,Seong-Whan Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27247v1.html">Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deok-Seon Kim, Seo-Hyun Lee, Kang Yin et al.
                </div>

                <div class="paper-summary">
                    This study addresses the limitation of current Brain-to-Speech (BTS) systems in decoding predefined content by demonstrating the feasibility of synthesizing previously unseen sentences. It leverages phoneme-level information from high-density EEG, both independently and in conjunction with EMG signals, to achieve open-vocabulary neural communication. The research provides crucial neurophysiological insights to enhance EEG decoding, marking a significant step towards personalized and adaptive communication and rehabilitation solutions for patients.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Communication Disorders</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27247v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27247v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27247v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27247v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27237v1"
                     data-domains="Oncology,Pathology,Lung Cancer,Bladder Cancer,Colorectal Cancer"
                     data-keywords="Whole Slide Image analysis,Pathology,Foundation Models,Model Fusion,Heterogeneous Models,Computational Pathology,Cancer Diagnosis,Machine Learning"
                     data-authors="Zhidong Yang,Xiuhui Shi,Wei Ba,Zhigang Song,Haijing Luan,Taiyuan Hu,Senlin Lin,Jiguang Wang,Shaohua Kevin Zhou,Rui Yan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27237v1.html">Fusion of Heterogeneous Pathology Foundation Models for Whole Slide Image Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhidong Yang, Xiuhui Shi, Wei Ba et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FuseCPath, a novel framework designed to fuse heterogeneous pathological Foundation Models (FMs) for improved Whole Slide Image (WSI) analysis. By addressing performance variability caused by diverse FMs through multi-view clustering, cluster-level re-embedding, and collaborative distillation, FuseCPath achieves state-of-the-art ensemble performance on challenging cancer datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Lung Cancer</span>
                    
                    <span class="domain-tag">Bladder Cancer</span>
                    
                    <span class="domain-tag">Colorectal Cancer</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27237v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27237v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27237v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27237v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27213v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Pulmonology (implied by Chest CT)"
                     data-keywords="Continual Learning,Self-Supervised Learning,Chest CT,Domain Shift,Privacy-Aware AI,Catastrophic Forgetting,Feature Distillation,Multi-Window Imaging"
                     data-authors="Ren Tasai,Guang Li,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27213v1.html">Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ren Tasai, Guang Li, Ren Togo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel privacy-aware continual self-supervised learning (CSSL) framework designed to learn diverse and domain-shift-robust features from multi-window chest computed tomography (CT) images. It addresses challenges like data scarcity, privacy constraints, and domain shifts arising from varied CT window settings, which typically hinder robust medical AI model development. By integrating a latent replay mechanism and a unique feature distillation technique, the framework effectively mitigates catastrophic forgetting and demonstrates superior performance in learning generalizable representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pulmonology (implied by Chest CT)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27213v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27213v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27213v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27213v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27197v1"
                     data-domains="Public Health,Epidemiology,Emergency Medicine,Trauma Care,Preventive Medicine,Health Policy"
                     data-keywords="Graph Neural Network,Traffic Risk Forecasting,Public Health,Urban Planning,Spatial Diffusion,Temporal Attention,Accident Prediction,Transportation Safety"
                     data-authors="Ziyuan Gao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27197v1.html">MDAS-GNN: Multi-Dimensional Spatiotemporal GNN with Spatial Diffusion for Urban Traffic Risk Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziyuan Gao
                </div>

                <div class="paper-summary">
                    MDAS-GNN, a Multi-Dimensional Attention-based Spatial-diffusion Graph Neural Network, is introduced to address urban traffic risk forecasting by integrating traffic safety, infrastructure, and environmental risks. It leverages feature-specific spatial diffusion and multi-head temporal attention to capture complex spatiotemporal dependencies in urban transportation networks. The model demonstrates superior performance over baselines, particularly in long-term accident risk prediction, offering advanced capabilities for urban planning and infrastructure optimization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Trauma Care</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27197v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27197v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27197v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27197v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27194v1"
                     data-domains="Digital Health,Integrated Care Systems,Medical Device Development & Regulation,Hospital Information Systems (HIS),Precision Medicine Infrastructure"
                     data-keywords="System of Systems (SoS),Lifecycle Management,Model-Based Systems Engineering (MBSE),Product Lifecycle Management (PLM),Digital Twin,Interoperability,Healthcare Systems,Network-Centric Development"
                     data-authors="Vahid Salehi,Josef Vilsmeier,Shirui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27194v1.html">From product to system network challenges in system of systems lifecycle management</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vahid Salehi, Josef Vilsmeier, Shirui Wang
                </div>

                <div class="paper-summary">
                    This paper addresses the growing complexity in product development, where isolated products are now interconnected nodes in networked Systems of Systems (SoS), rendering traditional linear lifecycle models inadequate. It proposes a practical framework for SoS lifecycle management, integrating Model-Based Systems Engineering (MBSE) for semantics, Product Lifecycle Management (PLM) for governance, and digital thread/twin for continuous feedback, underpinned by four key principles and a three-step roadmap for network-centric development. The ultimate goal is to enhance change robustness, reduce throughput times, and improve sustainability in complex system design.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Integrated Care Systems</span>
                    
                    <span class="domain-tag">Medical Device Development & Regulation</span>
                    
                    <span class="domain-tag">Hospital Information Systems (HIS)</span>
                    
                    <span class="domain-tag">Precision Medicine Infrastructure</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27194v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27194v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27194v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27194v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27158v1"
                     data-domains="Nephrology,Transplant Medicine,Pathology,Histopathology"
                     data-keywords="Banff Classification,Renal Transplant Biopsy,Deep Learning,Computational Pathology,AI Limitations,Image Segmentation,Object Detection,Histopathology"
                     data-authors="Yanfan Zhu,Juming Xiong,Ruining Deng,Yu Wang,Yaohong Wang,Shilin Zhao,Mengmeng Yin,Yuqing Liu,Haichun Yang,Yuankai Huo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27158v1.html">How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yanfan Zhu, Juming Xiong, Ruining Deng et al.
                </div>

                <div class="paper-summary">
                    This study investigates the feasibility of approximating the complex Banff lesion scores for renal transplant biopsies using existing deep learning models within a modular, rule-based framework. While achieving partial successes, the research identified critical limitations in current AI pipelines, including structural omission, hallucination, and detection ambiguity, ultimately highlighting the need for modular evaluation and computational grading standards to enhance interpretability and performance in transplant pathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Transplant Medicine</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27130v1"
                     data-domains="Pharmacology,Drug Development,Toxicology,Pharmaceutical Research,Biomedical Informatics,Precision Medicine"
                     data-keywords="AI Agents,Drug Discovery,Large Language Models,Autonomous Systems,Drug Repurposing,Robotic Platforms,Pharmaceutical R&D,AI Architectures"
                     data-authors="Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27130v1.html">AI Agents in Drug Discovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Srijit Seal, Dinh Long Huynh, Moudather Chelbi et al.
                </div>

                <div class="paper-summary">
                    This paper presents a comprehensive overview of how AI agents, built upon large language models (LLMs) coupled with perception, computation, action, and memory tools, are transforming drug discovery by autonomously reasoning, acting, and learning through complex research workflows. It details various agentic AI architectures and illustrates their real-world applications across key stages of drug discovery, demonstrating substantial gains in speed, reproducibility, and scalability, compressing multi-month workflows into hours.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27130v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27130v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27130v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27130v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27097v1"
                     data-domains="Reproductive Medicine,Gynecology,Endocrinology,Computational Biology,Fertility"
                     data-keywords="Gene Deconvolution,Hierarchical Bayesian Model,RNA Sequencing,Single-cell Transcriptomics,Human Endometrium,Menstrual Cycle,Cell-type Specific Expression,Decidualization"
                     data-authors="Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27097v1.html">Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Crystal Su, Kuai Yu, Mingyuan Shao et al.
                </div>

                <div class="paper-summary">
                    This paper presents a probabilistic hierarchical Bayesian model designed to deconvolve bulk RNA-seq data, leveraging a single-cell reference to infer cell-type-specific expression profiles and proportions. Applied to the human endometrium across the menstrual cycle, the model successfully reveals dynamic shifts in cell populations and identifies crucial cell-type-specific differential gene expression, such as decidualization markers. This approach provides a robust framework for understanding complex tissue heterogeneity and its functional implications in dynamic biological contexts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Reproductive Medicine</span>
                    
                    <span class="domain-tag">Gynecology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Fertility</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27097v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27097v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27097v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27097v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27074v1"
                     data-domains="q-bio.BM"
                     data-keywords="q-bio.BM,cond-mat.mes-hall,cond-mat.soft"
                     data-authors="Carlos Bustamante,Christian Kaiser,Erik Lindhal,Robert Sosa,Giovanni Volpe">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27074v1.html">How Do Proteins Fold?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Carlos Bustamante, Christian Kaiser, Erik Lindhal et al.
                </div>

                <div class="paper-summary">
                    How proteins fold remains a central unsolved problem in biology. While the
idea of a folding code embedded in the amino acid sequence was introduced more
than 6 decades ago, this code remains undefined. While we now have powerful
predictive tools to predict the final native structure of proteins, we...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.BM</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27074v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27074v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27074v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27074v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27030v1"
                     data-domains="Immunology,Vaccinology,Infectious Disease Research,Evolutionary Medicine,Oncology (tumor evolution)"
                     data-keywords="Phylogenetic trees,Ranked tree shapes,Heterochronous,F-matrices,Combinatorics,B cell affinity maturation,Evolutionary biology,Phylograms"
                     data-authors="Chris Jennings-Shaffer,Cherith Chen,Julia A Palacios,Frederick A Matsen IV">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27030v1.html">Generalizing matrix representations to fully heterochronous ranked tree shapes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chris Jennings-Shaffer, Cherith Chen, Julia A Palacios et al.
                </div>

                <div class="paper-summary">
                    This paper extends the F-matrix framework, previously established for isochronous ranked phylogenetic tree shapes, to fully heterochronous ranked tree shapes. It establishes an explicit bijection between a new class of F-matrices and these heterochronous tree shapes, offering a method for straightforward enumeration and the development of probabilistic models for evolutionary processes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Infectious Disease Research</span>
                    
                    <span class="domain-tag">Evolutionary Medicine</span>
                    
                    <span class="domain-tag">Oncology (tumor evolution)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27030v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27030v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27030v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27030v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26996v1"
                     data-domains="Radiology,Diagnostic Imaging"
                     data-keywords="Medical Image Segmentation,Mixture of Experts (MoE),Vision-Language Models,Foundation Models,CT Imaging,Textual Embeddings,Multi-scale Features,Deep Learning"
                     data-authors="Arghavan Rezvani,Xiangyi Yan,Anthony T. Wu,Kun Han,Pooya Khosravi,Xiaohui Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26996v1.html">MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Arghavan Rezvani, Xiangyi Yan, Anthony T. Wu et al.
                </div>

                <div class="paper-summary">
                    MoME introduces a novel Mixture of Visual Language Medical Experts (MoE) architecture, adapted from Large Language Models, for medical image segmentation. It leverages multi-scale visual features and textual embeddings to enable dynamic expert selection, achieving strong and competitive precision on a comprehensive benchmark of 10 datasets encompassing 3,410 CT scans. The approach demonstrates a robust integration of foundation models and textual information for enhanced medical image analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26996v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26996v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26996v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26996v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26974v1"
                     data-domains="Clinical Informatics,Health Information Management,Medical Natural Language Processing,Digital Health,EHR Systems"
                     data-keywords="Medical Order Extraction,Doctor-Patient Consultations,Clinical Documentation,Electronic Health Records (EHR),Large Language Models (LLMs),Natural Language Processing (NLP),Shared Task,Healthcare AI"
                     data-authors="Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26974v1.html">Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jean-Philippe Corbeil, Asma Ben Abacha, Jerome Tremblay et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MEDIQA-OE 2025, the inaugural shared task focused on extracting actionable medical orders from doctor-patient consultations, a critical step towards automating clinical documentation. Six participating teams explored diverse methodologies, including both closed- and open-weight large language models, to address the challenge of converting spoken interactions into structured Electronic Health Record (EHR) entries. The paper details the task, dataset, final leaderboard, and the innovative solutions developed by the participants.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Information Management</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">EHR Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26974v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26974v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26974v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26974v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26969v1"
                     data-domains="Public Health,Primary Care,Epidemiology,Health Informatics,Violence Prevention,Social Medicine"
                     data-keywords="Frame Semantics,Natural Language Processing,Gender-Based Violence,Underreporting,E-medical Records,Public Health Surveillance,Primary Care,Notifiable Events"
                     data-authors="L√≠via Dutra,Arthur Lorenzi,La√≠s Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Ol√≠via Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26969v1.html">Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> L√≠via Dutra, Arthur Lorenzi, La√≠s Berno et al.
                </div>

                <div class="paper-summary">
                    This research introduces a novel methodology leveraging frame semantic patterns to identify notifiable events within unstructured open-text fields of electronic medical records. Applied to detect underreporting of gender-based violence (GBV) in Brazilian primary care, the approach demonstrated robust performance with a precision of 0.726 in identifying violence reports. The methodology is designed to be transparent, efficient, and language-agnostic, making it adaptable for various public health surveillance contexts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Violence Prevention</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26969v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26969v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26969v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26969v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26961v1"
                     data-domains="Clinical Neuroimaging,Neuroradiology,Neurology,Neurosurgery,Medical Image Analysis"
                     data-keywords="Deep Learning,Brain Lesion Segmentation,Multi-modal MRI,Hybrid Architecture,Swin Transformer,Clinical Neuroimaging,Generalization,Robustness"
                     data-authors="Md. Mehedi Hassan,Shafqat Alam,Shahriar Ahmed Seam,Maruf Ahmed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26961v1.html">SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md. Mehedi Hassan, Shafqat Alam, Shahriar Ahmed Seam et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SYNAPSE-Net, a unified and adaptive deep learning framework designed for robust and generalized segmentation of heterogeneous brain lesions from multi-modal MRI. By integrating a novel hybrid architecture with multi-stream CNNs, a Swin Transformer bottleneck, dynamic cross-modal attention, and a hierarchical gated decoder, coupled with a variance reduction training strategy, the model achieves state-of-the-art performance across diverse brain pathologies. The framework demonstrates high generalization and reliability, providing a clinically feasible solution for automated lesion segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Neuroimaging</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26961v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26961v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26961v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26961v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26940v1"
                     data-domains="Public health,Epidemiology,Health informatics,Disease surveillance,Emergency medical services (EMS),Health equity,Geographic information systems (GIS) in health"
                     data-keywords="Mobility prediction,Algorithmic fairness,Demographic disparity,Incremental sampling,Clustering,Public health,Data equity,Machine learning"
                     data-authors="Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26940v1.html">Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ashwin Kumar, Hanyu Zhang, David A. Schweidel et al.
                </div>

                <div class="paper-summary">
                    This paper reveals significant demographic disparities in state-of-the-art mobility prediction models, where predictive performance varies widely across racial and ethnic user groups due to underlying dataset biases. To counteract this, the authors propose Fairness-Guided Incremental Sampling (FGIS), which, alongside a novel Size-Aware K-Means (SAKM) clustering method for inferring proxy demographic labels, incrementally builds fairer training datasets. FGIS successfully reduces inter-group performance disparities by up to 40% with minimal overall accuracy loss, demonstrating impactful fairness gains, especially in low-resource settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health informatics</span>
                    
                    <span class="domain-tag">Disease surveillance</span>
                    
                    <span class="domain-tag">Emergency medical services (EMS)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26940v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26940v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26940v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26940v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26928v1"
                     data-domains="Radiation Oncology,Medical Physics,Radiobiology"
                     data-keywords="FLASH effect,Ultra-high dose-rates (UHDR),Hydrogen peroxide (H2O2),G-values,Radiation chemistry,Monte-Carlo simulations,Radiotherapy,Water radiolysis"
                     data-authors="Marc Benjamin Hahn">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26928v1.html">Ultra-High Dose-Rates, the FLASH Effect, and Hydrogen Peroxide Yields: Do Experiments and Simulations Really Disagree?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marc Benjamin Hahn
                </div>

                <div class="paper-summary">
                    This paper critically analyzes the significant discrepancies observed between experimental measurements and Monte-Carlo simulations concerning hydrogen peroxide (H2O2) yields (g-values) in water irradiated at ultra-high dose-rates (UHDR), a key aspect of the FLASH effect. It reviews existing literature, covering diverse experimental setups and simulation methodologies, to pinpoint potential causes for these contradictions and advocate for the development of testable, mechanistic models to resolve the issue.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiobiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26928v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26928v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26928v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26928v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26923v1"
                     data-domains="Radiology,Oncology,Medical Imaging,Pulmonology"
                     data-keywords="lung nodule detection,curriculum learning,data-efficient,YOLOv11,deep learning,chest CT,medical imaging,limited data"
                     data-authors="Yi Luo,Yike Guo,Hamed Hooshangnejad,Kai Ding">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26923v1.html">Scale-Aware Curriculum Learning for Ddata-Efficient Lung Nodule Detection with YOLOv11</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yi Luo, Yike Guo, Hamed Hooshangnejad et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Scale Adaptive Curriculum Learning (SACL), a novel training strategy designed to overcome challenges in deep learning-based lung nodule detection when annotated data is scarce. SACL dynamically adjusts its curriculum based on available data scale, demonstrating significant performance improvements (up to 4.6% mAP50) over baseline methods in data-limited scenarios, while maintaining comparable performance on full datasets without architectural modifications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26923v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26923v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26923v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26923v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26903v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,physics.med-ph"
                     data-authors="Rochak Dhakal,Chen Zhao,Zixin Shi,Joyce H. Keyak,Tadashi S. Kaneko,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Weihua Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26903v1.html">PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rochak Dhakal, Chen Zhao, Zixin Shi et al.
                </div>

                <div class="paper-summary">
                    Quantitative computed tomography (QCT) plays a crucial role in assessing bone
strength and fracture risk by enabling volumetric analysis of bone density
distribution in the proximal femur. However, deploying automated segmentation
models in practice remains difficult because deep networks trained on...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26903v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26903v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26903v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26903v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26887v1"
                     data-domains="biology,biophysics,biomedical informatics,medicine,neuroscience"
                     data-keywords="AI multi-agent system,scientific discovery,biomedical informatics,research automation,deep learning,literature review,code generation,medical research"
                     data-authors="Francisco Villaescusa-Navarro,Boris Bolliet,Pablo Villanueva-Domingo,Adrian E. Bayer,Aidan Acquah,Chetana Amancharla,Almog Barzilay-Siegal,Pablo Bermejo,Camille Bilodeau,Pablo C√°rdenas Ram√≠rez,Miles Cranmer,Urbano L. Fran√ßa,ChangHoon Hahn,Yan-Fei Jiang,Raul Jimenez,Jun-Young Lee,Antonio Lerario,Osman Mamun,Thomas Meier,Anupam A. Ojha,Pavlos Protopapas,Shimanto Roy,David N. Spergel,Pedro Taranc√≥n-√Ålvarez,Ujjwal Tiwari,Matteo Viel,Digvijay Wadekar,Chi Wang,Bonny Y. Wang,Licong Xu,Yossi Yovel,Shuwen Yue,Wen-Han Zhou,Qiyao Zhu,Jiajun Zou,√ç√±igo Zubeldia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26887v1.html">The Denario project: Deep knowledge AI agents for scientific discovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Francisco Villaescusa-Navarro, Boris Bolliet, Pablo Villanueva-Domingo et al.
                </div>

                <div class="paper-summary">
                    The Denario project introduces a novel AI multi-agent system designed to function as a comprehensive scientific research assistant. This system demonstrates capabilities spanning idea generation, literature review, research planning, code execution, data visualization, and the drafting and reviewing of full scientific papers, successfully generating expert-validated papers across numerous scientific disciplines, including various medical fields.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">biology</span>
                    
                    <span class="domain-tag">biophysics</span>
                    
                    <span class="domain-tag">biomedical informatics</span>
                    
                    <span class="domain-tag">medicine</span>
                    
                    <span class="domain-tag">neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26887v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26887v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26887v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26887v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26783v1"
                     data-domains="Epidemiology,Clinical Trials,Health Services Research,Pharmacoepidemiology,Public Health,Precision Medicine"
                     data-keywords="causal inference,average treatment effect,Riesz regression,covariate balancing,density-ratio estimation,TMLE,matching estimator,debiased estimation"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26783v1.html">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper introduces a unified theoretical framework for causal inference, integrating various established methods such as Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and matching estimators for Average Treatment Effect (ATE) estimation. It elucidates the profound interconnections and equivalences among these diverse approaches, particularly emphasizing the pivotal role of 'balancing weights' (also known as Riesz representers or clever covariates) and how different methods estimate them.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Health Services Research</span>
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26783v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26783v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26759v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Computed Tomography,Oncology (due to lesion types)"
                     data-keywords="CT reconstruction,medical imaging,deep learning,generalization,multi-organ,dataset,lesion detection,optimization-based methods"
                     data-authors="Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26759v1.html">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Multi-Organ medical image REconstruction (MORE) dataset, a comprehensive collection of CT scans spanning 9 diverse anatomies and 15 lesion types, designed to address the generalization limitations of existing deep learning CT reconstruction methods. It enables robust model training and rigorous evaluation of generalization capabilities. The authors also establish a strong optimization-based baseline model that demonstrates enhanced robustness on unseen anatomies, affirming the value of comprehensive datasets for improving model generalization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computed Tomography</span>
                    
                    <span class="domain-tag">Oncology (due to lesion types)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26723v1"
                     data-domains="Personalized Medicine,Precision Health,Clinical Decision Support,Health Policy,Pharmacogenomics,Public Health Interventions"
                     data-keywords="Policy Learning,Causal Inference,Treatment Effect,Empirical Welfare Maximization,Conditional Average Treatment Effect,Machine Learning,Optimization,Regularization"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26723v1.html">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper establishes a fundamental equivalence between two prominent policy learning paradigms: Empirical Welfare Maximization (EWM) and the plug-in approach based on Conditional Average Treatment Effect (CATE) estimation. By demonstrating that both are based on essentially the same optimization problem via a reparameterization, the study unifies their theoretical guarantees and interchangability. Leveraging this insight, the author proposes a novel regularization method that offers a convex and computationally efficient training procedure for policy learning, circumventing the typically NP-hard combinatorial step of EWM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Precision Health</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26723v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26723v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26715v1"
                     data-domains="Precision medicine,Biomarker discovery,Clinical diagnostics,Prognostics,Metabolomics,Proteomics,Pharmacology"
                     data-keywords="Mass spectrometry,Deep learning,Foundation model,Spectral identification,Biological interpretation,Biomarkers,Disease diagnostics,Clinical outcomes"
                     data-authors="Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26715v1.html">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Asher, Devesh Shah, Amy A. Caudy et al.
                </div>

                <div class="paper-summary">
                    LSM-MS2 is a novel large-scale deep learning foundation model developed to enhance both spectral identification and biological interpretation of mass spectrometry data. Trained on millions of spectra, it achieves state-of-the-art performance in identifying challenging compounds and generating rich spectral embeddings that directly enable disease differentiation and clinical outcome prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision medicine</span>
                    
                    <span class="domain-tag">Biomarker discovery</span>
                    
                    <span class="domain-tag">Clinical diagnostics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Metabolomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-03 06:31:30</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>