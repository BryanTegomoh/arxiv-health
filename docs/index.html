<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">178</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (6), Medical Imaging (5), Clinical Informatics (5)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (6)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (5)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (5)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Oncology">Oncology (4)</option>
                        
                        <option value="Bioinformatics">Bioinformatics (4)</option>
                        
                        <option value="Surgical Planning">Surgical Planning (3)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (3)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.05920v1"
                     data-domains="Orthognathic Surgery,Maxillofacial Surgery,Dentistry,Plastic Surgery,Medical Imaging,Surgical Planning,Biomedical Engineering"
                     data-keywords="Orthognathic Surgery,Surgical Prediction,Neural Implicit Representations,Craniofacial Model,Soft Tissue Deformation,Facial Aesthetics,Signed Distance Function (SDF),Surgical Planning"
                     data-authors="Jiawen Yang,Yihui Cao,Xuanyu Tian,Yuyao Zhang,Hongjiang Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05920v1.html">NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiawen Yang, Yihui Cao, Xuanyu Tian et al.
                </div>

                <div class="paper-summary">
                    This paper introduces NICE (Neural Implicit Craniofacial Model), a novel approach utilizing implicit neural representations to accurately predict postoperative facial appearance in orthognathic surgery. NICE addresses the complex, nonlinear interactions between skeletal movements and soft tissue, outperforming existing methods by providing more precise predictions, especially in critical facial regions like the lips and chin.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthognathic Surgery</span>
                    
                    <span class="domain-tag">Maxillofacial Surgery</span>
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Plastic Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05920v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05920v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05920v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05920v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05863v1"
                     data-domains="Clinical Informatics,Biomedical Research,Medical Education,Decision Support Systems,Patient Information"
                     data-keywords="Medical QA,LLMs,RAG,Fine-tuning,LLaMA-2,Hallucination,Factual Accuracy,Clinical Informatics"
                     data-authors="Tasnimul Hassan,Md Faisal Karim,Haziq Jeelani,Elham Behnam,Robert Green,Fayeq Jeelani Syed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05863v1.html">Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tasnimul Hassan, Md Faisal Karim, Haziq Jeelani et al.
                </div>

                <div class="paper-summary">
                    This paper presents a Retrieval-Augmented Generation (RAG) based medical question-answering (QA) system designed to address challenges of factual accuracy and hallucinations in LLMs for clinical use. By fine-tuning open-source LLMs (LLaMA-2 and Falcon) with LoRA and grounding answers in retrieved medical literature, the system significantly improves accuracy and reduces unsupported content, demonstrating potential for reliable biomedical QA applications. The fine-tuned LLaMA-2 model achieved 71.8% accuracy on PubMedQA, a substantial improvement over its 55.4% zero-shot baseline.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Decision Support Systems</span>
                    
                    <span class="domain-tag">Patient Information</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05863v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05863v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05863v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05863v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05836v1"
                     data-domains="Psychiatry,Clinical Psychology,Psychotherapy,Mental Health,Behavioral Health"
                     data-keywords="Large Language Models,Personalized Networks,Psychotherapy,Treatment Personalization,Case Conceptualization,Therapy Transcripts,In-context Learning,Mental Health AI"
                     data-authors="Clarissa W. Ong,Hiba Arnaout,Kate Sheehan,Estella Fox,Eugen Owtscharow,Iryna Gurevych">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05836v1.html">Using Large Language Models to Create Personalized Networks From Therapy Sessions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Clarissa W. Ong, Hiba Arnaout, Kate Sheehan et al.
                </div>

                <div class="paper-summary">
                    This paper presents an end-to-end pipeline leveraging Large Language Models (LLMs) to automatically generate personalized psychological networks from therapy session transcripts. The multi-step approach, which includes in-context learning for process identification and a two-step clustering method for network formation, was significantly preferred by experts for its clinical utility and interpretability over direct LLM prompting.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Psychotherapy</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05836v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05836v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05836v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05836v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05824v1"
                     data-domains="Neuro-oncology,Pathology,Cancer Genomics,Computational Pathology,Medical AI"
                     data-keywords="Glioma,IDH1 mutation,Multimodal AI,Oncology Agent,Histopathology,Prognosis,Personalized Medicine,Machine Learning"
                     data-authors="Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05824v1.html">Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hafsa Akebli, Adam Shephard, Vincenzo Della Mea et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Multimodal Oncology Agent (MOA) designed for accurate IDH1 mutation prediction in low-grade gliomas. The MOA integrates a histology analysis tool, based on the TITAN foundation model, with a reasoning component that processes structured clinical and genomic data, further enriched by external biomedical sources like PubMed and OncoKB. The agent achieved a superior F1-score of 0.912 when fusing histology features, outperforming clinical, histology, and fused baselines in identifying IDH1 mutations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Cancer Genomics</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05824v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05824v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05824v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05824v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05814v1"
                     data-domains="Neurology,Radiology,Neuroimaging,Geriatrics,Clinical Informatics"
                     data-keywords="Alzheimer's Disease,Early Diagnosis,Federated Learning,Domain Adaptation,Uncertainty Quantification,Multi-center Study,Structural MRI,Neurodegeneration"
                     data-authors="Fubao Zhu,Zhanyuan Jia,Zhiguo Wang,Huan Huang,Danyang Sun,Chuang Han,Yanting Li,Jiaofen Nan,Chen Zhao,Weihua Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05814v1.html">UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer's Disease Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fubao Zhu, Zhanyuan Jia, Zhiguo Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces UG-FedDA, an Uncertainty-Guided Federated Domain Adaptation framework designed for multi-center Alzheimer's disease (AD) detection, addressing inter-site data heterogeneity and privacy concerns. By integrating uncertainty quantification (UQ) with federated learning, the method achieves robust AD classification across diverse datasets. The framework demonstrated consistent improvements in accuracy, sensitivity, and AUC for AD vs. normal controls (NC), mild cognitive impairment (MCI) vs. AD, and NC vs. MCI tasks on ADNI, AIBL, and OASIS datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05814v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05814v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05814v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05814v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05740v1"
                     data-domains="Surgery,Colorectal Surgery,Medical Imaging,Artificial Intelligence in Medicine,Medical Education"
                     data-keywords="Vision-Language Models (VLMs),Surgical Scene Understanding,Complete Mesocolic Excision (CME),Knowledge Distillation,Privacy-Preserving AI,Supervised Fine-Tuning (SFT),Direct Preference Optimization (DPO),Medical AI"
                     data-authors="Lennart Maack,Julia-Kristin Gra√ü,Lisa-Marie Toscha,Nathaniel Melling,Alexander Schlaefer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05740v1.html">Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lennart Maack, Julia-Kristin Gra√ü, Lisa-Marie Toscha et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a privacy-preserving framework to train local Vision Large Language Models (VLMs) specifically for surgical scene understanding, focusing on anatomy explanation during Complete Mesocolic Excision (CME). By distilling expert knowledge from a general-purpose teacher LLM into an efficient local VLM, the authors demonstrate a significant increase in surgical domain knowledge while ensuring patient data privacy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Colorectal Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05740v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05740v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05740v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05740v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05671v1"
                     data-domains="Clinical Medical Education,Medical Training,Healthcare Simulation"
                     data-keywords="Medical Education,Socratic Teaching,Large Language Models (LLMs),Multi-Agent Simulation,Clinical Training,Reinforcement Learning,Collaborative Reasoning,Pedagogical AI"
                     data-authors="Zhitao He,Haolin Yang,Zeyu Qin,Yi R Fung">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05671v1.html">MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhitao He, Haolin Yang, Zeyu Qin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedTutor-R1, a novel multimodal Socratic tutor designed for one-to-many instruction in clinical medical education, addressing the scarcity of expert instruction and the need for collaborative reasoning skills. Utilizing a multi-agent pedagogical simulator (ClinEdu) and a specialized Socratic teaching dialogue dataset (ClinTeach), MedTutor-R1 is instruction-tuned and then optimized with reinforcement learning using a three-axis rubric for adaptive strategies. Experimental results demonstrate that MedTutor-R1 significantly outperforms base models, achieving over 20% higher average pedagogical scores and exhibiting strong adaptability, thus highlighting the efficacy of the developed simulator.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Medical Education</span>
                    
                    <span class="domain-tag">Medical Training</span>
                    
                    <span class="domain-tag">Healthcare Simulation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05658v1"
                     data-domains="General Medicine,Medical Informatics,Clinical Decision Support"
                     data-keywords="Large Language Models,Medical Reasoning,Question Answering,Multilingual AI,Retrieval-Augmented Generation,Clinical Decision Support,Medical QA Benchmarks,Fine-tuning"
                     data-authors="Pietro Ferrazzi,Aitor Soroa,Rodrigo Agerri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05658v1.html">Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pietro Ferrazzi, Aitor Soroa, Rodrigo Agerri
                </div>

                <div class="paper-summary">
                    This paper introduces a novel method to generate 500k multilingual reasoning traces in English, Italian, and Spanish, grounded in factual medical knowledge from Wikipedia, to enhance Large Language Models (LLMs) for medical Question Answering (QA). By employing a retrieval-augmented generation approach and extending existing QA datasets, these traces significantly improve LLM performance in both few-shot and fine-tuning settings, achieving state-of-the-art results among 8B-parameter models. The work provides crucial resources to develop safer and more transparent multilingual clinical decision-support tools.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05658v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05658v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05658v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05658v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05649v1"
                     data-domains="Disease Diagnostics,Cell Therapy,Biomedical Research,Oncology,Hematology,Regenerative Medicine"
                     data-keywords="Deterministic Lateral Displacement (DLD),microfluidics,cell sorting,machine learning,particle-based simulation,cell mechanics,design optimization,surrogate modeling"
                     data-authors="Khayrul Islam,Mehedi Hasan,Yaling Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05649v1.html">Physics-Guided Surrogate Modeling for Machine Learning-Driven DLD Design Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Khayrul Islam, Mehedi Hasan, Yaling Liu
                </div>

                <div class="paper-summary">
                    This paper introduces a simulation-driven machine learning (ML) framework designed to optimize Deterministic Lateral Displacement (DLD) microfluidic devices for label-free cell sorting. By integrating high-fidelity particle-based simulations with supervised ML, the framework rapidly predicts optimal DLD geometries based on cellular mechanical properties like bending rigidity and shear modulus, overcoming traditional trial-and-error design challenges. A deployable web interface is also demonstrated, enhancing accessibility for real-world prototyping.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Disease Diagnostics</span>
                    
                    <span class="domain-tag">Cell Therapy</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Hematology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05649v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05649v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05649v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05649v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05613v1"
                     data-domains="Medical Imaging,Radiology,Pathology Segmentation,Diagnostics,Surgical Planning"
                     data-keywords="Few-Shot Learning,Semantic Segmentation,Cross-Domain,Knowledge Distillation,Medical Imaging,Lightweight Models,Computational Efficiency,Deep Learning"
                     data-authors="Pasquale De Marinis,Pieter M. Blok,Uzay Kaymak,Rogier Brussee,Gennaro Vessio,Giovanna Castellano">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05613v1.html">DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pasquale De Marinis, Pieter M. Blok, Uzay Kaymak et al.
                </div>

                <div class="paper-summary">
                    DistillFSS proposes a novel framework for Cross-Domain Few-Shot Semantic Segmentation (CD-FSS) that internalizes support-set knowledge into a lightweight student model via teacher-student distillation. This approach eliminates the need for support images at test time, enabling fast and efficient inference while allowing rapid adaptation to novel classes and unseen domains. Evaluated on a new benchmark including medical imaging, DistillFSS matches or surpasses state-of-the-art baselines, especially in multi-class and multi-shot scenarios, with significant efficiency gains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology Segmentation</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05613v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05613v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05613v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05613v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05576v1"
                     data-domains="Clinical diagnosis,Medical decision support,Therapeutics,AI in healthcare"
                     data-keywords="Clinical reasoning,Large Language Models (LLMs),AI in medicine,Executor-Analyst Framework,Context Utilization Failure,Modular AI,Training-free,Therapeutics"
                     data-authors="Ting-Ting Xie,Yixin Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05576v1.html">CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ting-Ting Xie, Yixin Zhang
                </div>

                <div class="paper-summary">
                    This paper introduces CureAgent, an Executor-Analyst Framework designed to overcome "Context Utilization Failure" in small LLM-based clinical agents by decoupling tool execution from clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts) and employing a Stratified Ensemble strategy, it achieves state-of-the-art performance on CURE-Bench without costly finetuning. The work provides insights into context scaling and toolset complexity, laying a foundation for trustworthy AI-driven therapeutics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical diagnosis</span>
                    
                    <span class="domain-tag">Medical decision support</span>
                    
                    <span class="domain-tag">Therapeutics</span>
                    
                    <span class="domain-tag">AI in healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05576v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05576v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05576v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05576v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05573v1"
                     data-domains="Immunogenetics,Autoimmunology,Genetic Epidemiology,Human Genetics,Pharmacogenomics,Transplantation Medicine,Precision Medicine"
                     data-keywords="HLA,Linkage Disequilibrium (LD),Conditional Informatics Correlation Coefficient (CICC),Autoimmune Disorders,Population Genomics,Disease Gene Mapping,Precision Medicine,Haplotype"
                     data-authors="Fei Zhang,Weixiong Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05573v1.html">Refined HLA Linkage Disequilibrium Architectures of World Populations by a Novel Allelic Correlation Measure</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fei Zhang, Weixiong Zhang
                </div>

                <div class="paper-summary">
                    This paper introduces the Conditional Informatics Correlation Coefficient (CICC), a novel and robust measure designed to overcome limitations of existing methods in characterizing complex linkage disequilibrium (LD) within the human leukocyte antigen (HLA) region. By applying CICC to global population datasets, the study identified 10 novel high-LD regions and nine strongly linked regions consistently shared across five global populations, offering a refined understanding of HLA architecture.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunogenetics</span>
                    
                    <span class="domain-tag">Autoimmunology</span>
                    
                    <span class="domain-tag">Genetic Epidemiology</span>
                    
                    <span class="domain-tag">Human Genetics</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05573v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05573v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05573v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05573v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05571v1"
                     data-domains="Radiology,Pulmonology,Medical Imaging,Image-Guided Surgery,Oncology"
                     data-keywords="medical image registration,3D correspondence,diffusion models,voxel descriptors,lung CT,training-free,semantic features,spatial analysis"
                     data-authors="Xingyu Zhang,Anna Reithmeir,Fryderyk K√∂gl,Rickmer Braren,Julia A. Schnabel,Daniel M. Lang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05571v1.html">MedDIFT: Multi-Scale Diffusion-Based Correspondence in 3D Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xingyu Zhang, Anna Reithmeir, Fryderyk K√∂gl et al.
                </div>

                <div class="paper-summary">
                    MedDIFT introduces a novel, training-free 3D correspondence framework that leverages multi-scale features from a pretrained latent medical diffusion model to generate rich voxel descriptors. This method accurately matches images via cosine similarity, achieving performance comparable to state-of-the-art learning-based models and surpassing conventional registration techniques on lung CT data. Its key advantage is eliminating the need for task-specific training, simplifying deployment for critical medical imaging tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Image-Guided Surgery</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05571v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05571v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05571v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05571v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05537v1"
                     data-domains="Radiology,Diagnostic Imaging,Clinical Decision Support,Preventive Medicine"
                     data-keywords="incidentalomas,radiology reports,large language models (LLMs),natural language processing (NLP),automated surveillance,follow-up recommendations,medical imaging,contextual reasoning"
                     data-authors="Namu Park,Farzad Ahmed,Zhaoyi Sun,Kevin Lybarger,Ethan Breinhorst,Julie Hu,Ozlem Uzuner,Martin Gunn,Meliha Yetisgen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05537v1.html">Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Namu Park, Farzad Ahmed, Zhaoyi Sun et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates large language models (LLMs) against supervised methods for fine-grained, lesion-level identification of incidentalomas requiring follow-up directly from radiology reports. The study demonstrates that generative LLMs, especially an anatomy-informed GPT-OSS-20b model with structured lesion tagging, significantly outperform traditional supervised baselines and achieve performance comparable to human experts, paving the way for reliable automated incidental finding surveillance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05537v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05537v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05537v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05537v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05502v1"
                     data-domains="Drug Discovery,Pharmaceutical Research,Systems Biology,Clinical Pharmacology,Translational Medicine"
                     data-keywords="Quantitative Systems Pharmacology,QSP modeling,multi-agent systems,knowledge graphs,drug development,human-in-the-loop,SimBiology,biomedical modeling"
                     data-authors="Omid Bazgir,Vineeth Manthapuri,Ilia Rattsev,Mohammad Jafarnejad">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05502v1.html">GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Omid Bazgir, Vineeth Manthapuri, Ilia Rattsev et al.
                </div>

                <div class="paper-summary">
                    GRASP is a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface designed to automate and streamline Quantitative Systems Pharmacology (QSP) model development. It encodes QSP models as typed biological knowledge graphs, compiles them to executable MATLAB/SimBiology code while preserving critical constraints, and significantly outperforms baseline methods in terms of model quality and correctness. This framework makes complex QSP modeling more accessible and rigorous for domain experts, accelerating drug development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Translational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05502v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05502v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05502v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05502v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05494v1"
                     data-domains="Radiology,Diagnostic Imaging,Oncology,Anatomy,Surgical Planning"
                     data-keywords="medical image segmentation,Transformer decoder,attention mechanisms,frequency-spatial analysis,multi-scale features,deep learning,tumor segmentation,organ boundary extraction"
                     data-authors="Fan Zhang,Zhiwei Gu,Hua Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05494v1.html">Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fan Zhang, Zhiwei Gu, Hua Wang
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Transformer decoder framework designed to overcome limitations in capturing edge details, local textures, and spatial continuity in medical image segmentation. It integrates three specialized modules‚ÄîAdaptive Cross-Fusion Attention (ACFA), Triple Feature Fusion Attention (TFFA), and Structural-aware Multi-scale Masking Module (SMMM)‚Äîto enhance feature representation and interaction. The framework significantly improves segmentation accuracy and generalization, particularly for high-precision tasks like tumor segmentation and organ boundary extraction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05494v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05494v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05494v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05494v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05469v1"
                     data-domains="Oncology (Breast Cancer),Cardiology (Heart Disease),Endocrinology (Pima Diabetes)"
                     data-keywords="Ensemble learning,Bias-variance tradeoff,Overfitting,Tabular data,Medical diagnostics,Classification,Generalization gap,Dataset complexity"
                     data-authors="Zubair Ahmed Mohammad">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05469v1.html">How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zubair Ahmed Mohammad
                </div>

                <div class="paper-summary">
                    This study investigates how ensemble learning effectively balances high accuracy with low overfitting by examining its bias-variance trade-off across four tabular classification tasks, including medical datasets. It demonstrates that ensembles, particularly tree-based methods, significantly improve test accuracy while maintaining small generalization gaps, especially on non-linear data, providing practical guidance for model selection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology (Breast Cancer)</span>
                    
                    <span class="domain-tag">Cardiology (Heart Disease)</span>
                    
                    <span class="domain-tag">Endocrinology (Pima Diabetes)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05469v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05469v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05469v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05469v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05462v1"
                     data-domains="Pharmaceutical Research,Drug Discovery,Computational Biology,Medicinal Chemistry,Bioinformatics"
                     data-keywords="Drug Discovery,MLOps,Model Management,Machine Learning,Generative AI,LLM Agents,Computational Models,Scalability"
                     data-authors="Yan-Shiun Wu,Nathan A. Morin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05462v1.html">Model Gateway: Model Management Platform for Model-Driven Drug Discovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.SE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yan-Shiun Wu, Nathan A. Morin
                </div>

                <div class="paper-summary">
                    The Model Gateway is a management platform designed for machine learning (ML) and scientific computational models within the drug discovery pipeline. It integrates Large Language Model (LLM) Agents and Generative AI tools to automate MLOps tasks such as model registration, execution, and dynamic consensus. This platform aims to significantly accelerate model-driven drug discovery by providing a scalable and reliable infrastructure for model management.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05462v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05462v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05462v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05462v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05438v1"
                     data-domains="Radiology,Orthopedics,Neurosurgery,General Surgery,Internal Medicine,Telemedicine,Medical Education"
                     data-keywords="Extended Reality (XR),Electronic Health Records (EHR),Medical Visualization,FHIR,AI Segmentation,Clinical Decision Support,Immersive Analytics,Collaborative Healthcare"
                     data-authors="Benoit Marteau,Shaun Q. Y. Tan,Jieru Li,Andrew Hornback,Yishan Zhong,Shaunna Wang,Christian Lowson,Jason Woloff,Joshua M. Pahys,Steven W. Hwang,Coleman Hilton,May D. Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05438v1.html">EXR: An Interactive Immersive EHR Visualization in Extended Reality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Benoit Marteau, Shaun Q. Y. Tan, Jieru Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EXR, an Extended Reality (XR) platform designed for immersive and interactive visualization of Electronic Health Records (EHRs). It integrates structured and unstructured patient data with volumetric medical imaging in a shared 3D environment, leveraging FHIR for interoperability and AI for image segmentation, aiming to serve as a foundation for next-generation clinical decision-support tools.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05438v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05438v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05438v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05438v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05416v1"
                     data-domains="Critical Care Medicine,Infectious Disease,Clinical Informatics,Healthcare AI"
                     data-keywords="Sepsis Prediction,Graph Convolutional Networks,Electronic Health Records,Patient Embeddings,Machine Learning,Intensive Care,Early Warning Systems,Triplet Representation"
                     data-authors="Bozhi Dan,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05416v1.html">Sepsis Prediction Using Graph Convolutional Networks over Patient-Feature-Value Triplets</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bozhi Dan, Di Wu, Ji Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Triplet-GCN, a novel single-branch graph convolutional network model designed for early sepsis prediction from complex, sparse, and heterogeneous Electronic Health Record (EHR) data. By representing EHR as patient-feature-value triplets and constructing a bipartite patient-feature graph, the model learns enriched patient embeddings, significantly outperforming traditional tabular machine learning baselines in discrimination and balanced error metrics for timely sepsis detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Infectious Disease</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05416v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05416v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05416v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05416v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05391v1"
                     data-domains="Pathology,Digital Pathology,Computational Pathology"
                     data-keywords="Whole Slide Image,Pathology,Multimodal Large Language Models,Computational Efficiency,Redundancy Reduction,Sparse Tokens,Deep Learning,Digital Pathology"
                     data-authors="Qingqiao Hu,Weimin Lyu,Meilong Xu,Kehan Qi,Xiaoling Hu,Saumya Gupta,Jiawei Zhou,Chao Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05391v1.html">LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qingqiao Hu, Weimin Lyu, Meilong Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LoC-Path, an efficient multimodal large language model (MLLM) framework for pathology whole slide image (WSI) understanding, addressing the excessive computational cost of existing models. Motivated by the observation that WSI tile features exhibit significant redundancy, LoC-Path replaces heavy slide-level encoders with novel redundancy-reducing modules. The framework achieves performance comparable to state-of-the-art WSI MLLMs while significantly reducing computational and memory requirements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05391v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05391v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05391v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05391v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05373v1"
                     data-domains="Clinical informatics,Critical care medicine,Epidemiology,Health outcomes research,Medical natural language processing"
                     data-keywords="Causal inference,Text data,Confounding,Positivity assumption,Token rationalization,Treatment effect estimation,MIMIC-III,Natural language processing"
                     data-authors="Lijinghua Zhang,Hengrui Cai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05373v1.html">Text Rationalization for Robust Causal Effect Estimation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lijinghua Zhang, Hengrui Cai
                </div>

                <div class="paper-summary">
                    This paper introduces Confounding-Aware Token Rationalization (CATR), a novel framework addressing the challenge of positivity assumption violations when using high-dimensional text as confounders in causal inference. CATR selects a sparse, necessary subset of textual tokens to preserve confounding information, mitigating positivity violations and yielding more accurate, stable, and interpretable causal effect estimates. The method was validated on synthetic data and a real-world clinical dataset (MIMIC-III).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical informatics</span>
                    
                    <span class="domain-tag">Critical care medicine</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health outcomes research</span>
                    
                    <span class="domain-tag">Medical natural language processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05373v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05373v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05373v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05373v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05365v1"
                     data-domains="Genetics (Fragile X Syndrome),Psychiatry (comorbid depression),Endocrinology (Type 2 Diabetes),Cardiology (hypertension),Remote Patient Monitoring,Diagnostic Medicine"
                     data-keywords="Autonomous Reasoning,Model Context Protocol,Healthcare AI,Clinical Decision Support,Longitudinal Reasoning,Explainable AI,HL7/FHIR,FDA SaMD"
                     data-authors="Zag ElSayed,Craig Erickson,Ernest Pedapati">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05365v1.html">MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zag ElSayed, Craig Erickson, Ernest Pedapati
                </div>

                <div class="paper-summary">
                    This paper introduces MCP-AI, an innovative architectural framework that integrates the Model Context Protocol (MCP) to enable autonomous, context-aware clinical reasoning in healthcare. It moves beyond traditional CDSS and prompt-based LLMs by facilitating longitudinal, collaborative, and human-verifiable AI workflows. Validated through use cases in diagnostic modeling and remote care coordination, MCP-AI demonstrates its capability to streamline clinical processes, ensure secure AI responsibility transitions, and support physician-in-the-loop validation while adhering to regulatory standards.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genetics (Fragile X Syndrome)</span>
                    
                    <span class="domain-tag">Psychiatry (comorbid depression)</span>
                    
                    <span class="domain-tag">Endocrinology (Type 2 Diabetes)</span>
                    
                    <span class="domain-tag">Cardiology (hypertension)</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05365v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05365v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05365v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05365v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05350v1"
                     data-domains="Psychiatry,Occupational Health,Clinical Psychology,Public Health,Neurodevelopmental Disorders"
                     data-keywords="neurodivergence,women,software engineering,gender bias,underdiagnosis,masking,mental health,occupational health,inclusion,burnout"
                     data-authors="Munazza Zaib,Wei Wang,Dulaji Hidellaarachchi,Isma Farah Siddiqui">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05350v1.html">Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.SE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Munazza Zaib, Wei Wang, Dulaji Hidellaarachchi et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the significant research gap concerning neurodivergent women in Software Engineering (SE), who face unique challenges stemming from the intersection of gender bias and neurological differences. It proposes a novel hybrid methodological approach, integrating InclusiveMag and GenderMag frameworks, to systematically analyze these issues. The initial phase presents a targeted literature review, synthesizing challenges into cognitive, social, organizational, structural, and career progression categories, underscoring how under/late diagnosis and masking intensify exclusion.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Occupational Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Neurodevelopmental Disorders</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05350v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05350v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05350v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05350v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05346v1"
                     data-domains="Infectious diseases,Personalized medicine,Early disease diagnosis,Molecular diagnostics,Medical imaging"
                     data-keywords="nanoparticle counting,digital diagnostics,SARS-CoV-2,multiple-hypothesis test,image processing,low-abundance analytes,biomarker detection,statistical decision theory"
                     data-authors="Neil H. Kim,Xiao-Liu Chu,Joseph B. DeGrandchamp,Matthew R. Foreman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05346v1.html">Hypothesis-Based Particle Detection for Accurate Nanoparticle Counting and Digital Diagnostics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.comp-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Neil H. Kim, Xiao-Liu Chu, Joseph B. DeGrandchamp et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel hypothesis-based particle counting algorithm designed for nanoparticle-based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model. The method achieves robust and interpretable nanoparticle counting without requiring training data or empirical parameter tuning, demonstrating its utility in detecting SARS-CoV-2 DNA biomarkers and providing insights into particle aggregation for digital molecular diagnostics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious diseases</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Early disease diagnosis</span>
                    
                    <span class="domain-tag">Molecular diagnostics</span>
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05346v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05346v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05346v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05346v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05329v1"
                     data-domains="Neurology,Psychiatry,Neuroscience,Diagnostic Imaging,Computational Anatomy"
                     data-keywords="Thalamic Nuclei Segmentation,T1-weighted MRI,Deep Learning,3D U-Net,Coordinate Convolution,Neuroimaging,Neurological Disorders,Psychiatric Disorders"
                     data-authors="Anqi Feng,Zhangxing Bian,Samuel W. Remedios,Savannah P. Hays,Blake E. Dewey,Alexa Colinco,Jiachen Zhuo,Dan Benjamini,Jerry L. Prince">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05329v1.html">CATNUS: Coordinate-Aware Thalamic Nuclei Segmentation Using T1-Weighted MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anqi Feng, Zhangxing Bian, Samuel W. Remedios et al.
                </div>

                <div class="paper-summary">
                    CATNUS addresses the challenge of accurate thalamic nuclei segmentation from T1-weighted MRI using a 3D U-Net enhanced with coordinate convolution layers. It demonstrates improved segmentation accuracy, robust test-retest reliability, and strong out-of-distribution generalization across diverse MRI acquisitions, facilitating large-scale neuroimaging studies and clinical assessments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05329v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05329v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05329v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05329v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05288v1"
                     data-domains="Health Information Technology (Health IT),Cybersecurity in Healthcare,Medical Device Security,Digital Health Infrastructure,Hospital Operations Management"
                     data-keywords="WebShells,cybersecurity,malware classification,representation learning,machine learning,Graph Neural Networks,Large Language Models,dynamic analysis"
                     data-authors="Feijiang Han">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05288v1.html">Beyond Detection: A Comprehensive Benchmark and Study on Representation Learning for Fine-Grained Webshell Family Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Feijiang Han
                </div>

                <div class="paper-summary">
                    This paper presents the first systematic study to automate fine-grained WebShell family classification, moving beyond passive detection to enable proactive defense against evolving cyber threats. It introduces a methodology leveraging dynamic function call traces, augmented by Large Language Models, and benchmarks various representation learning models to establish a robust baseline for identifying specific malware lineages threatening critical sectors like healthcare and finance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Information Technology (Health IT)</span>
                    
                    <span class="domain-tag">Cybersecurity in Healthcare</span>
                    
                    <span class="domain-tag">Medical Device Security</span>
                    
                    <span class="domain-tag">Digital Health Infrastructure</span>
                    
                    <span class="domain-tag">Hospital Operations Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05288v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05288v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05288v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05288v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05287v1"
                     data-domains="Pharmacology,Drug Discovery,Oncology,Molecular Biology,Bioinformatics,Personalized Medicine"
                     data-keywords="miRNA-drug association,Graph Transformer,Machine Learning,Drug Discovery,Pharmacology,SMILES,RNA sequence,Word2Vec"
                     data-authors="Ziqi Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05287v1.html">DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziqi Zhang
                </div>

                <div class="paper-summary">
                    This paper introduces DMAGT, a novel machine learning model based on a multi-layer transformer-based graph neural network, designed to predict associations between drugs and miRNAs. By integrating drug molecular structures (SMILES) and miRNA base structures via Word2Vec embeddings and graph transformers, DMAGT overcomes the limitations of traditional wet lab experiments. The model demonstrated superior performance with an AUC up to 95.24% and successfully validated 14 out of 20 top predictions for specific anticancer drugs, offering a significant shortcut for miRNA drug development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Molecular Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05287v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05287v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05287v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05287v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05267v1"
                     data-domains="Rare Disease Diagnosis,Personalized Medicine,Medical Imaging Analysis,Drug Discovery and Development,Clinical Decision Support Systems,Digital Pathology"
                     data-keywords="Epistemic Uncertainty,Data Scarcity,Bayesian Learning,Conformal Prediction,Synthetic Data,Information Theory,Uncertainty Quantification,Data Efficiency"
                     data-authors="Osvaldo Simeone,Yaniv Romano">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05267v1.html">Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.IT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Osvaldo Simeone, Yaniv Romano
                </div>

                <div class="paper-summary">
                    This review paper addresses the critical challenge of limited training data and resulting epistemic uncertainty in AI systems, particularly within healthcare applications. It synthesizes formal methodologies focusing on two complementary approaches: quantifying epistemic uncertainty through frameworks like generalized Bayesian learning and conformal prediction, and mitigating data scarcity via synthetic data augmentation, all underscored by an information-theoretic perspective.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Disease Diagnosis</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05267v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05267v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05267v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05267v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05256v1"
                     data-domains="Medical Informatics,Clinical Documentation,Health Information Technology,Artificial Intelligence in Medicine,Healthcare Operations"
                     data-keywords="Clinical Note Generation,Large Language Models,GPT-4,Chain-of-Thought Prompting,ICD-10,Clinical Ontology,Knowledge Graph,Electronic Health Records"
                     data-authors="Ivan Makohon,Mohamad Najafi,Jian Wu,Mathias Brochhausen,Yaohang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05256v1.html">Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ivan Makohon, Mohamad Najafi, Jian Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an advanced method for generating clinical notes using GPT-4, addressing the significant time physicians spend on manual documentation. The approach combines Chain-of-Thought (CoT) prompting with semantic search results and a clinical ontology knowledge graph, utilizing ICD codes and patient information as inputs. The study found that this enhanced prompting technique substantially outperforms standard one-shot prompts in generating high-quality clinical notes on a subset of the CodiEsp dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Documentation</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Healthcare Operations</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05256v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05256v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05256v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05256v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05240v1"
                     data-domains="Remote Patient Monitoring,Geriatrics,Rehabilitation,Telemedicine,Surgical Robotics (assistive/monitoring),Movement Disorder Diagnostics"
                     data-keywords="Event cameras,Video reconstruction,Diffusion models,Low power,Continuous monitoring,Wearable technology,Hybrid sensing,Computer vision"
                     data-authors="Dmitrii Torbunov,Onur Okuducu,Yi Huang,Odera Dim,Rebecca Coles,Yonggang Cui,Yihui Ren">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05240v1.html">IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dmitrii Torbunov, Onur Okuducu, Yi Huang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces IE2Video, a novel task for reconstructing full RGB video sequences from a hybrid input of a single initial RGB keyframe and subsequent continuous event camera data. The aim is to enable low-power, continuous video monitoring for systems like wearables by reducing conventional RGB camera capture, then reconstructing the standard video offline. The authors demonstrate that adapting pretrained text-to-video diffusion models, specifically LTX, with event data injection via learned encoders and low-rank adaptation significantly outperforms autoregressive baselines in perceptual quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Surgical Robotics (assistive/monitoring)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05240v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05240v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05240v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05240v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05222v1"
                     data-domains="Virology,Vaccinology,Infectious Disease Epidemiology,Public Health,Bioinformatics"
                     data-keywords="Influenza A,Antigenicity,Semi-supervised Learning,Protein Language Models,Vaccine Strain Selection,Haemagglutinin,Genomic Surveillance,Machine Learning"
                     data-authors="Yanhua Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05222v1.html">Mitigating the Antigenic Data Bottleneck: Semi-supervised Learning with Protein Language Models for Influenza A Surveillance</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yanhua Xu
                </div>

                <div class="paper-summary">
                    This paper addresses the critical bottleneck of limited phenotypic labels for rapidly evolving Influenza A viruses (IAVs) by proposing a novel approach that combines pre-trained Protein Language Models (PLMs) with Semi-Supervised Learning (SSL). The study demonstrates that SSL strategies, particularly Self-training, significantly improve predictive accuracy of antigenic evolution even with scarce labeled data (e.g., 25% availability). This methodology enables more effective use of abundant unlabeled genomic sequences for influenza surveillance and timely vaccine strain selection, offering a promising solution to a long-standing challenge in vaccinology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Virology</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05222v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05222v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05222v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05222v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05217v1"
                     data-domains="Clinical Prediction,Electronic Health Records (EHR) analysis,Mortality Prediction,Readmission Prediction,Medical Informatics"
                     data-keywords="Tokenization,Clinical Time Series,EHR,Transformers,MIMIC-IV,Predictive Modeling,Deep Learning,Medical AI,Parameter Efficiency"
                     data-authors="Rafi Al Attrach,Rajna Fani,David Restrepo,Yugang Jia,Peter Sch√ºffler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05217v1.html">Rethinking Tokenization for Clinical Time Series: When Less is More</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rafi Al Attrach, Rajna Fani, David Restrepo et al.
                </div>

                <div class="paper-summary">
                    This paper systematically evaluates tokenization strategies for clinical time series modeling using transformer architectures on the MIMIC-IV dataset. It reveals that simpler, parameter-efficient approaches, particularly frozen pretrained code encoders, often achieve strong performance, while explicit time encodings provide no consistent statistically significant benefit across evaluated tasks. The study highlights that optimal tokenization is task-dependent, with value features showing varying importance for different clinical predictions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Prediction</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) analysis</span>
                    
                    <span class="domain-tag">Mortality Prediction</span>
                    
                    <span class="domain-tag">Readmission Prediction</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05217v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05217v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05217v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05217v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05216v1"
                     data-domains="Electronic Health Records (EHR),Laboratory Medicine,Critical Care,Clinical Informatics,Predictive Analytics,Pathophysiology"
                     data-keywords="EHR,Masked Autoencoders,Coefficient of Variation,Volatility,Biomarkers,Laboratory Tests,Pretraining,Clinical Prediction"
                     data-authors="Rajna Fani,Rafi Al Attrach,David Restrepo,Yugang Jia,Leo Anthony Celi,Peter Sch√ºffler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05216v1.html">Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rajna Fani, Rafi Al Attrach, David Restrepo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Coefficient of Variation Masking (CV-Masking), a volatility-aware pretraining strategy for Masked Autoencoders (MAEs) applied to Electronic Health Records (EHRs). Unlike uniform masking, CV-Masking adaptively adjusts masking probabilities based on the intrinsic variability of each clinical feature, combined with a value-only masking objective. This novel approach systematically improves feature reconstruction, downstream predictive performance, and model convergence, leading to more robust and clinically meaningful EHR representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Electronic Health Records (EHR)</span>
                    
                    <span class="domain-tag">Laboratory Medicine</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05216v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05216v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05216v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05216v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05208v1"
                     data-domains="Gerontology,Preventive Medicine,Anti-aging Medicine,Rehabilitation Medicine,Cognitive Neuroscience,Public Health,Biogerontology"
                     data-keywords="Peakspan,functional performance,aging,healthspan,rejuvenative medicine,cognitive function,physiological capacity,artificial intelligence"
                     data-authors="Alex Zhavoronkov,Dominika Wilczok">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05208v1.html">Peakspan: Defining, Quantifying and Extending the Boundaries of Peak Productive Lifespan</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alex Zhavoronkov, Dominika Wilczok
                </div>

                <div class="paper-summary">
                    This paper introduces 'Peakspan,' a novel metric defining the age interval during which an individual maintains at least 90% of their peak functional performance in specific physiological or cognitive domains. It highlights that traditional health metrics, like Healthspan, overlook a critical functional decline, revealing that most biological systems peak early, resulting in a remarkably short Peakspan and a significant portion of adult life spent in a 'healthy but declined' state.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gerontology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Anti-aging Medicine</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05208v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05208v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05208v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05208v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05114v1"
                     data-domains="Pediatrics,Neuroradiology,Developmental Neurology,Neonatology,Clinical Neuroscience"
                     data-keywords="Deep learning,Infant brain segmentation,Pediatric MRI,Domain randomization,Multi-contrast imaging,Neurodevelopment,Image analysis,Dataset shift"
                     data-authors="Malte Hoffmann,Lilla Z√∂llei,Adrian V. Dalca">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05114v1.html">Deep infant brain segmentation from multi-contrast MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Malte Hoffmann, Lilla Z√∂llei, Adrian V. Dalca
                </div>

                <div class="paper-summary">
                    This paper introduces BabySeg, a deep learning framework for robust and accurate brain segmentation in infants and young children from multi-contrast MRI. It addresses the challenges of diverse pediatric neuroimaging protocols by employing domain randomization and flexible feature pooling, achieving state-of-the-art performance with a single model and significantly reduced runtime.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Developmental Neurology</span>
                    
                    <span class="domain-tag">Neonatology</span>
                    
                    <span class="domain-tag">Clinical Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05114v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05114v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05114v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05114v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05092v1"
                     data-domains="Medical Imaging,Computational Biology,Genomics,Drug Discovery,Clinical Informatics,Digital Pathology"
                     data-keywords="Diffusion models,Generative AI,Continuous state spaces,Discrete state spaces,Stochastic differential equations,Markov chains,ELBO,Medical informatics"
                     data-authors="Vincent Pauline,Tobias H√∂ppe,Kirill Neklyudov,Alexander Tong,Stefan Bauer,Andrea Dittadi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05092v1.html">Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vincent Pauline, Tobias H√∂ppe, Kirill Neklyudov et al.
                </div>

                <div class="paper-summary">
                    This paper provides a foundational and self-contained introduction to diffusion models, unifying their theoretical treatment across both continuous and discrete state spaces. It bridges the gap between continuous stochastic differential equations and discrete-time Markov chains, establishing a common variational framework and highlighting how design choices influence model dynamics, which is crucial for developing robust generative AI for diverse medical data environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05092v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05092v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05092v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05092v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05080v1"
                     data-domains="Drug Discovery,Pharmacology,Medicinal Chemistry,Therapeutics Development,Biotechnology"
                     data-keywords="Structure-based drug design,Generative models,De novo drug design,Molecular docking,Flow matching,Ligand discovery,Computational chemistry,Protein-ligand interaction"
                     data-authors="Ian Dunn,Liv Toft,Tyler Katz,Juhi Gupta,Riya Shah,Ramith Hettiarachchi,David R. Koes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05080v1.html">OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ian Dunn, Liv Toft, Tyler Katz et al.
                </div>

                <div class="paper-summary">
                    OMTRA is a novel multi-modal flow matching generative model that unifies various structure-based drug design (SBDD) tasks, including de novo ligand design and docking. It leverages a newly curated dataset of 500 million 3D molecular conformers to achieve state-of-the-art performance in key SBDD applications, although the benefits from large-scale pretraining and multi-task training were modest.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Therapeutics Development</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05080v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05080v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05080v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05080v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05066v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,cs.AI,cs.CL"
                     data-authors="Huascar Sanchez,Briland Hitaj,Jules Bergmann,Linda Briesemeister">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05066v1.html">Multi-LLM Collaboration for Medication Recommendation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huascar Sanchez, Briland Hitaj, Jules Bergmann et al.
                </div>

                <div class="paper-summary">
                    As healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fa...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05066v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05066v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05066v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05066v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05030v1"
                     data-domains="Biomechanics,Rehabilitation Medicine,Orthopedics,Sports Medicine,Physical Therapy,Geriatrics,Neurology"
                     data-keywords="ground reaction forces,ground reaction moments,insole sensors,deep learning,attention network,biomechanics,gait analysis,rehabilitation,spatial priors,temporal priors"
                     data-authors="Xuan Li,Samuel Bello">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05030v1.html">Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xuan Li, Samuel Bello
                </div>

                <div class="paper-summary">
                    This paper introduces a Dual-Path Region-Guided Attention Network for accurate, insole-based estimation of three-dimensional ground reaction forces and moments (GRFs/GRMs). The network integrates anatomy-inspired spatial and temporal priors with a region-level attention mechanism and a complementary path for full sensor context. It demonstrates superior performance over strong baselines, achieving significantly lower normalized root mean square errors on both an insole dataset and a public walking dataset, proving robust performance for GRF/GRM estimation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05030v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05030v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05030v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05030v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05012v1"
                     data-domains="Clinical Trials,Evidence-Based Medicine,Drug Development,Pharmacovigilance,Medical Information Retrieval,Patient Safety"
                     data-keywords="RAG,Contrastive Learning,Evidence Re-ranking,Factuality,Transparency,Clinical Trials,Hallucinations,Safety-critical Systems"
                     data-authors="Francielle Vargas,Daniel Pedronette">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05012v1.html">Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Francielle Vargas, Daniel Pedronette
                </div>

                <div class="paper-summary">
                    This paper introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method for Retrieval Augmented Generation (RAG) systems designed to enhance factuality and transparency. CER fine-tunes embeddings with contrastive learning and generates token-level attribution rationales, using subjectivity-based hard negative selection to align the embedding space with evidential reasoning. Evaluated on clinical trial reports, CER demonstrates improved retrieval accuracy, mitigates hallucinations, and provides transparent, evidence-based retrieval crucial for safety-critical domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Evidence-Based Medicine</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Medical Information Retrieval</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05012v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05012v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05012v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05012v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04980v1"
                     data-domains="Precision medicine,Pharmacogenomics,Chronic disease management,Clinical trial design,Public health analytics,Epidemiology,Bioinformatics"
                     data-keywords="Causal inference,longitudinal data,Individual Treatment Effects (ITEs),Causal Representation Learning (CRL),Variational Autoencoder (VAE),Recurrent Neural Networks (RNNs),Contrastive Predictive Coding (CPC),Counterfactual regression,Time-varying confounding,Interpretability"
                     data-authors="Mouad EL Bouchattaoui">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04980v1.html">Learning Causality for Longitudinal Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mouad EL Bouchattaoui
                </div>

                <div class="paper-summary">
                    This thesis presents advanced machine learning methods for causal inference and causal representation learning in complex, high-dimensional, time-varying medical/health data. It introduces a Causal Dynamic Variational Autoencoder (CDVAE) for robust Individual Treatment Effect (ITE) estimation and an efficient RNN-based framework with Contrastive Predictive Coding (CPC) for long-term counterfactual prediction. Furthermore, it enhances interpretability by mapping latent causes to observed variables using a novel Jacobian-based approach, providing theoretical guarantees and superior performance across tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision medicine</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Chronic disease management</span>
                    
                    <span class="domain-tag">Clinical trial design</span>
                    
                    <span class="domain-tag">Public health analytics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04980v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04980v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04980v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04980v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04967v1"
                     data-domains="Ophthalmology,Retinal Imaging,Diagnostic Medicine,Artificial Intelligence in Healthcare"
                     data-keywords="few-shot learning,retinal disease diagnosis,imbalanced data,episodic learning,CLAHE,ResNet-50,diabetic retinopathy,macular degeneration"
                     data-authors="Jasmaine Khale,Ravi Prakash Srivastava">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04967v1.html">Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jasmaine Khale, Ravi Prakash Srivastava
                </div>

                <div class="paper-summary">
                    This paper proposes a balanced few-shot episodic learning framework for accurate retinal disease diagnosis, specifically tackling the challenges of data scarcity and class imbalance in medical datasets. By integrating balanced sampling, targeted augmentation (including CLAHE), and an ImageNet-pretrained ResNet-50 encoder, the method significantly enhances diagnostic accuracy and reduces bias toward majority classes, notably improving the detection of underrepresented retinal diseases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Retinal Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04967v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04967v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04967v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04967v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05169v1"
                     data-domains="Genomics,Medical Imaging Analysis,Electronic Health Records (EHR) Mining,Personalized Medicine,Disease Subtyping,Biomarker Discovery"
                     data-keywords="Multi-View Clustering,Unsupervised Learning,Machine Learning,Data Fusion,Healthcare AI,Deep Learning,Graph-Based Methods,Scalability"
                     data-authors="Abdelmalik Moujahid,Fadi Dornaika">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05169v1.html">Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abdelmalik Moujahid, Fadi Dornaika
                </div>

                <div class="paper-summary">
                    This comprehensive survey provides an in-depth analysis of Multi-View Clustering (MVC), an unsupervised learning paradigm designed to overcome the limitations of single-view methods and computational challenges associated with complex, multi-source datasets. It systematically categorizes MVC techniques, evaluates their strengths and weaknesses, and discusses practical challenges, emerging trends, and future research directions. The paper integrates insights from over 140 publications, including comparative analyses of data fusion strategies and investigations into practical use cases, notably in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Mining</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Disease Subtyping</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05169v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05169v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05169v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05169v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04943v1"
                     data-domains="geriatric care,assisted living,patient monitoring,rehabilitation,telemedicine,elderly care,behavioral health"
                     data-keywords="multimodal deep networks,human action recognition,adaptive fusion,gating mechanisms,RGB,optical flow,audio,depth,violence detection,active assisted living,human-computer interaction"
                     data-authors="Novanto Yudistira">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04943v1.html">Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Novanto Yudistira
                </div>

                <div class="paper-summary">
                    This study introduces a novel approach for human action recognition by employing multimodal deep neural networks with adaptive fusion strategies, specifically utilizing gating mechanisms across RGB, optical flow, audio, and depth information. It demonstrates superior accuracy and robustness compared to traditional unimodal methods by selectively integrating relevant features, leading to a more holistic representation of actions and promising advancements in recognition performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">geriatric care</span>
                    
                    <span class="domain-tag">assisted living</span>
                    
                    <span class="domain-tag">patient monitoring</span>
                    
                    <span class="domain-tag">rehabilitation</span>
                    
                    <span class="domain-tag">telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04943v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04943v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04943v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04943v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04938v1"
                     data-domains="Neurology,Rare Diseases,Cognitive Disorders,Digital Health,Precision Medicine,Endocrinology (specifically for PKU),Artificial Intelligence in Medicine"
                     data-keywords="Neurocognitive monitoring,Speech AI,Relational Graph Transformer,Rare neurological diseases,Phenylketonuria (PKU),Digital biomarkers,Brain fog,Predictive analytics"
                     data-authors="Raquel Norel,Michele Merler,Pavitra Modi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04938v1.html">Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Raquel Norel, Michele Merler, Pavitra Modi
                </div>

                <div class="paper-summary">
                    This paper proposes a novel method for continuous neurocognitive monitoring in rare neurological diseases by integrating smartphone-based speech AI with Relational Graph Transformer (RELGT) architectures. A proof-of-concept in phenylketonuria (PKU) demonstrated that a speech-derived metric, "Proficiency in Verbal Discourse," significantly correlates with blood phenylalanine levels (p = -0.50, p < 0.005) but not with traditional cognitive tests, suggesting its unique ability to capture subtle cognitive changes. The ultimate goal is to enable predictive alerts for cognitive decompensation weeks in advance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Cognitive Disorders</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04938v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04938v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04938v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04938v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04937v1"
                     data-domains="Neurology,Neuropharmacology,Diagnostics,Biomarkers,Geriatric Medicine,Precision Medicine,Neuroimmunology,Genetic Engineering"
                     data-keywords="Alzheimer's disease,amyloid-$Œ≤$,tau pathology,neuroinflammation,combination therapy,multi-target therapy,precision medicine,biomarkers,gene editing,neuromodulation"
                     data-authors="She Xutong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04937v1.html">A Systemic Pathological Network Model and Combinatorial Intervention Strategies for Alzheimer's Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.MN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> She Xutong
                </div>

                <div class="paper-summary">
                    This paper proposes a systemic pathological network model for Alzheimer's disease (AD), integrating amyloid-$Œ≤$, tau, and neuroinflammation as intricately interacting pathologies, moving beyond the linear amyloid cascade hypothesis. It advocates for a paradigm shift in AD management towards preemptive, biomarker-guided, and personalized combination interventions that simultaneously target these multiple pathways, leveraging early diagnostic detection and emerging technological platforms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuropharmacology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Biomarkers</span>
                    
                    <span class="domain-tag">Geriatric Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04937v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04937v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04937v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04937v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-08 06:34:02</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>