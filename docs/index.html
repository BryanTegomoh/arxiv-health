<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">156</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (15), Diagnostic Imaging (8), Oncology (8)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (15)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (8)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (4)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (4)</option>
                        
                        <option value="Neurology">Neurology (3)</option>
                        
                        <option value="Cardiology">Cardiology (3)</option>
                        
                        <option value="Medical Image Analysis">Medical Image Analysis (3)</option>
                        
                        <option value="Preventive Medicine">Preventive Medicine (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.26783v1"
                     data-domains="Epidemiology,Clinical Trials,Health Economics,Personalized Medicine,Public Health Research,Comparative Effectiveness Research,Pharmacoeconomics,Outcomes Research"
                     data-keywords="Causal inference,Average Treatment Effect (ATE),Riesz regression,Targeted Maximum Likelihood Estimation (TMLE),Covariate balancing,Density ratio estimation,Matching estimator,Machine learning,Bias correction"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26783v1.html">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper introduces a unified theoretical framework for causal inference, specifically for Average Treatment Effect (ATE) estimation. It integrates and reveals profound relationships between several prominent methods, including Riesz regression, covariate balancing, density-ratio estimation (DRE), Targeted Maximum Likelihood Estimation (TMLE), and the matching estimator, highlighting their common underlying principles in estimating balancing weights and reducing bias.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Public Health Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26783v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26783v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26759v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Computational Medicine"
                     data-keywords="CT reconstruction,deep learning,medical imaging,generalization,multi-organ,dataset,optimization-based methods,lesion types"
                     data-authors="Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26759v1.html">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MORE, a Multi-Organ Medical Image REconstruction dataset, to address the lack of generalization in current deep learning-based CT reconstruction methods. MORE comprises CT scans from 9 diverse anatomies and 15 lesion types, designed to facilitate robust model training and rigorous evaluation of generalization capabilities. The authors also establish a strong baseline solution, demonstrating that comprehensive datasets improve model generalization and that optimization-based methods enhance robustness for unseen anatomies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26723v1"
                     data-domains="personalized medicine,precision health,clinical decision support,pharmacogenomics,public health interventions,chronic disease management"
                     data-keywords="policy learning,causal inference,personalized medicine,treatment effect,empirical welfare maximization,conditional average treatment effect,machine learning,optimization"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26723v1.html">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper establishes an exact equivalence between two prominent policy learning approaches‚ÄîEmpirical Welfare Maximization (EWM) and the plug-in method based on Conditional Average Treatment Effect (CATE) estimation. By demonstrating that both approaches are rooted in the same underlying optimization problem via a reparameterization, it unifies their theoretical foundations and introduces a novel, computationally efficient regularization method for policy learning that bypasses the typically NP-hard steps associated with EWM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">personalized medicine</span>
                    
                    <span class="domain-tag">precision health</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                    <span class="domain-tag">pharmacogenomics</span>
                    
                    <span class="domain-tag">public health interventions</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26723v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26723v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26715v1"
                     data-domains="Clinical Diagnostics,Precision Medicine,Oncology,Metabolomics,Proteomics,Disease Prognostics"
                     data-keywords="Mass Spectrometry,Deep Learning,Foundation Model,Spectral Identification,Biological Interpretation,Disease Diagnostics,Clinical Outcomes,Biomarker Discovery"
                     data-authors="Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26715v1.html">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Asher, Devesh Shah, Amy A. Caudy et al.
                </div>

                <div class="paper-summary">
                    LSM-MS2 introduces a novel large-scale deep learning foundation model trained on millions of mass spectrometry spectra to learn a semantic chemical space. This model achieves state-of-the-art performance in spectral identification, significantly enhancing accuracy for challenging isomeric compounds and increasing identifications in complex biological samples while maintaining robustness. Crucially, LSM-MS2 generates rich spectral embeddings that enable direct biological interpretation, facilitating the differentiation of disease states and prediction of clinical outcomes across diverse translational applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Metabolomics</span>
                    
                    <span class="domain-tag">Proteomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26703v1"
                     data-domains="Oncology,Urology,Diagnostic Radiology,Medical Imaging,Digital Pathology"
                     data-keywords="Prostate Cancer,Micro-ultrasound,Foundation Models,AI in Medicine,Diagnostic Imaging,Prospective Validation,PRI-MUS,PI-RADS"
                     data-authors="Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26703v1.html">ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To et al.
                </div>

                <div class="paper-summary">
                    ProstNFound+ introduces an adaptation of medical foundation models (FMs) for prostate cancer (PCa) detection from micro-ultrasound (¬µUS), validated prospectively for the first time. This novel system demonstrates strong generalization and no performance degradation on new clinical data, offering interpretable cancer heatmaps and risk scores that align with established clinical protocols. The study highlights its potential as a scalable and interpretable alternative to expert-driven diagnostic methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26703v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26703v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26703v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26703v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26700v1"
                     data-domains="Pharmacoepidemiology,Health Outcomes Research,Personalized Medicine,Clinical Decision Support,Comparative Effectiveness Research"
                     data-keywords="Causal machine learning,Individualized treatment effects,Conditional exchangeability,Negative control outcomes,Unmeasured confounding,Simulation study,Observational studies,Treatment effect heterogeneity"
                     data-authors="Gerard T. Portela,Jason B. Gibbons,Sebastian Schneeweiss,Rishi J. Desai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26700v1.html">Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss et al.
                </div>

                <div class="paper-summary">
                    This paper critically evaluates the performance of causal machine learning (ML) models, specifically causal forest and X-learner, in predicting individualized treatment effects (ITEs) when the crucial conditional exchangeability assumption is violated, a common issue in observational studies. Through a simulation study, it demonstrates that such violations lead to inaccurate ITE estimates and even false indications of heterogeneity, while successfully establishing negative control outcomes (NCOs) as a valuable empirical diagnostic tool for detecting subgroup-specific unmeasured confounding.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Health Outcomes Research</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Comparative Effectiveness Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26700v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26700v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26700v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26700v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26685v1"
                     data-domains="Oncology,Immunotherapy,Vaccinology,Medical AI/Machine Learning,Health Economics,Biomarker Discovery"
                     data-keywords="Algorithm-to-Outcome Concordance (AOC),AI-to-Clinical Translation,Personalized Neoantigen Vaccines,Melanoma,AUC,HR/ORR,Tumor Mutational Burden (TMB),Cost-Effectiveness"
                     data-authors="Xiyao Yu,Kai Fu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26685v1.html">A Proposed Framework for Quantifying AI-to-Clinical Translation: The Algorithm-to-Outcome Concordance (AOC) Metric</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiyao Yu, Kai Fu
                </div>

                <div class="paper-summary">
                    This paper proposes the Algorithm-to-Outcome Concordance (AOC) metric, a quantitative framework to bridge the gap between AI-driven prediction models for personalized neoantigen vaccines and their clinical outcomes. Through systematic synthesis of simulated melanoma vaccine trials, the study demonstrates the metric's utility, revealing heterogeneous concordance and identifying factors influencing translational fidelity, while also highlighting its economic implications for healthcare. The AOC aims to standardize the evaluation of AI-to-clinical translation for future vaccine development and regulatory processes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunotherapy</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Medical AI/Machine Learning</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26685v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26685v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26685v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26685v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26683v1"
                     data-domains="Healthcare,Medical Question Answering,Clinical Decision Support,Medical Knowledge Management"
                     data-keywords="LLMs,Ontology,Healthcare AI,Domain Adaptation,Self-Evolution,Medical QA,Fine-tuning,Low-Resource Learning"
                     data-authors="Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26683v1.html">Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingchen Tu, Zhiqiang Liu, Juan Li et al.
                </div>

                <div class="paper-summary">
                    Evontree proposes a novel framework for Large Language Models (LLMs) to self-evolve their domain knowledge in data-sensitive fields like healthcare, leveraging a small set of high-quality ontology rules. It systematically extracts, validates, and enhances domain knowledge within LLMs without extensive external datasets, achieving up to a 3.7% accuracy improvement on medical QA benchmarks through self-distilled fine-tuning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare</span>
                    
                    <span class="domain-tag">Medical Question Answering</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Knowledge Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26683v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26683v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26668v1"
                     data-domains="Diagnostic Imaging,Cardiology,Neurology,Vascular Surgery,Biomedical Engineering"
                     data-keywords="Zoeppritz equations,ultrasound,reflection coefficients,angle of incidence,density,speed of sound,critical angle,waveform distortion,arterial plaque,cerebrovascular accidents"
                     data-authors="Harry G. Saavedra,Ramiro Moro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26668v1.html">Zoeppritz equations: from seismology to medical exploration</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Harry G. Saavedra, Ramiro Moro
                </div>

                <div class="paper-summary">
                    This paper investigates extending the application of Zoeppritz equations, traditionally used in seismology, to medical ultrasound for detailed tissue characterization. It demonstrates how analyzing angle-dependent reflection coefficients, critical angles, and waveform distortions can separate density from speed of sound mismatches and determine the thickness of intermediate layers, even at subwavelength resolution, which has significant implications for medical diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26668v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26668v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26668v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26668v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26635v1"
                     data-domains="Radiology,Oncology,Neurology,Cardiology,Abdominal Imaging,Musculoskeletal Imaging,Pathology"
                     data-keywords="MRI segmentation,Segment Anything Model (SAM),Deep Learning,Transformer,Medical Imaging,AI in Medicine,Generalization"
                     data-authors="Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26635v1.html">SAMRI: Segment Anything Model for MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhao Wang, Wei Dai, Thuy Thanh Dao et al.
                </div>

                <div class="paper-summary">
                    SAMRI is an MRI-specialized adaptation of the Segment Anything Model (SAM) designed to address the challenges of accurate and efficient MRI segmentation. By selectively fine-tuning SAM's mask decoder with a two-stage strategy on 1.1 million labeled MR slices, SAMRI achieves state-of-the-art accuracy (mean Dice of 0.87) and robust generalization across diverse anatomical regions, including small and clinically important structures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Abdominal Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26582v1"
                     data-domains="Radiology,Medical Diagnostics,Clinical Decision Support,Medical Image Analysis"
                     data-keywords="Visual Question Answering (VQA),Cross-domain Adaptation,Medical Imaging,Domain Generalization,Deep Learning,Plug-and-Play,Large Language Models (LLMs),MedVQA-RAD"
                     data-authors="Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26582v1.html">CATCH: A Modular Cross-domain Adaptive Template with Hook</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinjin Li, Yulie Lu, Jinghan Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CATCH, a modular, plug-and-play framework designed to improve the generalization of Visual Question Answering (VQA) models, like LLaVA, when applied to out-of-domain scenarios such as medical imaging. CATCH achieves this by decoupling visual and linguistic adaptation through a domain classifier and a dual adapter mechanism (Prompt and Visual Adapters) dynamically injected via a hook interface, critically requiring no retraining of the backbone VQA model. Experimental results demonstrate consistent performance gains across diverse benchmarks, including a significant +2.6 VQA score increase on the MedVQA-RAD dataset, showcasing its scalability for multi-domain VQA deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26568v1"
                     data-domains="Orthopedics,Radiology,Pediatrics,Diagnostic Imaging"
                     data-keywords="Spine Segmentation,Ultrasound Volume Projection Imaging,Scoliosis Diagnosis,Deep Learning,Transformer,Scale-Adaptive,Structure-Affinity,Medical Imaging"
                     data-authors="Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26568v1.html">SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao Xie, Zixun Huang, Yushen Zuo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SA¬≤Net, a novel deep learning architecture designed for accurate spine segmentation from Ultrasound Volume Projection Imaging (VPI), crucial for intelligent scoliosis diagnosis. SA¬≤Net addresses challenges like capturing global contextual knowledge and encoding rich structural information by employing a scale-adaptive complementary strategy and a structure-affinity transformation with a Transformer decoder. The method achieves superior segmentation performance and adaptability across various backbones, positioning it as a promising tool for advanced spinal image analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26568v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26568v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26568v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26568v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26566v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,cs.AI"
                     data-authors="Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26566v1.html">Multiclass Local Calibration With the Jensen-Shannon Distance</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cesare Barbera, Lorenzo Perini, Giovanni De Toni et al.
                </div>

                <div class="paper-summary">
                    Developing trustworthy Machine Learning (ML) models requires their predicted
probabilities to be well-calibrated, meaning they should reflect true-class
frequencies. Among calibration notions in multiclass classification, strong
calibration is the most stringent, as it requires all predicted probabi...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26563v1"
                     data-domains="physics.med-ph"
                     data-keywords="physics.med-ph"
                     data-authors="Nathan Torelli,Madalyne Day,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26563v1.html">Fraction-variant VMAT planning for patients with complex gynecological and head-and-neck cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Madalyne Day, Jan Unkelbach
                </div>

                <div class="paper-summary">
                    Background and Purpose: Increasing the number of arcs in volumetric modulated
arc therapy (VMAT) allows for better intensity modulation and may improve plan
quality. However, this leads to longer delivery times, which may cause patient
discomfort and increase intra-fractional motion. In this study, ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">physics.med-ph</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26525v1"
                     data-domains="regenerative medicine,drug discovery and development,diagnostics,therapeutics,biomedical devices,precision medicine,tissue engineering,synthetic biology"
                     data-keywords="biological engineering,bioinspired approaches,biological approaches,biohybrid approaches,data-driven discovery,artificial intelligence,healthcare advances,interdisciplinary education"
                     data-authors="Ulrike A. Nuber,Viktor Stein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26525v1.html">Biological Engineering: What does it mean? Where does it -- need to -- go?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ulrike A. Nuber, Viktor Stein
                </div>

                <div class="paper-summary">
                    This paper comprehensively analyzes biological engineering, defining it as the convergence of engineering and biology, and structuring it into bioinspired, biological, and biohybrid approaches. It dissects the inherent challenges and opportunities within this interdisciplinary field, proposing data-driven discovery and artificial intelligence as crucial tools to overcome the lack of traditional reductionist models. Furthermore, it advocates for a specialized educational framework for future biological engineers, emphasizing mathematical, technical, and AI competencies to address current scientific and societal challenges.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">regenerative medicine</span>
                    
                    <span class="domain-tag">drug discovery and development</span>
                    
                    <span class="domain-tag">diagnostics</span>
                    
                    <span class="domain-tag">therapeutics</span>
                    
                    <span class="domain-tag">biomedical devices</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26501v1"
                     data-domains="Cardiology,Preventive Medicine,Digital Health,Wearable Technology,Biomedical Engineering"
                     data-keywords="ECG,Out-of-Distribution detection,Anomaly Detection,Deep Learning,Wearables,Cardiovascular Disease,Patient Safety,Deep SVDD,Neural Architecture Search"
                     data-authors="Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26501v1.html">Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mustafa Fuad Rifet Ibrahim, Maurice Meijer, Alexander Schlaefer et al.
                </div>

                <div class="paper-summary">
                    This paper proposes utilizing lightweight Unsupervised Anomaly Detection (UAD) filters as an upstream mechanism to enhance the robustness and safety of deep learning models for ECG classification on wearables. By effectively identifying Out-of-Distribution (OOD) data like unseen pathologies or noise-corrupted signals, these filters prevent erroneous high-confidence predictions. Integrating an optimized Deep SVDD filter improved diagnostic classifier accuracy by up to 21 percentage points in simulated deployments, making continuous cardiovascular monitoring more reliable.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Wearable Technology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26501v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26501v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26501v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26501v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26498v1"
                     data-domains="Radiology,Emergency Medicine,Neurological Imaging,Clinical AI Development,Medical Informatics"
                     data-keywords="Large Language Models,Clinical AI,AI triage,Intracranial Hemorrhage,CT head,Performance Assessment,Ensemble Learning,Radiology,Ground Truth"
                     data-authors="Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26498v1.html">A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Adam E. Flanders, Yifan Peng, Luciano Prevedello et al.
                </div>

                <div class="paper-summary">
                    This study demonstrates that an ensemble of multiple large language models (LLMs) can provide a more reliable and consistent method for retrospectively assessing the performance of a clinical AI triage tool, specifically for intracranial hemorrhage (ICH) detection, compared to using a single LLM. Analyzing a large dataset of head CT reports, the researchers found that LLM ensembles achieved superior performance metrics in deriving ground truth evaluations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Neurological Imaging</span>
                    
                    <span class="domain-tag">Clinical AI Development</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26444v1"
                     data-domains="Precision Medicine,Chronic Obstructive Pulmonary Disease (COPD),Rare Diseases,Clinical Decision Support Systems,Pharmacology/Therapeutics"
                     data-keywords="Personalized medicine,Treatment outcome prediction,Scarce data,Knowledge distillation,Adaptive fusion,Chronic Obstructive Pulmonary Disease,Clinical decision support,Machine learning"
                     data-authors="Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26444v1.html">Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenjie Chen, Li Zhuang, Ziying Luo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Cross-Fidelity Knowledge Distillation and Adaptive Fusion Network (CFKD-AFN) to improve personalized treatment outcome prediction when only scarce, high-fidelity trial data is available. By leveraging abundant low-fidelity simulation data via dual-channel knowledge distillation and attention-guided fusion, CFKD-AFN achieves significant prediction accuracy improvements (6.67-74.55%) and robustness for diseases like COPD. The research also presents an interpretable variant to aid clinical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Chronic Obstructive Pulmonary Disease (COPD)</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Pharmacology/Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26444v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26444v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26444v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26411v1"
                     data-domains="Radiology,Medical Imaging,AI in Healthcare,Diagnostic Imaging"
                     data-keywords="MedSAE,MedCLIP,Mechanistic Interpretability,Sparse Autoencoders,Medical Vision,Chest Radiographs,AI in Healthcare,Explainable AI"
                     data-authors="Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26411v1.html">MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riccardo Renzulli, Colas Lepoutre, Enrico Cassano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Medical Sparse Autoencoders (MedSAEs) to enhance the interpretability of MedCLIP, a medical vision-language model, by dissecting its latent space. Using an evaluation framework combining correlation, entropy, and automated neuron naming via MedGEMMA, the authors demonstrate that MedSAE neurons achieve superior monosemanticity and interpretability compared to raw MedCLIP features on the CheXpert dataset. This work represents a scalable advancement toward developing clinically reliable and transparent AI models for medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26411v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26411v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26411v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26411v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26390v1"
                     data-domains="Radiology,Medical Imaging Analysis,Diagnostic Imaging,Oncology (for tumor segmentation/treatment planning)"
                     data-keywords="Multi-organ segmentation,Deep learning,Computer-aided diagnosis,Spatial prior,Dual encoder,Cross-attention,Flow-based decoder,Medical imaging"
                     data-authors="Xizhi Tian,Changjun Zhou,Yulin. Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26390v1.html">SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xizhi Tian, Changjun Zhou, Yulin. Yang
                </div>

                <div class="paper-summary">
                    This paper introduces SPG-CDENet, a novel two-stage deep learning architecture designed to improve multi-organ segmentation accuracy, particularly addressing challenges posed by variations in organ size and shape. It utilizes a spatial prior network for coarse localization and a cross dual encoder network with global and local feature processing, enhanced by symmetric cross-attention and a flow-based decoder. Extensive experiments demonstrate its superior performance on public datasets, affirming its effectiveness in computer-aided diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (for tumor segmentation/treatment planning)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26390v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26390v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26390v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26388v1"
                     data-domains="Nuclear Medicine,Radiology,Neuroimaging,Medical Physics,Oncology"
                     data-keywords="PET,motion correction,head movement,brain imaging,22Na,44Sc,image reconstruction,signal-to-noise ratio"
                     data-authors="Machiel Kolstein,Mokhtar Chmeissani,Andreu Pacheco">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26388v1.html">Monitoring Head Movement in a Brain PET Scanner</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Machiel Kolstein, Mokhtar Chmeissani, Andreu Pacheco
                </div>

                <div class="paper-summary">
                    This paper presents a simulation study of CrowN@22, a novel head monitoring device designed to mitigate motion artifacts during brain PET scans. Utilizing six low-activity non-pure positron emitter point sources (e.g., 22Na) in a crown-like arrangement, the device leverages specific gamma photon detection (e.g., 1274 keV from 22Na) to achieve a superb signal-to-noise ratio. The simulation demonstrates its capability to track head movements with a precision of less than 0.3 degrees or 0.5 mm at a 1 Hz sampling rate, even in the presence of high background brain activity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26388v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26388v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26388v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26388v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26350v1"
                     data-domains="Radiology,Pathology,Medical Image Classification,Hippocampus Segmentation,Diagnostic Imaging"
                     data-keywords="Federated Learning,Architectural Heterogeneity,Domain Shift,Graph Neural Networks,Medical Imaging,Privacy-Preserving AI,Collaborative Learning,Statistical Heterogeneity"
                     data-authors="Furkan Pala,Islem Rekik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26350v1.html">UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Furkan Pala, Islem Rekik
                </div>

                <div class="paper-summary">
                    UnifiedFL is a novel federated learning (FL) framework designed to overcome critical challenges where clients possess fundamentally different neural architectures and non-identically distributed datasets with significant domain shifts. It unifies heterogeneous local networks using a shared Graph Neural Network (GNN), distance-driven clustering, and a two-tier aggregation policy to achieve superior performance in medical image classification and segmentation tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Image Classification</span>
                    
                    <span class="domain-tag">Hippocampus Segmentation</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26350v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26350v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26350v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26350v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26342v1"
                     data-domains="Systems Biology,Pharmacology,Drug Development,Molecular Diagnostics,Disease Pathogenesis,Personalized Medicine"
                     data-keywords="Causal Discovery,Interventional Constraints,Linear Causal Models,Causal Effects,Constrained Optimization,Biological Networks,Drug Discovery,Treatment Design"
                     data-authors="Zhigao Guo,Feng Dong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26342v1.html">Linear Causal Discovery with Interventional Constraints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhigao Guo, Feng Dong
                </div>

                <div class="paper-summary">
                    This paper introduces "interventional constraints" into linear causal discovery, a novel concept encoding high-level causal knowledge as inequality constraints on total causal effects between variables. By explicitly enforcing known causal influences (e.g., "PIP3 positively activates Akt"), this method significantly improves model accuracy and consistency with established findings, thereby accelerating the discovery of new causal relationships crucial for applications like designing new treatments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Molecular Diagnostics</span>
                    
                    <span class="domain-tag">Disease Pathogenesis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26342v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26342v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26342v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26315v1"
                     data-domains="Ophthalmology,Endocrinology,Diabetology,Preventive Medicine"
                     data-keywords="Diabetic Retinopathy,CNN,Vision Transformer (ViT),Hybrid Model,Theory of Evidence,Feature Fusion,Automated Diagnosis,Medical Imaging"
                     data-authors="Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26315v1.html">A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel hybrid framework for diabetic retinopathy (DR) grading, combining CNN and Vision Transformer (ViT) architectures, to overcome the performance limitations of single-backbone systems. Leveraging the theory of evidence, the framework adaptively fuses local and global features, demonstrating improved accuracy and enhanced interpretability in DR diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26272v1"
                     data-domains="Radiation Oncology,Medical Physics,Thoracic Oncology,Pulmonology"
                     data-keywords="Reirradiation,NSCLC,Non-coplanar radiotherapy,Beam orientation optimization,EQD2,OAR sparing,VMAT,Radiation oncology"
                     data-authors="Nathan Torelli,Jonas Willmann,Katja Daehler,Madalyne Day,Nicolaus Andratschke,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26272v1.html">Simultaneous optimization of non-coplanar beam orientations and cumulative EQD2 distribution for high-dose reirradiation of locoregionally recurrent non-small cell lung cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Jonas Willmann, Katja Daehler et al.
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a novel algorithm for simultaneous optimization of non-coplanar beam orientations and cumulative EQD2 distribution for high-dose reirradiation of locoregionally recurrent non-small cell lung cancer (NSCLC). It demonstrated that non-coplanar plans can significantly reduce maximum cumulative EQD2 to critical organs-at-risk (OARs) compared to conventional coplanar techniques, while maintaining target coverage. This advancement aims to improve the therapeutic window for challenging reirradiation cases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Thoracic Oncology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26272v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26272v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26272v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26272v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26188v1"
                     data-domains="Healthcare administration,Quality improvement,Population health management,Patient risk stratification,Health economics,Public health policy"
                     data-keywords="hospital readmissions,medical claims data,machine learning,predictive analytics,Random Forest,Principal Component Analysis,AUC,healthcare quality"
                     data-authors="Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26188v1.html">Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Avinash Kadimisetty, Arun Rajagopalan, Vijendra SK
                </div>

                <div class="paper-summary">
                    This paper investigates the prediction of all-cause hospital readmissions using machine learning models applied to high-dimensional medical claims data. It compares Logistic Regression, Random Forest, and Support Vector Machines, employing Principal Component Analysis for dimensionality reduction. The Random Forest model demonstrated the highest predictive performance based on the Area Under Curve (AUC) metric, offering a robust tool for identifying at-risk patients and crucial contributing factors.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare administration</span>
                    
                    <span class="domain-tag">Quality improvement</span>
                    
                    <span class="domain-tag">Population health management</span>
                    
                    <span class="domain-tag">Patient risk stratification</span>
                    
                    <span class="domain-tag">Health economics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26188v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26188v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26188v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26151v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging,Preventive Medicine"
                     data-keywords="Mammography,Breast Cancer,Vision-Language Models (VLMs),Computer-Aided Diagnosis (CAD),Risk Prediction,Multi-view,Self-supervision,Synthetic Data"
                     data-authors="Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26151v1.html">MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MV-MLM, a novel Multi-View Mammography and Language Model, designed for breast cancer diagnosis and risk prediction. It addresses the challenge of limited finely annotated medical datasets by leveraging multi-view mammography images paired with synthetic radiology reports, employing cross-modal self-supervision. The model achieves state-of-the-art performance across malignancy classification, subtype classification, and image-based cancer risk prediction, demonstrating strong data efficiency without requiring actual radiology reports.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26151v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26151v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26151v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26148v1"
                     data-domains="Geriatric Care,Remote Patient Monitoring,Smart Hospitals,Assisted Living Facilities,Rehabilitation,Preventive Care"
                     data-keywords="Human Activity Recognition,Wi-Fi CSI,Edge AI,Privacy-Preserving,Energy-Efficient,GRU,Embedded Systems,Healthcare Monitoring"
                     data-authors="Kexing Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26148v1.html">STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kexing Liu
                </div>

                <div class="paper-summary">
                    STAR proposes an energy-efficient, privacy-preserving edge-AI framework for Human Activity Recognition (HAR) using Wi-Fi Channel State Information (CSI) in resource-constrained environments. It integrates a lightweight GRU-based neural network with adaptive signal processing and hardware co-optimization, achieving high accuracy (93.52% for 7 activities) and real-time performance on embedded devices. This solution offers a practical and scalable approach for applications like healthcare monitoring, overcoming the computational inefficiency and high latency of previous methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Geriatric Care</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Smart Hospitals</span>
                    
                    <span class="domain-tag">Assisted Living Facilities</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26148v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26148v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26148v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26148v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26083v1"
                     data-domains="Magnetic Resonance Imaging (MRI),Radiology,Clinical Diagnostics,Medical Image Reconstruction"
                     data-keywords="Specialized Generalist Models,Task-Aware Memory,Large Language Models,Magnetic Resonance Imaging,Medical AI,Clinical Reports,Deep Learning,Domain Adaptation"
                     data-authors="Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26083v1.html">Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhua Jiang, Shuang Cheng, Yihao Liu et al.
                </div>

                <div class="paper-summary">
                    Nirvana introduces a Specialized Generalist Model (SGM) with a novel task-aware memory mechanism, linear time complexity, and on-the-fly domain adaptation capabilities. Utilizing a Task-Aware Memory Trigger and Specialized Memory Updater, Nirvana achieves competitive performance on general language tasks and superior, high-quality MRI reconstruction, along with accurate preliminary clinical report generation, even with a frozen backbone adapted through task-related parameter adjustments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Medical Image Reconstruction</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26083v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26083v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26083v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26083v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26049v1"
                     data-domains="Pediatric Orthopedics,Radiology,Emergency Medicine,Musculoskeletal Imaging"
                     data-keywords="ultrasound segmentation,in-context learning,deep learning,pediatric fractures,musculoskeletal ultrasound,bony regions,data efficiency,image concatenation"
                     data-authors="Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26049v1.html">FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuyue Zhou, Jessica Knight, Shrimanti Ghosh et al.
                </div>

                <div class="paper-summary">
                    FlexICL is a novel visual in-context learning (ICL) framework designed for efficient segmentation of bony regions in pediatric elbow and wrist ultrasound images, addressing the challenge of scarce expert annotations. By employing innovative concatenation methods and data augmentation, it achieves robust performance requiring only 5% of training data. The framework significantly outperforms state-of-the-art ICL and conventional segmentation models, demonstrating its potential as a scalable solution for medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatric Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Musculoskeletal Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26049v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26049v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26049v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26049v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26032v1"
                     data-domains="Endocrinology,Radiology,Oncology,Internal Medicine,Clinical Informatics,Public Health,Pathology"
                     data-keywords="Incidental Thyroid Findings,Natural Language Processing,Radiology Reports,Thyroid Cancer,Overdiagnosis,Thyroid Nodule,Diagnostic Cascade,Epidemiology"
                     data-authors="Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26032v1.html">Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Felipe Larios, Mariana Borras-Osorio, Yuqi Wu et al.
                </div>

                <div class="paper-summary">
                    This research developed an AI-enabled Natural Language Processing (NLP) pipeline to analyze radiology reports for incidental thyroid findings (ITFs) in a large patient cohort. It revealed ITFs are common (7.8%) and significantly trigger diagnostic cascades (ultrasound, biopsy, thyroidectomy), often leading to the detection of small, low-risk papillary thyroid cancers, underscoring their role in thyroid cancer overdiagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26032v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26032v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26032v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26032v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26014v1"
                     data-domains="Oncology,Clinical Research,Prognostics,Personalized Medicine,Biomedical Research"
                     data-keywords="Survival analysis,Discrete-time,Mixture-of-Experts (MoE),Patient heterogeneity,Risk prediction,Deep learning,Breast cancer,C-index"
                     data-authors="Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26014v1.html">Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hyeonjun Lee, Hyungseob Shin, Gunhee Nam et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a dual Mixture-of-Experts (MoE) framework designed for discrete-time survival analysis, aiming to enhance risk predictions by effectively modeling patient heterogeneity and temporal dynamics. The framework integrates a feature-encoder MoE for subgroup-aware representation learning with a hazard MoE that leverages patient features and time embeddings. Evaluated on breast cancer datasets, the method consistently improved the time-dependent C-index, demonstrating its effectiveness and flexible integration into existing deep learning survival pipelines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26014v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26014v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26014v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26014v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26004v1"
                     data-domains="Emergency Medicine,Trauma Surgery,Pre-hospital Care,Public Health,Disaster Preparedness,Critical Care Transport"
                     data-keywords="traffic incident detection,drones,artificial intelligence,deep learning,real-time surveillance,emergency response,thermal imaging,trauma care,transportation safety"
                     data-authors="Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26004v1.html">DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.RO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bai Li, Achilleas Kourtellis, Rong Cao et al.
                </div>

                <div class="paper-summary">
                    DARTS is a novel drone-based, AI-powered system designed for real-time traffic incident detection, addressing limitations of conventional methods such as slow response and infrastructure dependence. By integrating adaptive drone surveillance, thermal imaging, and a lightweight deep learning framework, DARTS achieved 99% detection accuracy and demonstrated a 12-minute earlier incident verification in a field test compared to traditional systems. This facilitates significantly faster emergency response, proactive traffic control, and improved management of incident-induced congestion.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Trauma Surgery</span>
                    
                    <span class="domain-tag">Pre-hospital Care</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Disaster Preparedness</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26004v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26004v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26004v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25998v1"
                     data-domains="Neurology,Neurocritical Care,Anesthesiology,Psychiatry,Palliative Care,Rehabilitation Medicine"
                     data-keywords="Integrated Information Theory,Consciousness,Phenomenology,Ontology,Cause-effect power,Qualia,Consciousness assessment,Disorders of consciousness"
                     data-authors="Giulio Tononi,Melanie Boly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25998v1.html">Integrated Information Theory: A Consciousness-First Approach to What Exists</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Giulio Tononi, Melanie Boly
                </div>

                <div class="paper-summary">
                    Integrated Information Theory (IIT) presents a 'consciousness-first' approach to existence, positing that subjective experience is fundamental and its essential properties (axioms of phenomenal existence) can be formalized into physical postulates. The theory claims an entity's intrinsic cause-effect power upon itself, characterized by specific structure, accounts for all aspects of consciousness, providing an explanatory identity between physical structure and subjective experience.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurocritical Care</span>
                    
                    <span class="domain-tag">Anesthesiology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Palliative Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25998v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25998v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25998v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25998v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25962v1"
                     data-domains="Medical Image Reconstruction,Computational Imaging,Diagnostic Imaging,Bio-medical Signal Processing,Scientific Computing in Medicine"
                     data-keywords="neural networks,dataless training,optimization,medical image reconstruction,inverse problems,training-data-free,re-parameterization,data scarcity"
                     data-authors="Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25962v1.html">On the Dataless Training of Neural Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvaro Velasquez, Susmit Jha, Ismail R. Alkhouri
                </div>

                <div class="paper-summary">
                    This paper surveys the emerging field of dataless training of neural networks for optimization problems, where models are re-parameterized to solve problems without explicit training data. It categorizes these methods into architecture-agnostic and architecture-specific approaches, motivated by the limitations of data-driven methods and the inherent scarcity of data in domains like medical imaging. The review highlights the promising results of this approach across various applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Image Reconstruction</span>
                    
                    <span class="domain-tag">Computational Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Bio-medical Signal Processing</span>
                    
                    <span class="domain-tag">Scientific Computing in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25962v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25962v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25962v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25962v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25954v1"
                     data-domains="Public Health,Epidemiology,Global Health,Health Informatics,Health Systems Strengthening"
                     data-keywords="Geospatial Foundation Models,LMICs,Health data,Predictive modeling,XGBoost,Public health,Health information systems,Malawi"
                     data-authors="Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25954v1.html">Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lynn Metz, Rachel Haggard, Michael Moszczynski et al.
                </div>

                <div class="paper-summary">
                    This study demonstrates the utility of Geospatial Foundation Models (GeoFMs) in improving the prediction of routine health programmatic outputs in low- and middle-income countries (LMICs) where traditional data are often constrained. By synthesizing diverse spatial, temporal, and behavioral data into mathematical embeddings, GeoFMs, particularly a Multi-GeoFM approach, enhanced predictive performance for key health indicators compared to baseline geostatistical methods. The research concludes that integrating multiple GeoFM sources can efficiently supplement and strengthen routine health information systems in resource-limited settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Health Systems Strengthening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25954v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25954v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25954v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25954v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25944v1"
                     data-domains="Radiation Oncology,Urology,Medical Education,Medical Physics"
                     data-keywords="Virtual Reality,HDR Brachytherapy,Prostate Cancer,Medical Simulation,Oncology Training,Confidence Assessment,Radiation Oncology,Medical Education"
                     data-authors="Anton Varlukhin,Mackenzie Smith,Fahad Alam,Amandeep Tagger,Gerard Morton,Moti Paudel,Andrew Loblaw,Lucas Mendez,Douglas Hoover,Raffi Karshafian,Humza Nusrat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25944v1.html">Development and pilot evaluation of a virtual reality simulator for HDR prostate brachytherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anton Varlukhin, Mackenzie Smith, Fahad Alam et al.
                </div>

                <div class="paper-summary">
                    This paper details the development and pilot evaluation of a virtual reality (VR) simulator for high dose rate (HDR) prostate brachytherapy, featuring modules for patient preparation and template-guided needle insertion. The study demonstrated that immediate participation in the VR simulation significantly increased self-reported confidence among oncology staff and trainees across key procedural domains. These findings suggest the simulator's potential for informing future curriculum design in brachytherapy training.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25944v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25944v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25944v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25944v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25924v1"
                     data-domains="Clinical trials,epidemiology,pharmacoepidemiology,public health,personalized medicine,health informatics,disease modeling"
                     data-keywords="Causal inference,confounding,proxy variables,multi-domain learning,identifiability,treatment effects,personalized medicine,epidemiology"
                     data-authors="Manuel Iglesias-Alonso,Felix Schur,Julius von K√ºgelgen,Jonas Peters">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25924v1.html">Transferring Causal Effects using Proxies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manuel Iglesias-Alonso, Felix Schur, Julius von K√ºgelgen et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of estimating causal effects in multi-domain settings where a key confounder is unobserved, but a proxy variable for it is available. It proposes a novel methodology to identify and estimate these causal effects in a target domain, even when the causal effect itself changes across domains and only the proxy is observed. The work provides theoretical proofs for identifiability and introduces two consistent estimation techniques with derived confidence intervals, supported by simulations and a real-world application.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                    <span class="domain-tag">epidemiology</span>
                    
                    <span class="domain-tag">pharmacoepidemiology</span>
                    
                    <span class="domain-tag">public health</span>
                    
                    <span class="domain-tag">personalized medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25924v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25924v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25924v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25924v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25908v1"
                     data-domains="Biomedical Research,Pharmacology,Toxicology,Public Health Preparedness,Medical Ethics,Clinical Decision Support,Drug Discovery,Biosecurity"
                     data-keywords="LLM trustworthiness,Scientific AI,Truthfulness,Adversarial robustness,Scientific safety,Biosecurity,Medical ethics,AI evaluation"
                     data-authors="Emily Herron,Junqi Yin,Feiyi Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25908v1.html">SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Emily Herron, Junqi Yin, Feiyi Wang
                </div>

                <div class="paper-summary">
                    SciTrust 2.0 introduces a comprehensive framework to evaluate the trustworthiness of Large Language Models (LLMs) in scientific applications, spanning truthfulness, adversarial robustness, scientific safety, and ethics. The study surprisingly found that general-purpose industry LLMs, particularly GPT-o4-mini, consistently outperformed science-specialized models across all dimensions, while the latter exhibited significant deficiencies in logical and ethical reasoning and alarming vulnerabilities in high-risk domains like biosecurity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Public Health Preparedness</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25908v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25908v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25908v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25908v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25867v1"
                     data-domains="Radiology,Pathology,Medical Imaging (e.g., X-ray, CT, MRI, Ultrasound, Microscopy - indicated by VQA-RAD, PathVQA, 13 modalities mentioned),Anatomy (28 anatomical regions)"
                     data-keywords="Medical VQA,Large Multimodal Models,Data Synthesis,Generator-Verifier,Reinforcement Learning,Biomedical Imaging,Clinical Validity,MedSynVQA"
                     data-authors="Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25867v1.html">MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoke Huang, Ningsen Wang, Hui Liu et al.
                </div>

                <div class="paper-summary">
                    MedVLSynther introduces a novel rubric-guided generator-verifier framework that synthesizes high-quality, multiple-choice medical Visual Question Answering (VQA) data directly from open biomedical literature. This approach addresses the critical shortage of medical VQA training data, producing MedSynVQA, and significantly enhances the performance of open-weight Large Multimodal Models (LMMs) on various medical VQA benchmarks, outperforming existing specialized medical LMMs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging (e.g., X-ray, CT, MRI, Ultrasound, Microscopy - indicated by VQA-RAD, PathVQA, 13 modalities mentioned)</span>
                    
                    <span class="domain-tag">Anatomy (28 anatomical regions)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25867v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25867v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25867v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25867v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25759v1"
                     data-domains="Radiology,Digital Pathology,Medical Image Analysis,Oncology (e.g., tumor detection)"
                     data-keywords="Multiple Instance Learning,Correlated MIL,Generalization Gaps,Synthetic Data,Medical Imaging,Contextual Relationships,Bayes Estimator,Deep Learning"
                     data-authors="Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25759v1.html">Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ethan Harvey, Dennis Johan Loevlie, Michael C. Hughes
                </div>

                <div class="paper-summary">
                    This paper investigates the limitations of Multiple Instance Learning (MIL) methods in medical imaging tasks where contextual relationships between instances (e.g., adjacent patches or slices) are crucial. By designing a synthetic classification task where context is paramount, the authors demonstrate significant generalization gaps, showing that both conventional and newer correlated MIL approaches struggle to perform optimally compared to a Bayes estimator.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Oncology (e.g., tumor detection)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25758v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Health,Digital Therapeutics,Behavioral Health"
                     data-keywords="psychological counseling,large language models,AI agent,longitudinal therapy,adaptive strategies,emotional understanding,therapeutic planning,mental health"
                     data-authors="He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25758v1.html">TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> He Hu, Yucheng Zhou, Chiyuan Ma et al.
                </div>

                <div class="paper-summary">
                    TheraMind introduces a strategic and adaptive AI agent for longitudinal psychological counseling, overcoming limitations of existing large language models (LLMs) in emotional understanding, adaptive strategies, and multi-session memory. Its novel dual-loop architecture‚Äîcomprising an Intra-Session Loop for dynamic dialogue and a Cross-Session Loop for strategic therapeutic planning‚Äîenables continuous, personalized care. Validated in high-fidelity simulations, TheraMind significantly outperforms other methods, particularly on multi-session metrics like Coherence and Therapeutic Attunement, demonstrating its effectiveness in emulating advanced therapeutic behaviors.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25758v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25758v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25758v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25758v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25679v1"
                     data-domains="Emergency Medical Services (EMS) Logistics,Disaster Response Logistics,Remote Healthcare Delivery,Medical Supply Chain Optimization"
                     data-keywords="Deep Reinforcement Learning,UAV Navigation,Urban Flow,Turbulence,Proximal Policy Optimization,Gated Transformer eXtra Large,Autonomous Systems,Fluid Dynamics"
                     data-authors="Federica Tonti,Ricardo Vinuesa">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25679v1.html">Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Federica Tonti, Ricardo Vinuesa
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Deep Reinforcement Learning (DRL) strategy for optimal UAV navigation in a high-fidelity 3D urban flow simulation characterized by turbulence and recirculation zones. The proposed flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture significantly enhances navigation success and reduces crash rates compared to traditional methods and other DRL approaches, paving the way for safer and more efficient UAV operations in complex urban environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medical Services (EMS) Logistics</span>
                    
                    <span class="domain-tag">Disaster Response Logistics</span>
                    
                    <span class="domain-tag">Remote Healthcare Delivery</span>
                    
                    <span class="domain-tag">Medical Supply Chain Optimization</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25679v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25679v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25679v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25679v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25816v1"
                     data-domains="Clinical Informatics,Health Data Science,Medical Record Management,Artificial Intelligence in Healthcare,Clinical Decision Support Systems"
                     data-keywords="Clinical NLP,Electronic Health Records,FHIR,Semantic Question Answering,Entity-Aware Retrieval,Large Language Models,Retrieval Augmented Generation,Clinical Documentation"
                     data-authors="Tarun Kumar Chawdhury,Jon D. Duke">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25816v1.html">Beyond Long Context: When Semantics Matter More than Tokens</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tarun Kumar Chawdhury, Jon D. Duke
                </div>

                <div class="paper-summary">
                    This paper validates the Clinical Entity Augmented Retrieval (CLEAR) method for semantic question answering over lengthy Electronic Health Records (EHR) clinical notes, which are typically stored as FHIR attachments. CLEAR significantly improves both accuracy (58.3% win rate, 0.878 semantic similarity) and efficiency (78% fewer tokens) compared to large context inference and traditional RAG, especially for very long documents. The study introduces a reusable evaluation platform for clinical QA systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Data Science</span>
                    
                    <span class="domain-tag">Medical Record Management</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Healthcare</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25816v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25816v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25816v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25816v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25628v1"
                     data-domains="Clinical medicine,Medical informatics,Healthcare AI,Diagnostic support,Prognostic assessment"
                     data-keywords="Electronic Health Records (EHRs),Large Language Models (LLMs),Clinical Decision Support,Reasoning,Foundational Models,Medical AI,Instruction Tuning,MIMIC-IV"
                     data-authors="Yusheng Liao,Chaoyi Wu,Junwei Liu,Shuyang Jiang,Pengcheng Qiu,Haowen Wang,Yun Yue,Shuai Zhen,Jian Wang,Qianrui Fan,Jinjie Gu,Ya Zhang,Yanfeng Wang,Yu Wang,Weidi Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25628v1.html">EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yusheng Liao, Chaoyi Wu, Junwei Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EHR-R1, a series of reasoning-enhanced foundational language models specifically designed for robust Electronic Health Record (EHR) analysis. It leverages a novel, large-scale instruction dataset (EHR-Ins) generated via a thinking-graph-driven framework and a multi-stage training paradigm to imbue LLMs with extensive EHR domain knowledge and complex reasoning capabilities. EHR-R1 significantly outperforms state-of-the-art commercial and open-source LLMs, including GPT-4o, on a new comprehensive benchmark (EHR-Bench) for diverse EHR tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical medicine</span>
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                    <span class="domain-tag">Diagnostic support</span>
                    
                    <span class="domain-tag">Prognostic assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25628v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25628v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25628v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25588v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology,Digital Health,eHealth"
                     data-keywords="psychiatric diagnosis,LLM consortium,fine-tuned LLM,reasoning LLM,decision support system,mental health,standardization,responsible AI"
                     data-authors="Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25588v1.html">Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eranga Bandara, Ross Gore, Atmaram Yarlagadda et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel AI-powered decision support system designed to standardize psychiatric diagnoses by mitigating the inherent subjectivity and variability in current clinical practices. It integrates a consortium of fine-tuned Large Language Models (LLMs), specialized in psychiatrist-patient conversational data, with an OpenAI-gpt-oss reasoning LLM, orchestrated by LLM agents, to produce robust and highly accurate mental health assessments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">eHealth</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25588v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25588v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25588v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25588v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-01 06:28:12</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>