<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">170</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (13), Oncology (11), Medical Imaging (11)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (13)</option>
                        
                        <option value="Oncology">Oncology (11)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (11)</option>
                        
                        <option value="Public Health">Public Health (8)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Cardiology">Cardiology (5)</option>
                        
                        <option value="Pharmacology">Pharmacology (5)</option>
                        
                        <option value="Digital Pathology">Digital Pathology (4)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.27680v1"
                     data-domains="Radiology,Oncology,Nuclear Medicine,Diagnostic Imaging"
                     data-keywords="PET/CT,Vision-Language Model,3D Imaging,Automated Reporting,Lesion Segmentation,Mask-Aware Modeling,Radiology,Deep Learning"
                     data-authors="Danyal Maqbool,Changhee Lee,Zachary Huemann,Samuel D. Church,Matthew E. Larson,Scott B. Perlman,Tomas A. Romero,Joshua D. Warner,Meghan Lubner,Xin Tie,Jameson Merkow,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27680v1.html">PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Danyal Maqbool, Changhee Lee, Zachary Huemann et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PETAR-4B, a 3D mask-aware vision-language model designed for automated generation of localized findings in PET/CT radiology reports. The authors address the limitation of current medical VLMs to 2D imaging by extending them to complex 3D PET/CT data, leveraging a newly created large-scale dataset of over 11,000 lesion descriptions. PETAR-4B integrates PET, CT, and lesion contour information, significantly improving the quality of report generation through comprehensive automated and human evaluations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27680v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27680v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27680v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27680v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27679v1"
                     data-domains="Pulmonology,Oncology,Radiology,Medical Imaging,Public Health Screening"
                     data-keywords="dark-field X-ray imaging,lung cancer screening,deep learning,U-Net,early-stage tumor detection,preclinical models,low-dose imaging,attenuation radiography"
                     data-authors="Joyoni Dey,Hunter C. Meyer,Murtuza S. Taqi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27679v1.html">Dark-Field X-Ray Imaging Significantly Improves Deep-Learning based Detection of Synthetic Early-Stage Lung Tumors in Preclinical Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Joyoni Dey, Hunter C. Meyer, Murtuza S. Taqi
                </div>

                <div class="paper-summary">
                    This paper investigates X-ray dark-field imaging (DFI) combined with deep learning to improve early-stage lung tumor detection, addressing the limited accessibility and high false-positive rates of current low-dose computed tomography (LDCT). Using a U-Net segmentation network on synthetic tumors in euthanized mouse lungs, DFI-only input achieved significantly higher sensitivity (83.7%) compared to attenuation-only (51%) while maintaining comparable specificity. The study concludes that DFI substantially enhances early-tumor detectability, offering potential as an accessible, low-cost, low-dose alternative for preclinical or limited-resource screening.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Public Health Screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27679v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27679v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27679v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27679v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27677v1"
                     data-domains="Hospital Management,Patient Safety,Geriatrics (Elderly Care),Psychiatric Facilities,Security and Access Control (Healthcare),Emergency Medicine"
                     data-keywords="Person Re-identification,Vision Transformer,Occlusion Robustness,Surveillance,Deep Learning,Data Augmentation,Knowledge Distillation,Computer Vision"
                     data-authors="Bo Li,Duyuan Zheng,Xinyang Liu,Qingwen Li,Hong Li,Hongyan Cui,Ge Gao,Chen Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27677v1.html">Vision Transformer for Robust Occluded Person Reidentification in Complex Surveillance Scenes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bo Li, Duyuan Zheng, Xinyang Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Sh-ViT (Shuffling Vision Transformer), a lightweight and robust model designed for occluded person re-identification (ReID) in complex surveillance scenes, addressing challenges like occlusion, viewpoint distortion, and poor image quality. Sh-ViT, built on ViT-Base, incorporates a Shuffle module, scenario-adapted data augmentation, and DeiT-based knowledge distillation, demonstrating superior performance on a newly constructed real-world dataset (MyTT) and the public Market1501 dataset, outperforming existing CNN and ViT baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Hospital Management</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Geriatrics (Elderly Care)</span>
                    
                    <span class="domain-tag">Psychiatric Facilities</span>
                    
                    <span class="domain-tag">Security and Access Control (Healthcare)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27677v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27677v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27677v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27677v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27671v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Discovery,Structural Biology,Computational Biology"
                     data-keywords="Structure-based Drug Design (SBDD),Protein-Guided Drug Design,MolChord,NatureLM,Diffusion Model,Direct Preference Optimization (DPO),Multi-modal Alignment,Drug Discovery"
                     data-authors="Wei Zhang,Zekun Guo,Yingce Xia,Peiran Jin,Shufang Xie,Tao Qin,Xiang-Yang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27671v1.html">MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei Zhang, Zekun Guo, Yingce Xia et al.
                </div>

                <div class="paper-summary">
                    MolChord proposes a novel structure-sequence alignment approach for protein-guided drug design, integrating multi-modal representations (structural, sequential, textual) to generate molecular ligands. It utilizes NatureLM as a molecule generator with a diffusion-based structure encoder, and refines drug properties through a preference-aware dataset and Direct Preference Optimization. The method achieves state-of-the-art performance on CrossDocked2020, highlighting its potential for practical drug discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27663v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Nuclear Medicine,Image-guided Surgery,Computational Imaging in Healthcare"
                     data-keywords="Bayesian imaging,model selection,misspecification testing,cross-validation,data fission,inverse problems,image reconstruction,machine learning priors"
                     data-authors="Tom Sprunck,Marcelo Pereyra,Tobias Liaudat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27663v1.html">Bayesian model selection and misspecification testing in imaging inverse problems only from noisy and partial measurements</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tom Sprunck, Marcelo Pereyra, Tobias Liaudat
                </div>

                <div class="paper-summary">
                    This paper introduces a novel methodology for unsupervised model selection and misspecification testing in Bayesian imaging inverse problems, particularly when ground truth data is unavailable. By combining Bayesian cross-validation with a randomized measurement splitting technique called data fission, the approach effectively evaluates imaging models, including those with modern machine learning-defined priors. The methodology demonstrates excellent selection and detection accuracy with low computational cost, making it highly suitable for complex computational imaging tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Image-guided Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27663v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27663v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27663v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27663v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27646v1"
                     data-domains="Radiology,Ophthalmology,Cardiology,Neurology,Medical Image Analysis"
                     data-keywords="blood vessel segmentation,semantic segmentation,few-shot learning,zero-shot learning,shape priors,synthetic data,generalization,Convolutional Neural Networks"
                     data-authors="Cesar H. Comin,Wesley N. Galv√£o">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27646v1.html">VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cesar H. Comin, Wesley N. Galv√£o
                </div>

                <div class="paper-summary">
                    This paper introduces VessShape, a novel methodology for generating large-scale synthetic 2D datasets designed to instill a strong shape bias in blood vessel segmentation models. By leveraging geometric priors like tubular and branching structures while varying textures, VessShape aims to overcome data scarcity and improve model generalization across different imaging modalities. The pre-trained models demonstrate robust few-shot performance, requiring minimal real-world annotations (4-10 samples) for fine-tuning, and exhibit notable zero-shot capabilities in unseen domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27646v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27646v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27646v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27646v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27629v2"
                     data-domains="Infectious Diseases,Drug Discovery,Public Health,Biodefense,AI in Medicine,Vaccinology"
                     data-keywords="bio-foundation models,dual-use dilemma,biorisk evaluation,AI safety,biosecurity,virus understanding,machine learning,drug development"
                     data-authors="Boyi Wei,Zora Che,Nathaniel Li,Udari Madhushani Sehwag,Jasper G√∂tting,Samira Nedungadi,Julian Michael,Summer Yue,Dan Hendrycks,Peter Henderson,Zifan Wang,Seth Donoughe,Mantas Mazeika">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27629v2.html">Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Boyi Wei, Zora Che, Nathaniel Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces `eval`, a framework to assess the robustness of procedures designed to mitigate the dual-use risks of open-weight bio-foundation models. It finds that current data filtering methods are insufficient, as malicious knowledge can be recovered and generalized through fine-tuning, and dangerous capabilities may already be present in pre-trained models. The research highlights the critical need for more robust safety strategies beyond data filtering for these powerful AI models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biodefense</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27629v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27629v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27629v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27629v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27552v1"
                     data-domains="Multilingual healthcare,Clinical natural language processing,Medical informatics,Biomedical informatics,Patient screening,Electronic Health Records (EHR) analysis"
                     data-keywords="multilingual BERT,medical NLP,domain adaptation,cross-lingual transfer,low-resource languages,clinical notes,named entity recognition,healthcare applications"
                     data-authors="Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27552v1.html">Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yinghao Luo, Lang Zhou, Amrish Jhingoer et al.
                </div>

                <div class="paper-summary">
                    This study investigates the effectiveness of domain-specific pre-training on multilingual BERT models for medical NLP tasks across Dutch, Romanian, and Spanish. It demonstrates that adapting models to specific medical domains significantly enhances performance, with clinical domain models outperforming general biomedical ones, and also reveals promising cross-lingual transferability, offering a strategy to address data scarcity in low-resource healthcare languages.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Multilingual healthcare</span>
                    
                    <span class="domain-tag">Clinical natural language processing</span>
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                    <span class="domain-tag">Biomedical informatics</span>
                    
                    <span class="domain-tag">Patient screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27552v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27552v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27552v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27552v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27535v1"
                     data-domains="Clinical Informatics,Medical Artificial Intelligence,Patient Engagement,Cardiology,Primary Care,Healthcare Quality Improvement"
                     data-keywords="Patient-Centered Care,Clinical Summarization,Large Language Models,AI in Healthcare,Mixed-Methods,Atrial Fibrillation,Natural Language Processing,Shared Decision-Making"
                     data-authors="Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27535v1.html">Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Maria Lizarazo Jimenez, Ana Gabriela Claros, Kieran Green et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Patient-Centered Summaries (PCS) as a new standard for AI clinical summarization, aiming to capture patient values beyond biological data. Through a mixed-methods approach involving patient and clinician input, a framework was developed and used to evaluate open-source Large Language Models (LLMs), revealing that while LLMs show promise in fluency, they currently fall short of human experts in correctness and patient-centeredness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Patient Engagement</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27535v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27535v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27535v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27535v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27508v1"
                     data-domains="Oncology,Radiology,Nuclear Medicine,Pulmonology,Medical Imaging"
                     data-keywords="lung tumor segmentation,PET-CT,multimodal imaging,Visual Mamba,deep learning,cross-modal perception,medical image analysis,computational efficiency"
                     data-authors="Elena Mulero Ayll√≥n,Linlin Shen,Pierangelo Veltri,Fabrizia Gelardi,Arturo Chiti,Paolo Soda,Matteo Tortora">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27508v1.html">Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elena Mulero Ayll√≥n, Linlin Shen, Pierangelo Veltri et al.
                </div>

                <div class="paper-summary">
                    This paper introduces vMambaX, a lightweight multimodal framework utilizing a Context-Gated Cross-Modal Perception Module (CGM) and Visual Mamba architecture for accurate PET-CT lung tumor segmentation. It adaptively integrates anatomical and functional information to enhance inter-modality features while suppressing noise. Evaluated on the PCLT20K dataset, vMambaX demonstrated superior performance compared to baseline models with reduced computational complexity, showcasing its potential for efficient lung cancer analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27508v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27508v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27508v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27508v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27497v1"
                     data-domains="Drug discovery,Medicinal chemistry,Computational biology,Pharmaceutical research,Material science (biomaterials)"
                     data-keywords="3D molecule generation,autoregressive models,Transformers,deep learning,drug discovery,SE(3) invariance,tokenization,geometric deep learning"
                     data-authors="Haorui Li,Weitao Du,Yuqiang Li,Hongyu Guo,Shengchao Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27497v1.html">InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haorui Li, Weitao Du, Yuqiang Li et al.
                </div>

                <div class="paper-summary">
                    InertialAR is a novel Transformer-based autoregressive model that addresses key challenges in 3D molecule generation, particularly canonical tokenization and modeling hybrid atom-based tokens. It achieves this by leveraging inertial frames for invariant tokenization, integrating geometric awareness via geometric rotary positional encoding (GeoRoPE), and employing a hierarchical prediction paradigm. The model demonstrates state-of-the-art performance in both unconditional and controllable 3D molecule generation across multiple benchmark datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug discovery</span>
                    
                    <span class="domain-tag">Medicinal chemistry</span>
                    
                    <span class="domain-tag">Computational biology</span>
                    
                    <span class="domain-tag">Pharmaceutical research</span>
                    
                    <span class="domain-tag">Material science (biomaterials)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27497v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27497v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27497v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27497v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27442v1"
                     data-domains="Medical Imaging Analysis,Diagnostic Support,Radiology,Pathology,Dermatology,Ophthalmology,Clinical Decision Support"
                     data-keywords="Vision Transformer,Medical Imaging,Compact Models,Efficient AI,Supervised Classification,Grad-CAM,Generalization,Low-Resource Settings"
                     data-authors="Aon Safdar,Mohamed Saadeldin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27442v1.html">CoMViT: An Efficient Vision Backbone for Supervised Classification in Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aon Safdar, Mohamed Saadeldin
                </div>

                <div class="paper-summary">
                    CoMViT is a novel, compact Vision Transformer (ViT) architecture specifically designed for efficient supervised classification in medical imaging. It addresses the high computational demands and overfitting tendencies of traditional ViTs on small medical datasets by integrating several architectural optimizations, achieving robust performance across diverse MedMNIST datasets with significantly reduced parameters.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Diagnostic Support</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27442v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27442v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27442v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27442v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27421v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Medical AI,Public Health"
                     data-keywords="Deep learning,Fairness,Bias,Image segmentation,Breast cancer,Age bias,Ethnic bias,MAMA-MIA"
                     data-authors="Aditya Parikh,Sneha Das,Aasa Feragen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27421v1.html">Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aditya Parikh, Sneha Das, Aasa Feragen
                </div>

                <div class="paper-summary">
                    This paper audits the fairness of automated segmentation labels in the MAMA-MIA breast cancer dataset, revealing significant age and ethnic biases. It identifies an intrinsic age-related bias against younger patients, hypothesized to be linked to physiological factors, and demonstrates how data aggregation can obscure site-specific ethnic biases. The study underscores the critical need for granular fairness evaluations in deep learning models for diagnostic imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27421v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27421v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27421v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27421v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27403v1"
                     data-domains="Medical Imaging,Genomics,Electronic Health Records (EHR) Analysis,Digital Pathology,Personalized Medicine,Clinical Decision Support Systems"
                     data-keywords="Federated Learning,Matrix Orthogonalization,Communication Efficiency,Non-IID Data,Client Drift,Momentum Aggregation,Medical AI,Privacy-preserving AI"
                     data-authors="Junkang Liu,Fanhua Shang,Junchao Zhou,Hongying Liu,Yuanyuan Liu,Jin Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27403v1.html">FedMuon: Accelerating Federated Learning with Matrix Orthogonalization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junkang Liu, Fanhua Shang, Junchao Zhou et al.
                </div>

                <div class="paper-summary">
                    FedMuon is a novel optimizer for Federated Learning (FL) designed to accelerate convergence and reduce communication rounds by leveraging matrix orthogonalization for local updates. It addresses critical challenges like client drift and moment reinitialization in non-IID FL settings through momentum aggregation and local-global alignment, demonstrating significant empirical and theoretical advantages.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Analysis</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27403v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27403v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27403v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27403v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27354v1"
                     data-domains="Infectious Disease,Public Health,Veterinary Medicine,Food Safety,Immunology,Epidemiology,Antimicrobial Resistance"
                     data-keywords="aquaculture,streptococcosis,Streptococcus iniae,Streptococcus agalactiae,disease control,genetic engineering,vaccines,One-Health,biosecurity,IoT"
                     data-authors="Hussein Aliu Sule,Abdulwakil Olawale Saba,Choo Yee Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27354v1.html">Streptococcosis in aquaculture: Advances, challenges, and future directions in disease control and prevention</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hussein Aliu Sule, Abdulwakil Olawale Saba, Choo Yee Yu
                </div>

                <div class="paper-summary">
                    This review paper comprehensively synthesizes current knowledge on streptococcal infections, particularly from *Streptococcus iniae* and *Streptococcus agalactiae*, which pose significant threats to global aquaculture and food security. It analyzes advanced strategies for disease control and prevention, including genetic engineering for disease resistance, optimized farming practices, real-time monitoring via IoT and big data, and diverse vaccine development. The paper emphasizes a holistic One-Health approach, advocating for collaboration to enhance the sustainability and productivity of aquaculture systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Veterinary Medicine</span>
                    
                    <span class="domain-tag">Food Safety</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27354v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27354v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27354v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27354v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27326v1"
                     data-domains="Oncology,Diagnostic Radiology,Medical Imaging,Preventive Medicine"
                     data-keywords="Breast Cancer,MRI,Classification,Early Detection,Medical Imaging,Machine Learning,ODELIA Challenge,Screening"
                     data-authors="Benjamin Hamm,Yannick Kirchhoff,Maximilian Rokuss,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27326v1.html">MeisenMeister: A Simple Two Stage Pipeline for Breast Cancer Classification on MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Benjamin Hamm, Yannick Kirchhoff, Maximilian Rokuss et al.
                </div>

                <div class="paper-summary">
                    This paper presents "MeisenMeister," a simple two-stage pipeline for breast cancer classification on MRI, developed for the ODELIA Breast MRI Challenge 2025. It addresses the critical need for robust classification-based approaches to improve early breast cancer detection, particularly in large-scale screening, given the scarcity of high-quality segmentation labels in breast MRI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27326v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27326v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27326v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27326v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27321v1"
                     data-domains="Cardiology,Critical Care Medicine,Internal Medicine,Medical Informatics,Predictive Analytics in Healthcare"
                     data-keywords="electronic health records,electrocardiogram,multimodal learning,time series analysis,deep learning,clinical prediction,cardiovascular disease,mortality prediction"
                     data-authors="Yu-Chen Kuo,Yi-Ju Tseng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27321v1.html">MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu-Chen Kuo, Yi-Ju Tseng
                </div>

                <div class="paper-summary">
                    MedM2T is a novel time-aware multimodal framework designed to integrate diverse medical data, such as Electronic Health Records (EHR) and Electrocardiograms (ECGs), by effectively handling temporal complexities and granularity gaps. It employs specialized encoders, hierarchical fusion, and cross-modal attention, demonstrating superior performance in critical clinical prediction tasks like cardiovascular disease prediction, in-hospital mortality, and ICU length-of-stay. The framework's robustness and broad applicability position it as a promising tool for clinical prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27321v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27321v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27321v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27321v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27315v1"
                     data-domains="Cardiology,Diagnostic Radiology,Interventional Cardiology,Medical Imaging"
                     data-keywords="Coronary Artery Segmentation,Deep Learning,UNet,DenseNet121,Self-ONN,X-ray Angiography,Coronary Artery Disease (CAD),Image Preprocessing"
                     data-authors="Alvee Hassan,Rusab Sarmun,Muhammad E. H. Chowdhury,M. Murugappan,Md. Sakib Abrar Hossain,Sakib Mahmud,Abdulrahman Alqahtani,Sohaib Bassam Zoghoul,Amith Khandakar,Susu M. Zughaier,Somaya Al-Maadeed,Anwarul Hasan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27315v1.html">CASR-Net: An Image Processing-focused Deep Learning-based Coronary Artery Segmentation and Refinement Network for X-ray Coronary Angiogram</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvee Hassan, Rusab Sarmun, Muhammad E. H. Chowdhury et al.
                </div>

                <div class="paper-summary">
                    CASR-Net is a novel deep learning-based three-stage pipeline developed for accurate and robust coronary artery segmentation and refinement in X-ray angiograms, specifically designed to address challenges like poor image quality and stenotic vessels. It integrates a unique multichannel preprocessing strategy, a UNet with a DenseNet121 encoder and a Self-ONN based decoder, and a contour refinement module. The model achieved state-of-the-art performance, outperforming existing methods in segmenting both healthy and stenotic arteries, thus offering a valuable clinical tool.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27307v1"
                     data-domains="Medical Imaging,Telemedicine,Radiology,Digital Pathology,Medical Informatics"
                     data-keywords="Medical image protection,Zero-watermarking,Dual quaternions,Matrix decomposition,Fragile watermarking,Copyright protection,Tampering detection,Digital watermarking"
                     data-authors="Mingcui Zhang,Zhigang Jia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27307v1.html">A fragile zero-watermarking method based on dual quaternion matrix decomposition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingcui Zhang, Zhigang Jia
                </div>

                <div class="paper-summary">
                    This paper proposes a novel fragile zero-watermarking method leveraging dual quaternion matrix decomposition to protect medical images. The approach aims to address critical issues of copyright ownership and content tampering during transmission and sharing by correlating the original image with a watermark without modifying the carrier, thus enabling both copyright protection and content integrity verification.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27307v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27307v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27307v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27307v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27296v1"
                     data-domains="Ultrasound,Optical Coherence Tomography (OCT),Magnetic Resonance Imaging (MRI),Computed Tomography (CT),Endoscopy"
                     data-keywords="medical image super-resolution,state-space models,Mamba,frequency analysis,attention mechanisms,deep learning,diagnostic imaging,image enhancement"
                     data-authors="Wenfeng Huang,Xiangyun Liao,Wei Cao,Wenjing Jia,Weixin Si">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27296v1.html">Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenfeng Huang, Xiangyun Liao, Wei Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FGMamba, a novel frequency-aware gated state-space model designed for medical image super-resolution (SR). FGMamba effectively unifies global dependency modeling and fine-detail enhancement through its Gated Attention-enhanced State-Space Module (GASM) and Pyramid Frequency Fusion Module (PFFM). It achieves superior diagnostic image quality (PSNR/SSIM) across five diverse medical imaging modalities with a compact parameter footprint, outperforming existing CNN and Transformer-based state-of-the-art methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ultrasound</span>
                    
                    <span class="domain-tag">Optical Coherence Tomography (OCT)</span>
                    
                    <span class="domain-tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="domain-tag">Computed Tomography (CT)</span>
                    
                    <span class="domain-tag">Endoscopy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27296v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27296v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27296v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27296v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27282v1"
                     data-domains="Biomedical Research,Disease Diagnostics,Pathology,Physiology,Cell Biology,Histology"
                     data-keywords="X-ray microtomography,phase imaging,photon-counting detector,radiation dose,native tissue,multimodal imaging,quantum efficiency,biomedical research"
                     data-authors="Dominik John,Gregor Breitenhuber,Sami Wirtensohn,Franziska Hinterdobler,Luka Gaetani,Sara Savatoviƒá,Jens Lucht,Markus Osterhoff,Marina Eckermann,Tim Salditt,Julia Herzen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27282v1.html">Near-perfect efficiency in X-ray phase microtomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.optics</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dominik John, Gregor Breitenhuber, Sami Wirtensohn et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel X-ray phase microtomography setup that achieves near-perfect efficiency and high visibility, addressing critical limitations of current methods. By integrating an X-ray waveguide, a structured phase modulator, and a photon-counting detector, it enables dose-efficient multimodal imaging of native-state biological specimens. This advance promises to revolutionize biomedical research, disease diagnostics, and the understanding of tissue structure in physiological environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Disease Diagnostics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Physiology</span>
                    
                    <span class="domain-tag">Cell Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27282v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27282v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27282v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27282v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27281v1"
                     data-domains="Pharmacology,Drug Discovery,Pharmaceutical Research,Bioinformatics,Medicinal Chemistry"
                     data-keywords="Drug-Target Affinity (DTA),Deep Learning,Hierarchical Feature Learning,Multi-scale Representation,Computational Drug Discovery,Sequence-based Prediction,Bilinear Attention,Drug Screening"
                     data-authors="Minghui Li,Yuanhang Wang,Peijin Guo,Wei Wan,Shengshan Hu,Shengqing Hu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27281v1.html">HiF-DTA: Hierarchical Feature Learning Network for Drug-Target Affinity Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Minghui Li, Yuanhang Wang, Peijin Guo et al.
                </div>

                <div class="paper-summary">
                    HiF-DTA is a novel hierarchical deep learning network designed to improve Drug-Target Affinity (DTA) prediction by addressing limitations in existing sequence-based methods. It achieves superior performance by simultaneously extracting global sequence semantic and local topological features from drugs and proteins, and by modeling drugs with multi-scale representations (atomic, substructural, molecular) fused via bilinear attention. This approach significantly outperforms state-of-the-art baselines, confirming the importance of its global-local extraction and multi-scale fusion components.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27281v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27281v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27281v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27281v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27274v1"
                     data-domains="Clinical Informatics,Pharmacology,Personalized Medicine,Healthcare AI,Medical Decision Making,Health Systems Research"
                     data-keywords="Drug Recommendation,Medical Knowledge Graph,Traceability,Explainable AI,Multi-task Learning,Healthcare AI,Patient Health Records,Clinical Decision Support"
                     data-authors="Yu Lin,Zhen Jia,Philipp Christmann,Xu Zhang,Shengdong Du,Tianrui Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27274v1.html">Traceable Drug Recommendation over Medical Knowledge Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.IR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu Lin, Zhen Jia, Philipp Christmann et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TraceDR, a novel drug recommendation (DR) system built upon medical knowledge graphs (MKGs), designed to address the critical lack of traceability in existing deep learning-based DR systems. By employing a multi-task learning framework, TraceDR simultaneously predicts medication recommendations and provides explicit evidence for these suggestions, thereby ensuring the derivation process is transparent and explainable. The authors also contribute a new large-scale testbed, DrugRec, for DR, created through an automatic patient health record construction framework, to support more diverse disease and drug scenarios.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                    <span class="domain-tag">Medical Decision Making</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27274v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27274v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27274v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27274v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27267v1"
                     data-domains="Internal Medicine,Surgery,Pediatrics,Cardiology"
                     data-keywords="Medical LLMs,Quantitative Reasoning,Clinical Calculation,Benchmark,Reinforcement Learning,Medical Decision Support,Evaluation,State-of-the-Art"
                     data-authors="Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27267v1.html">MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kangkun Mao, Jinru Ding, Jiayuan Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedCalc-Eval, the largest benchmark for evaluating Large Language Models' (LLMs) medical calculation abilities, comprising 700+ tasks ranging from equation-based formulas to rule-based scoring systems. To improve performance, the authors developed MedCalc-Env, a reinforcement learning environment, which, when used to fine-tune a Qwen2.5-32B model, achieved state-of-the-art results on MedCalc-Eval with enhanced numerical sensitivity and reasoning robustness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27267v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27267v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27267v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27267v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27265v1"
                     data-domains="Medical Imaging Analysis,Radiology,Diagnostics,Pathology (implied by diverse modalities)"
                     data-keywords="Vision-Language Models,Medical Imaging,Model Merging,Test-Time Adaptation,Jensen-Shannon Divergence,Zero-Shot Learning,Clinical Deployment,Modality Shift"
                     data-authors="Raza Imam,Hu Wang,Dwarikanath Mahapatra,Mohammad Yaqub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27265v1.html">T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Raza Imam, Hu Wang, Dwarikanath Mahapatra et al.
                </div>

                <div class="paper-summary">
                    This paper introduces T^3 (Test-Time Task adaptive merging) and its batch-wise variant T^3_B, a novel framework designed to dynamically merge vision-language models for medical imaging analysis. By computing per-sample (or batch-wise) interpolation coefficients based on Jensen-Shannon divergence between model outputs, T^3 effectively combines the strengths of robust generalist models and precise expert models, achieving state-of-the-art accuracy and error reduction across diverse medical modalities while maintaining computational efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Pathology (implied by diverse modalities)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27265v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27265v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27265v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27265v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27247v1"
                     data-domains="Neurology,Rehabilitation Medicine,Assistive Technology,Neuroprosthetics,Speech-Language Pathology,Bioengineering"
                     data-keywords="Brain-to-speech (BTS),Neural communication,Open-vocabulary,EEG,EMG,Speech synthesis,Phoneme decoding,Rehabilitation"
                     data-authors="Deok-Seon Kim,Seo-Hyun Lee,Kang Yin,Seong-Whan Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27247v1.html">Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deok-Seon Kim, Seo-Hyun Lee, Kang Yin et al.
                </div>

                <div class="paper-summary">
                    This study explores open-vocabulary neural communication by demonstrating the feasibility of reconstructing previously unseen sentences through speech synthesis, leveraging phoneme-level information derived from high-density EEG, both independently and combined with EMG signals. It also offers neurophysiological insights to enhance EEG decoding accuracy, marking a significant step towards personalized communication and rehabilitation solutions for patients. The research aims to move beyond predefined words/sentences towards unconstrained speech decoding for neural communication.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Neuroprosthetics</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27247v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27247v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27247v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27247v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27237v1"
                     data-domains="Oncology,Pathology,Lung Cancer,Bladder Cancer,Colorectal Cancer,Digital Pathology"
                     data-keywords="Computational Pathology,Whole Slide Image (WSI),Foundation Models (FMs),Deep Learning,Feature Fusion,Cancer Diagnosis,TCGA,Heterogeneity"
                     data-authors="Zhidong Yang,Xiuhui Shi,Wei Ba,Zhigang Song,Haijing Luan,Taiyuan Hu,Senlin Lin,Jiguang Wang,Shaohua Kevin Zhou,Rui Yan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27237v1.html">Fusion of Heterogeneous Pathology Foundation Models for Whole Slide Image Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhidong Yang, Xiuhui Shi, Wei Ba et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FuseCPath, a novel framework designed to effectively fuse heterogeneous pathological foundation models (FMs) for Whole Slide Image (WSI) analysis, addressing performance variability caused by diverse training data and architectures. The framework achieves superior ensemble performance through multi-view clustering for discriminative patch selection, cluster-level re-embedding for patch-level feature fusion, and collaborative distillation for slide-level feature fusion, demonstrating state-of-the-art results on TCGA cancer datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Lung Cancer</span>
                    
                    <span class="domain-tag">Bladder Cancer</span>
                    
                    <span class="domain-tag">Colorectal Cancer</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27237v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27237v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27237v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27237v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27213v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Thoracic Imaging"
                     data-keywords="Continual Self-Supervised Learning (CSSL),Multi-Window Chest CT,Domain Shift,Privacy-Aware AI,Catastrophic Forgetting,Latent Replay,Feature Distillation,Wasserstein Distance"
                     data-authors="Ren Tasai,Guang Li,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27213v1.html">Privacy-Aware Continual Self-Supervised Learning on Multi-Window Chest Computed Tomography for Domain-Shift Robustness</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ren Tasai, Guang Li, Ren Togo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel privacy-aware continual self-supervised learning (CSSL) framework designed to build robust and generalizable AI models for multi-window chest computed tomography (CT). It addresses challenges like data scarcity, domain shifts (particularly due to varying CT window settings), and privacy concerns by integrating a latent replay-based mechanism to mitigate catastrophic forgetting and a feature distillation technique for learning domain-shift-robust representations. The framework demonstrates superior performance in learning diverse features across different CT window settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Thoracic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27213v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27213v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27213v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27213v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27197v1"
                     data-domains="Public Health,Injury Epidemiology,Preventive Medicine,Emergency Medicine,Environmental Health,Health Policy"
                     data-keywords="Traffic Risk Forecasting,Graph Neural Network (GNN),Public Health,Injury Prevention,Spatiotemporal Modeling,Multi-Dimensional Features,Urban Planning,Road Safety"
                     data-authors="Ziyuan Gao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27197v1.html">MDAS-GNN: Multi-Dimensional Spatiotemporal GNN with Spatial Diffusion for Urban Traffic Risk Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziyuan Gao
                </div>

                <div class="paper-summary">
                    MDAS-GNN addresses the critical public health challenge of urban traffic accidents by developing a novel Multi-Dimensional Spatiotemporal Graph Neural Network. This framework integrates traffic safety, infrastructure, and environmental risk dimensions with feature-specific spatial diffusion and multi-head temporal attention to accurately forecast accident risk. Evaluated on UK accident data, MDAS-GNN significantly outperforms baseline methods, providing advanced predictive capabilities crucial for urban planning and safety interventions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Injury Epidemiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27197v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27197v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27197v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27197v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27194v1"
                     data-domains="Digital Health,Medical Device Development,Healthcare Information Technology (HIT),Telemedicine Systems,Electronic Health Records (EHR) Systems,Clinical Decision Support Systems"
                     data-keywords="System of Systems (SoS),Lifecycle Management,Model-Based Systems Engineering (MBSE),Product Lifecycle Management (PLM),Digital Thread,Digital Twin,Interoperability,Healthcare Systems"
                     data-authors="Vahid Salehi,Josef Vilsmeier,Shirui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27194v1.html">From product to system network challenges in system of systems lifecycle management</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vahid Salehi, Josef Vilsmeier, Shirui Wang
                </div>

                <div class="paper-summary">
                    This paper addresses the growing challenges of managing modern networked systems (System of Systems, SoS) where traditional linear lifecycle models prove inadequate, especially concerning interoperability, configuration, and governance across organizational boundaries. It proposes a practical framework for SoS lifecycle management, integrating Model-Based Systems Engineering (MBSE) as a semantic backbone, Product Lifecycle Management (PLM) for governance, CAD-CAE for model-derived domains, and digital thread/twin for continuous feedback. The paper also identifies four guiding principles and a three-step roadmap for transitioning to network-centric development, aiming to enhance robustness, shorten throughput times, and improve reuse and sustainability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Medical Device Development</span>
                    
                    <span class="domain-tag">Healthcare Information Technology (HIT)</span>
                    
                    <span class="domain-tag">Telemedicine Systems</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27194v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27194v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27194v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27194v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27158v1"
                     data-domains="Nephrology,Transplant Pathology,Anatomic Pathology,Computational Pathology,Digital Pathology"
                     data-keywords="AI,Deep Learning,Banff Classification,Renal Transplant,Biopsy,Pathology,Computational Pathology,Inter-observer Variability"
                     data-authors="Yanfan Zhu,Juming Xiong,Ruining Deng,Yu Wang,Yaohong Wang,Shilin Zhao,Mengmeng Yin,Yuqing Liu,Haichun Yang,Yuankai Huo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27158v1.html">How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yanfan Zhu, Juming Xiong, Ruining Deng et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the current capabilities of deep learning models in computationally replicating the Banff Classification for renal transplant biopsies. By employing a modular, rule-based framework to approximate Banff lesion scores, the study reveals partial successes but also critical limitations, including structural omission, hallucination, and detection ambiguity, highlighting that current AI pipelines struggle with expert-level grading despite occasional matching final scores.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Transplant Pathology</span>
                    
                    <span class="domain-tag">Anatomic Pathology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27130v1"
                     data-domains="Pharmacology,Drug Development,Medicinal Chemistry,Toxicology,Biotechnology,Pharmaceutical Research"
                     data-keywords="AI Agents,Drug Discovery,Large Language Models (LLMs),Autonomous Systems,Robotic Platforms,Toxicity Prediction,Drug Repurposing,Closed-Loop Systems"
                     data-authors="Srijit Seal,Dinh Long Huynh,Moudather Chelbi,Sara Khosravi,Ankur Kumar,Mattson Thieme,Isaac Wilks,Mark Davies,Jessica Mustali,Yannick Sun,Nick Edwards,Daniil Boiko,Andrei Tyrin,Douglas W. Selinger,Ayaan Parikh,Rahul Vijayan,Shoman Kasbekar,Dylan Reid,Andreas Bender,Ola Spjuth">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27130v1.html">AI Agents in Drug Discovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Srijit Seal, Dinh Long Huynh, Moudather Chelbi et al.
                </div>

                <div class="paper-summary">
                    This paper provides a conceptual and technical overview of AI agents, built on LLMs and specialized tools, as transformative tools in drug discovery, capable of autonomous reasoning, action, and learning through complex research workflows. It details various agentic AI architectures and their applications across key drug discovery stages, notably highlighting real-world implementations demonstrating substantial gains in speed, reproducibility, and scalability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27130v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27130v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27130v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27130v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27097v1"
                     data-domains="Reproductive Medicine,Gynecology,Endocrinology,Computational Biology in Medicine,Pathology"
                     data-keywords="Hierarchical Bayesian model,Gene deconvolution,RNA sequencing,Human endometrium,Menstrual cycle,Cell-type specific expression,Decidualization,Fertility"
                     data-authors="Crystal Su,Kuai Yu,Mingyuan Shao,Daniel Bauer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27097v1.html">Hierarchical Bayesian Model for Gene Deconvolution and Functional Analysis in Human Endometrium Across the Menstrual Cycle</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Crystal Su, Kuai Yu, Mingyuan Shao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a probabilistic hierarchical Bayesian model designed to deconvolve bulk RNA-seq data into constituent cell-type expression profiles and proportions, leveraging a high-resolution single-cell reference. Applied to human endometrial tissue across the menstrual cycle, the model successfully reveals dynamic shifts in cellular composition and identifies cell-type-specific gene expression changes, including crucial functional markers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Reproductive Medicine</span>
                    
                    <span class="domain-tag">Gynecology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Computational Biology in Medicine</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27097v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27097v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27097v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27097v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27074v2"
                     data-domains="Neurodegenerative Diseases,Rare Genetic Disorders,Oncology,Drug Discovery,Molecular Diagnostics,Pharmacology,Pathology"
                     data-keywords="protein folding,folding pathways,protein misfolding,single-molecule force spectroscopy,hydrogen exchange,AlphaFold,energy landscape,structural biology,biophysics,molecular dynamics"
                     data-authors="Carlos Bustamante,Christian Kaiser,Erik Lindahl,Robert Sosa,Giovanni Volpe">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27074v2.html">How Do Proteins Fold?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-31</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Carlos Bustamante, Christian Kaiser, Erik Lindahl et al.
                </div>

                <div class="paper-summary">
                    This paper reviews the long-standing problem of how proteins fold, emphasizing the undefined 'folding code' and the current lack of a predictive framework for dynamic folding pathways, despite significant progress in static structure prediction. It highlights recent advancements in single-molecule experimental techniques and computational algorithms (like AlphaFold), which together are poised to finally unravel the mysteries of protein folding pathways, misfolding mechanisms, and their implications for biology and medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                    <span class="domain-tag">Rare Genetic Disorders</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Molecular Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27074v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27074v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27074v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27074v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27030v1"
                     data-domains="Immunology,Evolutionary Biology,Infectious Diseases,Computational Biology,Population Genetics"
                     data-keywords="phylogenetic trees,ranked tree shapes,heterochronous,F-matrices,bijection,rooted phylograms,B cell affinity maturation,combinatorial methods"
                     data-authors="Chris Jennings-Shaffer,Cherith Chen,Julia A Palacios,Frederick A Matsen IV">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27030v1.html">Generalizing matrix representations to fully heterochronous ranked tree shapes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chris Jennings-Shaffer, Cherith Chen, Julia A Palacios et al.
                </div>

                <div class="paper-summary">
                    This paper generalizes the **F**-matrix framework, previously applied to isochronous ranked phylogenetic tree shapes, to fully heterochronous ranked tree shapes, where leaves can have diverse sampling times. It establishes an explicit bijection between a specific class of **F**-matrices and these heterochronous tree shapes, offering a structured method for their enumeration and the development of probabilistic models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Evolutionary Biology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Population Genetics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27030v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27030v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27030v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27030v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.27003v1"
                     data-domains="Public Health,Mental Health,Social Epidemiology,Digital Health,Health Psychology"
                     data-keywords="Online communities,Social media,Toxicity,Sentiment analysis,Premier League,Mental health,Public health,Racism"
                     data-authors="Muhammad Zeeshan Mazhar,Tolga Buz,Yiran Su">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.27003v1.html">Are Online Sports Fan Communities Becoming More Offensive? A Quantitative Review of Topics, Trends, and Toxicity of r/PremierLeague</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.SI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Zeeshan Mazhar, Tolga Buz, Yiran Su
                </div>

                <div class="paper-summary">
                    This paper quantitatively analyzed over 1.1 million comments from r/PremierLeague (2013-2022) to map the evolution of its online fan community, focusing on sentiment, topics, and toxicity. The study revealed a significant expansion in discussion diversity but also a concerning rise in negative sentiment and toxicity over time. Furthermore, the subreddit has become a venue for users to voice frustrations about broader societal issues like racism, the COVID-19 pandemic, and political tensions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Social Epidemiology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Health Psychology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.27003v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.27003v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.27003v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.27003v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26996v1"
                     data-domains="Radiology,Diagnostic Imaging,Anatomy Segmentation,Oncology,Image-Guided Therapy"
                     data-keywords="Medical Image Segmentation,Mixture of Experts (MoE),Vision-Language Models,Foundation Models,CT Scans,Textual Embeddings,Deep Learning,Medical AI"
                     data-authors="Arghavan Rezvani,Xiangyi Yan,Anthony T. Wu,Kun Han,Pooya Khosravi,Xiaohui Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26996v1.html">MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Arghavan Rezvani, Xiangyi Yan, Anthony T. Wu et al.
                </div>

                <div class="paper-summary">
                    This study introduces MoME, a novel Mixture of Visual Language Medical Experts, which adapts the successful Mixture of Experts (MoE) paradigm from Large Language Models (LLMs) to medical vision-language tasks for image segmentation. MoME integrates multi-scale visual features with textual embeddings to enable dynamic expert selection, demonstrating strong and competitive precision across a comprehensive benchmark of 10 datasets comprising 3,410 CT scans.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Anatomy Segmentation</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Image-Guided Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26996v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26996v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26996v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26996v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26974v1"
                     data-domains="Clinical Informatics,Health Information Technology (Health IT),Medical Documentation,Patient Care Operations,Computational Medicine"
                     data-keywords="Medical Order Extraction,Doctor-Patient Consultations,Shared Task,Large Language Models (LLMs),Electronic Health Records (EHRs),Clinical Documentation,Natural Language Processing (NLP),MEDIQA-OE"
                     data-authors="Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26974v1.html">Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jean-Philippe Corbeil, Asma Ben Abacha, Jerome Tremblay et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the MEDIQA-OE 2025 shared task, the inaugural challenge focused on automatically extracting actionable medical orders from doctor-patient consultations for Electronic Health Records (EHRs). Addressing an unexplored area in clinical documentation, the task aims to significantly reduce clinician burden and enhance patient care. The paper overviews the task, dataset, participant solutions leveraging various LLMs, and the final leaderboard from six participating teams.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Information Technology (Health IT)</span>
                    
                    <span class="domain-tag">Medical Documentation</span>
                    
                    <span class="domain-tag">Patient Care Operations</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26974v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26974v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26974v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26974v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26969v1"
                     data-domains="Public Health,Primary Care,Epidemiology,Health Informatics,Social Medicine,Violence Prevention"
                     data-keywords="Frame Semantics,Notifiable Events,Underreporting,Gender-Based Violence,Electronic Medical Records,Natural Language Processing,Public Health,Health Surveillance"
                     data-authors="L√≠via Dutra,Arthur Lorenzi,La√≠s Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Ol√≠via Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26969v1.html">Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> L√≠via Dutra, Arthur Lorenzi, La√≠s Berno et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel methodology leveraging frame semantic patterns to identify underreported notifiable events within unstructured open-text fields of electronic medical records. Applied to the detection of gender-based violence (GBV) in Brazilian primary care data, the approach achieved a precision of 0.726, demonstrating a robust, transparent, and adaptable NLP pipeline for public health surveillance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Social Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26969v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26969v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26969v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26969v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26961v1"
                     data-domains="Neuroradiology,Neurology,Neurosurgery,Oncology,Stroke Medicine"
                     data-keywords="Brain Lesion Segmentation,Multi-modal MRI,Deep Learning,Swin Transformer,Cross-Modal Attention,White Matter Hyperintensities,Stroke,Brain Tumors"
                     data-authors="Md. Mehedi Hassan,Shafqat Alam,Shahriar Ahmed Seam,Maruf Ahmed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26961v1.html">SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md. Mehedi Hassan, Shafqat Alam, Shahriar Ahmed Seam et al.
                </div>

                <div class="paper-summary">
                    SYNAPSE-Net proposes a unified and adaptive deep learning framework to address the critical challenge of robustly segmenting heterogeneous brain lesions from multi-modal MRI, overcoming the generalization limitations of current specialized models. Leveraging a novel hybrid architecture and a variance reduction training strategy, it achieved state-of-the-art performance across diverse brain pathologies including WMH, stroke lesions, and brain tumors. This framework provides a robust and clinically feasible solution for automated lesion segmentation, demonstrating superior accuracy and generalization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Stroke Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26961v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26961v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26961v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26961v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26940v1"
                     data-domains="Public Health,Epidemiology,Health Disparities Research,Emergency Medical Services (EMS) planning,Healthcare Resource Allocation"
                     data-keywords="Mobility Prediction,Algorithmic Fairness,Group Inequity,Demographic Disparity,Incremental Sampling,Public Health,Machine Learning,Location-based Services"
                     data-authors="Ashwin Kumar,Hanyu Zhang,David A. Schweidel,William Yeoh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26940v1.html">Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ashwin Kumar, Hanyu Zhang, David A. Schweidel et al.
                </div>

                <div class="paper-summary">
                    This paper audits state-of-the-art next location prediction models, revealing significant demographic disparities in predictive performance across racial and ethnic user groups. To address this, the authors propose Fairness-Guided Incremental Sampling (FGIS), which utilizes a novel Size-Aware K-Means (SAKM) clustering method to infer proxy demographic labels, enabling the construction of fairer training datasets. Their approach reduces total inter-group disparity by up to 40% with minimal accuracy trade-offs, demonstrating the efficacy of data-centric interventions for algorithmic fairness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Disparities Research</span>
                    
                    <span class="domain-tag">Emergency Medical Services (EMS) planning</span>
                    
                    <span class="domain-tag">Healthcare Resource Allocation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26940v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26940v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26940v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26940v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26928v1"
                     data-domains="Radiation Oncology,Medical Physics,Cancer Therapy,Radiobiology"
                     data-keywords="FLASH effect,Ultra-High Dose-Rates,Hydrogen Peroxide Yields,Radiation Chemistry,Monte Carlo Simulation,Radiotherapy,Dose-Rate,Radical-Radical Interaction"
                     data-authors="Marc Benjamin Hahn">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26928v1.html">Ultra-High Dose-Rates, the FLASH Effect, and Hydrogen Peroxide Yields: Do Experiments and Simulations Really Disagree?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marc Benjamin Hahn
                </div>

                <div class="paper-summary">
                    This paper critically analyzes the discrepancies between experimental measurements and Monte-Carlo simulations of hydrogen peroxide (H2O2) yields in water irradiated at ultra-high dose-rates (UHDR), a crucial aspect of understanding the FLASH effect. It reviews recent and classical literature to identify potential reasons for these inconsistencies and proposes pathways to develop testable models for advancing FLASH radiotherapy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Cancer Therapy</span>
                    
                    <span class="domain-tag">Radiobiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26928v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26928v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26928v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26928v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26923v1"
                     data-domains="Radiology,Oncology,Medical Imaging,Diagnostic Medicine,AI in Healthcare"
                     data-keywords="Lung Nodule Detection,Curriculum Learning,Data Efficiency,Deep Learning,YOLOv11,Chest CT,Early Cancer Diagnosis,Medical Imaging AI"
                     data-authors="Yi Luo,Yike Guo,Hamed Hooshangnejad,Kai Ding">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26923v1.html">Scale-Aware Curriculum Learning for Ddata-Efficient Lung Nodule Detection with YOLOv11</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yi Luo, Yike Guo, Hamed Hooshangnejad et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Scale Adaptive Curriculum Learning (SACL), a novel dynamic training strategy for data-efficient lung nodule detection using deep learning, specifically with YOLOv11. SACL addresses the challenge of limited annotated medical data by dynamically adjusting curriculum design based on the available data scale. It achieves significant performance improvements over traditional methods in data-scarce clinical scenarios, providing a practical solution for early lung cancer diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26923v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26923v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26923v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26923v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26903v1"
                     data-domains="Orthopedics,Radiology,Endocrinology,Geriatrics,Medical Imaging"
                     data-keywords="Proximal Femur Segmentation,Domain Adaptation,Transformer Networks,Quantitative Computed Tomography (QCT),Bone Density,Osteoporosis,Deep Learning,Multi-center Studies"
                     data-authors="Rochak Dhakal,Chen Zhao,Zixin Shi,Joyce H. Keyak,Tadashi S. Kaneko,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Weihua Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26903v1.html">PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rochak Dhakal, Chen Zhao, Zixin Shi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PF-DAformer, a domain-adaptive transformer segmentation framework designed for robust proximal femur segmentation in multi-institutional Quantitative Computed Tomography (QCT) scans. It addresses the critical challenge of domain shift, where deep learning models fail when applied across different datasets, by integrating adversarial and statistical alignment strategies within a 3D TransUNet backbone. The goal is to ensure stable and reproducible bone density analyses for fracture risk assessment, regardless of variations in scanning equipment or patient demographics across institutions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26903v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26903v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26903v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26903v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26887v1"
                     data-domains="Biology,Biophysics,Biomedical Informatics,Medicine,Neuroscience"
                     data-keywords="AI multi-agent system,scientific discovery,medical research automation,biomedical informatics,deep learning,literature review automation,code generation,hypothesis generation"
                     data-authors="Francisco Villaescusa-Navarro,Boris Bolliet,Pablo Villanueva-Domingo,Adrian E. Bayer,Aidan Acquah,Chetana Amancharla,Almog Barzilay-Siegal,Pablo Bermejo,Camille Bilodeau,Pablo C√°rdenas Ram√≠rez,Miles Cranmer,Urbano L. Fran√ßa,ChangHoon Hahn,Yan-Fei Jiang,Raul Jimenez,Jun-Young Lee,Antonio Lerario,Osman Mamun,Thomas Meier,Anupam A. Ojha,Pavlos Protopapas,Shimanto Roy,David N. Spergel,Pedro Taranc√≥n-√Ålvarez,Ujjwal Tiwari,Matteo Viel,Digvijay Wadekar,Chi Wang,Bonny Y. Wang,Licong Xu,Yossi Yovel,Shuwen Yue,Wen-Han Zhou,Qiyao Zhu,Jiajun Zou,√ç√±igo Zubeldia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26887v1.html">The Denario project: Deep knowledge AI agents for scientific discovery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Francisco Villaescusa-Navarro, Boris Bolliet, Pablo Villanueva-Domingo et al.
                </div>

                <div class="paper-summary">
                    Denario is an AI multi-agent system designed to function as a comprehensive scientific research assistant, capable of tasks ranging from idea generation and literature review to code execution, data plotting, and drafting/reviewing scientific papers. It demonstrates its capabilities by generating full, expert-evaluated papers across diverse scientific disciplines, including several medical fields, showcasing its potential to accelerate scientific discovery. The system features a modular architecture, enabling both specific task execution and end-to-end deep research analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biology</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                    <span class="domain-tag">Medicine</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26887v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26887v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26887v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26887v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26783v1"
                     data-domains="Epidemiology,Clinical Trials (Observational Studies),Health Services Research,Pharmacovigilance,Public Health,Comparative Effectiveness Research"
                     data-keywords="Causal Inference,Average Treatment Effect (ATE),Riesz Regression,Density Ratio Estimation (DRE),Targeted Maximum Likelihood Estimation (TMLE),Covariate Balancing,Matching Estimator,Balancing Weights"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26783v1.html">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper proposes a unified theoretical framework for causal inference, specifically for Average Treatment Effect (ATE) estimation, by integrating diverse methodologies such as Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and matching estimators. The theory highlights the central role of 'balancing weights,' also known as Riesz representers or clever covariates, in bridging these seemingly distinct approaches and delineating their interrelationships and equivalences.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Trials (Observational Studies)</span>
                    
                    <span class="domain-tag">Health Services Research</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26783v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26783v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26759v1"
                     data-domains="Diagnostic Radiology,Medical Imaging,Anatomical Imaging,Oncology"
                     data-keywords="CT Reconstruction,Deep Learning,Medical Imaging,Multi-Organ Dataset,Generalization,Radiology,Optimization-based Methods,Lesion Detection"
                     data-authors="Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26759v1.html">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MORE (Multi-Organ Medical Image REconstruction Dataset) to address the critical limitation of current deep learning CT reconstruction methods regarding generalization to diverse anatomies and lesion types. Comprising CT scans across 9 distinct anatomies and 15 lesion types, MORE facilitates robust model training and rigorous evaluation of generalization capabilities. The authors also establish a strong baseline solution that outperforms prior approaches, demonstrating that comprehensive datasets improve generalization and optimization-based methods enhance robustness for unseen anatomies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Anatomical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26723v1"
                     data-domains="Precision medicine,Personalized therapeutics,Clinical decision support systems,Treatment recommendation,Pharmacogenomics,Public health interventions"
                     data-keywords="Policy learning,Conditional Average Treatment Effect,Causal inference,Empirical Welfare Maximization,Personalized medicine,Treatment optimization,Machine learning,Convex optimization"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26723v1.html">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper establishes an exact equivalence between two major policy learning paradigms, Empirical Welfare Maximization (EWM) and the plug-in approach based on Conditional Average Treatment Effect (CATE) estimation, through a reparameterization of the policy class. This unification reveals their interchangeability and shared theoretical guarantees, leading to the development of a novel, convex, and computationally efficient regularization method for policy learning that circumvents the NP-hard combinatorial step inherent in traditional EWM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision medicine</span>
                    
                    <span class="domain-tag">Personalized therapeutics</span>
                    
                    <span class="domain-tag">Clinical decision support systems</span>
                    
                    <span class="domain-tag">Treatment recommendation</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26723v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26723v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26715v1"
                     data-domains="Diagnostics,Prognostics,Biomarker Discovery,Precision Medicine,Metabolomics,Proteomics,Translational Research"
                     data-keywords="mass spectrometry,deep learning,foundation model,spectral identification,biological interpretation,spectral embeddings,disease diagnostics,clinical outcomes"
                     data-authors="Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26715v1.html">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Asher, Devesh Shah, Amy A. Caudy et al.
                </div>

                <div class="paper-summary">
                    LSM-MS2 is a novel large-scale deep learning foundation model trained on millions of mass spectrometry (MS) spectra to learn a semantic chemical space. It achieves state-of-the-art performance in spectral identification, significantly improving accuracy and yield, while also generating rich spectral embeddings that enable direct biological interpretation for differentiating disease states and predicting clinical outcomes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Metabolomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-04 06:33:00</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>