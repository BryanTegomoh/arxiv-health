<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">141</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (9), Medical Imaging (9), Neurology (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (9)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (9)</option>
                        
                        <option value="Neurology">Neurology (7)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Epidemiology">Epidemiology (5)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Oncology">Oncology (5)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (5)</option>
                        
                        <option value="Psychiatry">Psychiatry (4)</option>
                        
                        <option value="Mental Health">Mental Health (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.25759v1"
                     data-domains="Digital Pathology,Radiology,Histopathology,Medical Image Analysis,Computational Microscopy"
                     data-keywords="Multiple Instance Learning,Correlated Instances,Medical Imaging,Generalization Gap,Synthetic Data,Bayes Estimator,Contextual Learning,Deep Learning"
                     data-authors="Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25759v1.html">Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ethan Harvey, Dennis Johan Loevlie, Michael C. Hughes
                </div>

                <div class="paper-summary">
                    This paper investigates the limitations of Multiple Instance Learning (MIL) in medical imaging tasks where instances (e.g., image patches or slices) are contextually correlated. By designing a synthetic classification task with a known optimal Bayes estimator, the authors demonstrate that both conventional and newer correlated MIL methods exhibit significant generalization gaps, struggling to leverage essential contextual relationships even with extensive training data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computational Microscopy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25758v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Health,Digital Therapeutics,Behavioral Health"
                     data-keywords="psychological counseling,large language models (LLMs),AI agent,longitudinal therapy,dual-loop architecture,adaptive strategies,emotional understanding,mental health"
                     data-authors="He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25758v1.html">TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> He Hu, Yucheng Zhou, Chiyuan Ma et al.
                </div>

                <div class="paper-summary">
                    TheraMind introduces a novel strategic and adaptive AI agent for longitudinal psychological counseling, addressing the limitations of existing large language models (LLMs) in emotional understanding, adaptive strategies, and long-term memory across multiple sessions. Employing a dual-loop architecture, it manages both in-session dialogue tactics and cross-session therapeutic strategy, demonstrating superior performance in a high-fidelity simulation environment based on real clinical cases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25758v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25758v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25758v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25758v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25628v1"
                     data-domains="Clinical decision support,Diagnostic assistance,Treatment planning,Patient risk stratification,Medical record review"
                     data-keywords="EHR analysis,Large Language Models (LLMs),Clinical Reasoning,Medical NLP,Foundational Models,Instruction Tuning,MIMIC-IV,Decision Support"
                     data-authors="Yusheng Liao,Chaoyi Wu,Junwei Liu,Shuyang Jiang,Pengcheng Qiu,Haowen Wang,Yun Yue,Shuai Zhen,Jian Wang,Qianrui Fan,Jinjie Gu,Ya Zhang,Yanfeng Wang,Yu Wang,Weidi Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25628v1.html">EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yusheng Liao, Chaoyi Wu, Junwei Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EHR-R1, a series of reasoning-enhanced foundational language models specifically designed for electronic health record (EHR) analysis, leveraging a novel thinking-graph-driven framework to generate high-quality reasoning instruction data (EHR-Ins). Through multi-stage training, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, demonstrating significant outperformance over state-of-the-art LLMs, including GPT-4o, on a new comprehensive EHR-Bench benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                    <span class="domain-tag">Diagnostic assistance</span>
                    
                    <span class="domain-tag">Treatment planning</span>
                    
                    <span class="domain-tag">Patient risk stratification</span>
                    
                    <span class="domain-tag">Medical record review</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25628v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25628v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25628v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25588v1"
                     data-domains="Psychiatry,Mental Health,eHealth,Clinical Decision Support"
                     data-keywords="Psychiatric Diagnosis,Large Language Models (LLMs),Decision Support System,Mental Health,AI in Medicine,Standardization,Fine-tuning,Reasoning LLM"
                     data-authors="Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25588v1.html">Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eranga Bandara, Ross Gore, Atmaram Yarlagadda et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System to standardize psychiatric diagnoses, addressing the inherent subjectivity of current dialogue-based evaluations. It leverages fine-tuned LLMs on psychiatrist-patient interactions, aggregating their predictions, which are then refined by a reasoning LLM and orchestrated by novel LLM agents. Experimental results demonstrate the system's robust and highly accurate diagnostic capabilities, paving the way for next-generation AI-powered eHealth systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">eHealth</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25588v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25588v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25588v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25588v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25531v1"
                     data-domains="Rare Diseases,Neurology,Pediatrics,Clinical Trials,Pharmacology,Biostatistics"
                     data-keywords="rare diseases,longitudinal data,treatment switches,variational autoencoders,mixed-effects regression,spinal muscular atrophy,latent representations,statistical inference"
                     data-authors="Clemens Sch√§chter,Maren Hackenberg,Michelle Pfaffenlehner,F√©lix B. Tambe-Ndonfack,Thorsten Schmidt,Astrid Pechmann,Janbernd Kirschner,Jan Hasenauser,Harald Binder">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25531v1.html">Using latent representations to link disjoint longitudinal data for mixed-effects regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Clemens Sch√§chter, Maren Hackenberg, Michelle Pfaffenlehner et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel methodology to analyze the impact of treatment switches in rare diseases, particularly when longitudinal patient data are disjoint due to the use of different measurement instruments over time. It achieves this by employing variational autoencoders (VAEs) to map observations into a shared latent space, enabling mixed-effects regression on these aligned representations, and presents a new statistical testing approach for joint parameter estimation. The approach, applied to Spinal Muscular Atrophy, successfully quantifies treatment switch effects and demonstrates its utility for addressing challenges in small data settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25531v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25531v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25531v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25531v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25522v1"
                     data-domains="Radiology,Oncology,Hepatology,Medical Imaging,Surgical Planning"
                     data-keywords="Liver tumor segmentation,UNet-based architectures,ResNet,Attention mechanisms,CBAM,Multi-phase CECT,Grad-CAM,Medical image analysis"
                     data-authors="Doan-Van-Anh Ly,Thi-Thu-Hien Pham,Thanh-Hai Le">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25522v1.html">Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Doan-Van-Anh Ly, Thi-Thu-Hien Pham, Thanh-Hai Le
                </div>

                <div class="paper-summary">
                    This study comparatively evaluates UNet-based architectures for liver tumor segmentation in multi-phase Contrast-Enhanced Computed Tomography (CECT), finding that ResNet-based models, particularly ResNetUNet3+ enhanced with the Convolutional Block Attention Module (CBAM), consistently outperform newer Transformer and State-space (Mamba) backbones. The ResNetUNet3+ with CBAM achieved superior performance across multiple metrics, demonstrating robust capability for accurate lesion and healthy tissue identification and precise boundary delineation, offering a promising direction for clinical liver tumor detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25522v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25522v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25522v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25522v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25471v1"
                     data-domains="cs.AI"
                     data-keywords="cs.AI,cs.CY"
                     data-authors="Willem Fourie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25471v1.html">Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Willem Fourie
                </div>

                <div class="paper-summary">
                    In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25471v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25471v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25471v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25471v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25445v1"
                     data-domains="Safety-critical healthcare applications,Clinical decision support systems,Medical diagnostics,Treatment planning,Patient monitoring,Robotics in surgery"
                     data-keywords="Agentic AI,Symbolic AI,Neural AI,Hybrid AI,Healthcare AI,AI Ethics,AI Governance,Systematic Review"
                     data-authors="Mohamad Abou Ali,Fadi Dornaika">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25445v1.html">Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohamad Abou Ali, Fadi Dornaika
                </div>

                <div class="paper-summary">
                    This survey paper addresses the fragmented understanding of Agentic AI by proposing a novel dual-paradigm framework, categorizing systems into Symbolic/Classical and Neural/Generative lineages. It comprehensively analyzes 90 studies, detailing architectural principles, domain-specific applications (including healthcare, finance, robotics), and associated ethical challenges, ultimately advocating for intentional integration of both paradigms to build robust and trustworthy hybrid AI systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Safety-critical healthcare applications</span>
                    
                    <span class="domain-tag">Clinical decision support systems</span>
                    
                    <span class="domain-tag">Medical diagnostics</span>
                    
                    <span class="domain-tag">Treatment planning</span>
                    
                    <span class="domain-tag">Patient monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25445v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25445v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25445v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25445v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25384v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Health Support,Digital Therapeutics"
                     data-keywords="Synthetic data,Mental health AI,Cognitive Behavioral Therapy (CBT),Large Language Models (LLMs),Therapeutic dialogue generation,Privacy-preserving AI,Anxiety,Depression"
                     data-authors="Doan Nam Long Vu,Rui Tan,Lena Moench,Svenja Jule Francke,Daniel Woiwod,Florian Thomas-Odenthal,Sanna Stroth,Tilo Kircher,Christiane Hermann,Udo Dannlowski,Hamidreza Jamalabadi,Shaoxiong Ji">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25384v1.html">Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation from Questionnaires</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Doan Nam Long Vu, Rui Tan, Lena Moench et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SQPsych, an LLM-driven pipeline for generating synthetic therapist-client dialogues based on structured client profiles and psychological questionnaires, addressing the scarcity of real therapy data. Utilizing open-weight LLMs to comply with data privacy regulations, the framework simulates CBT-based conversations for conditions like anxiety and depression. The resulting fine-tuned models, SQPsychLLM, demonstrate strong performance in therapeutic skills, highlighting the potential of synthetic data for scalable and data-secure AI in mental health.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Health Support</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25384v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25384v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25384v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25384v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25347v1"
                     data-domains="Cardiology,Radiology,Preventive Medicine"
                     data-keywords="Coronary artery calcium (CAC),CT angiography (CCTA),Radiomics,Machine learning,Pseudo-labeling,Coronary artery disease (CAD),Risk stratification"
                     data-authors="Ayman Abaid,Gianpiero Guidone,Sara Alsubai,Foziyah Alquahtani,Talha Iqbal,Ruth Sharif,Hesham Elzomor,Emiliano Bianchini,Naeif Almagal,Michael G. Madden,Faisal Sharif,Ihsan Ullah">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25347v1.html">3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine Learning Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ayman Abaid, Gianpiero Guidone, Sara Alsubai et al.
                </div>

                <div class="paper-summary">
                    This study presents a radiomics-based machine learning framework for 3D CT-based coronary calcium assessment, utilizing pseudo-labeling to overcome the scarcity of expert annotations. It demonstrates that radiomics features, coupled with traditional classifiers, significantly outperform deep learning features derived from pre-trained foundation models (CT-FM, RadImageNet) for classifying zero versus non-zero coronary artery calcium in non-contrast CCTA scans, achieving 84% accuracy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25347v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25347v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25347v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25347v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25328v1"
                     data-domains="Radiation Oncology,Medical Physics,Cancer Therapy,Diagnostic Imaging"
                     data-keywords="Particle therapy,Prompt Gamma Timing (PGT),Stopping power,Analytical model,Monte-Carlo simulation,Spatiotemporal reconstruction,Dose verification,Medical physics"
                     data-authors="Julius Werner,Malte Schmidt,Francesco Pennazio,Jorge Roser,Jona Kasprzak,Veronica Ferrero,Magdalena Rafecas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25328v1.html">Analytical Model of Prompt Gamma Timing for Spatiotemporal Emission Reconstruction in Particle Therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Julius Werner, Malte Schmidt, Francesco Pennazio et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an analytical system model for Prompt Gamma Timing (PGT) to reconstruct spatiotemporal prompt-gamma emissions in particle therapy. The model significantly reduces computational time by 1500 times compared to Monte-Carlo (MC) based models, enabling faster evaluation of new detector arrangements and beam scenarios. Despite minor differences in multi-detector configurations, the analytical model maintains accuracy in stopping power estimation, proving robust for critical clinical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Cancer Therapy</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25328v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25328v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25328v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25328v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25232v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology,Medical Informatics"
                     data-keywords="psychiatric comorbidity,diagnostic dialogues,synthetic EMR,AI in psychiatry,natural language processing,medical datasets,mental health screening,clinical interview"
                     data-authors="Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25232v1.html">From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tianxi Wan, Jiaming Luo, Siyuan Chen et al.
                </div>

                <div class="paper-summary">
                    This research addresses the challenge of psychiatric comorbidity by developing a novel, clinically-grounded approach to generate a large-scale diagnostic dialogue dataset. They constructed 502 synthetic Electronic Medical Records (EMRs) for common comorbid conditions and then used a multi-agent framework, mimicking clinical interview protocols, to generate 3,000 multi-turn diagnostic dialogues, validated by psychiatrists. The resulting dataset, PsyCoTalk, is the first to support comorbidity and aims to improve diagnostic accuracy and treatment planning by enabling the development of AI models for multi-disorder psychiatric screening.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25232v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25232v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25232v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25232v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25227v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Computational Pathology"
                     data-keywords="Source-Free Domain Adaptation,Medical Image Segmentation,Deep Learning,Denoising,Patch Mixing,Pseudo-labeling,Domain Shift,Hard Sample Selection"
                     data-authors="Quang-Khai Bui-Tran,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Ba-Thinh Lam,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25227v1.html">Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain Adaptation in Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Quang-Khai Bui-Tran, Thanh-Huy Nguyen, Hoang-Thien Nguyen et al.
                </div>

                <div class="paper-summary">
                    This research introduces a novel Source-Free Domain Adaptation (SFDA) framework for medical image segmentation, designed to overcome challenges of sample difficulty and noisy supervision under domain shift, particularly relevant for privacy-sensitive medical data. The framework employs progressive adaptation through hard sample selection, denoised pseudo-label refinement, and patch mixing to align target distributions. It achieves state-of-the-art performance, demonstrating improved boundary delineation and robust segmentation across benchmark datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25227v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25227v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25227v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25227v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25199v1"
                     data-domains="Dermatology,Vascular Medicine,Cardiology,Pulmonology,Diagnostic Imaging"
                     data-keywords="AI diagnosis,multimodal AI,early detection,skin cancer,blood clots,cardiopulmonary,image processing,audio analysis,lightweight AI"
                     data-authors="Manisha More,Kavya Bhand,Kaustubh Mukdam,Kavya Sharma,Manas Kawtikwar,Hridayansh Kaware,Prajwal Kavhar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25199v1.html">AI-Powered Early Detection of Critical Diseases using Image Processing and Audio Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manisha More, Kavya Bhand, Kaustubh Mukdam et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a multimodal AI diagnostic framework that integrates image analysis, thermal imaging, and audio signal processing for the early detection of skin cancer, vascular blood clots, and cardiopulmonary abnormalities. The system employs specialized AI models‚ÄîMobileNetV2 for skin lesions, SVM for thermal clot detection, and Random Forest for cardiopulmonary sounds‚Äîachieving competitive accuracies. The proposed framework demonstrates potential as a lightweight, deployable solution for accessible AI-based pre-diagnostic healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Vascular Medicine</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25199v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25199v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25199v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25199v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25184v1"
                     data-domains="telemedicine,e-health,medical education,patient safety,health informatics,remote patient monitoring"
                     data-keywords="face verification,online learning,YOLOv5,residual network,deep learning,mask-robust,identity authentication,telemedicine security"
                     data-authors="Zhifeng Wang,Minghui Wang,Chunyan Zeng,Jialong Yao,Yang Yang,Hongmin Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25184v1.html">Mask-Robust Face Verification for Online Learning via YOLOv5 and Residual Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhifeng Wang, Minghui Wang, Chunyan Zeng et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a mask-robust face verification system for online learning environments, leveraging YOLOv5 for real-time face detection and a residual network for deep feature extraction. The system aims to enhance the security and stability of online education by accurately authenticating student identities even when masks are present, using Euclidean distance comparison against a student face database.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">telemedicine</span>
                    
                    <span class="domain-tag">e-health</span>
                    
                    <span class="domain-tag">medical education</span>
                    
                    <span class="domain-tag">patient safety</span>
                    
                    <span class="domain-tag">health informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25184v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25184v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25184v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25184v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25164v1"
                     data-domains="Radiology,Neuroradiology,Medical Imaging,Clinical Reporting,Neurology"
                     data-keywords="Medical Image Captioning,Transformers,MRI,Vision-Language Alignment,Deep Learning,DEiT,MediCareBERT,MultiCaRe dataset,Radiology"
                     data-authors="Yogesh Thakku Suresh,Vishwajeet Shivaji Hogale,Luca-Alexandru Zamfira,Anandavardhana Hegde">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25164v1.html">Transformers in Medicine: Improving Vision-Language Alignment for Medical Image Captioning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yogesh Thakku Suresh, Vishwajeet Shivaji Hogale, Luca-Alexandru Zamfira et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a transformer-based multimodal framework designed to generate clinically relevant captions for MRI scans, integrating a DEiT-Small vision transformer, MediCareBERT, and an LSTM decoder. The system is engineered to semantically align image and textual embeddings using a hybrid cosine-MSE loss and contrastive inference. Benchmarking on the MultiCaRe dataset demonstrates that focusing on domain-specific data, specifically brain-only MRIs, significantly improves caption accuracy and semantic alignment compared to general MRI images.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Reporting</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25164v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25164v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25164v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25164v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25157v1"
                     data-domains="Ophthalmology,Diagnostic Imaging,Optometry,Ocular Surface Disease"
                     data-keywords="vision transformer,thin film interferometry,tear film thickness,real-time inference,dry eye disease,ophthalmology,medical imaging,phase unwrapping"
                     data-authors="Gautam A. Viruthagiri,Arnuv Tandon,Gerald G. Fuller,Vinny Chandran Suja">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25157v1.html">Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gautam A. Viruthagiri, Arnuv Tandon, Gerald G. Fuller et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a vision transformer-based approach for real-time inference of thin liquid film thickness profiles directly from interference patterns, addressing the computational and noise sensitivity issues of traditional methods. Trained on a hybrid dataset of synthetic and experimental tear film data, the model leverages long-range spatial correlations to resolve phase ambiguities and reconstruct temporally coherent profiles in a single pass. It demonstrates state-of-the-art performance on noisy, rapidly-evolving films, enabling automated, consistent thickness reconstruction at real-time speeds for clinical applications like dry eye disease diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Optometry</span>
                    
                    <span class="domain-tag">Ocular Surface Disease</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25157v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25157v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25157v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25157v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25128v1"
                     data-domains="Epidemiology,Clinical trials (observational),Pharmacovigilance,Personalized medicine,Public health research"
                     data-keywords="Causal inference,Data augmentation,Instrumental variables,Confounding bias,Treatment effect estimation,Generalization,Interventions,Machine learning"
                     data-authors="Uzair Akbar,Niki Kilbertus,Hao Shen,Krikamol Muandet,Bo Dai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25128v1.html">An Analysis of Causal Effect Estimation using Outcome Invariant Data Augmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Uzair Akbar, Niki Kilbertus, Hao Shen et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel framework where outcome-invariant data augmentation (DA) is utilized to improve causal effect estimation and generalization across interventions, moving beyond its traditional role in i.i.d. settings. The authors argue that such DA can be conceptualized as interventions on the treatment generating mechanism, effectively helping to reduce bias from hidden confounders, similar to instrumental variables (IVs). They introduce IV-like (IVL) regression, which regularizes IV-based estimators, and show that a compositional, worst-case application of parameterized DA within this framework can significantly enhance performance in causal estimation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical trials (observational)</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Public health research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25128v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25128v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25128v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25128v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25085v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Control,Biostatistics,Health Policy Planning"
                     data-keywords="Epidemiological modeling,SIR model,Disease dynamics,Population migration,Public health interventions,Differential equations,Cure dynamics,Network epidemiology"
                     data-authors="Daniel Perkins,Davis Hunter,Drake Brown,Trevor Garrity,Wyatt Pochman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25085v1.html">Explorations of Epidemiological Dynamics across Multiple Population Hubs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Perkins, Davis Hunter, Drake Brown et al.
                </div>

                <div class="paper-summary">
                    This paper extends the classical SIR model to include complexities like a cure and inter-city migration, using a system of differential equations to simulate disease transmission across networked populations. It presents theoretical findings on population convergence in migration frameworks (without deaths) and numerical results on how cure timing affects mortality rates and how localized interventions impact disease spread across cities. The work offers a more expressive tool for epidemiological research and public health planning by modeling epidemics at a local scope.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Control</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Health Policy Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25085v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25085v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25085v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25085v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25051v1"
                     data-domains="Oncology,Radiology,Medical Imaging,Public Health Screening"
                     data-keywords="breast cancer,vision-language models,mammography,CAD systems,multi-modal deep learning,convolutional neural networks,early detection,clinical deployment"
                     data-authors="Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25051v1.html">Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi et al.
                </div>

                <div class="paper-summary">
                    This study introduces a novel Vision-Language Model (VLM) framework for breast cancer detection that synergistically combines visual features from 2D mammograms with structured textual descriptors from clinical metadata and synthesized reports. By integrating ConvNets with language representations, the proposed multi-modal approach achieves superior performance in cancer detection and calcification identification compared to unimodal and vision transformer baselines, enabling practical clinical deployment across diverse populations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Public Health Screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25051v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25051v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25051v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25051v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25037v1"
                     data-domains="Epidemiology,Precision Medicine,Pharmacogenomics,Public Health,Clinical Trial Design,Drug Discovery"
                     data-keywords="Causal discovery,Graph distance,Acyclic Directed Mixed Graphs (ADMGs),Latent confounding,Cause-effect estimands,Identification via fixing,Symbolic verifier,Causal inference"
                     data-authors="Zhufeng Li,Niki Kilbertus">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25037v1.html">Graph Distance Based on Cause-Effect Estimands with Latents</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhufeng Li, Niki Kilbertus
                </div>

                <div class="paper-summary">
                    This paper introduces a novel graph distance measure for Acyclic Directed Mixed Graphs (ADMGs) designed to evaluate causal discovery methods, especially in the presence of latent confounding. The measure quantifies how differences between causal graphs distort cause-effect estimands using identification via fixing and a symbolic verifier, offering a more robust evaluation tool than existing metrics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25037v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25037v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25037v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25037v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25026v1"
                     data-domains="Radiology,Oncology,Neurology,Medical Imaging,Clinical Decision Support Systems"
                     data-keywords="Radiomics,Machine Learning,Robustness,Distribution Shift,MRI,XGBoost,Feature Selection,Uncertainty Quantification,Phantom Study,Calibration"
                     data-authors="Sarmad Ahmad Khan,Simon Bernatz,Zahra Moslehi,Florian Buettner">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25026v1.html">Machine Learning based Analysis for Radiomics Features Robustness in Real-World Deployment Scenarios</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sarmad Ahmad Khan, Simon Bernatz, Zahra Moslehi et al.
                </div>

                <div class="paper-summary">
                    This study systematically investigates the robustness of radiomics-based machine learning models against distribution shifts caused by variations in MRI protocols, segmentation, and inter-observer variability. Using a fruit phantom, it demonstrates that models trained on protocol-invariant features maintain high performance, while dataset augmentation significantly improves uncertainty calibration. The findings establish a framework for developing robust radiomics models for real-world clinical deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25026v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25026v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25026v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25026v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25007v1"
                     data-domains="Healthcare Administration,Medical Billing and Coding,Clinical Documentation Improvement,Revenue Cycle Management"
                     data-keywords="CPT E/M Coding,Large Language Models (LLM),Medical Billing,Healthcare Automation,Clinical Documentation,Coding Accuracy,Physician Burden,ProFees"
                     data-authors="Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25007v1.html">Taming the Real-world Complexities in CPT E/M Coding with Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Islam Nassar, Yang Lin, Yuan Jin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ProFees, an LLM-based framework designed to automate Current Procedural Terminology (CPT) Evaluation and Management (E/M) coding, a complex task critical for medical billing. ProFees aims to tackle the real-world complexities inherent in E/M coding, significantly reducing physicians' documentation burden and improving billing accuracy. The framework demonstrates substantial improvements in coding accuracy on a real-world dataset compared to existing solutions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Administration</span>
                    
                    <span class="domain-tag">Medical Billing and Coding</span>
                    
                    <span class="domain-tag">Clinical Documentation Improvement</span>
                    
                    <span class="domain-tag">Revenue Cycle Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25007v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25007v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25007v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25007v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24986v1"
                     data-domains="Neurology,Epileptology,Clinical Neurophysiology,Biomedical Engineering"
                     data-keywords="Epilepsy,Seizure Detection,Seizure Prediction,EEG,Machine Learning,Deep Learning,LSTM,Clinical Validation"
                     data-authors="Ria Jayanti,Tanish Jain">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24986v1.html">Epileptic Seizure Detection and Prediction from EEG Data: A Machine Learning Approach with Clinical Validation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ria Jayanti, Tanish Jain
                </div>

                <div class="paper-summary">
                    This study proposes a novel machine learning approach that integrates real-time seizure detection and proactive prediction from EEG data, moving beyond traditional reactive seizure management. Utilizing the CHB-MIT Scalp EEG Database, Logistic Regression achieved 90.9% detection accuracy and 89.6% recall, while an LSTM deep learning model demonstrated 89.26% accuracy for seizure prediction, highlighting the potential for early intervention.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Epileptology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24986v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24986v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24986v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24986v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24980v1"
                     data-domains="Dermatology,Wound Care,Geriatrics,Nursing,Critical Care,Medical Imaging"
                     data-keywords="Pressure Ulcer,Severity Classification,Multimodal Language Model,Agentic Reflection,Explainable AI,Medical Imaging,Wound Assessment,Deep Learning"
                     data-authors="Reza Saadati Fard,Emmanuel Agu,Palawat Busaranuvong,Deepak Kumar,Shefalika Gautam,Bengisu Tulu,Diane Strong,Lorraine Loretz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24980v1.html">FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Reza Saadati Fard, Emmanuel Agu, Palawat Busaranuvong et al.
                </div>

                <div class="paper-summary">
                    FT-ARM introduces a fine-tuned multimodal large language model (MLLM) with an agentic self-reflection mechanism for accurate and interpretable pressure ulcer (PU) severity classification (Stages I-IV). It achieved 85% accuracy, outperforming prior CNN models by 4%, and is designed for live inference while providing clinically grounded natural-language explanations, addressing the critical need for consistent and explainable automated wound assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Wound Care</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Nursing</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24980v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24980v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24980v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24980v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24976v1"
                     data-domains="cs.CR"
                     data-keywords="cs.CR,cs.AI"
                     data-authors="Banafsheh Saber Latibari,Najmeh Nazari,Hossein Sayadi,Houman Homayoun,Abhijit Mahalanobis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24976v1.html">Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Banafsheh Saber Latibari, Najmeh Nazari, Hossein Sayadi et al.
                </div>

                <div class="paper-summary">
                    Vision Transformers (ViTs) have emerged as powerful architectures in medical
image analysis, excelling in tasks such as disease detection, segmentation, and
classification. However, their reliance on large, attention-driven models makes
them vulnerable to hardware-level attacks. In this paper, we pr...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CR</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24976v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24976v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24976v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24976v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24955v1"
                     data-domains="Epidemiology,Public Health,Infectious Diseases,Global Health,Vector-Borne Diseases,Zoonoses,Biosecurity"
                     data-keywords="geohabnet,habitat connectivity,species dispersal,network analysis,biosecurity,epidemiology,vector-borne diseases,public health surveillance"
                     data-authors="Aaron I. Plex Sul√°,Krishna Keshav,Ashish Adhikari,Romaric A. Mouafo-Tchinda,Jacobo Robledo,Stavan Nikhilchandra Shah,Karen A. Garrett">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24955v1.html">geohabnet: An R package for mapping habitat connectivity for biosecurity and conservation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aaron I. Plex Sul√°, Krishna Keshav, Ashish Adhikari et al.
                </div>

                <div class="paper-summary">
                    The `geohabnet` R package is introduced as a novel tool for mapping habitat connectivity, which moves beyond traditional habitat quality assessments to evaluate the potential importance of geographic locations for species spread. It employs a network framework that incorporates dispersal probabilities and habitat availability, offering a reproducible and scalable approach to support biosecurity, invasion science, and conservation efforts for host-dependent species like pathogens and arthropod pests.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Vector-Borne Diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24955v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24955v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24955v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24955v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24936v1"
                     data-domains="Remote Patient Monitoring,Geriatric Care,Rehabilitation Assessment,Ambient Assisted Living,Fall Detection,Sleep Monitoring"
                     data-keywords="Wi-Fi Sensing,Human Activity Recognition,Hybrid Architecture,Inception-BiLSTM,Support Vector Machine (SVM),Overfitting Mitigation,Model Generalization,Doppler-derived Data"
                     data-authors="Alison M. Fernandes,Hermes I. Del Monego,Bruno S. Chang,Anelise Munaretto,H√©lder M. Fontes,Rui L. Campos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24936v1.html">IBIS: A Powerful Hybrid Architecture for Human Activity Recognition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alison M. Fernandes, Hermes I. Del Monego, Bruno S. Chang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces IBIS, a novel hybrid architecture integrating Inception-BiLSTM with a Support Vector Machine (SVM), specifically designed to overcome the pervasive problem of overfitting in Wi-Fi sensing for Human Activity Recognition (HAR). By applying this robust approach to Doppler-derived data, IBIS achieves nearly 99% accuracy in movement recognition, demonstrating significantly improved model generalization and robust classification boundaries. The solution offers a low-cost, non-intrusive method with high potential for applications in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Geriatric Care</span>
                    
                    <span class="domain-tag">Rehabilitation Assessment</span>
                    
                    <span class="domain-tag">Ambient Assisted Living</span>
                    
                    <span class="domain-tag">Fall Detection</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24936v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24936v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24936v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24936v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24889v1"
                     data-domains="Neurology,Emergency Medicine,Diagnostic Imaging (indirectly),Critical Care"
                     data-keywords="EEG,Stroke Diagnosis,Deep Learning,GRU-TCN,Deep Q-Network,Adaptive Thresholding,Machine Learning,Triage"
                     data-authors="Shakeel Abdulkareem,Bora Yimenicioglu,Andrea Yang,Khartik Uppalapati,Aneesh Gudipati,Zhaoyang Fan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24889v1.html">Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep Q-learning thresholding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shakeel Abdulkareem, Bora Yimenicioglu, Andrea Yang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an adaptive multitask EEG-based classifier for rapid stroke diagnosis, utilizing a GRU-TCN neural network to predict stroke type, lateralization, and severity from EEG signals. A key innovation is the integration of a deep Q-network (DQN) that adaptively tunes decision thresholds in real-time, significantly improving stroke-type diagnostic accuracy. The system aims to provide accurate, bedside-deployable tools for early stroke triage.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging (indirectly)</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24889v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24889v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24889v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24889v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24703v1"
                     data-domains="Radiation Oncology,Medical Physics,Cancer Therapy"
                     data-keywords="Carbon Ion Therapy,Cluster Dose,U-Net,Transfer Learning,Dose Prediction,Monte Carlo Simulation,Machine Learning,Radiation Oncology"
                     data-authors="Miriam Schwarze,Hui Khee Looe,Bj√∂rn Poppe,Leo Thomas,Hans Rabus">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24703v1.html">Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning from a Pretrained Dose Prediction U-Net</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Miriam Schwarze, Hui Khee Looe, Bj√∂rn Poppe et al.
                </div>

                <div class="paper-summary">
                    This study demonstrates a novel approach for predicting cluster dose distributions in carbon ion therapy using a U-Net neural network. By employing transfer learning from a U-Net pretrained on conventional dose distributions, the method accurately estimates cluster doses for single pencil beams in milliseconds, addressing the computational intensity of current Monte Carlo simulations. This proof-of-principle work shows the feasibility of accelerating cluster dose estimation with machine learning, significantly reducing reliance on extensive, costly training data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Cancer Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24703v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24703v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24703v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24703v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24677v1"
                     data-domains="medical question answering,clinical decision support,medical education simulation"
                     data-keywords="medical LLMs,role cognition,prompt engineering,neuron ablation,reasoning pathways,medical decision support,cognitive differentiation,linguistic imitation"
                     data-authors="Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24677v1.html">Dissecting Role Cognition in Medical LLMs via Neuronal Ablation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xun Liang, Huayi Lai, Hanyu Wang et al.
                </div>

                <div class="paper-summary">
                    This study introduces the RP-Neuron-Activated Evaluation Framework (RPNA) to investigate whether role prompts in medical LLMs induce distinct, role-specific cognitive processes or merely alter linguistic style. Employing neuron ablation and representation analysis on medical QA datasets, the research found that role prompts do not significantly enhance reasoning abilities but primarily affect surface-level linguistic features, indicating no genuine cognitive differentiation across simulated clinical roles.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">medical question answering</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                    <span class="domain-tag">medical education simulation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24677v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24677v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24677v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24677v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24670v2"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Discovery,Structural Biology,Pharmaceutical Development,Computational Biology"
                     data-keywords="protein-ligand cofolding,drug discovery,foundation model,deep learning,SO(3)-equivariant diffusion,structural prediction,synthetic data,RMSD"
                     data-authors="Genesis Research Team,Alejandro Dobles,Nina Jovic,Kenneth Leidal,Pranav Murugan,David C. Williams,Drausin Wulsin,Nate Gruver,Christina X. Ji,Korrawat Pruegsanusak,Gianluca Scarpellini,Ansh Sharma,Wojciech Swiderski,Andrea Bootsma,Richard Strong Bowen,Charlotte Chen,Jamin Chen,Marc Andr√© D√§mgen,Benjamin DiFrancesco,J. D. Fishman,Alla Ivanova,Zach Kagin,David Li-Bland,Zuli Liu,Igor Morozov,Jeffrey Ouyang-Zhang,Frank C. Pickard IV,Kushal S. Shah,Ben Shor,Gabriel Monteiro da Silva,Roy Tal,Maxx Tessmer,Carl Tilbury,Cyr Vetcher,Daniel Zeng,Maruan Al-Shedivat,Aleksandra Faust,Evan N. Feinberg,Michael V. LeVine,Matteus Pan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24670v2.html">Pearl: A Foundation Model for Placing Every Atom in the Right Location</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Genesis Research Team, Alejandro Dobles, Nina Jovic et al.
                </div>

                <div class="paper-summary">
                    Pearl is a novel foundation model designed to accurately predict the three-dimensional structures of protein-ligand complexes, a critical challenge in drug discovery. It achieves state-of-the-art performance by leveraging large-scale synthetic data, SO(3)-equivariant diffusion architectures, and controllable inference mechanisms. Pearl significantly surpasses existing models, including AlphaFold 3, across various benchmarks, promising to accelerate therapeutic design.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmaceutical Development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24670v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24670v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24670v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24670v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24654v1"
                     data-domains="General Diagnostics,Clinical Decision Support Systems,Medical Education (for training simulations),Precision Medicine (for tailored diagnostic pathways)"
                     data-keywords="Large Language Models,Reinforcement Learning,Medical Diagnosis,Virtual Clinical Environment,Diagnostic Agents,Electronic Health Records,Adaptive Examination Selection,Clinical Decision Support"
                     data-authors="Pengcheng Qiu,Chaoyi Wu,Junwei Liu,Qiaoyu Zheng,Yusheng Liao,Haowen Wang,Yun Yue,Qianrui Fan,Shuai Zhen,Jian Wang,Jinjie Gu,Yanfeng Wang,Ya Zhang,Weidi Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24654v1.html">Evolving Diagnostic Agents in a Virtual Clinical Environment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pengcheng Qiu, Chaoyi Wu, Junwei Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DiagAgent, a novel large language model trained with reinforcement learning in DiagGym, a virtual clinical environment that simulates multi-turn diagnostic processes using electronic health records. DiagAgent learns to adaptively select examinations and commit to final diagnoses, demonstrating significant performance improvements over state-of-the-art LLMs in diagnostic accuracy and examination recommendation efficiency across various diagnostic settings. The research highlights that interactive learning in clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Diagnostics</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Education (for training simulations)</span>
                    
                    <span class="domain-tag">Precision Medicine (for tailored diagnostic pathways)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24654v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24654v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24654v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24654v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24653v1"
                     data-domains="Anatomic Pathology,Digital Pathology,Oncology,Diagnostic Medicine,Medical Education"
                     data-keywords="Digital pathology,Eye-tracking,Mouse tracking,Whole-slide imaging,Diagnostic errors,Behavioral data,AI in medicine,Cancer diagnosis"
                     data-authors="Veronica Thai,Rui Li,Meng Ling,Shuning Jiang,Jeremy Wolfe,Raghu Machiraju,Yan Hu,Zaibo Li,Anil Parwani,Jian Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24653v1.html">Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Veronica Thai, Rui Li, Meng Ling et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual search and decision-making processes of pathologists during digital cancer diagnosis. It addresses the significant gap in behavioral data needed to understand diagnostic errors and inconsistencies, which contribute to the average 70% accuracy rate in pathology. The dataset aims to facilitate research into human diagnostic cognition and improve the training of both pathologists and AI diagnostic systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Anatomic Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24653v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24653v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24653v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24653v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24602v1"
                     data-domains="Infectious Disease (Vaccinology, Antimicrobial Resistance),Oncology (Cancer Evolution, Therapeutic Resistance),Epidemiology,Public Health"
                     data-keywords="Evolutionary generalization,Population heterogeneity,Drug resistance,Vaccination strategies,Implicit regularization,Demographic noise,Generalist solutions,Evolutionary dynamics"
                     data-authors="Federica Ferretti,Mehran Kardar,Arvind Murugan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24602v1.html">Learning to generalize in evolution through annealed population heterogeneity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Federica Ferretti, Mehran Kardar, Arvind Murugan
                </div>

                <div class="paper-summary">
                    This paper demonstrates that "annealed population heterogeneity" (APH), where individuals experience varied environmental conditions over time, acts as an implicit regularization mechanism to facilitate evolutionary generalization. Mathematically, APH introduces a variance-weighted demographic noise term that penalizes across-environment fitness variance, biasing evolution towards generalist solutions, analogous to mini-batching in stochastic gradient descent. Through numerical simulations and theoretical analysis, the authors discuss the conditions under which this process promotes evolutionary strategies that generalize across environments and anticipate future challenges.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease (Vaccinology, Antimicrobial Resistance)</span>
                    
                    <span class="domain-tag">Oncology (Cancer Evolution, Therapeutic Resistance)</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24602v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24602v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24602v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24602v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24551v1"
                     data-domains="Clinical Note Synthesis,Medical Imaging Analysis,Electronic Health Records (EHR),Genomics,Diagnosis,Personalized Medicine,Decision Support"
                     data-keywords="Generative AI,Healthcare AI,Medical Data Ecosystem,Data-Centric Paradigm,Large Language Models (LLMs),Multimodal Medical Data,Clinical Decision Support,Knowledge Retrieval"
                     data-authors="Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24551v1.html">Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gang Chen, Changshuo Liu, Gene Anne Ooi et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a data-centric paradigm for the design and deployment of Generative AI (GenAI) systems in healthcare. It establishes a foundational medical data ecosystem to sustainably integrate, represent, and retrieve diverse medical data and knowledge, thereby enabling GenAI models for tasks like clinical note synthesis, diagnosis, and personalized treatments. The ultimate goal is to reduce clinician cognitive burden and improve overall healthcare delivery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Note Synthesis</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR)</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24551v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24551v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24551v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24551v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24503v1"
                     data-domains="Digital Health,Medical Imaging,Clinical Decision Support Systems,Personalized Medicine,Genomics,Public Health Informatics"
                     data-keywords="Federated Learning,Personalized Federated Learning,Out-of-Distribution Generalization,Heterogeneous Data,Client Drift,FedAvg,FLIU,Adaptive Personalization"
                     data-authors="Mortesa Hussaini,Jan Thei√ü,Anthony Stein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24503v1.html">Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mortesa Hussaini, Jan Thei√ü, Anthony Stein
                </div>

                <div class="paper-summary">
                    This paper addresses the critical trade-off in Federated Learning between optimizing local model performance and ensuring out-of-distribution (OOD) generalization, especially in heterogeneous data environments. It proposes Federated Learning with Individualized Updates (FLIU), an extension of FedAvg featuring an adaptive personalization factor, and thoroughly evaluates various FL approaches on both local performance and OOD generalization across diverse data heterogeneity levels. The study aims to provide a nuanced understanding of FL model behavior by examining performance at different stages within communication rounds.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24503v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24503v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24503v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24503v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24500v1"
                     data-domains="Critical Care Medicine,Sepsis Management,Intensive Care Units,Infectious Diseases,Clinical Informatics,Machine Learning in Medicine"
                     data-keywords="sepsis,ICU,MIMIC-IV,benchmark,machine learning,critical care,mortality prediction,treatment variables"
                     data-authors="Yong Huang,Zhongqi Yang,Amir Rahmani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24500v1.html">MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yong Huang, Zhongqi Yang, Amir Rahmani
                </div>

                <div class="paper-summary">
                    MIMIC-Sepsis introduces a new, curated benchmark dataset and framework derived from MIMIC-IV, designed for reproducible modeling of sepsis trajectories in the ICU. It addresses limitations of outdated datasets and limited clinical intervention coverage in prior research. A key finding is that incorporating standardized treatment variables significantly improves the performance of predictive models, particularly Transformer-based architectures, across various sepsis-related tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Sepsis Management</span>
                    
                    <span class="domain-tag">Intensive Care Units</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24500v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24500v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24500v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24500v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24473v1"
                     data-domains="Oncology,Gastroenterology,Public Health,Biostatistics,Clinical Decision Support"
                     data-keywords="survival analysis,machine learning,colorectal cancer,prognosis,XGBoost-AFT,C-Index,SHAP,censored data"
                     data-authors="Lucas Buk Cardoso,Simone Aldrey Angelo,Yasmin Pacheco Gil Bonilha,Fernando Maia,Adeylson Guimar√£es Ribeiro,Maria Paula Curado,Gisele Aparecida Fernandes,Vanderlei Cunha Parro,Fl√°vio Almeida de Magalh√£es Cipparrone,Alexandre Dias Porto Chiavegatto Filho,Tatiana Natasha Toporcov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24473v1.html">Methodology for Comparing Machine Learning Algorithms for Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lucas Buk Cardoso, Simone Aldrey Angelo, Yasmin Pacheco Gil Bonilha et al.
                </div>

                <div class="paper-summary">
                    This study presents a comprehensive comparative methodological analysis of six machine learning models tailored for survival analysis (MLSA) using a large dataset of nearly 45,000 colorectal cancer patients. It evaluates their performance in predicting patient survival, particularly focusing on handling censored data, and provides insights into model interpretability. The findings demonstrate the superior performance of XGBoost-AFT, highlighting the significant potential of MLSA to enhance survival prediction and aid clinical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24473v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24473v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24473v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24473v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24438v1"
                     data-domains="Clinical Decision Support,Patient Education,Medical Research Synthesis,Telemedicine,Public Health Information,Medical Ethics,Pharmacovigilance"
                     data-keywords="Large Language Models,AI Evaluation,Fidelity,High-Stakes Domains,Medical AI,Content Generation,Reliability,Benchmarks"
                     data-authors="Abdullah Mushtaq,Rafay Naeem,Ezieddin Elmahjub,Ibrahim Ghaznavi,Shawqi Al-Maliki,Mohamed Abdallah,Ala Al-Fuqaha,Junaid Qadir">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24438v1.html">Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.65</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abdullah Mushtaq, Rafay Naeem, Ezieddin Elmahjub et al.
                </div>

                <div class="paper-summary">
                    This research evaluates the faithfulness and accuracy of Large Language Models (LLMs) (GPT-4o, Ansari AI, Fanar) in generating Islamic content, using a novel dual-agent evaluation framework. It found that while GPT-4o performed best quantitatively, and Ansari AI qualitatively, all models still fall short in reliably producing accurate and cited faith-sensitive content. The study highlights the critical need for robust, community-driven benchmarks for LLM content, especially in high-stakes domains like medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Medical Research Synthesis</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Public Health Information</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24438v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24438v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24438v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24438v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24398v1"
                     data-domains="Neurology,Neuroradiology,Medical Imaging,Stroke Rehabilitation,Biomarkers"
                     data-keywords="Post-stroke MRI,Brain abnormalities,Unsupervised learning,Generative model,REFLECT,Focal lesions,Non-lesional abnormalities,Imaging biomarkers,Stroke outcome,Atrophy"
                     data-authors="Youwan Mah√©,Elise Bannier,St√©phanie Leplaideur,Elisa Fromont,Francesca Galassi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24398v1.html">Unsupervised Detection of Post-Stroke Brain Abnormalities</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Youwan Mah√©, Elise Bannier, St√©phanie Leplaideur et al.
                </div>

                <div class="paper-summary">
                    This paper introduces REFLECT, a flow-based generative model, for the unsupervised detection of both focal lesions and non-lesional post-stroke brain abnormalities like atrophy and ventricular enlargement. The study demonstrates that training the model on healthy control data significantly outperforms training on lesion-free stroke patient data, achieving improved segmentation of lesions and higher sensitivity to secondary structural changes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Stroke Rehabilitation</span>
                    
                    <span class="domain-tag">Biomarkers</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24398v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24398v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24398v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24398v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24385v2"
                     data-domains="Radiology,Medical Imaging,Clinical Decision Support,Healthcare AI"
                     data-keywords="Radiology Reports,Medical Image Classification,Machine Learning,Pre-training,Fine-tuning,Image-Text Alignment,Diagnostic Tasks,Prognostic Tasks"
                     data-authors="Herman Bergstr√∂m,Zhongqi Yue,Fredrik D. Johansson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24385v2.html">When are radiology reports useful for training medical image classifiers?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Herman Bergstr√∂m, Zhongqi Yue, Fredrik D. Johansson
                </div>

                <div class="paper-summary">
                    This paper systematically investigates the utility of integrating radiology reports during both pre-training and fine-tuning phases for medical image classifiers, across diverse diagnostic and prognostic tasks. It reveals that while pre-training with reports benefits tasks where labels are explicit in text, fine-tuning with reports consistently yields significant improvements, often having a greater impact than the pre-training strategy itself. The findings provide actionable insights into optimizing the leverage of privileged text data in medical AI development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24385v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24385v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24385v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24385v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24380v1"
                     data-domains="Drug Discovery,Medicinal Chemistry,Pharmacology,Target Identification"
                     data-keywords="Combinatorial Synthesis Libraries,Virtual Screening,Drug Discovery,Neural Network Surrogate,Docking Score Optimization,High-Throughput Screening,Molecular Design,Computational Chemistry"
                     data-authors="Aryan Pedawi,Jordi Silvestre-Ryan,Bradley Worley,Darren J Hsu,Kushal S Shah,Elias Stehle,Jingrong Zhang,Izhar Wallach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24380v1.html">APEX: Approximate-but-exhaustive search for ultra-large combinatorial synthesis libraries</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aryan Pedawi, Jordi Silvestre-Ryan, Bradley Worley et al.
                </div>

                <div class="paper-summary">
                    This paper introduces APEX, an approximate-but-exhaustive search protocol designed to overcome the challenges of virtual screening in ultra-large make-on-demand combinatorial synthesis libraries (CSLs). APEX utilizes a neural network surrogate that exploits CSL structure to predict objectives and constraints, enabling full library enumeration on a GPU in under a minute. This approach allows for efficient and accurate retrieval of approximate top-$k$ compounds, significantly outperforming existing virtual screening methods in both accuracy and speed.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Target Identification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24380v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24380v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24380v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24380v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24379v1"
                     data-domains="Tissue Pathology,Medical Imaging,Diagnostic Imaging,Histopathology"
                     data-keywords="Polarization image fusion,Multi-scale network,Luminance-aware,Tissue pathology,Deep learning,Image processing,S0,DOLP"
                     data-authors="Zhuangfan Huang,Xiaosong Li,Gao Wang,Tao Ye,Haishu Tan,Huafeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24379v1.html">A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhuangfan Huang, Xiaosong Li, Gao Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Luminance-aware Multi-Scale Network (MLSN) for polarization image fusion, effectively combining S0 and DOLP images to reveal detailed surface roughness and material properties. The network innovatively addresses challenges like complex luminance environments and inherent contrast differences through specialized encoder, bottleneck, and decoder modules. Alongside a new diverse multi-scene polarization dataset (MSP), MLSN achieves state-of-the-art performance, with significant implications for applications such as tissue pathology analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Tissue Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24379v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24379v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24379v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24379v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24378v1"
                     data-domains="Neurology,Radiology,Neuroimaging,Stroke research,Medical informatics"
                     data-keywords="Stroke lesion segmentation,Deep learning,Clinical deployment,ONNX Runtime,Float16 quantization,Modular framework,Neuroimaging,Medical software"
                     data-authors="Yann Kerverdo,Florent Leray,Youwan Mah√©,St√©phanie Leplaideur,Francesca Galassi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24378v1.html">Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yann Kerverdo, Florent Leray, Youwan Mah√© et al.
                </div>

                <div class="paper-summary">
                    This paper introduces StrokeSeg, a modular, lightweight, and deployment-ready software framework designed to translate high-performing deep learning stroke lesion segmentation models, typically challenging to integrate clinically, into practical applications. By decoupling preprocessing, inference, and postprocessing, and leveraging ONNX Runtime with Float16 quantization, StrokeSeg reduces model size by 50% while maintaining equivalent segmentation performance to original PyTorch pipelines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Stroke research</span>
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24378v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24378v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24378v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24378v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.24368v1"
                     data-domains="Diagnostics,Prognostics,Clinical Decision Support,Risk Stratification"
                     data-keywords="Machine Learning,Healthcare,Model Reliability,Instance Hardness,Confidence-based Rejection,Data Quality,Uncertainty Quantification,Safety-critical Systems"
                     data-authors="Maria Gabriela Valeriano,David Kohan Marzag√£o,Alfredo Montelongo,Carlos Roberto Veiga Kiffer,Natan Katz,Ana Carolina Lorena">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.24368v1.html">Filtering instances and rejecting predictions to obtain reliable models in healthcare</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-28</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Maria Gabriela Valeriano, David Kohan Marzag√£o, Alfredo Montelongo et al.
                </div>

                <div class="paper-summary">
                    This research proposes a novel two-step data-centric approach to enhance the reliability of Machine Learning (ML) models, particularly for high-stakes healthcare applications. It combines Instance Hardness (IH) filtering during training to improve data quality with a confidence-based rejection mechanism during inference to ensure only reliable predictions are retained, demonstrating improved model reliability on real-world healthcare datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.24368v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.24368v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.24368v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.24368v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-10-30 06:33:27</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>