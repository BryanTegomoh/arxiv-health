<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">154</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Medical Imaging (7), Oncology (7), Neurology (6)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Medical Imaging">Medical Imaging (7)</option>
                        
                        <option value="Oncology">Oncology (7)</option>
                        
                        <option value="Neurology">Neurology (6)</option>
                        
                        <option value="Radiology">Radiology (6)</option>
                        
                        <option value="Digital Health">Digital Health (5)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (5)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (4)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.05114v1"
                     data-domains="Pediatric Neurology,Developmental Neuroscience,Neuroradiology,Medical Imaging,Child Psychiatry Research"
                     data-keywords="Infant brain segmentation,Deep learning,MRI,Domain randomization,Pediatric neuroimaging,Multi-contrast MRI,Brain development,Medical image analysis"
                     data-authors="Malte Hoffmann,Lilla Z√∂llei,Adrian V. Dalca">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05114v1.html">Deep infant brain segmentation from multi-contrast MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Malte Hoffmann, Lilla Z√∂llei, Adrian V. Dalca
                </div>

                <div class="paper-summary">
                    This paper introduces BabySeg, a deep learning framework designed for accurate and robust brain segmentation from multi-contrast MRI in infants and young children. It addresses the challenges of pediatric neuroimaging, such as diverse protocols and artifacts, by employing domain randomization and a novel feature pooling mechanism, achieving state-of-the-art performance with a single model and significantly faster runtime.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatric Neurology</span>
                    
                    <span class="domain-tag">Developmental Neuroscience</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Child Psychiatry Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05114v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05114v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05114v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05114v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05092v1"
                     data-domains="Medical Imaging,Genomics,Electronic Health Records (EHR) Analysis,Computational Biology,Drug Discovery,Personalized Medicine,Physiological Signal Processing"
                     data-keywords="diffusion models,generative modeling,general state spaces,stochastic differential equations,continuous-time Markov chains,ELBO,medical AI,multimodal data"
                     data-authors="Vincent Pauline,Tobias H√∂ppe,Kirill Neklyudov,Alexander Tong,Stefan Bauer,Andrea Dittadi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05092v1.html">Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vincent Pauline, Tobias H√∂ppe, Kirill Neklyudov et al.
                </div>

                <div class="paper-summary">
                    This paper provides a self-contained, unified theoretical framework for diffusion models across both continuous and discrete state spaces, bridging the gap between existing treatments. It connects discrete-time dynamics to their continuous-time limits (Stochastic Differential Equations and Continuous-Time Markov Chains) and derives core principles like the Evidence Lower Bound (ELBO), offering a comprehensive roadmap for generative modeling across diverse data types.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Analysis</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05092v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05092v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05092v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05092v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05080v1"
                     data-domains="Pharmacology,Drug Development,Oncology,Infectious Diseases,Neuroscience,Immunology"
                     data-keywords="Structure-Based Drug Design,Generative Models,Multi-Task Learning,De Novo Drug Design,Drug Discovery,Flow Matching,Protein-Ligand Binding,Computational Chemistry"
                     data-authors="Ian Dunn,Liv Toft,Tyler Katz,Juhi Gupta,Riya Shah,Ramith Hettiarachchi,David R. Koes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05080v1.html">OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ian Dunn, Liv Toft, Tyler Katz et al.
                </div>

                <div class="paper-summary">
                    OMTRA is a novel multi-task generative model leveraging multi-modal flow matching for structure-based drug design (SBDD). It unifies various SBDD tasks, including de novo ligand design and docking, achieving state-of-the-art performance. This is accomplished through a consistent generative framework trained on a newly curated, large-scale dataset of 500M 3D molecular conformers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05080v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05080v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05080v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05080v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05066v1"
                     data-domains="pharmacology,clinical informatics,general medicine,AI in healthcare,precision medicine"
                     data-keywords="LLM,collaboration,medication recommendation,AI reliability,clinical decision support,LLM Chemistry,ensemble learning,healthcare AI"
                     data-authors="Huascar Sanchez,Briland Hitaj,Jules Bergmann,Linda Briesemeister">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05066v1.html">Multi-LLM Collaboration for Medication Recommendation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huascar Sanchez, Briland Hitaj, Jules Bergmann et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel approach to enhance the reliability of AI-driven medication recommendations by leveraging multi-LLM collaboration guided by a framework called "LLM Chemistry." By quantifying collaborative compatibility among LLMs, this method aims to create ensembles that are effective, stable, and calibrated, thereby overcoming issues of hallucination and inconsistency often found in individual LLMs or naive ensembles. Preliminary results suggest this interaction-aware collaboration can generate credible and patient-specific medication recommendations from brief clinical vignettes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">pharmacology</span>
                    
                    <span class="domain-tag">clinical informatics</span>
                    
                    <span class="domain-tag">general medicine</span>
                    
                    <span class="domain-tag">AI in healthcare</span>
                    
                    <span class="domain-tag">precision medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05066v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05066v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05066v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05066v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05030v1"
                     data-domains="Rehabilitation Medicine,Biomechanics,Orthopedics,Sports Medicine,Physical Therapy,Gait Analysis"
                     data-keywords="Ground Reaction Force,Ground Reaction Moment,Insole Sensors,Deep Learning,Attention Network,Biomechanics,Rehabilitation,Activity Monitoring"
                     data-authors="Xuan Li,Samuel Bello">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05030v1.html">Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xuan Li, Samuel Bello
                </div>

                <div class="paper-summary">
                    This paper introduces a Dual-Path Region-Guided Attention Network for accurate, insole-based estimation of three-dimensional ground reaction forces and moments (GRFs/GRMs). The proposed deep learning model integrates anatomy-inspired spatial and temporal priors with a region-level attention mechanism, complemented by a path capturing full sensor field context. It significantly outperforms traditional CNN and CNN-LSTM architectures on two datasets, demonstrating robust performance critical for biomechanics research and clinical rehabilitation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05030v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05030v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05030v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05030v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.05012v1"
                     data-domains="Clinical Trials,Drug Development,Clinical Decision Support Systems,Medical Research,Health Informatics,Pharmacovigilance"
                     data-keywords="RAG,Contrastive Learning,Evidence Re-ranking,Factual Evidence,Hallucination Mitigation,Clinical Trials,Transparency,Evidential Reasoning"
                     data-authors="Francielle Vargas,Daniel Pedronette">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.05012v1.html">Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Francielle Vargas, Daniel Pedronette
                </div>

                <div class="paper-summary">
                    This paper introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method designed to improve the factuality and transparency of Retrieval-Augmented Generation (RAG) systems. CER fine-tunes embeddings using contrastive learning with subjectivity-based hard negative selection and generates token-level attribution rationales, creating an embedding space aligned with evidential reasoning. Evaluated on clinical trial reports, CER demonstrates improved retrieval accuracy, mitigates hallucinations, and provides transparent, evidence-based retrieval essential for safety-critical domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.05012v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.05012v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.05012v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.05012v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04980v1"
                     data-domains="Precision Medicine,Epidemiology,Pharmacogenomics,Chronic Disease Management,Drug Discovery,Clinical Trials,Digital Health"
                     data-keywords="Causal Inference,Longitudinal Data,Individual Treatment Effects,Causal Representation Learning,Variational Autoencoder,Recurrent Neural Networks,Contrastive Predictive Coding,Interpretability"
                     data-authors="Mouad EL Bouchattaoui">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04980v1.html">Learning Causality for Longitudinal Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mouad EL Bouchattaoui
                </div>

                <div class="paper-summary">
                    This thesis introduces novel methods for causal inference and causal representation learning (CRL) specifically designed for high-dimensional, time-varying data. It proposes the Causal Dynamic Variational Autoencoder (CDVAE) for robust Individual Treatment Effect (ITE) estimation under unobserved confounding, develops an efficient RNN-based framework for long-term counterfactual regression, and advances CRL interpretability by revealing how latent causes map to observed variables. The work demonstrates state-of-the-art performance across various tasks and provides theoretical guarantees for its contributions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04980v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04980v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04980v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04980v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04967v1"
                     data-domains="Ophthalmology,Medical Imaging,Diagnostic Medicine,Artificial Intelligence in Medicine"
                     data-keywords="Retinal Disease Diagnosis,Few-Shot Learning,Episodic Learning,Class Imbalance,Deep Learning,Image Augmentation,CLAHE,Diabetic Retinopathy,Macular Degeneration"
                     data-authors="Jasmaine Khale,Ravi Prakash Srivastava">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04967v1.html">Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jasmaine Khale, Ravi Prakash Srivastava
                </div>

                <div class="paper-summary">
                    This paper proposes a balanced few-shot episodic learning framework for accurate retinal disease diagnosis, addressing challenges of data scarcity and class imbalance inherent in medical imaging datasets. By integrating balanced sampling, targeted augmentation (including CLAHE), and a ResNet-50 encoder, the method significantly improves diagnostic accuracy and reduces bias towards majority classes, particularly benefiting underrepresented retinal conditions on the RFMiD dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04967v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04967v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04967v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04967v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04943v1"
                     data-domains="Gerontology,Telemedicine,Patient Monitoring,Assisted Living,Rehabilitation,Clinical Informatics,Emergency Medicine (Violence Detection)"
                     data-keywords="Multimodal Fusion,Deep Learning,Human Action Recognition,Gating Mechanisms,Adaptive Weighting,Active Assisted Living,Violence Detection,Computer Vision"
                     data-authors="Novanto Yudistira">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04943v1.html">Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Novanto Yudistira
                </div>

                <div class="paper-summary">
                    This study introduces an adaptive fusion methodology for human action recognition leveraging deep neural networks across multiple modalities (RGB, optical flows, audio, depth). By employing gating mechanisms for selective information integration, the approach significantly enhances accuracy and robustness, surpassing traditional unimodal methods in tasks like action recognition, violence detection, and self-supervised learning. This innovation promises to revolutionize action recognition systems, particularly in applications like surveillance, human-computer interaction, and active assisted living.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gerontology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Patient Monitoring</span>
                    
                    <span class="domain-tag">Assisted Living</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04943v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04943v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04943v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04943v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04938v1"
                     data-domains="Neurology,Rare Diseases,Cognitive Science,Digital Health,Pediatrics (specifically for PKU),AI in Medicine"
                     data-keywords="Neurocognitive Monitoring,Speech AI,Relational Graph Transformers,Rare Neurological Diseases,Phenylketonuria,Digital Biomarkers,Personalized Medicine,Brain Fog"
                     data-authors="Raquel Norel,Michele Merler,Pavitra Modi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04938v1.html">Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Raquel Norel, Michele Merler, Pavitra Modi
                </div>

                <div class="paper-summary">
                    This paper proposes a novel approach for continuous neurocognitive monitoring in patients with rare neurological diseases, particularly focusing on subtle cognitive symptoms like "brain fog" often missed by traditional tests. It integrates smartphone-based speech AI for analyzing verbal discourse proficiency with Relational Graph Transformer (RELGT) architectures to process diverse medical data. A proof-of-concept in phenylketonuria (PKU) demonstrates that a speech-derived metric correlates significantly with a biochemical marker (blood phenylalanine) but not with standard cognitive assessments, suggesting its potential as an early, sensitive digital biomarker.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Cognitive Science</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Pediatrics (specifically for PKU)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04938v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04938v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04938v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04938v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04937v1"
                     data-domains="Neurology,Neuropharmacology,Diagnostics,Geriatric Medicine,Precision Medicine,Biomarker Research"
                     data-keywords="Alzheimer's disease,amyloid-$Œ≤$,tau pathology,neuroinflammation,combination therapy,multi-target therapy,precision medicine,biomarkers"
                     data-authors="She Xutong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04937v1.html">A Systemic Pathological Network Model and Combinatorial Intervention Strategies for Alzheimer's Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.MN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> She Xutong
                </div>

                <div class="paper-summary">
                    This paper proposes a systemic pathological network model for Alzheimer's disease (AD), emphasizing the intricate cross-talk between amyloid-$Œ≤$ (A$Œ≤$), tau, and neuroinflammation. It critically analyzes the modest efficacy of current single-target therapies, advocating for a shift towards biomarker-guided, personalized combination interventions to fundamentally alter AD's disease trajectory.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuropharmacology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Geriatric Medicine</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04937v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04937v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04937v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04937v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04890v1"
                     data-domains="Fetal Medicine,Radiology,Prenatal Diagnosis,Maternal-Fetal Medicine"
                     data-keywords="Fetal MRI,Pose Estimation,Equivariance,Symmetry-Aware,Head Motion Correction,Adaptive Prescription,Medical Imaging,Clinical Translation"
                     data-authors="Ramya Muthukrishnan,Borjan Gagoski,Aryn Lee,P. Ellen Grant,Elfar Adalsteinsson,Polina Golland,Benjamin Billot">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04890v1.html">Equivariant Symmetry-Aware Head Pose Estimation for Fetal MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ramya Muthukrishnan, Borjan Gagoski, Aryn Lee et al.
                </div>

                <div class="paper-summary">
                    E(3)-Pose is a novel, fast pose estimation method designed to robustly track fetal head motion in MRI by explicitly modeling rotation equivariance and anatomical symmetry. This method aims to enable automatic adaptive prescription of 2D diagnostic MRI slices, crucial for overcoming challenges posed by fetal movement. E(3)-Pose achieves state-of-the-art accuracy, superior robustness, and generalization on clinical fetal MRI datasets, thereby demonstrating significant potential for clinical translation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Fetal Medicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Prenatal Diagnosis</span>
                    
                    <span class="domain-tag">Maternal-Fetal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04890v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04890v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04890v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04890v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04889v1"
                     data-domains="Diagnostic Imaging,Radiology,Neurology,Point-of-Care Imaging"
                     data-keywords="Electromagnetic Interference (EMI),Low-Field MRI,FENCE,Capacitive Coupling,RF Coil,Signal-to-Noise Ratio (SNR),Portability,Image Quality,Flexible PCB,Faraday Shield"
                     data-authors="Julia Pfitzer,Martin Uecker,Hermann Scharfetter">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04889v1.html">FENCE: Flexible Electric Noise Cancellation Endo-shield for the Suppression of Electromagnetic Interference in Low-Field MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Julia Pfitzer, Martin Uecker, Hermann Scharfetter
                </div>

                <div class="paper-summary">
                    This paper introduces FENCE (Flexible Electric Noise Cancellation Endo-shield), a novel, retrofittable solution designed to suppress electromagnetic interference (EMI) in low-field MRI systems operating without conventional Faraday shields. By blocking capacitive EMI coupling from the body to the RF coil, FENCE, especially when combined with segmented coils, significantly improves signal-to-noise ratio (SNR) and reduces EMI, thereby enhancing image quality while preserving system portability and accessibility.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Point-of-Care Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04889v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04889v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04889v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04889v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04875v1"
                     data-domains="Radiology,Diagnostic Imaging,Pulmonology,AI in Medicine"
                     data-keywords="Multi-label lesion detection,Chest X-rays,Self-prompted detection,Dual-text fusion,Medical imaging,Artificial intelligence,Diagnostic support,Thoracic diseases"
                     data-authors="Qing Xu,Yanqian Wang,Xiangjian Hea,Yue Li,Yixuan Zhang,Rong Qu,Wenting Duan,Zhen Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04875v1.html">SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qing Xu, Yanqian Wang, Xiangjian Hea et al.
                </div>

                <div class="paper-summary">
                    SP-Det is a novel self-prompted framework for multi-label lesion detection in chest X-rays that overcomes the limitation of labor-intensive expert annotations by automatically generating rich textual context. It achieves state-of-the-art detection accuracy by fusing global semantic context prompts with disease-specific beacon prompts and enhancing features bidirectionally. This approach significantly improves diagnostic capabilities while eliminating the dependency on manual expert input, making automated lesion detection more practical for clinical use.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04875v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04875v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04875v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04875v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04847v1"
                     data-domains="Cardiology,Pulmonology,Respiratory Medicine,Infectious Diseases (e.g., COVID-19),Telemedicine,Physiological Monitoring"
                     data-keywords="Medical audio,Auscultation,Language models,Clinical semantics,Audio-language alignment,Diagnostic AI,Cardio-respiratory sounds,Deep learning"
                     data-authors="Tsai-Ning Wang,Lin-Lin Chen,Neil Zeghidour,Aaqib Saeed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04847v1.html">Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.SD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tsai-Ning Wang, Lin-Lin Chen, Neil Zeghidour et al.
                </div>

                <div class="paper-summary">
                    This paper introduces AcuLa (Audio-Clinical Understanding via Language Alignment), a lightweight post-training framework that integrates semantic understanding into audio encoders by aligning them with medical language models. By leveraging large language models to generate clinical reports from existing audio metadata, AcuLa achieves state-of-the-art results across 18 cardio-respiratory tasks, significantly enhancing diagnostic accuracy for audio-based health monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Respiratory Medicine</span>
                    
                    <span class="domain-tag">Infectious Diseases (e.g., COVID-19)</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04847v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04847v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04847v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04847v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04843v1"
                     data-domains="Eating Disorders,Mental Health,Clinical Psychology,Public Health,Digital Psychiatry"
                     data-keywords="generative AI,eating disorders,AI risks,mental health,qualitative research,clinical psychology,AI safeguards,digital health"
                     data-authors="Amy Winecoff,Kevin Klyman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04843v1.html">From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Amy Winecoff, Kevin Klyman
                </div>

                <div class="paper-summary">
                    Generative AI systems pose significant and often subtle risks to individuals vulnerable to eating disorders, as existing safeguards frequently overlook critical clinical cues. This study employed expert interviews to develop a seven-category taxonomy of these risks, illustrating how interactions with AI can exacerbate clinical features of eating disorders. The findings provide a framework for enhancing risk assessment, safeguard design, and expert-guided evaluation practices for AI technologies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Eating Disorders</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Digital Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04843v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04843v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04843v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04843v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04834v1"
                     data-domains="Clinical Informatics,Medical NLP,Digital Health,EHR Management,Epidemiology (for comorbidity analysis)"
                     data-keywords="Large Language Models,LLMs,Multilingual NLP,Information Extraction,Electronic Health Records,Comorbidity,Italian Healthcare,Zero-shot"
                     data-authors="Vignesh Kumar Kembu,Pierandrea Morandini,Marta Bianca Maria Ranzini,Antonino Nocera">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04834v1.html">Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vignesh Kumar Kembu, Pierandrea Morandini, Marta Bianca Maria Ranzini et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the zero-shot, multilingual capability of open-source Large Language Models (LLMs) for extracting information, specifically comorbidities, from Italian Electronic Health Records (EHRs) in an on-premises setting. The study found that while LLMs show potential, many struggled or exhibited significant performance variability and generalization issues, generally underperforming traditional pattern matching and manual annotations for this critical task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical NLP</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">EHR Management</span>
                    
                    <span class="domain-tag">Epidemiology (for comorbidity analysis)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04834v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04834v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04834v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04834v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04829v1"
                     data-domains="Radiology,Medical Physics,Biomedical Engineering,Computational Neuroscience (for brain imaging)"
                     data-keywords="Sphere Packing,AI-Assisted Discovery,Medical Imaging,Semidefinite Programming (SDP),Bayesian Optimization,Monte Carlo Tree Search (MCTS),Sample-Efficient AI,Geometric Problems"
                     data-authors="Rasul Tutunov,Alexandre Maraval,Antoine Grosnit,Xihan Li,Jun Wang,Haitham Bou-Ammar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04829v1.html">Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rasul Tutunov, Alexandre Maraval, Antoine Grosnit et al.
                </div>

                <div class="paper-summary">
                    This research introduces a sample-efficient, model-based AI framework to tackle the challenging sphere packing problem, a longstanding mathematical enigma relevant to various fields including medical imaging. By formulating the construction of Semidefinite Programs (SDPs) as a sequential decision process, the 'SDP game', the AI combines Bayesian optimization with Monte Carlo Tree Search to efficiently explore solutions despite computationally intensive evaluations. The study achieved new state-of-the-art upper bounds for sphere packing in dimensions 4-16, demonstrating AI's capacity to advance rigid mathematical problems with limited data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Computational Neuroscience (for brain imaging)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04829v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04829v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04829v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04829v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04821v1"
                     data-domains="Dermatology,Gastroenterology"
                     data-keywords="generative models,flow matching,latent space,medical image segmentation,uncertainty quantification,variational autoencoders,deep learning,confidence maps"
                     data-authors="Huynh Trinh Ngoc,Hoang Anh Nguyen Kim,Toan Nguyen Hai,Long Tran Quoc">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04821v1.html">LatentFM: A Latent Flow Matching Approach for Generative Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huynh Trinh Ngoc, Hoang Anh Nguyen Kim, Toan Nguyen Hai et al.
                </div>

                <div class="paper-summary">
                    LatentFM introduces a novel flow-based generative model for medical image segmentation, operating efficiently within a lower-dimensional latent space. It leverages two Variational Autoencoders (VAEs) and a conditional velocity field to produce diverse, highly accurate, and uncertainty-aware segmentation predictions, including explicit confidence maps for clinicians.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04821v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04821v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04821v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04821v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04662v1"
                     data-domains="Orthopedics,Rheumatology,Pathology,Diagnostic Imaging Research,Musculoskeletal Biology"
                     data-keywords="spectral micro-CT,calcification,fibrocartilage,osteoarthritis,femoroacetabular impingement,material decomposition,3D quantification,photon-counting detector"
                     data-authors="Vittoria Mazzini,Paolo Cardarelli,Andrew L. Coathup,Eleonora Olivotto,Francesco Grassi,Enrico Tassinari,Simone Velardita,Angelo Taibi,Luca Brombal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04662v1.html">Spectral micro-CT for quantitative analysis of calcification in fibrocartilage</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vittoria Mazzini, Paolo Cardarelli, Andrew L. Coathup et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel quantitative spectral micro-CT method for 3D visualization and quantification of calcification in fibrocartilage, specifically in hip labrum samples from patients with osteoarthritis and femoroacetabular impingement. The technique enables volumetric analysis of calcium distribution within intact, paraffin-embedded tissues, offering a non-destructive alternative or complement to traditional histology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging Research</span>
                    
                    <span class="domain-tag">Musculoskeletal Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04662v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04662v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04662v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04662v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04629v1"
                     data-domains="Drug Discovery,Pharmaceutical Research,Medicinal Chemistry,Chemical Synthesis,Biotechnology"
                     data-keywords="molecular understanding,molecular generation,multi-task learning,large language models,drug discovery,retrosynthesis,small molecules,biomedical AI"
                     data-authors="Chenyang Zuo,Siqi Fan,Zaiqing Nie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04629v1.html">BioMedGPT-Mol: Multi-task Learning for Molecular Understanding and Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chenyang Zuo, Siqi Fan, Zaiqing Nie
                </div>

                <div class="paper-summary">
                    BioMedGPT-Mol is introduced as a novel molecular language model that leverages multi-task learning to enhance molecular understanding and generation for drug discovery. By post-training a general-purpose reasoning model on a curated, large-scale dataset, it achieves remarkable performance on molecular benchmarks and demonstrates competitive capabilities as an end-to-end retrosynthetic planner.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Chemical Synthesis</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04629v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04629v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04629v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04629v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04618v1"
                     data-domains="Neurology,Neuroprosthetics,Rehabilitation Medicine,Neurosurgery"
                     data-keywords="Neural Decoding,Speech BCI,ECoG,Vision Transformers,Contrastive Learning,Epidural,Paralysis,Communication,Wireless Implantable"
                     data-authors="Mohamed Baha Ben Ticha,Xingchen Ran,Guillaume Saldanha,Ga√´l Le Godais,Phil√©mon Roussel,Marc Aubert,Amina Fontanell,Thomas Costecalde,Lucas Struber,Serpil Karakas,Shaomin Zhang,Philippe Kahane,Guillaume Charvet,St√©phan Chabard√®s,Blaise Yvert">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04618v1.html">Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohamed Baha Ben Ticha, Xingchen Ran, Guillaume Saldanha et al.
                </div>

                <div class="paper-summary">
                    This paper presents an innovative offline speech decoding pipeline designed to directly regress acoustic speech from electrocorticographic (ECoG) signals. It leverages an encoder-decoder deep neural architecture integrating Vision Transformers and contrastive learning to enhance decoding performance, particularly for surface ECoG recordings. A key contribution is the first reported attempt to decode speech from a fully implantable and wireless epidural recording system, opening avenues for long-term clinical applications in patients with severe paralysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroprosthetics</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04618v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04618v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04618v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04618v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04599v1"
                     data-domains="Public Health,Addiction Medicine,Mental Health,Digital Forensics (Health-related crime),Child Protection"
                     data-keywords="malicious image detection,vision-language models,semantic segmentation,zero-shot learning,content moderation,adversarial robustness,public health,drug content"
                     data-authors="Sheng Hang,Chaoxiang He,Hongsheng Hu,Hanqing Hu,Bin Benjamin Zhu,Shi-Feng Sun,Dawu Gu,Shuo Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04599v1.html">Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sheng Hang, Chaoxiang He, Hongsheng Hu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel zero-shot pipeline for malicious image analysis that simultaneously detects harmful content, identifies specific illicit elements, and localizes them with pixel-accurate masks in a single pass. The method achieves high recall and precision on a newly annotated dataset spanning drug, sexual, violent, and extremist content, demonstrating significant robustness against adversarial attacks and offering a practical, explainable tool for fine-grained content moderation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Addiction Medicine</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Forensics (Health-related crime)</span>
                    
                    <span class="domain-tag">Child Protection</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04599v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04599v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04599v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04599v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04580v1"
                     data-domains="Healthcare AI,Medical Informatics,Digital Health,Clinical Decision Support,Medical Research"
                     data-keywords="Large Language Models (LLMs),Confidentiality,Access Control,Secure Model Distribution,Tensor-level Encryption,Safetensors,Healthcare AI,Data Privacy"
                     data-authors="Huifeng Zhu,Shijie Li,Qinfeng Li,Yier Jin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04580v1.html">A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huifeng Zhu, Shijie Li, Qinfeng Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CryptoTensors, a secure and format-compatible file structure designed for the confidential distribution of large language models (LLMs) fine-tuned with sensitive data. By extending the widely adopted Safetensors format, CryptoTensors integrates tensor-level encryption and embedded access control, addressing the critical lack of built-in confidentiality in current LLM deployment methods. The solution is validated as a light-weight, efficient, and developer-friendly approach for safeguarding LLM weights, demonstrated through performance benchmarking and compatibility with major inference frameworks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04580v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04580v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04580v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04580v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04576v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Zishuo Wan,Qinqin Kang,Yi Huang,Yun Bian,Dawei Ding,Ke Yan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04576v1.html">TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zishuo Wan, Qinqin Kang, Yi Huang et al.
                </div>

                <div class="paper-summary">
                    Tumor segmentation and diagnosis in contrast-enhanced Computed Tomography (CT) rely heavily on the physiological dynamics of contrast agents. However, obtaining a complete multi-phase series is often clinically unfeasible due to radiation concerns or scanning limitations, leading to the "missing mod...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04576v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04576v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04576v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04576v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04564v1"
                     data-domains="Pathology,Digital Pathology,Histopathology,Medical Imaging,Diagnostic Medicine"
                     data-keywords="Deep Learning,Microscopic Images,Dataset Creation,Annotation,Pathology,Image Acquisition,Domain Shifts,Annotation Quality"
                     data-authors="Christof A. Bertram,Viktoria Weiss,Jonas Ammeling,F. Maria Schabel,Taryn A. Donovan,Frauke Wilm,Christian Marzahl,Katharina Breininger,Marc Aubreville">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04564v1.html">Dataset creation for supervised deep learning-based analysis of microscopic images -- review of important considerations and recommendations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christof A. Bertram, Viktoria Weiss, Jonas Ammeling et al.
                </div>

                <div class="paper-summary">
                    This review provides a comprehensive guide for creating high-quality, large-scale datasets essential for supervised deep learning models in microscopic image analysis. It addresses the inherent complexities and challenges, such as domain variability and bias, by offering practical recommendations across image acquisition, annotation software selection, and annotation creation. The ultimate goal is to enable the development of generalizable and robust deep learning models, particularly for pathology applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04564v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04564v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04564v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04564v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04536v1"
                     data-domains="Public Health,Emergency Medicine,Preventive Medicine,Forensic Toxicology"
                     data-keywords="Alcohol Intoxication Detection,Facial Video Analysis,Deep Learning,Recurrent Fusion Model,Graph Attention Networks,3D ResNet,Spatiotemporal Features,Public Safety"
                     data-authors="Bita Baroutian,Atefe Aghaei,Mohsen Ebrahimi Moghaddam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04536v1.html">Detection of Intoxicated Individuals from Facial Video Sequences via a Recurrent Fusion Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bita Baroutian, Atefe Aghaei, Mohsen Ebrahimi Moghaddam
                </div>

                <div class="paper-summary">
                    This study introduces a novel video-based recurrent fusion model for detecting alcohol intoxication from facial video sequences, integrating facial landmark analysis via a Graph Attention Network (GAT) with spatiotemporal visual features from a 3D ResNet. The model dynamically fuses these features with adaptive prioritization, achieving 95.82% accuracy, 0.977 precision, and 0.97 recall. It outperforms prior methods, demonstrating significant potential for non-invasive public safety applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Forensic Toxicology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04536v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04536v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04536v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04536v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04535v1"
                     data-domains="Diagnostics,Therapeutics,Surgical Robotics,Personalized Medicine,Clinical Decision Support,Drug Discovery,Medical Imaging"
                     data-keywords="AI agents,LLM,tool simulation,Generalist Tool Model (GTM),Context-Aware Response Generation (CARG),reinforcement learning,medical AI,scalable training"
                     data-authors="Zhenzhen Ren,Xinpeng Zhang,Zhenxing Qian,Yan Gao,Yu Shi,Shuxin Zheng,Jiyan He">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04535v1.html">GTM: Simulating the World of Tools for AI Agents</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhenzhen Ren, Xinpeng Zhang, Zhenxing Qian et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Generalist Tool Model (GTM), a 1.5-billion-parameter AI model designed to function as a universal tool simulator, addressing the high cost and complexity of training Large Language Model (LLM) agents with real-world tools. Utilizing the Context-Aware Response Generation (CARG) pipeline, GTM synthesizes training data across 300 diverse domains, including medicine, enabling it to rapidly generate accurate and contextually appropriate tool outputs. The model demonstrates significantly faster simulation speeds and strong generalization, positioning it as a foundational component for efficient and scalable AI agent development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Therapeutics</span>
                    
                    <span class="domain-tag">Surgical Robotics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04535v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04535v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04535v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04535v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04520v1"
                     data-domains="Dermatology (ISIC for skin lesions),Gastroenterology (Kvasir for GI tract images),Radiology/Oncology (BUSI for breast ultrasound),Ophthalmology (REFUGE for retinal fundus images/glaucoma)"
                     data-keywords="Medical image segmentation,Zero-shot learning,Test-time adaptation,SAM (Segment Anything Model),Vision Transformer (ViT),Boundary-aware attention,Gaussian prompts,Domain shift"
                     data-authors="Chenlin Xu,Lei Zhang,Lituan Wang,Xinyu Pu,Pengfei Ma,Guangwu Qian,Zizhou Wang,Yan Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04520v1.html">Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chenlin Xu, Lei Zhang, Lituan Wang et al.
                </div>

                <div class="paper-summary">
                    BA-TTA-SAM is a novel test-time adaptation framework designed to address the challenges of zero-shot medical image segmentation, particularly for models like SAM that struggle with domain shifts and data scarcity. It significantly enhances SAM's performance by integrating encoder-level Gaussian prompt injection and cross-layer boundary-aware attention alignment. The framework achieved an average 12.4% DICE score improvement on diverse medical datasets, outperforming state-of-the-art models without requiring source-domain training.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology (ISIC for skin lesions)</span>
                    
                    <span class="domain-tag">Gastroenterology (Kvasir for GI tract images)</span>
                    
                    <span class="domain-tag">Radiology/Oncology (BUSI for breast ultrasound)</span>
                    
                    <span class="domain-tag">Ophthalmology (REFUGE for retinal fundus images/glaucoma)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04520v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04520v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04520v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04520v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04518v1"
                     data-domains="Oncology,Medical Informatics,Clinical Natural Language Processing,Health Information Technology,Real-World Evidence"
                     data-keywords="ChemoTimelines 2025,LLM,Chemotherapy Timeline Extraction,Clinical Notes,Fine-tuning,Natural Language Processing,Oncology,Electronic Health Records"
                     data-authors="Tianmai M. Zhang,Zhaoyi Sun,Sihang Zeng,Chenxi Li,Neil F. Abernethy,Barbara D. Lam,Fei Xia,Meliha Yetisgen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04518v1.html">UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tianmai M. Zhang, Zhaoyi Sun, Sihang Zeng et al.
                </div>

                <div class="paper-summary">
                    The UW-BioNLP team participated in ChemoTimelines 2025, focusing on extracting chemotherapy timelines from raw clinical notes using advanced LLM systems. They developed a two-step workflow combining LLM-based event extraction with algorithmic normalization, evaluating strategies such as fine-tuning, chain-of-thought, and dictionary lookups. Their most successful approach, a fine-tuned Qwen3-14B model, achieved the highest official score of 0.678, providing valuable insights for future medical timeline extraction tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Natural Language Processing</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Real-World Evidence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04518v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04518v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04518v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04518v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04425v1"
                     data-domains="Neurology,Movement Disorders,Geriatrics,Rehabilitation Medicine,Diagnostic Imaging"
                     data-keywords="Parkinson's Disease,Gait Analysis,RGB-D Fusion,Multimodal Learning,Large Language Models,Explainable AI,Clinical Interpretability,Movement Disorders"
                     data-authors="Manar Alnaasan,Md Selim Sarowar,Sungho Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04425v1.html">Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manar Alnaasan, Md Selim Sarowar, Sungho Kim
                </div>

                <div class="paper-summary">
                    This paper introduces an explainable multimodal RGB-D fusion framework for Parkinson's Disease (PD) gait recognition, addressing limitations of single-modality inputs, low robustness, and lack of clinical interpretability in existing methods. The system leverages advanced deep learning and a Large Language Model (LLM) to achieve higher accuracy, improved robustness in challenging conditions, and provide clinically meaningful textual explanations of gait patterns. It offers a novel vision-language paradigm that bridges the gap between visual analysis and clinical understanding for PD diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Movement Disorders</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04425v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04425v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04425v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04425v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04401v1"
                     data-domains="Medical Imaging,Oncology,Radiology,Biomedical Engineering"
                     data-keywords="microwave imaging,breast imaging,deep learning,conformal antenna array,image reconstruction,time-domain signals,dielectric breast imaging,antenna positioning"
                     data-authors="Wenyi Shao,Beibei Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04401v1.html">Learnt Microwave Image Reconstruction with A Conformal Antenna Array</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenyi Shao, Beibei Zhou
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning model for reconstructing 2D dielectric breast images from time-domain signals, distinguishing itself by integrating antenna positioning into the processing pipeline. Utilizing a conformal antenna array, the system adapts to diverse breast sizes to optimize data collection and mitigate signal attenuation inherent in fixed arrays. By leveraging antenna position data for pre-estimation of the breast surface, the neural network effectively focuses on image reconstruction within the region of interest, with numerical results indicating good quality image reconstruction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04401v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04401v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04401v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04401v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04397v1"
                     data-domains="Radiology,Diagnostic Imaging,Pulmonology (implied by chest X-rays),Pathology (general disease detection)"
                     data-keywords="Transfer Learning,Deep Learning,Medical Image Classification,Chest X-ray,Convolutional Neural Networks,Disease Detection,InceptionV3,ResNet"
                     data-authors="Zeeshan Ahmad,Shudi Bao,Meng Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04397v1.html">Performance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zeeshan Ahmad, Shudi Bao, Meng Chen
                </div>

                <div class="paper-summary">
                    This paper comprehensively evaluates the performance of six deep convolutional neural network models (AlexNet, VGG16, ResNet18, ResNet34, ResNet50, InceptionV3) using transfer learning for disease detection on a custom chest X-ray dataset. The study finds that InceptionV3 consistently achieves superior performance across standard metrics, while demonstrating that transfer learning is largely beneficial, especially with limited data, and provides insights for model selection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pulmonology (implied by chest X-rays)</span>
                    
                    <span class="domain-tag">Pathology (general disease detection)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04397v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04397v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04397v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04397v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04354v1"
                     data-domains="Hospital Medicine,Clinical Pathology,Internal Medicine,Health Informatics,Healthcare Operations,Quality Improvement"
                     data-keywords="Machine Learning,Clinical Decision Support,Laboratory Utilization,Complete Blood Count (CBC),Electronic Health Record (EHR),Inpatient Care,Healthcare Costs,Implementation Science"
                     data-authors="April S. Liang,Fatemeh Amrollahi,Yixing Jiang,Conor K. Corbin,Grace Y. E. Kim,David Mui,Trevor Crowell,Aakash Acharya,Sreedevi Mony,Soumya Punnathanam,Jack McKeown,Margaret Smith,Steven Lin,Arnold Milstein,Kevin Schulman,Jason Hom,Michael A. Pfeffer,Tho D. Pham,David Svec,Weihan Chu,Lisa Shieh,Christopher Sharp,Stephen P. Ma,Jonathan H. Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04354v1.html">SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> April S. Liang, Fatemeh Amrollahi, Yixing Jiang et al.
                </div>

                <div class="paper-summary">
                    SmartAlert is an ML-driven clinical decision support system integrated into the EHR designed to predict stable lab results and reduce unnecessary repeat inpatient testing. A randomized controlled pilot focusing on CBC utilization demonstrated a significant 15% relative reduction in repetitive testing (1.54 vs 1.82 CBCs within 52 hours, p <0.01) without adverse safety outcomes. The study also provided critical implementation lessons for deploying complex ML models in clinical environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Hospital Medicine</span>
                    
                    <span class="domain-tag">Clinical Pathology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Healthcare Operations</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04354v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04354v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04354v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04354v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04333v1"
                     data-domains="Oncology,Lung Cancer,Kidney Cancer,Cervical Cancer,Molecular Diagnostics,Genomics,Precision Medicine"
                     data-keywords="RNA-seq,Early Cancer Detection,Biomarker Discovery,Graph Convolutional Networks,Machine Learning,Feature Selection,Oncology,Gene Expression"
                     data-authors="Shreyas Shende,Varsha Narayanan,Vishal Fenn,Yiran Huang,Dincer Goksuluk,Gaurav Choudhary,Melih Agraz,Mengjia Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04333v1.html">RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shreyas Shende, Varsha Narayanan, Vishal Fenn et al.
                </div>

                <div class="paper-summary">
                    RGE-GCN is a novel framework that integrates Graph Convolutional Networks with recursive gene elimination for RNA-seq based early cancer detection and biomarker discovery. It addresses the challenge of high-dimensional gene expression data by identifying reliable, compact, and interpretable sets of biomarkers. The method consistently outperforms traditional differential expression tools in accuracy and F1-scores across various cancer types, with identified genes aligning to known cancer pathways.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Lung Cancer</span>
                    
                    <span class="domain-tag">Kidney Cancer</span>
                    
                    <span class="domain-tag">Cervical Cancer</span>
                    
                    <span class="domain-tag">Molecular Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04314v1"
                     data-domains="Pathology,Diagnostic Imaging,Medical Image Analysis,Computational Pathology"
                     data-keywords="Vision Transformers,Hyperspectral Imaging,Spatial-Channel Decoupling,Infrared Pathology,DisentangleFormer,Medical Imaging,Biophysical Cues,Deep Learning"
                     data-authors="Jiashu Liao,Pietro Li√≤,Marc de Kamps,Duygu Sarikaya">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04314v1.html">DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiashu Liao, Pietro Li√≤, Marc de Kamps et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DisentangleFormer, a novel Vision Transformer architecture designed to overcome the limitation of entangled spatial and channel processing in standard self-attention mechanisms. It achieves robust multi-channel vision representation through principled spatial-channel decoupling, addressing a critical issue in hyperspectral imaging, particularly infrared pathology, where channels carry distinct biophysical or biochemical information. DisentangleFormer demonstrates state-of-the-art performance on various hyperspectral benchmarks, including an infrared pathology dataset, while also reducing computational costs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04314v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04314v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04314v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04314v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04287v1"
                     data-domains="Public Health,Infectious Disease Epidemiology,Global Health Security,Preventive Medicine,Pandemic Preparedness"
                     data-keywords="Artificial Intelligence,Horizon Scanning,Infectious Diseases,Public Health Preparedness,Signal Detection,Epidemiology,Decision Support,Risk Assessment"
                     data-authors="Ian Miles,Mayumi Wakimoto,Wagner Meira,Daniela Paula,Daylene Ticiane,Bruno Rosa,Jane Biddulph,Stelios Georgiou,Valdir Ermida">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04287v1.html">Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ian Miles, Mayumi Wakimoto, Wagner Meira et al.
                </div>

                <div class="paper-summary">
                    This review paper comprehensively examines the integration of Artificial Intelligence (AI) into Horizon Scanning specifically for identifying and responding to emerging infectious disease threats. It details how AI tools can bolster signal detection, data monitoring, scenario analysis, and decision support mechanisms within public health preparedness frameworks. The authors also address the inherent risks of AI adoption and propose strategies for its effective implementation and governance, contributing to the understanding of AI's potential and limitations in public health preparedness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Global Health Security</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Pandemic Preparedness</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04287v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04287v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04287v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04287v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04252v1"
                     data-domains="Oncology,Pharmacology,Medicinal Chemistry,Drug Discovery,Cancer Therapy"
                     data-keywords="Deep Learning,ChemBERTa,TDP1 Inhibitors,pIC50 Prediction,Drug Discovery,Cancer Chemoresistance,SMILES,Virtual Screening"
                     data-authors="Baichuan Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04252v1.html">Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Baichuan Zeng
                </div>

                <div class="paper-summary">
                    This paper introduces a deep learning framework that utilizes fine-tuned ChemBERTa, a pre-trained chemical language model, to predict the pIC50 values of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1) directly from SMILES strings. Leveraging a large, imbalanced dataset and advanced pre-training strategies, the developed model significantly outperforms classical baselines and demonstrates competitive performance with Random Forest for identifying potential TDP1 inhibitors. This robust, 3D-structure-free tool aims to accelerate early drug discovery for overcoming cancer chemoresistance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Cancer Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04252v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04252v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04252v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04252v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04238v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Leon Mayer,Piotr Kalinowski,Caroline Ebersbach,Marcel Knopp,Tim R√§dsch,Evangelia Christodoulou,Annika Reinke,Fiona R. Kolbinger,Lena Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04238v1.html">6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Leon Mayer, Piotr Kalinowski, Caroline Ebersbach et al.
                </div>

                <div class="paper-summary">
                    Vision-language models are increasingly integrated into clinical workflows. However, existing benchmarks primarily assess performance on common anatomical presentations and fail to capture the challenges posed by rare variants. To address this gap, we introduce AdversarialAnatomyBench, the first ben...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04238v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04238v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04238v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04238v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04232v1"
                     data-domains="Public Health,Epidemiology,Digital Health,Health Informatics,Infectious Disease Monitoring"
                     data-keywords="digital public health,social media,artificial intelligence,large language models,decentralized networks,disease surveillance,data access,epidemiology"
                     data-authors="Marcel Salath√©,Sharada P. Mohanty">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04232v1.html">Decentralized Social Media and Artificial Intelligence in Digital Public Health Monitoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marcel Salath√©, Sharada P. Mohanty
                </div>

                <div class="paper-summary">
                    This viewpoint paper analyzes the paradox in digital public health monitoring where advanced AI (e.g., LLMs) offers powerful analytical capabilities, yet researchers face dwindling access to social media data due to platform policy changes. It argues for adapting public health surveillance by embracing decentralized social networks and new methodologies, while advocating for policies that ensure privacy-respective access to public data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Infectious Disease Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04232v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04232v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04232v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04232v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04228v1"
                     data-domains="Clinical Decision Support Systems,Diagnostic AI,Medical Research and Discovery,Healthcare Informatics,Personalized Medicine,Drug Interaction Analysis"
                     data-keywords="Large Language Models,Logical Fallacies,Scientific Reasoning,Dual-Inference,Negation,Counterfactual Reasoning,Modus Ponens,Denying the Antecedent"
                     data-authors="Peter B. Walker,Hannah Davidson,Aiden Foster,Matthew Lienert,Thomas Pardue,Dale Russell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04228v1.html">Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Peter B. Walker, Hannah Davidson, Aiden Foster et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the susceptibility of Large Language Models (LLMs) to logical fallacies, especially when reasoning with negation or faulty premises, due to their prevalent affirmation-based inference. It demonstrates these systematic weaknesses in existing LLMs within scientific domains and introduces a novel dual-reasoning training framework. This framework integrates affirmative generation with structured counterfactual denial, computationally mirroring "denying the antecedent," to enable models that both affirm valid and explicitly reject invalid inferences, enhancing robustness and logical alignment with human reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                    <span class="domain-tag">Medical Research and Discovery</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04228v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04228v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04228v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04228v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04225v1"
                     data-domains="Genetics,Genomics,Biomedical Research,Genetic Epidemiology,Public Health Informatics"
                     data-keywords="Differential Privacy,GWAS,Genome-Wide Association Studies,Phenotype Randomization,Privacy-preserving,Summary Statistics,Optimization,Personalized Priors"
                     data-authors="Anupama Nandi,Seth Neel,Hyunghoon Cho">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04225v1.html">GOPHER: Optimization-based Phenotype Randomization for Genome-Wide Association Studies with Differential Privacy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anupama Nandi, Seth Neel, Hyunghoon Cho
                </div>

                <div class="paper-summary">
                    This paper introduces GOPHER, a suite of practical differential privacy (DP) mechanisms designed to release comprehensive genome-wide association study (GWAS) summary statistics while rigorously protecting participant privacy. By employing an optimization-based randomization approach and personalized priors, GOPHER significantly reduces the noise typically associated with DP in GWAS, demonstrating high accuracy on UK Biobank datasets with both real and simulated phenotypes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genetics</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Genetic Epidemiology</span>
                    
                    <span class="domain-tag">Public Health Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04225v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04225v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04225v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04225v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04210v1"
                     data-domains="General healthcare,Clinical decision support,Digital health,Medical informatics,AI in medicine"
                     data-keywords="healthcare AI,LLM safety,preference alignment,Kahneman-Tversky Optimization,Direct Preference Optimization,conversational medical assistants,patient safety,adversarial robustness"
                     data-authors="Huy Nghiem,Swetasudha Panda,Devashish Khatwani,Huy V. Nguyen,Krishnaram Kenthapadi,Hal Daum√©">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04210v1.html">Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Huy Nghiem, Swetasudha Panda, Devashish Khatwani et al.
                </div>

                <div class="paper-summary">
                    This paper presents an iterative post-deployment alignment framework that leverages Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to enhance the safety and trustworthiness of conversational medical AI assistants. By refining Large Language Models (LLMs) against domain-specific safety signals, the framework achieved up to a 42% improvement in detecting harmful queries, while also highlighting critical trade-offs with erroneous refusals and architecture-dependent calibration biases. This work contributes to balancing patient safety, user trust, and clinical utility in healthcare AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General healthcare</span>
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                    <span class="domain-tag">AI in medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04210v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04210v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04210v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04210v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04207v1"
                     data-domains="Neurology,Primary Care,Diagnostic Medicine,AI in Healthcare"
                     data-keywords="Multi-agent system,Large Language Models (LLM),Clinical Decision Support System (CDSS),Secondary Headache,Primary Care,Orchestrator-Specialist Architecture,Explainable AI,Diagnostic Accuracy"
                     data-authors="Xizhi Wu,Nelly Estefanie Garduno-Rapp,Justin F Rousseau,Mounika Thakkallapally,Hang Zhang,Yuelyu Ji,Shyam Visweswaran,Yifan Peng,Yanshan Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04207v1.html">Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xizhi Wu, Nelly Estefanie Garduno-Rapp, Justin F Rousseau et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an LLM-based multi-agent clinical decision support system, utilizing an orchestrator-specialist architecture, designed for explicit and interpretable secondary headache diagnosis from free-text clinical vignettes. The system, particularly when guided by clinical practice guidelines (GPrompt), demonstrated significantly higher diagnostic accuracy (F1 scores) compared to single-LLM baselines, with larger gains observed in smaller LLMs. This architecture demonstrates that structured multi-agent reasoning improves accuracy and offers a transparent approach for explainable decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04207v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04207v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04207v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04207v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04187v1"
                     data-domains="Pathology,Histopathology,Oncology,Neuropathology,Diagnostic Medicine"
                     data-keywords="Computational Pathology,Digital Pathology,Artificial Intelligence,Histopathology,Real-time AI,Platform-agnostic,Whole Slide Imaging,Telepathology"
                     data-authors="Jinzhen Hu,Kevin Faust,Parsa Babaei Zadeh,Adrienn Bourkas,Shane Eaton,Andrew Young,Anzar Alvi,Dimitrios George Oreopoulos,Ameesha Paliwal,Assem Saleh Alrumeh,Evelyn Rose Kamski-Hennekam,Phedias Diamandis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04187v1.html">OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jinzhen Hu, Kevin Faust, Parsa Babaei Zadeh et al.
                </div>

                <div class="paper-summary">
                    OnSight Pathology is a novel, platform-agnostic computer vision software designed to provide real-time AI inferences for histopathology. It overcomes existing barriers to AI adoption by operating locally on consumer-grade PCs via continuous screen captures, demonstrating robust utility across various diagnostic tasks and digital slide viewers without complex software integration. This solution aims to enhance diagnostic accuracy and accessibility by delivering secure and cost-effective AI analysis directly to the pathologist's workflow.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neuropathology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04187v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04187v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04187v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04187v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.04034v1"
                     data-domains="Medical Imaging (Radiology, Pathology),Diagnostic AI,Clinical Decision Support Systems,Personalized Medicine"
                     data-keywords="Out-of-Distribution Detection,Domain Feature Collapse,Information Theory,Information Bottleneck,Supervised Learning,Medical Imaging,Transfer Learning,Domain Filtering"
                     data-authors="Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.04034v1.html">Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hong Yang, Devroop Kar, Qi Yu et al.
                </div>

                <div class="paper-summary">
                    This paper offers the first theoretical explanation for the catastrophic failure of state-of-the-art Out-of-Distribution (OOD) detection methods when models are trained on single-domain datasets. It proves that supervised learning on single-domain data inevitably leads to "domain feature collapse," where domain-specific information is completely discarded, resolving this failure mode by preserving domain information through a novel domain filtering technique using pretrained representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging (Radiology, Pathology)</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.04034v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.04034v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.04034v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.04034v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.03994v1"
                     data-domains="Clinical Decision Support,Patient Engagement Platforms,Medical Information Retrieval,Telemedicine,Health Administration,Medical Education"
                     data-keywords="LLMs,policy violation detection,out-of-distribution detection,activation-space whitening,AI governance,medical services,regulatory compliance,computational ethics"
                     data-authors="Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.03994v1.html">Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Oren Rachmil, Roy Betser, Itay Gershon et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, training-free method for detecting policy violations in large language models (LLMs) by framing it as an out-of-distribution (OOD) detection problem. It employs activation-space whitening to decorrelate and standardize LLM hidden activations, using the Euclidean norm as a compliance score. The approach achieves state-of-the-art results on a challenging policy benchmark, offering an efficient and interpretable solution for robust LLM governance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Patient Engagement Platforms</span>
                    
                    <span class="domain-tag">Medical Information Retrieval</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Health Administration</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.03994v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.03994v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.03994v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.03994v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.03883v1"
                     data-domains="Oncology,Gastroenterology,Colorectal Surgery,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Rectal Cancer,Watch-and-Wait,Tumor Regrowth,Endoscopy,Deep Learning,Swin Transformer,Cross-Attention,Clinical Complete Response"
                     data-authors="Jorge Tapias Gomez,Despoina Kanata,Aneesh Rangnekar,Christina Lee,Julio Garcia-Aguilar,Joshua Jesse Smith,Harini Veeraraghavan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.03883v1.html">Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jorge Tapias Gomez, Despoina Kanata, Aneesh Rangnekar et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Dual Cross-Attention Siamese Transformer (SSDCA), a novel deep learning model designed for the early and objective detection of local tumor regrowth in rectal cancer patients undergoing watch-and-wait surveillance. By analyzing longitudinal endoscopic images from restaging and follow-up, SSDCA accurately distinguishes clinical complete response from local regrowth, achieving high sensitivity and robustness to imaging variations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Colorectal Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.03883v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.03883v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.03883v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.03883v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-07 06:25:08</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>