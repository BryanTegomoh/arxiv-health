<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">10</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">10</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">38</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (4), Medical Imaging (3), Emergency Medicine (2)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (3)</option>
                        
                        <option value="Emergency Medicine">Emergency Medicine (2)</option>
                        
                        <option value="Radiology">Radiology (2)</option>
                        
                        <option value="Pathology">Pathology (2)</option>
                        
                        <option value="Cardiology">Cardiology (2)</option>
                        
                        <option value="Predictive Medicine">Predictive Medicine (2)</option>
                        
                        <option value="Critical Care">Critical Care (1)</option>
                        
                        <option value="Hospital Administration">Hospital Administration (1)</option>
                        
                        <option value="Patient Safety">Patient Safety (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.14683v1"
                     data-domains="Critical Care,Emergency Medicine,Hospital Administration,Patient Safety,Healthcare Informatics,Triage"
                     data-keywords="Machine Learning,Early Warning System,Patient Deterioration,Electronic Health Records (EHR),Explainable AI (SHAP),Predictive Analytics,Critical Care,Hospital Operations"
                     data-authors="Dimitris Bertsimas,Yu Ma,Kimberly Villalobos Carballo,Gagan Singh,Michal Laskowski,Jeff Mather,Dan Kombert,Howard Haronian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14683v1.html">Early Warning Index for Patient Deteriorations in Hospitals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitris Bertsimas, Yu Ma, Kimberly Villalobos Carballo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Early Warning Index (EWI), a multimodal machine learning framework designed to predict patient deterioration in hospitals, encompassing risks of ICU admission, emergency response team dispatch, and mortality. Leveraging heterogeneous structured and unstructured EHR data, EWI integrates a human-in-the-loop process with explainable AI (SHAP) to provide interpretable risk assessments. Deployed as a hospital dashboard, it achieved a C-statistic of 0.796 and is currently used as a triage tool to proactively manage at-risk patients.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Hospital Administration</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14683v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14683v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14683v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14683v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14675v1"
                     data-domains="Pharmaceutical Modeling,Drug Discovery,Computational Biology,Public Health Informatics,Emergency Medicine,Personalized Medicine"
                     data-keywords="Echo State Networks,Reservoir Computing,Fractal Activation Functions,Chaotic Activation Functions,Echo State Property,Quantized Activation Functions,Machine Learning,Robust AI"
                     data-authors="Rae Chipera,Jenny Du,Irene Tsapara">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14675v1.html">Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.65</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rae Chipera, Jenny Du, Irene Tsapara
                </div>

                <div class="paper-summary">
                    This paper challenges the conventional reliance on smooth activation functions in reservoir computing by systematically investigating non-smooth variants, including chaotic, stochastic, and fractal functions, in echo state networks. It demonstrates that several non-smooth functions, notably the fractal Cantor function, not only maintain stability but significantly outperform traditional smooth activations in convergence speed and spectral radius tolerance, indicating potential for more robust AI models in critical applications like pharmaceutical modeling.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceutical Modeling</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Public Health Informatics</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14648v1"
                     data-domains="Neuro-oncology,Radiology,Medical Imaging,Oncology,Pediatric Oncology"
                     data-keywords="Brain Tumors,MRI Segmentation,Radiomics,Deep Learning,Model Ensemble,Neuro-oncology,BraTS Challenge,Medical Imaging"
                     data-authors="Daniel Capell√°n-Mart√≠n,Abhijeet Parida,Zhifan Jiang,Nishad Kulkarni,Krithika Iyer,Austin Tapp,Syed Muhammad Anwar,Mar√≠a J. Ledesma-Carbayo,Marius George Linguraru">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14648v1.html">Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Capell√°n-Mart√≠n, Abhijeet Parida, Zhifan Jiang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a flexible, modular, and adaptable pipeline for robust segmentation of diverse brain tumors on multi-parametric MRI, addressing challenges posed by varying tumor types. It improves performance by integrating state-of-the-art models, applying radiomic-guided subtyping for balanced training, and utilizing custom lesion-wise processing steps. The pipeline achieved competitive results on various BraTS challenge datasets, demonstrating the efficacy of lesion-aware processing and model selection for generalizable segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pediatric Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14648v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14648v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14648v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14648v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14640v1"
                     data-domains="Pathology,Oncology,Hematology,Diagnostic Imaging (Digital Pathology)"
                     data-keywords="Lymphoma Subtyping,Whole Slide Imaging (WSI),Deep Learning,Multiple Instance Learning (MIL),Histopathology,Multicenter Study,Generalization,Foundation Models"
                     data-authors="Rao Muhammad Umer,Daniel Sens,Jonathan Noll,Christian Matek,Lukas Wolfseher,Rainer Spang,Ralf Huss,Johannes Raffler,Sarah Reinke,Wolfram Klapper,Katja Steiger,Kristina Schwamborn,Carsten Marr">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14640v1.html">A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rao Muhammad Umer, Daniel Sens, Jonathan Noll et al.
                </div>

                <div class="paper-summary">
                    This paper presents the first multicenter lymphoma subtyping benchmark dataset for deep learning, leveraging HE-stained whole slide images. It systematically evaluates five pathology foundation models combined with two Multiple Instance Learning aggregators across various magnifications, achieving over 80% balanced accuracy on in-distribution data but revealing a substantial drop to around 60% on out-of-distribution sets, highlighting critical generalization challenges.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Hematology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging (Digital Pathology)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14640v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14640v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14640v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14640v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14594v1"
                     data-domains="Oncology,Pathology,Genomics,Prognostics,Medical Imaging"
                     data-keywords="Cancer survival prediction,Multimodal learning,Large Language Models (LLM),Pathology images (WSI),Genomic data,Prognostic knowledge,Deep learning,Attention mechanisms"
                     data-authors="Chenyu Zhao,Yingxue Xu,Fengtao Zhou,Yihui Wang,Hao Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14594v1.html">LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chenyu Zhao, Yingxue Xu, Fengtao Zhou et al.
                </div>

                <div class="paper-summary">
                    This paper introduces KEMM, an LLM-driven knowledge-enhanced multimodal model for cancer survival prediction, addressing challenges with high-dimensional data and insufficient labels. KEMM integrates LLM-refined expert reports and LLM-generated prognostic background knowledge, leveraging a Knowledge-Enhanced Cross-Modal (KECM) attention module to extract discriminative features. The model achieves state-of-the-art performance across five cancer datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14594v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14594v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14594v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14594v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14563v1"
                     data-domains="Cardiology,Predictive Medicine,Clinical Informatics,Public Health"
                     data-keywords="Cardiovascular Disease,Deep Learning,Gated Recurrent Units,Multi-Head Self-Attention,Tabular Data,Clinical Prediction,Hybrid Model,Early Detection"
                     data-authors="Tejaswani Dash,Gautam Datla,Anudeep Vurity,Tazeem Ahmad,Mohd Adnan,Saima Rafi,Saisha Patro,Saina Patro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14563v1.html">Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tejaswani Dash, Gautam Datla, Anudeep Vurity et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Residual GRU+MHSA, a novel, lightweight hybrid deep learning architecture designed for accurate and efficient cardiovascular disease (CVD) detection from tabular clinical records. The model, which integrates residual GRU units, channel reweighting, and multi-head self-attention, achieved superior performance on the UCI Heart Disease dataset, outperforming various classical and deep learning baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14559v1"
                     data-domains="Clinical Recommendation Systems,Predictive Medicine,Digital Health,Patient Monitoring,Therapeutic Interventions"
                     data-keywords="Counterfactual Explanations,Time Series,Explainable AI (XAI),Clinical Decision Support,Algorithmic Recourse,Temporal Coherence,Human-Centered AI,Robustness Analysis"
                     data-authors="Emmanuel C. Chukwu,Rianne M. Schouten,Monique Tabak,Mykola Pechenizkiy">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14559v1.html">Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Emmanuel C. Chukwu, Rianne M. Schouten, Monique Tabak et al.
                </div>

                <div class="paper-summary">
                    This paper critically examines current counterfactual explanation techniques for time series in clinical settings, arguing they are inadequate due to static data assumptions and a focus on minimal perturbations, failing to reflect the dynamic, causal, and human-centered nature of medical interventions. It advocates for a paradigm shift towards human-centered, temporally coherent, and actionable counterfactuals that align with clinical reasoning. The authors support their position by demonstrating that existing state-of-the-art methods are highly sensitive to stochastic noise, severely limiting their reliability and practical utility in real-world clinical environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Recommendation Systems</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Patient Monitoring</span>
                    
                    <span class="domain-tag">Therapeutic Interventions</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14559v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14559v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14559v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14559v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14556v1"
                     data-domains="Radiology,Medical Imaging,Oncology,Image-Guided Surgery,Diagnostic Imaging,Neuroimaging,Cardiology"
                     data-keywords="Medical Image Registration,Non-Rigid Registration (NRR),Artificial Intelligence (AI),Deep Learning (DL),Generalizable AI,Multi-Modal Imaging,Clinical Workflow,3D Registration"
                     data-authors="Sneha Sree C.,Dattesh Shanbhag,Sudhanya Chatterjee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14556v1.html">Test Time Optimized Generalized AI-based Medical Image Registration Method</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sneha Sree C., Dattesh Shanbhag, Sudhanya Chatterjee
                </div>

                <div class="paper-summary">
                    This paper introduces a novel AI-driven 3D non-rigid medical image registration (NRR) framework designed to overcome the limitations of existing methods, such as high computational costs, extensive parameter tuning, and the need for task-specific retraining. The core contribution is a generalizable AI approach that eliminates the requirement for anatomy- or modality-specific customization, enabling streamlined integration into diverse clinical environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Image-Guided Surgery</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14556v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14556v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14556v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14556v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14329v1"
                     data-domains="Neurology,Physical Medicine and Rehabilitation,Geriatrics,Kinesiology,Biomedical Engineering"
                     data-keywords="Stroke rehabilitation,gait analysis,wearable sensors,deep reinforcement learning,generative models,neuromuscular control,personalized medicine,motor recovery"
                     data-authors="Yanning Dai,Chenyu Tang,Ruizhi Zhang,Wenyu Yang,Yilan Zhang,Yuhui Wang,Junliang Chen,Xuhang Chen,Ruimou Xie,Yangyue Cao,Qiaoying Li,Jin Cao,Tao Li,Hubin Zhao,Yu Pan,Arokia Nathan,Xin Gao,Peter Smielewski,Shuo Gao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14329v1.html">A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yanning Dai, Chenyu Tang, Ruizhi Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a data-physics hybrid generative model designed to reconstruct patient-specific neuromuscular control from a single level-ground walking trial, enabling dynamic prediction of task-conditioned locomotion for stroke survivors. By integrating wearable sensor data with a physics controller and deep reinforcement learning, the framework generates physically plausible gait simulations for challenging scenarios like slopes and stairs. In a pilot study, clinicians using these predictions to guide rehabilitation achieved significantly larger gains in Fugl-Meyer lower-extremity scores compared to control clinicians.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Physical Medicine and Rehabilitation</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Kinesiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14329v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14329v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14329v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14329v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.14320v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.AI,cs.CY,cs.LG"
                     data-authors="Shuai Dong,Jie Zhang,Guoying Zhao,Shiguang Shan,Xilin Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.14320v1.html">Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-16</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shuai Dong, Jie Zhang, Guoying Zhao et al.
                </div>

                <div class="paper-summary">
                    Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.14320v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.14320v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.14320v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.14320v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-17 06:15:40</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>