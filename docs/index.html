<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">138</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (13), Diagnostic Imaging (10), Medical Imaging (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (13)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (10)</option>
                        
                        <option value="Neurology">Neurology (9)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (9)</option>
                        
                        <option value="Cardiology">Cardiology (6)</option>
                        
                        <option value="Preventive Medicine">Preventive Medicine (4)</option>
                        
                        <option value="Pharmacology">Pharmacology (4)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (4)</option>
                        
                        <option value="Medicinal Chemistry">Medicinal Chemistry (3)</option>
                        
                        <option value="Medical imaging">Medical Imaging (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.09867v1"
                     data-domains="Clinical reasoning,Diagnosis support,Medical report generation,Medical imaging analysis"
                     data-keywords="medical AI,multimodal unlearning,HIPAA compliance,GDPR,machine unlearning,data privacy,hierarchical data,MLLM"
                     data-authors="Fengli Wu,Vaidehi Patil,Jaehong Yoon,Yue Zhang,Mohit Bansal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09867v1.html">MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fengli Wu, Vaidehi Patil, Jaehong Yoon et al.
                </div>

                <div class="paper-summary">
                    MedForget is a novel hierarchy-aware multimodal unlearning testbed designed to address critical privacy and compliance challenges, such as the "right to be forgotten," in medical AI systems. It models hospital data hierarchically and uses multimodal instances with specific unlearning targets, revealing that current state-of-the-art unlearning methods struggle to achieve complete, hierarchy-aware forgetting without compromising diagnostic performance. Furthermore, it demonstrates that fine-grained unlearning leaves models vulnerable to reconstruction attacks, while coarse-grained unlearning offers more resistance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical reasoning</span>
                    
                    <span class="domain-tag">Diagnosis support</span>
                    
                    <span class="domain-tag">Medical report generation</span>
                    
                    <span class="domain-tag">Medical imaging analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09867v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09867v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09867v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09867v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09801v1"
                     data-domains="Radiology,Neuroradiology,Neuro-oncology,Medical Imaging"
                     data-keywords="Semi-supervised learning,Multi-modal imaging,Brain tumor segmentation,MRI,Modality fusion,Channel attention,Medical image analysis,Deep learning"
                     data-authors="Tien-Dat Chung,Ba-Thinh Lam,Thanh-Huy Nguyen,Thien Nguyen,Nguyen Lan Vi Vu,Hoang-Loc Cao,Phat Kim Huynh,Min Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09801v1.html">Modality-Specific Enhancement and Complementary Fusion for Semi-Supervised Multi-Modal Brain Tumor Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tien-Dat Chung, Ba-Thinh Lam, Thanh-Huy Nguyen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel semi-supervised multi-modal framework for brain tumor segmentation, specifically addressing challenges in integrating complementary information from various MRI modalities despite semantic discrepancies and misalignment. The proposed method utilizes a Modality-specific Enhancing Module (MEM) to strengthen unique features within each modality and a Complementary Information Fusion (CIF) module for adaptive cross-modal knowledge exchange. Experiments on the BraTS 2019 dataset demonstrate significant improvements in Dice and Sensitivity scores over existing baselines, particularly in scenarios with scarce labeled data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09801v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09801v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09801v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09801v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09784v1"
                     data-domains="Pharmaceutical formulation,Drug delivery,Biomaterials engineering,Medical device design"
                     data-keywords="Polymer solubility,SMILES strings,Deep learning,Machine learning,Pharmaceutical formulation,Drug delivery,Biomaterials,High-throughput screening"
                     data-authors="Andrew Reinhard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09784v1.html">Predicting Polymer Solubility in Solvents Using SMILES Strings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Andrew Reinhard
                </div>

                <div class="paper-summary">
                    This paper presents a deep learning framework designed to predict polymer solubility (expressed as weight percent) directly from the SMILES representations of both polymers and solvents. Utilizing a dataset of 8,049 polymer-solvent pairs and a fully connected neural network, the model achieved strong agreement with actual solubility values. The framework demonstrated robust generalizability on 25 unseen experimental combinations, validating its potential for scalable solubility prediction and high-throughput solvent screening, particularly relevant for pharmaceutical formulation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceutical formulation</span>
                    
                    <span class="domain-tag">Drug delivery</span>
                    
                    <span class="domain-tag">Biomaterials engineering</span>
                    
                    <span class="domain-tag">Medical device design</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09784v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09784v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09784v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09784v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09779v1"
                     data-domains="Cardiology,Radiology,Medical Imaging,Computational Medicine"
                     data-keywords="Few-shot learning,Cardiac MRI segmentation,Synthetic data generation,Lattice-of-Experts,Pathology-constrained,Zero-shot generalization,Medical image analysis,Deep learning"
                     data-authors="Mohamed Elbayumi,Mohammed S. M. Elbaz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09779v1.html">PathCo-LatticE: Pathology-Constrained Lattice-Of Experts Framework for Fully-supervised Few-Shot Cardiac MRI Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohamed Elbayumi, Mohammed S. M. Elbaz
                </div>

                <div class="paper-summary">
                    PathCo-LatticE is a novel fully supervised few-shot learning framework for cardiac MRI segmentation that overcomes data scarcity and domain shift limitations by generating pathology-guided synthetic supervision. It employs a Virtual Patient Engine for synthetic data generation, Self-Reinforcing Interleaved Validation for robust evaluation, and a dynamic Lattice-of-Experts for zero-shot generalization. The framework significantly outperforms state-of-the-art FSL methods in out-of-distribution settings, achieving near fully supervised performance with minimal labeled real data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09779v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09779v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09779v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09779v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09757v1"
                     data-domains="Drug Discovery,Pharmaceutical Research,Medicinal Chemistry,Computational Chemistry,Pharmacology"
                     data-keywords="Molecular Transformers,Mechanistic Interpretability,Sparse Autoencoders,Drug Design,Chemical Generation,Cheminformatics,Artificial Intelligence,Machine Learning"
                     data-authors="Kristof Varadi,Mark Marosi,Peter Antal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09757v1.html">Circuits, Features, and Heuristics in Molecular Transformers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kristof Varadi, Mark Marosi, Peter Antal
                </div>

                <div class="paper-summary">
                    This paper conducts a detailed mechanistic analysis of autoregressive transformers trained on drug-like small molecules to unravel how these models capture the fundamental rules of molecular representation. It identifies internal computational patterns consistent with both low-level syntactic parsing and more abstract chemical validity constraints, leveraging sparse autoencoders (SAEs) to extract feature dictionaries linked to chemically relevant activation patterns. The research demonstrates that these mechanistic insights significantly enhance predictive performance in various practical settings, advancing the interpretability and utility of AI in chemical design.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Computational Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09757v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09757v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09757v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09757v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09665v1"
                     data-domains="Medical imaging,Diagnostic AI,Radiology,Pathology,Public health (due to fairness considerations)"
                     data-keywords="Fair classification,Ensemble learning,Low-data regimes,Medical imaging,Algorithmic fairness,Data scarcity,Diagnostic AI,Health equity"
                     data-authors="Jonathan Rystr√∏m,Zihao Fu,Chris Russell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09665v1.html">OxEnsemble: Fair Ensembles for Low-Data Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jonathan Rystr√∏m, Zihao Fu, Chris Russell
                </div>

                <div class="paper-summary">
                    OxEnsemble is a novel ensemble learning approach designed to achieve fair classification in challenging low-data and demographically unbalanced settings, particularly relevant to medical imaging where false negatives can be fatal. It efficiently trains ensembles by aggregating predictions from members, each specifically constrained for fairness, demonstrating superior fairness-accuracy trade-offs and more consistent outcomes on medical datasets compared to existing methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Public health (due to fairness considerations)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09665v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09665v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09665v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09665v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09644v1"
                     data-domains="Medical imaging,Radiology,Clinical research,Computational pathology,Medical informatics"
                     data-keywords="Medical imaging,Artificial intelligence (AI),Open-source platform,Distributed learning,Data privacy,Reproducibility,Multi-center studies,Workflow orchestration,Clinical research"
                     data-authors="√únal Ak√ºnal,Markus Bujotzek,Stefan Denner,Benjamin Hamm,Klaus Kades,Philipp Schader,Jonas Scherer,Marco Nolden,Peter Neher,Ralf Floca,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09644v1.html">Kaapana: A Comprehensive Open-Source Platform for Integrating AI in Medical Imaging Research Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> √únal Ak√ºnal, Markus Bujotzek, Stefan Denner et al.
                </div>

                <div class="paper-summary">
                    Kaapana is a comprehensive open-source platform designed to overcome critical challenges in developing generalizable AI for medical imaging, such as regulatory constraints and fragmented infrastructure. It unifies data ingestion, cohort curation, processing workflows, and result inspection under a common user interface, enabling secure, distributed multi-center studies. By bringing the algorithm to the data, Kaapana improves reproducibility and scalability, fostering collaboration between clinicians and data scientists while maintaining institutional control over sensitive data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Clinical research</span>
                    
                    <span class="domain-tag">Computational pathology</span>
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09644v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09644v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09644v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09644v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09636v1"
                     data-domains="Mental Health,Psychiatry,Clinical Psychology,Digital Health"
                     data-keywords="Large Language Models,Mental Health,Clinical Reasoning,AI Assessment,Benchmarking,Reinforcement Learning,Reliability,Post-Training"
                     data-authors="Mengxi Xiao,Kailai Yang,Pengde Zhao,Enze Zhang,Ziyan Kuang,Zhiwei Liu,Weiguang Han,Shu Liao,Lianting Huang,Jinpeng Hu,Min Peng,Qianqian Xie,Sophia Ananiadou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09636v1.html">MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mengxi Xiao, Kailai Yang, Pengde Zhao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MentraSuite, a unified framework designed to advance reliable mental health reasoning in Large Language Models (LLMs). It proposes MentraBench, a comprehensive benchmark spanning various reasoning aspects and tasks, and Mindora, a post-trained LLM optimized for faithful and coherent reasoning through a hybrid SFT-RL approach. Mindora achieves superior performance and remarkable reasoning reliability on MentraBench, demonstrating its effectiveness in complex mental health scenarios.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09636v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09636v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09636v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09636v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09610v1"
                     data-domains="Neurology,Rehabilitation Medicine,Speech-Language Pathology,Geriatrics,Palliative Care"
                     data-keywords="Augmentative and Alternative Communication (AAC),Motor Neuron Disease (MND),Multimodal Communication,Image Recognition,Natural Language Generation (NLG),Assistive Technology,Human-Computer Interaction,Communication Aids"
                     data-authors="Boyin Yang,Puming Jiang,Per Ola Kristensson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09610v1.html">ImageTalk: Designing a Multimodal AAC Text Generation System Driven by Image Recognition and Natural Language Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Boyin Yang, Puming Jiang, Per Ola Kristensson
                </div>

                <div class="paper-summary">
                    This paper introduces ImageTalk, a novel multimodal augmentative and alternative communication (AAC) system for people living with Motor Neuron Disease (plwMND), addressing the limitations of traditional AAC systems. Leveraging image recognition and natural language generation, ImageTalk significantly enhances communication efficiency, demonstrating pronounced keystroke savings of 95.6% alongside high user satisfaction and consistent performance. The research also distills key design guidelines and user requirement levels for future AI-assisted AAC systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Palliative Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09610v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09610v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09610v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09610v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09591v1"
                     data-domains="Sleep Medicine,Neurology,Cardiology,Pulmonary Medicine,Preventive Medicine"
                     data-keywords="Polysomnography,Self-supervised learning,Foundation models,Sleep staging,Apnea diagnosis,Disease prediction,Mortality prediction,Contrastive learning"
                     data-authors="Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09591v1.html">Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Magnus Ruud Kjaer, Rahul Thapa, Gauri Ganjoo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Stanford Sleep Bench, a large-scale, multimodal polysomnography (PSG) dataset comprising over 17,000 recordings, to address the lack of shared benchmarks for sleep foundation models. It systematically evaluates self-supervised representation learning (SSRL) pre-training methods across various sleep-related and clinical disease prediction tasks. The study finds that contrastive learning significantly excels in mortality and disease prediction compared to other SSRL approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonary Medicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09591v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09591v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09591v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09591v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09579v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Pathology Detection"
                     data-keywords="Vision Transformers,Convolutional Neural Networks,Object Recognition,Object Detection,Medical Image Classification,ChestX-ray14,Swin Transformer,Data Augmentation"
                     data-authors="Dimitrios N. Vlachogiannis,Dimitrios A. Koutsomitropoulos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09579v1.html">Hands-on Evaluation of Visual Transformers for Object Recognition and Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios N. Vlachogiannis, Dimitrios A. Koutsomitropoulos
                </div>

                <div class="paper-summary">
                    This paper evaluates various Vision Transformers (ViTs), including pure, hierarchical, and hybrid types, against traditional Convolutional Neural Networks (CNNs) across object recognition, detection, and medical image classification tasks. The study found that hierarchical and hybrid ViTs, such as Swin and CvT, offer an excellent balance of accuracy and computational efficiency, often outperforming CNNs, particularly in tasks requiring a global understanding of visual contexts like medical imaging. Additionally, data augmentation significantly improved performance on medical images, notably with the Swin Transformer.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pathology Detection</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09579v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09579v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09579v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09579v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09566v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Development,Biotechnology,Precision Medicine,Therapeutics"
                     data-keywords="Drug discovery,Molecular design,Generative AI,Language models,Reinforcement learning,Monte Carlo tree search,Targeted therapeutics,Pharmacological properties"
                     data-authors="Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09566v1.html">Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junkai Ji, Zhangfan Yang, Dong Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Trio, a novel framework for closed-loop targeted molecular design that integrates fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search. Trio addresses limitations of traditional and previous generative drug discovery methods by enabling context-aware fragment assembly, enforcing physicochemical and synthetic feasibility, and strategically balancing exploration and exploitation in chemical space. Experimental results demonstrate that Trio reliably generates chemically valid and pharmacologically enhanced ligands, significantly outperforming state-of-the-art approaches in binding affinity, drug-likeness, synthetic accessibility, and molecular diversity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09525v1"
                     data-domains="Orthopedic surgery,Musculoskeletal radiology,Trauma surgery,Medical imaging"
                     data-keywords="CT imaging,Tibia fracture,Surgical planning,Neural registration,Autoencoder,Spatial Transformer Network,Bone reconstruction,Medical imaging,Deep learning,Masked input"
                     data-authors="Hongyou Zhou,Cederic A√ümann,Alaa Bejaoui,Heiko Tzsch√§tzsch,Mark Heyland,Julian Zierke,Niklas Tuttle,Sebastian H√∂lzl,Timo Auer,David A. Back,Marc Toussaint">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09525v1.html">Masked Registration and Autoencoding of CT Images for Predictive Tibia Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hongyou Zhou, Cederic A√ümann, Alaa Bejaoui et al.
                </div>

                <div class="paper-summary">
                    This research introduces a novel deep learning framework that combines neural registration and autoencoders to predict a patient-specific healthy tibia reconstruction from a fractured CT scan. The system assists surgical planning by transforming raw CTs to a standardized coordinate system and then generating a prediction of the intact bone, critically designed to be robust to masked (fractured) input.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedic surgery</span>
                    
                    <span class="domain-tag">Musculoskeletal radiology</span>
                    
                    <span class="domain-tag">Trauma surgery</span>
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09517v1"
                     data-domains="Psychiatry,Neurology,Clinical Diagnostics,Computational Neuroscience,Mental Health"
                     data-keywords="Major Depressive Disorder,EEG,Quanvolutional Neural Network,Deep Learning,Explainable AI,Biomarkers,Diagnostic Tool,Spectrotemporal Patterns"
                     data-authors="Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09517v1.html">QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nabil Anan Orka, Ehtashamul Haque, Maftahul Jannat et al.
                </div>

                <div class="paper-summary">
                    QuanvNeXt is an end-to-end fully quanvolutional neural network designed for EEG-based detection of major depressive disorder (MDD), incorporating a novel Cross Residual block for enhanced feature learning and parameter efficiency. The model achieved high diagnostic performance with 93.1% accuracy and 97.2% AUC-ROC on two datasets, surpassing state-of-the-art models, while also demonstrating well-calibrated predictions and interpretable identification of disease-specific spectrotemporal patterns. This establishes QuanvNeXt as an efficient and reliable approach for objective MDD diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09517v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09517v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09517v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09517v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09492v1"
                     data-domains="Medical Imaging,Radiology,Pathology (Histopathology),Dermatology (skin lesion analysis),Ophthalmology (retinal disease detection),Neurology (brain lesion detection)"
                     data-keywords="Self-supervised learning,State-space models,Vision Mamba,Linear-time complexity,Medical imaging,Pathology detection,Representation learning,High-resolution imaging"
                     data-authors="Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09492v1.html">StateSpace-SSL: Linear-Time Self-supervised Learning for Plant Disease Detectio</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abdullah Al Mamun, Miaohua Zhang, David Ahmedt-Aristizabal et al.
                </div>

                <div class="paper-summary">
                    StateSpace-SSL introduces a linear-time self-supervised learning framework for image analysis, utilizing a Vision Mamba state-space encoder to efficiently model continuous patterns and long-range dependencies. This approach overcomes the limitations of CNNs in capturing evolving structures and the quadratic computational cost of Transformers for high-resolution images, demonstrating superior performance in plant disease detection and learning compact, lesion-focused features.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology (Histopathology)</span>
                    
                    <span class="domain-tag">Dermatology (skin lesion analysis)</span>
                    
                    <span class="domain-tag">Ophthalmology (retinal disease detection)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09492v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09492v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09492v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09492v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09461v1"
                     data-domains="Reproductive Medicine,Embryology,Infertility Treatment,Assisted Reproductive Technologies"
                     data-keywords="Infertility,IVF,Embryo Selection,Cytoplasmic Strings,Time-Lapse Imaging,Deep Learning,Computer Vision,Biomarker"
                     data-authors="Anabia Sohail,Mohamad Alansari,Ahmed Abughali,Asmaa Chehab,Abdelfatah Ahmed,Divya Velayudhan,Sajid Javed,Hasan Al Marzouqi,Ameena Saad Al-Sumaiti,Junaid Kashir,Naoufel Werghi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09461v1.html">Cytoplasmic Strings Analysis in Human Embryo Time-Lapse Videos using Deep Learning Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anabia Sohail, Mohamad Alansari, Ahmed Abughali et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the first deep learning framework for automated detection and localization of Cytoplasmic Strings (CS) in human IVF embryo time-lapse videos, addressing the current subjective and labor-intensive manual assessment. By developing a novel Uncertainty-aware Contractive Embedding (NUCE) loss for highly imbalanced data and employing an RF-DETR-based localizer, the framework aims to improve embryo selection by objectively identifying this emerging biomarker.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Reproductive Medicine</span>
                    
                    <span class="domain-tag">Embryology</span>
                    
                    <span class="domain-tag">Infertility Treatment</span>
                    
                    <span class="domain-tag">Assisted Reproductive Technologies</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09461v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09461v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09461v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09461v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09422v1"
                     data-domains="Cardiology,Cardiovascular Imaging,Diagnostic Imaging,Medical Artificial Intelligence,Biomedical Engineering"
                     data-keywords="Echocardiography,Dataset Distillation,Video Analysis,Graph-Based Learning,Infomap Algorithm,Cardiovascular Imaging,Machine Learning,Medical Data Efficiency"
                     data-authors="Zhe Li,Hadrien Reynaud,Alberto Gomez,Bernhard Kainz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09422v1.html">InfoMotion: A Graph-Based Approach to Video Dataset Distillation for Echocardiography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhe Li, Hadrien Reynaud, Alberto Gomez et al.
                </div>

                <div class="paper-summary">
                    This paper introduces InfoMotion, a novel graph-based approach for distilling compact synthetic echocardiographic video datasets to address challenges with large-scale medical video data. By leveraging motion feature extraction, class-wise graph construction, and the Infomap algorithm, the method selects a diverse and informative subset. It achieves a 69.38% test accuracy on EchoNet-Dynamic using only 25 synthetic videos, demonstrating efficiency for medical video dataset distillation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09422v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09422v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09422v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09422v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09418v1"
                     data-domains="Cardiology,Diagnostic Imaging,Medical AI,Radiology"
                     data-keywords="Ultrasound echocardiography,Deep learning,Diffusion models,Self-supervised learning,Medical image synthesis,Cardiac function assessment,Label-free learning,Generative AI"
                     data-authors="Zhe Li,Hadrien Reynaud,Johanna P M√ºller,Bernhard Kainz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09418v1.html">Label-free Motion-Conditioned Diffusion Model for Cardiac Ultrasound Synthesis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhe Li, Hadrien Reynaud, Johanna P M√ºller et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Motion Conditioned Diffusion Model (MCDM), a novel label-free latent diffusion framework for synthesizing realistic echocardiography videos. It leverages self-supervised motion features, extracted by a custom Motion and Appearance Feature Extractor (MAFE) with auxiliary re-identification and optical flow losses, to condition video generation. Evaluated on the EchoNet-Dynamic dataset, MCDM achieves competitive and clinically realistic video synthesis without requiring manual labels.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09418v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09418v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09418v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09418v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09403v1"
                     data-domains="Clinical Decision Support,Medical Information Systems,Patient Education"
                     data-keywords="Medical LLMs,Black-box distillation,Safety alignment,Model extraction,Jailbreaking,Adversarial attacks,Meditron,LLaMA3"
                     data-authors="Sohely Jahan,Ruimin Sun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09403v1.html">Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sohely Jahan, Ruimin Sun
                </div>

                <div class="paper-summary">
                    This paper reveals a significant vulnerability in safety-aligned medical large language models (LLMs) through a black-box behavioral distillation attack. Adversaries can cheaply replicate a medical LLM's domain-specific reasoning while critically stripping its safety mechanisms, leading to a substantial increase in unsafe completions by the distilled surrogate model.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Information Systems</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09403v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09403v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09403v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09403v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09393v1"
                     data-domains="Neurosurgery,Radiology,Emergency Medicine,Neurology"
                     data-keywords="Subdural hematoma,deep learning,computed tomography,multimodal AI,medical imaging,clinical decision support,neurosurgery,image segmentation"
                     data-authors="Vasiliki Stoumpou,Rohan Kumar,Bernard Burman,Diego Ojeda,Tapan Mehta,Dimitris Bertsimas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09393v1.html">Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vasiliki Stoumpou, Rohan Kumar, Bernard Burman et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel multimodal deep-learning framework that integrates structured clinical data with 3D computed tomography (CT) imaging for highly accurate detection and precise localization of subdural hematoma (SDH). The framework achieved superior diagnostic performance (AUC 0.9407) and generated interpretable, anatomically meaningful localization maps, addressing the critical need for rapid and transparent tools in neurosurgical emergencies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09393v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09393v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09393v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09393v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09369v1"
                     data-domains="Clinical Decision Support Systems,Drug Discovery and Repurposing,Biomedical Informatics,Personalized Medicine,Electronic Health Record (EHR) Analysis,Genomics and Proteomics,Medical Research and Literature Analysis"
                     data-keywords="Hyperdimensional Computing,Knowledge Graphs,Large Language Models,Medical Reasoning,Computational Efficiency,Interpretability,Biomedical Informatics,Path-based Reasoning"
                     data-authors="Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09369v1.html">Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yezi Liu, William Youngwoo Chung, Hanning Chen et al.
                </div>

                <div class="paper-summary">
                    PathHD introduces a lightweight, encoder-free framework for LLM reasoning over Knowledge Graphs, replacing computationally expensive neural path scoring and multiple LLM calls with Hyperdimensional Computing (HDC). By encoding relation paths into block-diagonal hypervectors and using a single LLM adjudication, PathHD achieves comparable accuracy to neural baselines while significantly reducing latency and GPU memory. This approach offers improved interpretability, presenting a favorable accuracy-efficiency-interpretability trade-off.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Drug Discovery and Repurposing</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Electronic Health Record (EHR) Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09369v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09369v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09369v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09369v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09365v1"
                     data-domains="Drug Discovery,Pharmacology,Bioinformatics,Computational Chemistry,Molecular Medicine"
                     data-keywords="molecule-protein interaction,optimal transport,pseudo-labeling,knowledge graph,drug discovery,computational biology,virtual screening,zero-shot learning"
                     data-authors="Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09365v1.html">KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiayu Qin, Zhengquan Luo, Guy Tadmor et al.
                </div>

                <div class="paper-summary">
                    KGOT is a novel framework that enhances molecule-protein interaction (MPI) prediction by integrating diverse biological data, including molecular, protein, gene, and pathway-level interactions. It employs an optimal transport-based pseudo-labeling approach to generate high-quality labels for unlabeled molecule-protein pairs. This method significantly improves prediction accuracies and zero-shot capabilities over state-of-the-art techniques, demonstrating strong performance on virtual screening and protein retrieval tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Computational Chemistry</span>
                    
                    <span class="domain-tag">Molecular Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09365v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09365v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09365v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09365v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09315v1"
                     data-domains="Medical Image Analysis,Radiology,Pathology,Diagnostic Imaging"
                     data-keywords="noisy labels,medical image classification,benchmarking,deep learning,robustness,inter-observer variability,class imbalance,domain variability"
                     data-authors="Yuan Ma,Junlin Hou,Chao Zhang,Yukun Zhou,Zongyuan Ge,Haoran Xie,Lie Ju">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09315v1.html">Benchmarking Real-World Medical Image Classification with Noisy Labels: Challenges, Practice, and Outlook</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuan Ma, Junlin Hou, Chao Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LNMBench, a comprehensive benchmark to systematically assess the robustness of learning with noisy labels (LNL) methods in medical image analysis. It evaluates 10 representative LNL methods across diverse medical datasets, imaging modalities, and noise patterns, revealing significant performance degradation under high and real-world noise. The study highlights persistent challenges like class imbalance and domain variability, and proposes an effective improvement strategy for enhanced model robustness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09307v1"
                     data-domains="Gastroenterology,Oncology,Diagnostic Imaging,Medical Artificial Intelligence"
                     data-keywords="Polyp segmentation,Colorectal cancer,Foundation models,Knowledge distillation,Deep learning,U-Net,SAM,DINOv2,Medical imaging"
                     data-authors="Shivanshu Agnihotri,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09307v1.html">From SAM to DINOv2: Towards Distilling Foundation Models to Lightweight Baselines for Generalized Polyp Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shivanshu Agnihotri, Snehashis Majhi, Deepak Ranjan Nayak et al.
                </div>

                <div class="paper-summary">
                    The paper introduces Polyp-DiFoM, a novel distillation framework that transfers rich representations from large vision foundation models (like SAM, DINOv2) into lightweight segmentation baselines (U-Net, U-Net++) for generalized polyp segmentation. This approach effectively bridges the gap between powerful foundation models and practical medical imaging applications, demonstrating significant performance improvements over baselines and state-of-the-art models with nearly 9 times reduced computational overhead across five benchmark datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09307v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09307v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09307v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09307v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09289v1"
                     data-domains="Dermatology,Diagnostic Imaging,Medical Artificial Intelligence,Oncology (Skin Cancer Screening)"
                     data-keywords="Melanoma,Skin Lesion Classification,Deep Learning,Explainable AI (XAI),Dermatology,GradCAM++,FastCAV,Uncertainty Quantification,ISIC Dataset"
                     data-authors="Sukhrobbek Ilyosbekov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09289v1.html">MelanomaNet: Explainable Deep Learning for Skin Lesion Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sukhrobbek Ilyosbekov
                </div>

                <div class="paper-summary">
                    MelanomaNet presents an explainable deep learning system for multi-class skin lesion classification that overcomes the 'black box' challenge of traditional AI models. It achieves high diagnostic accuracy (85.61% accuracy, 0.8564 weighted F1) on the ISIC 2019 dataset by integrating four interpretability mechanisms, providing clinically meaningful explanations and quantifying prediction uncertainty.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Oncology (Skin Cancer Screening)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09289v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09289v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09289v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09289v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09278v1"
                     data-domains="Radiology,Surgical Planning,Anatomy Visualization,Medical Robotics,Pathology"
                     data-keywords="3D Colorization,Single-channel Reconstruction,Multi-view Consistency,Diffusion Models,Local-Global Approach,Medical Imaging,360¬∞ Scenes,Color Diversity"
                     data-authors="Yeonjin Chang,Juhwan Cho,Seunghyeon Seo,Wonsik Shin,Nojun Kwak">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09278v1.html">LoGoColor: Local-Global 3D Colorization for 360¬∞ Scenes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yeonjin Chang, Juhwan Cho, Seunghyeon Seo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LoGoColor, a novel pipeline for detailed 3D colorization of single-channel 3D reconstructed 360¬∞ scenes. It addresses the issue of monotonous and oversimplified colors from existing methods by generating consistently colorized multi-view training data, thus bypassing problematic color-averaging processes. LoGoColor ensures strict multi-view consistency through a Local-Global approach that partitions scenes and leverages a fine-tuned multi-view diffusion model, yielding quantitatively and qualitatively superior, diverse, and consistent 3D colorization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Anatomy Visualization</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09278v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09278v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09278v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09278v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09276v1"
                     data-domains="Neurology,Movement Disorders,Diagnostic Medicine,Geriatrics,Digital Health"
                     data-keywords="Parkinson's Disease,Hypomimia,Facial Expression Analysis,CLIP Architecture,LSTM,Neurodegenerative Disorder,Auxiliary Diagnosis,Computer Vision"
                     data-authors="Xiaochen Huang,Xiaochen Bi,Cuihua Lv,Xin Wang,Haoyan Zhang,Wenjing Jiang,Xin Ma,Yibin Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09276v1.html">Dynamic Facial Expressions Analysis Based Parkinson's Disease Auxiliary Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaochen Huang, Xiaochen Bi, Cuihua Lv et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel dynamic facial expression analysis method for auxiliary Parkinson's Disease (PD) diagnosis, targeting hypomimia through the analysis of reduced facial expressivity and rigidity. Utilizing a multimodal network leveraging CLIP for visual-textual integration and temporal dynamics, followed by an LSTM-based classifier, the method achieves 93.1% accuracy. This approach offers a more convenient and efficient diagnostic tool, outperforming existing in-vitro PD diagnostic techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Movement Disorders</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09244v1"
                     data-domains="Nephrology,Radiology,Diagnostic Imaging,Artificial Intelligence in Medicine,Urology"
                     data-keywords="Chronic Kidney Disease,Deep Learning,Convolutional Neural Network,CT Images,Explainable AI,Grad-CAM,SMOTE,Early Detection"
                     data-authors="Anas Bin Ayub,Nilima Sultana Niha,Md. Zahurul Haque">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09244v1.html">A Clinically Interpretable Deep CNN Framework for Early Chronic Kidney Disease Prediction Using Grad-CAM-Based Explainable AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anas Bin Ayub, Nilima Sultana Niha, Md. Zahurul Haque
                </div>

                <div class="paper-summary">
                    This paper introduces a deep Convolutional Neural Network (CNN) framework for early Chronic Kidney Disease (CKD) prediction from CT kidney images, incorporating SMOTE for class balancing and Grad-CAM for explainability. Trained on a diverse dataset encompassing normal, cyst, stone, and tumor cases, the model achieved a remarkable 100% classification accuracy, demonstrating significant potential for improving clinical diagnostics and early intervention strategies in nephrology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09244v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09244v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09244v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09244v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09198v1"
                     data-domains="Cardiology,Interventional Cardiology,Cardiovascular Surgery,Medical Imaging"
                     data-keywords="Transcatheter Aortic Valve Replacement (TAVR),Transcatheter Heart Valves (THV),Machine Learning,Permanent Pacemaker Implantation (PPI),Aortic Stenosis,Personalized Medicine,Clinical Decision Support,Data Integration"
                     data-authors="Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09198v1.html">Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Phevos Paschalidis, Vasiliki Stoumpou, Lisa Everest et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a machine learning approach to optimize transcatheter heart valve (THV) selection for Transcatheter Aortic Valve Replacement (TAVR) surgery. The primary objective is to minimize the risk of permanent pacemaker implantation (PPI), a common postoperative complication. The developed prescriptive model, utilizing a novel integrated dataset from U.S. and Greek populations, demonstrates significant reductions in PPI rates compared to the current standard of care.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09198v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09198v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09198v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09198v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09185v1"
                     data-domains="Neurology,Radiology,Personalized Medicine,Disease Modeling,Biomarker Discovery,Geriatrics"
                     data-keywords="Disease Progression,Latent Flow Matching,Longitudinal Imaging,Patient-Specific Dynamics,Generative Models,MRI,Clinical Severity,Interpretability"
                     data-authors="Hao Chen,Rui Yin,Yifan Chen,Qi Chen,Chao Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09185v1.html">Learning Patient-Specific Disease Dynamics with Latent Flow Matching for Longitudinal Imaging Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao Chen, Rui Yin, Yifan Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces $Œî$-LFM, a novel framework designed to model patient-specific disease progression by treating disease dynamics as a continuous velocity field. It leverages Flow Matching (FM) and a novel patient-specific latent alignment strategy to create a semantically meaningful latent space where trajectories monotonically correlate with disease severity. The method demonstrates strong empirical performance on longitudinal MRI benchmarks and offers enhanced interpretability and visualization of disease dynamics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Disease Modeling</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09185v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09185v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09185v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09185v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09173v1"
                     data-domains="Neurology,Neurosurgery,Medical Imaging,Biomedical Engineering,Therapeutic Ultrasound"
                     data-keywords="Transcranial Focused Ultrasound,Skull Acoustics,Viscous Model,Viscoelastic Model,Attenuation,Phase Velocity,Bone Microstructure,k-Wave"
                     data-authors="Samuel Clinard,Taylor Webb,Henrik Od√©en,Dennis L. Parker,Douglas A. Christensen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09173v1.html">The choice of viscous or viscoelastic models affects attenuation and velocity determination in simplified skull-mimicking digital phantoms</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Samuel Clinard, Taylor Webb, Henrik Od√©en et al.
                </div>

                <div class="paper-summary">
                    This paper investigates how the choice between viscous and viscoelastic acoustic models impacts predictions of ultrasound attenuation and phase velocity in simplified skull-mimicking digital phantoms containing microstructural pores. It reveals that while both models predict increased attenuation with pore size, they differ significantly in the peak attenuation values and their dependence on porosity, with viscoelastic models also showing less sensitivity to pore size for phase velocity. These distinct behaviors underscore the critical importance of selecting an appropriate acoustic model for accurately estimating skull acoustic properties in transcranial focused ultrasound therapies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Therapeutic Ultrasound</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09173v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09173v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09173v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09173v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09158v1"
                     data-domains="Rehabilitation Medicine,Orthopedics,Neurology,Sports Medicine,Physical Therapy,Biomedical Engineering"
                     data-keywords="Gait Kinematics,Riemannian Geometry,Euclidean Metrics,Symmetric Positive Definite (SPD) Matrices,Gait Variability,Biomechanical Efficiency,Clinical Biomechanics,Motor Control"
                     data-authors="Tom√°≈° B≈Ø≈æek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09158v1.html">Riemannian vs. Euclidean Representation of Gait Kinematics: A Comparative Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tom√°≈° B≈Ø≈æek
                </div>

                <div class="paper-summary">
                    This paper introduces a novel computational framework that utilizes Riemannian geometry to represent and analyze gait kinematics, overcoming the limitations of traditional Euclidean models that fail to capture the non-linear dynamics of human movement. The study demonstrates that manifold-based metrics reveal a non-linear 'inverted-U' pattern of gait variability with speed, indicating optimal biomechanical efficiency at higher speeds, a finding missed by Euclidean approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09134v1"
                     data-domains="Cardiology,Interventional Cardiology,Diagnostic Imaging"
                     data-keywords="Coronary Angiography,Fractional Flow Reserve (FFR),Quantitative Flow Ratio (QFR),Deep Learning,Virtual Stenting,Percutaneous Coronary Intervention (PCI),Coronary Artery Disease,Computer Vision"
                     data-authors="Georgy Kopanitsa,Oleg Metsker,Alexey Yakovlev">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09134v1.html">Integrated Pipeline for Coronary Angiography With Automated Lesion Profiling, Virtual Stenting, and 100-Vessel FFR Validation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Georgy Kopanitsa, Oleg Metsker, Alexey Yakovlev
                </div>

                <div class="paper-summary">
                    AngioAI-QFR introduces an end-to-end angiography-only pipeline leveraging deep learning for automated coronary artery disease assessment, integrating lesion profiling, virtual stenting, and automated angiography-derived Fractional Flow Reserve (QFR). The system demonstrates strong correlation with invasive FFR (r=0.89, MAE=0.045) and high diagnostic accuracy (AUC 0.93) for detecting hemodynamically significant lesions, operating near real-time. This practical pipeline unifies computer vision, functional profiling, and virtual PCI planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09134v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09134v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09134v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09134v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09127v1"
                     data-domains="Pediatric Dentistry,Clinical Pharmacology,Medical Informatics,Clinical Decision Support Systems,Artificial Intelligence in Medicine"
                     data-keywords="Large Language Models,Pediatric Dentistry,Antibiotic Recommendation,Knowledge Graph,Retrieval-Augmented Generation,Clinical Decision Support,Patient Safety,Medical Informatics"
                     data-authors="Zihan Han,Junyan Ge,Caifeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09127v1.html">Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihan Han, Junyan Ge, Caifeng Li
                </div>

                <div class="paper-summary">
                    This study introduces a Knowledge-Guided Large Language Model (KG-LLM) designed for automated understanding of pediatric dental records and safe antibiotic recommendation. By integrating a specialized knowledge graph, retrieval-augmented generation (RAG), and a multi-stage safety validation pipeline, the system significantly improves record interpretation, antibiotic prescription accuracy, and notably reduces unsafe antibiotic suggestions compared to a baseline LLM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatric Dentistry</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09127v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09127v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09127v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09127v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09114v1"
                     data-domains="healthcare administration,health insurance,clinical decision support,medical ethics"
                     data-keywords="AI governance,AI risk management,trustworthy AI,healthcare AI,operationalization,bias detection,error rates,compliance"
                     data-authors="Pamela Gupta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09114v1.html">AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pamela Gupta
                </div>

                <div class="paper-summary">
                    AI TIPS 2.0 introduces a comprehensive operational framework for AI governance designed to overcome critical challenges in current approaches, particularly inadequate use-case specific risk assessment, lack of actionable controls, and difficulty operationalizing trustworthy AI at scale. It directly addresses issues such as biased and error-prone AI systems leading to improper healthcare claim denials, as highlighted by the Humana class action lawsuit.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">healthcare administration</span>
                    
                    <span class="domain-tag">health insurance</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                    <span class="domain-tag">medical ethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09114v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09114v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09114v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09114v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09094v1"
                     data-domains="Neurology,Radiology,Medical Imaging,Diagnostic Imaging"
                     data-keywords="Causal Attribution,Distribution Shift,Medical Imaging,Image Segmentation,Deep Learning,Multiple Sclerosis,Shapley Values,Performance Gaps"
                     data-authors="Pedro M. Gordaliza,Nataliia Molchanova,Jaume Banus,Thomas Sanchez,Meritxell Bach Cuadra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09094v1.html">Causal Attribution of Model Performance Gaps in Medical Imaging Under Distribution Shifts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pedro M. Gordaliza, Nataliia Molchanova, Jaume Banus et al.
                </div>

                <div class="paper-summary">
                    This paper extends causal attribution frameworks to high-dimensional medical image segmentation, quantifying how acquisition protocols and annotation variability independently contribute to deep learning model performance degradation under distribution shifts. By modeling the data-generating process with a causal graph and employing Shapley values, the authors reveal that annotation shifts are the dominant cause of performance drops when models cross annotators, while acquisition shifts dominate when crossing imaging centers. This mechanism-specific quantification allows for targeted intervention strategies to improve model robustness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09094v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09094v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09094v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09094v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09076v1"
                     data-domains="Environmental Health,Public Health,Preventive Medicine,Respiratory Medicine"
                     data-keywords="Air Quality Forecasting,PM2.5,PM10,Facebook Prophet,Machine Learning,Deep Learning,Public Health,Environmental Health"
                     data-authors="Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09076v1.html">Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Moazzam Umer Gondal, Hamad ul Qudous, Asma Ahmad Farhan
                </div>

                <div class="paper-summary">
                    This study compares lightweight additive models (Facebook Prophet, NeuralProphet) against deep learning, machine learning, and traditional statistical models for urban air quality forecasting (PM$_{2.5}$, PM$_{10}$) in Beijing. It found that Facebook Prophet consistently outperformed all other models, achieving high accuracy ($R^2 > 0.94$), demonstrating that interpretable additive models can be highly competitive for public health-critical predictions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Respiratory Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09076v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09076v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09076v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09076v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09074v1"
                     data-domains="Public Health,Environmental Health,Epidemiology,Preventive Medicine,Emergency Medicine"
                     data-keywords="heatwave prediction,early warning system,deep learning,public health,mortality prediction,environmental health,climate change adaptation,all-cause mortality"
                     data-authors="Shangqing Xu,Zhiyuan Zhao,Megha Sharma,Jos√© Mar√≠a Mart√≠n-Olalla,Alexander Rodr√≠guez,Gregory A. Wellenius,B. Aditya Prakash">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09074v1.html">Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shangqing Xu, Zhiyuan Zhao, Megha Sharma et al.
                </div>

                <div class="paper-summary">
                    DeepTherm is a modular deep-learning-based early warning system designed to predict deadly heatwaves without relying on historical heat-related mortality data. It employs a novel dual-prediction pipeline to disentangle baseline mortality from all-cause mortality. Evaluated on real-world data across Spain, the system demonstrates consistent, robust, and accurate performance across diverse regions and population groups.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09074v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09074v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09074v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09074v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09069v1"
                     data-domains="Ophthalmology,Retinal Imaging,Macular Degeneration,Diagnostic Imaging"
                     data-keywords="Knowledge Distillation,Retinal OCT,Age-related Macular Degeneration (AMD),Choroidal Neovascularization (CNV),Deep Learning,EfficientNet,ConvNeXtV2,Edge Computing,Clinical AI"
                     data-authors="Erfan Nourbakhsh,Nasrin Sanjari,Ali Nourbakhsh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09069v1.html">KD-OCT: Efficient Knowledge Distillation for Clinical-Grade Retinal OCT Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Erfan Nourbakhsh, Nasrin Sanjari, Ali Nourbakhsh
                </div>

                <div class="paper-summary">
                    This study introduces KD-OCT, a novel knowledge distillation framework designed to compress computationally intensive deep learning models for retinal OCT classification into efficient, deployable models. By distilling a powerful ConvNeXtV2-Large teacher into a lightweight EfficientNet-B2 student, KD-OCT achieves near-teacher diagnostic performance for classifying normal, drusen, and CNV cases while significantly reducing model size and inference time. This enables real-time, high-accuracy AMD screening suitable for edge deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Retinal Imaging</span>
                    
                    <span class="domain-tag">Macular Degeneration</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09069v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09069v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09069v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09069v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09048v1"
                     data-domains="Clinical AI,Health Informatics,Patient Safety,Quality Improvement,Health Systems Management,Digital Health"
                     data-keywords="AI monitoring,healthcare AI,post-deployment,system integrity,performance monitoring,impact assessment,patient safety,clinical governance"
                     data-authors="Timothy Keyes,Alison Callahan,Abby S. Pandya,Nerissa Ambers,Juan M. Banda,Miguel Fuentes,Carlene Lugtu,Pranav Masariya,Srikar Nallan,Connor O'Brien,Thomas Wang,Emily Alsentzer,Jonathan H. Chen,Dev Dash,Matthew A. Eisenberg,Patricia Garcia,Nikesh Kotecha,Anurang Revri,Michael A. Pfeffer,Nigam H. Shah,Sneha S. Jain">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09048v1.html">Monitoring Deployed AI Systems in Health Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Timothy Keyes, Alison Callahan, Abby S. Pandya et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel framework for the post-deployment monitoring of artificial intelligence (AI) systems in health care, crucial for ensuring their safety, quality, and sustained benefit. Organized around principles of system integrity, performance, and impact, this framework provides practical guidance for creating monitoring plans that facilitate informed governance decisions regarding AI system updates, modifications, or decommissioning. The framework is actively utilized at Stanford Health Care, demonstrating its real-world applicability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical AI</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Quality Improvement</span>
                    
                    <span class="domain-tag">Health Systems Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09048v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09048v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09048v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09048v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09013v1"
                     data-domains="Neurosurgery,Neuroradiology,Medical Imaging,Computational Medicine,Vascular Surgery"
                     data-keywords="Intracranial Aneurysm,Hemodynamics,Graph Neural Network,Wall Shear Stress,Oscillatory Shear Index,Computational Fluid Dynamics,Risk Assessment,Machine Learning"
                     data-authors="Paul Garnier,Pablo Jeken-Rico,Vincent Lannelongue,Chiara Faitini,Aur√®le Goetz,Lea Chanvillard,Ramy Nemer,Jonathan Viquerat,Ugo Pelissier,Philippe Meliga,Jacques S√©dat,Thomas Liebig,Yves Chau,Elie Hachem">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09013v1.html">Graph Deep Learning for Intracranial Aneurysm Blood Flow Simulation and Risk Assessment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paul Garnier, Pablo Jeken-Rico, Vincent Lannelongue et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel graph neural network (GNN) surrogate model designed to rapidly and accurately simulate blood flow hemodynamics in intracranial aneurysms. By processing vascular geometries, the model predicts critical rupture risk indicators like wall shear stress and oscillatory shear index within minutes, overcoming the speed and resolution limitations of conventional CFD simulations and 4D Flow MRI. This approach aims to provide real-time, high-resolution hemodynamic analysis, transforming complex simulations into an accessible clinical decision support tool.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09013v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09013v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09013v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09013v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08882v1"
                     data-domains="Public Health Surveillance,Disaster Medicine,Telemedicine,Global Health,Environmental Health"
                     data-keywords="Federated Learning,Blockchain,Low Earth Orbit (LEO) Satellites,Space AI,Cybersecurity,Trust,Multi-vendor Networks,High-Altitude Platforms (HAPs)"
                     data-authors="Mohamed Elmahallawy,Asma Jodeiri Akbarfam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08882v1.html">Decentralized Trust for Space AI: Blockchain-Based Federated Learning Across Multi-Vendor LEO Satellite Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohamed Elmahallawy, Asma Jodeiri Akbarfam
                </div>

                <div class="paper-summary">
                    This paper introduces OrbitChain, a blockchain-backed framework designed to address critical trust challenges and slow convergence in Federated Satellite Learning (FSL) across multi-vendor Low Earth Orbit (LEO) satellite networks. By offloading consensus to High-Altitude Platforms (HAPs) and ensuring auditable provenance of model updates, OrbitChain significantly improves privacy, security, and global model accuracy while reducing computational overhead and convergence time.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                    <span class="domain-tag">Disaster Medicine</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08882v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08882v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08882v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08882v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08869v1"
                     data-domains="Healthcare Data Management,Clinical Research,Pharmacovigilance,Public Health Analytics,AI in Medicine"
                     data-keywords="Differentially Private,Synthetic Data,Generative Adversarial Networks (GANs),Context-Aware,Healthcare Data,Privacy Preservation,Implicit Rules,Constraint Matrix"
                     data-authors="Anantaa Kotal,Anupam Joshi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08869v1.html">Differentially Private Synthetic Data Generation Using Context-Aware GANs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anantaa Kotal, Anupam Joshi
                </div>

                <div class="paper-summary">
                    This paper introduces ContextGAN, a novel Differentially Private Generative Adversarial Network designed to generate high-quality synthetic data that captures complex, implicit domain-specific rules often missed by traditional methods. By integrating a constraint matrix and a context-aware discriminator, ContextGAN ensures adherence to critical domain constraints while simultaneously protecting sensitive information through differential privacy. The model's effectiveness is validated across healthcare, security, and finance, demonstrating improved realism and utility.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Data Management</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Public Health Analytics</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08869v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08869v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08869v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08869v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08842v1"
                     data-domains="Public Health,Epidemiology,Medical Entomology,Vector-borne Diseases,Disease Ecology"
                     data-keywords="Culex,mathematical model,vector control,spatial heterogeneity,mosquito-borne disease,ODE model,larvicide,adulticide"
                     data-authors="Suman Bhowmick,Patrick Irwin,Kristina Lopez,Megan Lindsay Fritz,Rebecca Lee Smith">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08842v1.html">A mathematical model of \textit{Culex} population abundance and the impact of vector control interventions in a patchy environment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Suman Bhowmick, Patrick Irwin, Kristina Lopez et al.
                </div>

                <div class="paper-summary">
                    This research developed a temperature-driven multi-patch Ordinary Differential Equation (ODE) model to simulate *Culex* mosquito dynamics and evaluate vector control interventions in a spatially heterogeneous environment. Integrating real-world entomological data, weather factors, and local abatement practices, the study found that models neglecting spatial connectivity can significantly misrepresent intervention effectiveness and vector persistence. The findings provide critical insights for optimizing control strategies to mitigate mosquito-borne disease risk.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Medical Entomology</span>
                    
                    <span class="domain-tag">Vector-borne Diseases</span>
                    
                    <span class="domain-tag">Disease Ecology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08842v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08842v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08842v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08842v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08828v1"
                     data-domains="Mobile Health (mHealth),Personalized Medicine,Adaptive Interventions,Clinical Trial Design (Sequential/MRTs),Preventive Medicine"
                     data-keywords="Individual Treatment Effects (ITEs),Prediction Intervals,Conformal Inference,Micro-Randomized Trials (MRTs),Time-Varying Treatments,Uncertainty Quantification,Personalized Medicine,Mobile Health (mHealth)"
                     data-authors="Swaraj Bose,Walter Dempsey">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08828v1.html">Prediction Intervals for Individual Treatment Effects in a Multiple Decision Point Framework using Conformal Inference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Swaraj Bose, Walter Dempsey
                </div>

                <div class="paper-summary">
                    This paper introduces a novel method for constructing prediction intervals for Individual Treatment Effects (ITEs) that vary over time and across multiple decision points. Utilizing conformal inference techniques, the proposed approach offers guaranteed lower bound coverage, notably with weaker assumptions compared to existing literature. The methodology is primarily supported by simulations mimicking micro-randomized trials (MRTs) in mobile health (mHealth) and demonstrated on the real-world Intern Health Study (IHS) MRT.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mobile Health (mHealth)</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Adaptive Interventions</span>
                    
                    <span class="domain-tag">Clinical Trial Design (Sequential/MRTs)</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08828v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08828v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08828v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08828v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08805v1"
                     data-domains="Clinical Decision Support,Personalized Medicine,Pharmacogenomics,Public Health Interventions,Risk Stratification,Prognostic Modeling"
                     data-keywords="Causal Inference,Uplift Modeling,Counterfactuals,Bivariate Beta Distribution,Personalized Medicine,Potential Outcomes,Treatment Effects,Precision Health"
                     data-authors="Th√©o Verhelst,Gianluca Bontempi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08805v1.html">Identifying counterfactual probabilities using bivariate distributions and uplift modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Th√©o Verhelst, Gianluca Bontempi
                </div>

                <div class="paper-summary">
                    This paper introduces a novel method for identifying counterfactual probabilities, which represent the joint distribution of potential outcomes under both treatment and control conditions. Building upon uplift modeling, the approach fits a bivariate beta distribution to predicted uplift scores to generate posterior distributions over individual-level counterfactual outcomes, offering richer causal insights than traditional uplift or machine learning models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Public Health Interventions</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08805v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08805v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08805v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08805v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08772v1"
                     data-domains="Oncology,Pharmacology,Drug Development,Synthetic Biology,Medicinal Chemistry"
                     data-keywords="Terpene Synthase (TPS),De Novo Enzyme Design,Generative AI,Protein Language Model,Drug Discovery,Enzyme Engineering,Natural Products,Machine Learning"
                     data-authors="Hamsini Ramanathan,Roman Bushuiev,Matou≈° Sold√°t,Jir√≠ Kohout,T√©o Hebra,Joshua David Smith,Josef Sivic,Tom√°≈° Pluskal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08772v1.html">De novo generation of functional terpene synthases using TpsGPT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hamsini Ramanathan, Roman Bushuiev, Matou≈° Sold√°t et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TpsGPT, a generative AI model fine-tuned on 79,000 terpene synthase (TPS) sequences, to rapidly design novel TPS enzymes, addressing the limitations of traditional costly and slow directed evolution methods. The model successfully generated a pool of de novo enzyme candidates, from which seven highly-ranked sequences were identified through rigorous in silico validation. Experimental testing confirmed functional enzymatic activity in at least two of these computationally designed sequences, demonstrating the power of AI for generating functional, evolutionarily distant enzymes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Synthetic Biology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08772v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08772v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08772v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08772v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.08751v1"
                     data-domains="Dermatology,Medical Imaging,Computational Pathology,AI in Healthcare"
                     data-keywords="Federated Learning,Model Pruning,Swin Transformer,Edge AI,Skin Lesion Classification,Multimodal AI,Model Compression,Skewness"
                     data-authors="Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.08751v1.html">Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel skewness-guided pruning method for multimodal Swin Transformers to enable efficient and privacy-preserving skin lesion classification on edge devices using Federated Learning (FL). By selectively pruning Multi-Head Self-Attention and Multi-Layer Perceptron layers based on output distribution skewness, the method achieves significant model size reduction (approx. 36%) without sacrificing diagnostic accuracy, making high-performance medical AI deployable in resource-constrained, privacy-sensitive environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.08751v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.08751v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.08751v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.08751v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-11 06:28:21</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>