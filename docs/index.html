<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">159</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Neurology (8), Radiology (8), Oncology (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Neurology">Neurology (8)</option>
                        
                        <option value="Radiology">Radiology (8)</option>
                        
                        <option value="Oncology">Oncology (7)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (6)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (6)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (4)</option>
                        
                        <option value="Computational Biology">Computational Biology (4)</option>
                        
                        <option value="Biostatistics">Biostatistics (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.21675v1"
                     data-domains="Public Health,Epidemiology,Health Policy,Social Medicine,Pharmacovigilance,Clinical Trials (especially pragmatic or community-based),Digital Health Interventions"
                     data-keywords="Causal inference,Network interference,Evolution-based models,Exposure mapping,Difference-in-differences (distributional),Treatment randomization,Spillover effects,Influencer networks"
                     data-authors="Sadegh Shirani,Mohsen Bayati">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21675v1.html">On Evolution-Based Models for Experimentation Under Interference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sadegh Shirani, Mohsen Bayati
                </div>

                <div class="paper-summary">
                    This paper proposes an evolution-based approach for estimating population-level causal effects in networked systems where intervention spillovers occur through unobserved interaction pathways. It argues that precisely recovering the network structure is unnecessary; instead, characterizing how outcomes evolve across observation rounds in response to interventions is sufficient, leveraging an exposure-mapping perspective to identify conditions for low-dimensional recursive outcome equations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Social Medicine</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21673v1"
                     data-domains="Neuro-oncology,Diagnostic Radiology,Neurology,Medical Imaging,Pathology"
                     data-keywords="Glioma,3D MRI,Deep Learning,Image Segmentation,Image Classification,Attention Mechanisms,Brain Tumor,Diagnosis"
                     data-authors="Pandiyaraju V,Sreya Mynampati,Abishek Karthik,Poovarasan L,D. Saraswathi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21673v1.html">Revolutionizing Glioma Segmentation & Grading Using 3D MRI - Guided Hybrid Deep Learning Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pandiyaraju V, Sreya Mynampati, Abishek Karthik et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a hybrid deep learning framework for accurate glioma segmentation and grading from 3D MRI data, integrating a U-Net for precise tumor demarcation and a DenseNet-VGG classifier with multihead and spatial-channel attention. The model achieved a 98% Dice coefficient for segmentation and 99% classification accuracy, significantly outperforming traditional methods and demonstrating potential for improved clinical diagnosis and treatment planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21673v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21673v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21673v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21673v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21655v1"
                     data-domains="q-bio.TO"
                     data-keywords="q-bio.TO"
                     data-authors="Guillaume Duprez,M√©lina Durande,Fran√ßois Graner,H√©l√®ne Delano√´-Ayari">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21655v1.html">Geometric Confinement Reveals Scale-Free Velocity Correlations in Epithelial Cell Monolayer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guillaume Duprez, M√©lina Durande, Fran√ßois Graner et al.
                </div>

                <div class="paper-summary">
                    Collective cell flows are a hallmark of tissue dynamics in development, wound healing, and various diseases. Here, we perform experiments on epithelial MDCK cell monolayers, over tens of hours without jamming, on millimeter-scale micropatterned substrates with or without free front (a strip or a clo...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.TO</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21600v1"
                     data-domains="Healthcare Research,Clinical Trials,Public Health Policy,Medical Record Synthetization,Pharmaceutical R&D,Health Informatics"
                     data-keywords="Generative AI,Synthetic Data,Tabular Data,Watermarking,Data Provenance,Discrete Fourier Transform (DFT),Robustness,Healthcare Data"
                     data-authors="Yizhou Zhao,Xiang Li,Peter Song,Qi Long,Weijie Su">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21600v1.html">TAB-DRW: A DFT-based Robust Watermark for Generative Tabular Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yizhou Zhao, Xiang Li, Peter Song et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TAB-DRW, an efficient and robust post-editing watermarking scheme designed for generative tabular data, addressing critical concerns about data provenance and misuse in fields like healthcare. By embedding watermark signals in the frequency domain via Discrete Fourier Transform (DFT) and a novel rank-based pseudorandom bit generation, TAB-DRW ensures strong detectability and robustness against post-modifications. The method preserves high data fidelity and fully supports mixed discrete-continuous features, outperforming existing computationally expensive or limited techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Research</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Public Health Policy</span>
                    
                    <span class="domain-tag">Medical Record Synthetization</span>
                    
                    <span class="domain-tag">Pharmaceutical R&D</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21600v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21600v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21600v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21600v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21587v1"
                     data-domains="Epidemiology,Infectious Diseases,Public Health,Computational Biology,Biostatistics"
                     data-keywords="Approximate Bayesian Computation,ABC-SMC,Parameter Inference,Mechanistic Models,Dynamical Systems,Epidemiology,PyMC,Likelihood-Free Methods"
                     data-authors="Mario Castro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21587v1.html">Approximate Bayesian Computation Made Easy: A Practical Guide to ABC-SMC for Dynamical Systems with \texttt{pymc}</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mario Castro
                </div>

                <div class="paper-summary">
                    This tutorial demystifies Approximate Bayesian Computation with Sequential Monte Carlo (ABC-SMC), a powerful likelihood-free method for parameter inference in mechanistic models with intractable likelihoods. Using Python's PyMC library and practical examples from predator-prey to hierarchical epidemic dynamics, it guides researchers through implementing, diagnosing, and interpreting ABC-SMC analyses, bridging the gap for those hesitant to adopt these complex methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21587v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21587v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21587v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21587v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21582v1"
                     data-domains="Oral and Maxillofacial Pathology,Oncology,Dentistry,Dermatology (oral manifestations)"
                     data-keywords="deep learning,oral cancer,multiclass classification,data augmentation,oversampling,computer-aided diagnosis,oral lesions,stratified splitting"
                     data-authors="Joy Naoum,Revana Salama,Ali Hamdi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21582v1.html">Deep Learning-Based Multiclass Classification of Oral Lesions with Stratified Augmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Joy Naoum, Revana Salama, Ali Hamdi
                </div>

                <div class="paper-summary">
                    This research develops a deep learning-based multiclass classifier for sixteen different oral lesions, aiming to improve early oral cancer diagnosis. The model addresses challenges of limited and imbalanced datasets by integrating stratified data splitting with advanced data augmentation and oversampling techniques. Achieving high performance metrics, the proposed system demonstrates superiority over existing methods and holds significant promise for clinical computer-aided diagnostics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oral and Maxillofacial Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Dermatology (oral manifestations)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21575v1"
                     data-domains="Radiology,Orthopedic Surgery,Interventional Radiology,Medical Imaging,Computer-Assisted Surgery"
                     data-keywords="landmark detection,pelvic fluoroscopy,2D/3D registration,U-Net,pose estimation,intra-operative imaging,medical imaging,deep learning"
                     data-authors="Chou Mo,Yehyun Suh,J. Ryan Martin,Daniel Moyer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21575v1.html">Enhanced Landmark Detection Model in Pelvic Fluoroscopy using 2D/3D Registration Loss</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chou Mo, Yehyun Suh, J. Ryan Martin et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel framework to enhance automated landmark detection in pelvic fluoroscopy, particularly addressing the limitation of current methods that assume a fixed Antero-Posterior view. It integrates 2D/3D landmark registration loss into the training process of a U-Net model to improve accuracy under realistic intra-operative conditions where patient pose is variable. The authors detail a comparative analysis of their proposed method against baseline U-Net and a U-Net trained/fine-tuned with Pose Estimation Loss.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedic Surgery</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computer-Assisted Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21575v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21575v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21575v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21575v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21563v1"
                     data-domains="Epidemiology,Pharmacokinetics,Genomics,Biostatistics,Personalized Medicine,Computational Biology,Clinical Trials Design"
                     data-keywords="Markov Chain Monte Carlo,MCMC,Robustness,Sampling Algorithms,Target Distribution,Pathologies,Roughness,Flatness,Bayesian Inference"
                     data-authors="Sam Power,Giorgos Vasdekis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21563v1.html">Some aspects of robustness in modern Markov Chain Monte Carlo</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ stat.CO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sam Power, Giorgos Vasdekis
                </div>

                <div class="paper-summary">
                    This paper reviews emerging 'robust' Markov Chain Monte Carlo (MCMC) algorithms designed to perform effectively even when target probability distributions exhibit challenging characteristics. It specifically focuses on two pathologies ‚Äì roughness (rapid variation leading to numerical instability) and flatness (barren, uninformative landscapes leading to inefficient exploration) ‚Äì detailing their impact on standard MCMC and outlining proposed algorithmic remedies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacokinetics</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21561v1"
                     data-domains="Clinical Informatics,Predictive Analytics in Healthcare,Preventive Medicine,Chronic Disease Management,Population Health Management"
                     data-keywords="Electronic Health Records,Clinical Risk Prediction,Machine Learning,Temporal Alignment,Multi-Scale Convolution,Time Series Analysis,Deep Learning,Healthcare Analytics"
                     data-authors="Wei-Chen Chang,Lu Dai,Ting Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21561v1.html">Machine Learning Approaches to Clinical Risk Prediction: Multi-Scale Temporal Alignment in Electronic Health Records</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei-Chen Chang, Lu Dai, Ting Xu
                </div>

                <div class="paper-summary">
                    This study introduces the Multi-Scale Temporal Alignment Network (MSTAN) to address the challenges of temporal irregularity, varying sampling intervals, and multi-scale dynamic dependencies inherent in Electronic Health Records (EHR) for clinical risk prediction. MSTAN employs a learnable temporal alignment mechanism and a multi-scale convolutional structure to model both long-term trends and short-term fluctuations in EHR sequences. Experimental results demonstrate that the proposed model significantly outperforms mainstream baselines across key performance metrics, offering a robust solution for complex medical time-series analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21561v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21561v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21561v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21561v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21530v1"
                     data-domains="Neurology,Geriatrics,Radiology,Medical Imaging,Computational Neuroscience"
                     data-keywords="Alzheimer's Disease,MRI Image Generation,Age-specific Prediction,Nonuniform Time Span,Quantitative Metrics,Disease Progression,Structural Similarity Index,Predictive Modeling"
                     data-authors="Xin Hong,Kaifeng Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21530v1.html">The Age-specific Alzheimer 's Disease Prediction with Characteristic Constraints in Nonuniform Time Span</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Hong, Kaifeng Huang
                </div>

                <div class="paper-summary">
                    This paper presents an innovative methodology for age-specific Alzheimer's disease prediction using sequential image generation. It addresses the challenge of accurately representing disease characteristics from irregularly timed input sequences by employing quantitative metrics and an age-scaling factor to synthesize age-specific MRI images. This approach facilitates the prediction of advanced disease stages, demonstrating improved MRI synthesis accuracy and achieving a high Structural Similarity Index for long-term prognosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21530v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21530v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21530v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21530v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21519v1"
                     data-domains="Immunology,Rheumatology,Pathology,Laboratory Medicine,Clinical Diagnostics"
                     data-keywords="Antinuclear Antibodies (ANA),Autoimmune Disorders,Deep Learning,Multi-Instance Multi-Label (MIML),Self-Paced Learning,Medical Imaging,Clinical Diagnostics,Fluorescent Pattern Recognition"
                     data-authors="Yiyang Jiang,Guangwu Qian,Jiaxin Wu,Qi Huang,Qing Li,Yongkang Wu,Xiao-Yong Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21519v1.html">Self-Paced Learning for Images of Antinuclear Antibodies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiyang Jiang, Guangwu Qian, Jiaxin Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning framework for the automated detection of Antinuclear Antibodies (ANA) from microscope images, a crucial but complex task in diagnosing autoimmune disorders. Addressing the multi-instance, multi-label (MIML) nature of ANA patterns, the framework employs an instance sampler, a probabilistic pseudo-label dispatcher, and self-paced learning to process unaltered images end-to-end. It significantly outperforms prior methods on ANA datasets and general medical MIML benchmarks, setting new state-of-the-art results.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Laboratory Medicine</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21519v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21519v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21519v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21519v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21500v1"
                     data-domains="Cardiology,Continuous Monitoring,Wearable Health Technology,Telemedicine,Preventive Medicine,Biomedical Signal Processing"
                     data-keywords="Physiological Signals,Time-Shift,Meta-Learning,Photoplethysmography (PPG),Ballistocardiography (BCG),Arterial Blood Pressure (ABP),Signal Transformation,Continuous Monitoring"
                     data-authors="Qian Hong,Cheng Bian,Xiao Zhou,Xiaoyu Li,Yelei Li,Zijing Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21500v1.html">Lost in Time? A Meta-Learning Framework for Time-Shift-Tolerant Physiological Signal Transformation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qian Hong, Cheng Bian, Xiao Zhou et al.
                </div>

                <div class="paper-summary">
                    ShiftSyncNet is a novel meta-learning framework designed to mitigate performance degradation caused by temporal misalignment in multimodal physiological signal transformation, crucial for continuous healthcare monitoring. It employs a bi-level optimization approach with a transformation network and a time-shift correction network that learns and applies Fourier phase shifts for signal alignment. The framework significantly outperforms strong baselines across multiple datasets, demonstrating enhanced accuracy and improved label quality in converting non-invasive signals to clinically meaningful ones.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Continuous Monitoring</span>
                    
                    <span class="domain-tag">Wearable Health Technology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21500v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21500v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21500v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21500v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21484v1"
                     data-domains="Physical Medicine and Rehabilitation,Neurology,Orthopedics,Biomechanics,Physical Therapy,Assistive Technology"
                     data-keywords="equinus foot,orthosis,electromyography (EMG),neuromuscular rehabilitation,dorsiflexion,U-Net,artificial intelligence,gait impairment"
                     data-authors="Manuel Terradillos Perea,Olga Alonso Gonzalez,Cristina Soguero Ruiz,David Gutierrez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21484v1.html">A Dynamic Anti-Equinus Orthosis with Electromyography Sensor for Neuromuscular Rehabilitation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manuel Terradillos Perea, Olga Alonso Gonzalez, Cristina Soguero Ruiz et al.
                </div>

                <div class="paper-summary">
                    EquiSay is a dynamic anti-equinus orthosis utilizing an anterior elastic tension system and an electromyography (EMG) sensor to improve ankle dorsiflexion and monitor neuromuscular activity in patients with equinus foot. The system also integrates AI models, including a U-Net for synthetic EMG data generation and a predictive framework for automatic threshold calibration, demonstrating improved dorsiflexion, increased patient satisfaction, and valuable clinical insights for rehabilitation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Physical Medicine and Rehabilitation</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21484v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21484v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21484v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21484v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21438v1"
                     data-domains="Pharmacology,Clinical medicine,Drug discovery,Systems medicine,Biomedical research,Personalized healthcare"
                     data-keywords="Drug repurposing,Multi-agent system,Natural language processing,Bioinformatics,Knowledge graph,Personalized medicine,Translational research,Disease modules"
                     data-authors="Simon S√ºwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21438v1.html">Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Simon S√ºwer, Kester Bagemihl, Sylvie Baier et al.
                </div>

                <div class="paper-summary">
                    ChatDRex is a novel conversational multi-agent system designed to simplify complex bioinformatics analyses for network-based drug repurposing and disease module identification. It provides natural language access to an extensive biomedical knowledge graph (NeDRex), enabling physicians and researchers without computer science expertise to predict drug candidates and accelerate therapeutic discovery. The system aims to democratize access to advanced bioinformatics, fostering hypothesis generation and ultimately advancing personalized medicine and translational research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical medicine</span>
                    
                    <span class="domain-tag">Drug discovery</span>
                    
                    <span class="domain-tag">Systems medicine</span>
                    
                    <span class="domain-tag">Biomedical research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21438v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21438v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21438v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21438v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21378v1"
                     data-domains="Medical Imaging (e.g., pathology detection, lesion identification),Clinical Decision Support Systems,Pharmacovigilance (adverse event detection),Disease Surveillance and Outbreak Detection,Physiological Monitoring (e.g., critical care, wearables),Medical Fraud Detection,Genomics and Proteomics (rare mutation detection)"
                     data-keywords="Anomaly Detection,Contaminated Data,Adaptive Rejection,Gaussian Mixture Model,Modified Z-score,Machine Learning,Healthcare AI,Robustness"
                     data-authors="Jungi Lee,Jungkwon Kim,Chi Zhang,Kwangsun Yoo,Seok-Joo Byun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21378v1.html">Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jungi Lee, Jungkwon Kim, Chi Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Adaptive and Aggressive Rejection (AAR), a novel method for robust anomaly detection in the presence of contaminated training data, a common challenge in real-world applications. AAR dynamically identifies and excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds, integrating both hard and soft rejection strategies to balance data preservation and anomaly exclusion. Extensive experiments demonstrate that AAR significantly outperforms state-of-the-art methods by 0.041 AUROC, enhancing robustness and reliability for applications in domains like healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging (e.g., pathology detection, lesion identification)</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Pharmacovigilance (adverse event detection)</span>
                    
                    <span class="domain-tag">Disease Surveillance and Outbreak Detection</span>
                    
                    <span class="domain-tag">Physiological Monitoring (e.g., critical care, wearables)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21378v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21378v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21378v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21378v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21363v1"
                     data-domains="Dermatology,Medical Diagnostics (general),Clinical Decision Support Systems"
                     data-keywords="Fidelity Assessment,Local Feature Attribution,Explainable AI (XAI),Directed Prediction Change (DPC),Trustworthy AI,Deterministic Evaluation,Medical Imaging,Skin Lesions"
                     data-authors="Kevin Iselborn,David Dembinsky,Adriano Lucieri,Andreas Dengel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21363v1.html">The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kevin Iselborn, David Dembinsky, Adriano Lucieri et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Directed Prediction Change (DPC) metric, a novel approach for efficiently and deterministically assessing the fidelity of local feature attribution methods to their underlying machine learning models. DPC modifies the existing Prediction Change metric by incorporating the direction of both perturbation and attribution, achieving an almost tenfold speedup and eliminating randomness compared to Monte Carlo-based metrics like local Infidelity, while measuring the same property.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Medical Diagnostics (general)</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21363v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21363v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21363v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21363v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21344v1"
                     data-domains="physics.med-ph"
                     data-keywords="physics.med-ph"
                     data-authors="Julius Werner,Francesco Pennazio,Piergiorgio Cerello,Elisa Fiorina,Simona Giordanengo,Felix Mas Milian,Alessio Mereghetti,Franco Mostardi,Marco Pullia,Sahar Ranjbar,Roberto Sacchi,Anna Vignati,Magdalena Rafecas,Veronica Ferrero">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21344v1.html">Stopping power monitoring during proton therapy by means of prompt gamma timing: first experimental results with a homogeneous phantom</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Julius Werner, Francesco Pennazio, Piergiorgio Cerello et al.
                </div>

                <div class="paper-summary">
                    Proton therapy's full potential is limited by uncertainties that prevent optimal dose distribution. Monitoring techniques can reduce these uncertainties and enable adaptive treatment planning. Spatiotemporal Emission Reconstruction from Prompt-Gamma Timing (SER-PGT) is a promising method that provid...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">physics.med-ph</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21344v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21344v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21344v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21344v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21339v1"
                     data-domains="Laparoscopic surgery,Robot-assisted surgery,Micro-surgery,Vascular anastomosis,Surgical oncology"
                     data-keywords="Multimodal Large Language Models,Surgical Scene Understanding,Benchmark Dataset,Pixel-level Segmentation,Visual Question Answering,MAVIS,Robot-assisted Surgery,Micro-surgery"
                     data-authors="Tae-Min Choi,Tae Kyeong Jeong,Garam Kim,Jaemin Lee,Yeongyoon Koh,In Cheul Choi,Jae-Ho Chung,Jong Woong Park,Juyoun Park">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21339v1.html">SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tae-Min Choi, Tae Kyeong Jeong, Garam Kim et al.
                </div>

                <div class="paper-summary">
                    SurgMLLMBench is a novel, unified multimodal benchmark designed to overcome limitations of existing surgical datasets by integrating pixel-level instrument segmentation and structured VQA annotations across diverse surgical domains. This benchmark, including the new MAVIS dataset, enables comprehensive evaluation and development of interactive multimodal LLMs for surgical scene understanding. Extensive baseline experiments demonstrate consistent cross-domain performance and effective generalization of models trained on SurgMLLMBench.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Laparoscopic surgery</span>
                    
                    <span class="domain-tag">Robot-assisted surgery</span>
                    
                    <span class="domain-tag">Micro-surgery</span>
                    
                    <span class="domain-tag">Vascular anastomosis</span>
                    
                    <span class="domain-tag">Surgical oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21339v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21339v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21339v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21339v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21223v1"
                     data-domains="Clinical Decision Support Systems,Medical Image Analysis (especially with noisy or incomplete data),Genomics and Proteomics (handling sparse, high-dimensional biological data),Personalized Medicine (modeling patient heterogeneity and uncertainty),Drug Discovery and Development (predicting drug efficacy with limited trial data),Epidemiology (modeling disease outbreaks with uncertain parameters)"
                     data-keywords="Variational Inference,Possibility Theory,Epistemic Uncertainty,Imprecise Probability,Donsker-Varadhan Formulation,Exponential Family,Bayesian Learning,Maxitive Entropy"
                     data-authors="Jasraj Singh,Shelvia Wongso,Jeremie Houssineau,Badr-Eddine Ch√©rief-Abdellatif">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21223v1.html">Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jasraj Singh, Shelvia Wongso, Jeremie Houssineau et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a principled formulation of possibilistic variational inference, termed the Maxitive Donsker-Varadhan Formulation, to address the challenges of traditional Bayesian Variational Inference (VI) when dealing with high-dimensional integrals and subjective probabilities. It adapts VI to possibility theory, an imprecise probability framework robust for modeling epistemic uncertainty in sparse or imprecise data, by rethinking core concepts like entropy and divergence. The work applies this new framework to exponential-family functions, highlighting its unique mathematical structures and parallels with probabilistic counterparts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Medical Image Analysis (especially with noisy or incomplete data)</span>
                    
                    <span class="domain-tag">Genomics and Proteomics (handling sparse, high-dimensional biological data)</span>
                    
                    <span class="domain-tag">Personalized Medicine (modeling patient heterogeneity and uncertainty)</span>
                    
                    <span class="domain-tag">Drug Discovery and Development (predicting drug efficacy with limited trial data)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21223v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21223v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21223v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21223v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21199v1"
                     data-domains="Epidemiology,Infectious Disease Modeling,Public Health,Disease Surveillance,Behavioral Epidemiology"
                     data-keywords="Epidemic outbreaks,Behavior adaptation,Distributed memory,Infectious disease modeling,Sustained oscillations,Pseudospectral approximation,Gamma distribution,Public health dynamics"
                     data-authors="Alessia and√≤,Simone De Reggi,Francesca Scarabel,Rossana Vermiglio,Jianhong Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21199v1.html">Behavior-induced oscillations in epidemic outbreaks with distributed memory: beyond the linear chain trick using numerical methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alessia and√≤, Simone De Reggi, Francesca Scarabel et al.
                </div>

                <div class="paper-summary">
                    This paper presents a mathematical model for infectious disease outbreaks, demonstrating how individuals' adaptive behavior, influenced by continuously distributed past information about new cases, can intrinsically drive epidemic dynamics. Utilizing advanced numerical methods, the study shows that behavior adaptation alone can generate sustained waves of infection, elucidating how the characteristics of the memory kernel and the level of minimal contact impact these oscillations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Disease Surveillance</span>
                    
                    <span class="domain-tag">Behavioral Epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21199v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21199v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21199v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21199v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21120v1"
                     data-domains="Pharmacology,Drug Discovery,Systems Biology,Computational Biology,Toxicology,Precision Medicine"
                     data-keywords="molecular modeling,cell-aware,multi-modal representations,hierarchical learning,drug discovery,chemical perturbations,tree-structured vector quantization,genomic responses"
                     data-authors="Mengran Li,Zelin Zang,Wenbin Xing,Junzhou Chen,Ronghui Zhang,Jiebo Luo,Stan Z. Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21120v1.html">Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mengran Li, Zelin Zang, Wenbin Xing et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CHMR (Cell-aware Hierarchical Multi-modal Representations), a novel framework for robust molecular modeling that addresses limitations in existing methods by integrating cell-aware hierarchical multi-modal data. CHMR jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies using a tree-structured vector quantization module, leading to significant performance improvements on molecular property prediction tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21120v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21120v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21120v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21120v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21114v1"
                     data-domains="Neurology,Diagnostic Imaging,Geriatrics,Computational Neuroscience,Dementia Care"
                     data-keywords="Alzheimer's Disease,Early Prediction,Generative Models,MRI,Brain Atrophy,Deep Learning,Medical Imaging,Temporal Modeling"
                     data-authors="Xin Honga,Jie Lin,Minghui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21114v1.html">Deformation-aware Temporal Generation for Early Prediction of Alzheimers Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Honga, Jie Lin, Minghui Wang
                </div>

                <div class="paper-summary">
                    This paper introduces the Deformation-Aware Temporal Generative Network (DATGN), a novel deep learning model designed to automate the learning and prediction of morphological brain changes for early Alzheimer's disease (AD) diagnosis. DATGN addresses missing MRI data through interpolation and then generates future MRI images that reflect AD-related brain atrophy. The generated synthetic data significantly improved AD classification accuracy when used with existing classifiers and qualitatively demonstrated accurate simulation of disease progression.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Dementia Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21114v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21114v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21114v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21114v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21109v1"
                     data-domains="Patient Stratification,Disease Risk Prediction,Healthcare Resource Allocation,Personalized Medicine,Clinical Trial Design,Public Health Surveillance,Medical Diagnosis Support"
                     data-keywords="Fair Clustering,Interpretable AI,Decision Trees,Fairness Constraints,Protected Attributes,Machine Learning,Algorithmic Fairness,Healthcare AI"
                     data-authors="Mudi Jiang,Jiahui Zhou,Xinying Liu,Zengyou He,Zhikui Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21109v1.html">Interpretable Fair Clustering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mudi Jiang, Jiahui Zhou, Xinying Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an interpretable and fair clustering framework that integrates fairness constraints directly into the structure of decision trees. It addresses the lack of interpretability in existing fair clustering methods, especially crucial for high-stakes applications. The proposed approach constructs decision trees that partition data fairly across protected groups, demonstrating competitive clustering performance, improved fairness, and interpretability, even with multiple sensitive attributes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Patient Stratification</span>
                    
                    <span class="domain-tag">Disease Risk Prediction</span>
                    
                    <span class="domain-tag">Healthcare Resource Allocation</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21109v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21109v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21109v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21109v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21075v1"
                     data-domains="Biomedical Research,Life Sciences,Drug Discovery,Medical Diagnostics,Genomics,Systems Biology,Precision Medicine"
                     data-keywords="Large Language Models (LLMs),Biomedical Knowledge,Balanced Fine-Tuning (BFT),Supervised Fine-Tuning (SFT),Sparse Data Learning,Adaptive Loss Weighting,Gene Interaction Prediction,Single-Cell Analysis"
                     data-authors="Zhenchao Tang,Fang Wang,Haohuai He,Jiale Zhou,Tianxu Lv,Jun Zhu,Shouzhi Chen,Minghao Yang,Yu Wang,Jiayang Wu,Yidong Song,Jianhua Yao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21075v1.html">Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhenchao Tang, Fang Wang, Haohuai He et al.
                </div>

                <div class="paper-summary">
                    This paper proposes Balanced Fine-Tuning (BFT), an efficient post-training method that addresses the limitations of standard Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) in aligning Large Language Models (LLMs) with specialized biomedical knowledge. BFT utilizes a novel two-layer weighting mechanism to learn complex reasoning from sparse data without external reward signals, significantly outperforming SFT and GeneAgent in various medical and biological tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Life Sciences</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21075v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21075v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21075v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21075v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21057v1"
                     data-domains="Neurology,Radiology,Geriatrics,Neuroimaging"
                     data-keywords="Alzheimer's Disease,Image Generation,Long-term Prediction,Uneven Time Series,Normal Inverse Gamma Distribution,Temporal Parameter Estimation,Uncertainty Estimation,Brain Imaging"
                     data-authors="Xin Hong,Xinze Sun,Yinhao Li,Yen-Wei Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21057v1.html">Long-Term Alzheimers Disease Prediction: A Novel Image Generation Method Using Temporal Parameter Estimation with Normal Inverse Gamma Distribution on Uneven Time Series</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Hong, Xinze Sun, Yinhao Li et al.
                </div>

                <div class="paper-summary">
                    This research introduces a novel Temporal Parameter Estimation within the Normal Inverse Gamma Distribution (T-NIG) model for long-term Alzheimer's Disease (AD) prediction. The model addresses the challenge of maintaining disease-related characteristics in image generation from unevenly spaced sequential data by incorporating a time parameter and uncertainty estimation. T-NIG demonstrates state-of-the-art performance in forecasting AD progression and generating future brain images while preserving critical disease features.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21057v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21057v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21057v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21057v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21042v1"
                     data-domains="pulmonary medicine,oncology,radiology,medical imaging,pathology"
                     data-keywords="lung nodules,CT scans,multi-agent system,precision diagnosis,radiology,oncology,AI in medicine,medical imaging"
                     data-authors="Cheng Yang,Hui Jin,Xinlei Yu,Zhipeng Wang,Yaoqun Liu,Fenglei Fan,Dajiang Lei,Gangyong Jia,Changmiao Wang,Ruiquan Ge">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21042v1.html">LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cheng Yang, Hui Jin, Xinlei Yu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LungNoduleAgent, a collaborative multi-agent system designed for the precise diagnosis of lung nodules from CT scans. It addresses current limitations of multimodal large language models (LLMs) in accurately describing nodule morphology and integrating medical expertise, showcasing superior performance over existing models through its structured, modular approach for identification, reporting, and malignancy reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">pulmonary medicine</span>
                    
                    <span class="domain-tag">oncology</span>
                    
                    <span class="domain-tag">radiology</span>
                    
                    <span class="domain-tag">medical imaging</span>
                    
                    <span class="domain-tag">pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21042v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21042v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21042v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21042v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20983v1"
                     data-domains="Histopathology,Oncology (Lung Cancer),Diagnostic Imaging,Digital Pathology"
                     data-keywords="Federated Learning,Homomorphic Encryption,Vision Transformer,Medical AI,Privacy-Preserving,Histopathology,Lung Cancer,CLS Token"
                     data-authors="Al Amin,Kamrul Hasan,Liang Hong,Sharif Ullah">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20983v1.html">Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Al Amin, Kamrul Hasan, Liang Hong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a privacy-preserving federated learning framework that integrates Vision Transformers (ViT) with lightweight homomorphic encryption (HE) to enable secure multi-institutional medical image classification for histopathology. By encrypting compact ViT CLS tokens instead of full gradients, the proposed method significantly reduces communication overhead (30-fold) while effectively thwarting gradient-based reconstruction attacks that could expose sensitive patient data. The framework achieves high classification accuracy (96.12% unencrypted, 90.02% encrypted) on lung cancer histopathology data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Oncology (Lung Cancer)</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20983v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20983v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20983v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20983v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20956v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging,Pathology,Breast Cancer Screening"
                     data-keywords="breast ultrasound,radiology report generation,vision-language model,multitask learning,BI-RADS,medical imaging,deep learning,clinical efficacy"
                     data-authors="Rawa Mohammed,Mina Attin,Bryar Shareef">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20956v1.html">BUSTR: Breast Ultrasound Text Reporting with a Descriptor-Aware Vision-Language Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rawa Mohammed, Mina Attin, Bryar Shareef
                </div>

                <div class="paper-summary">
                    BUSTR introduces a novel multitask vision-language framework for automated breast ultrasound (BUS) report generation (RRG), addressing the critical challenges of scarce paired image-report datasets and potential large language model (LLM) hallucinations. It constructs reports using structured descriptors and radiomics features, learning descriptor-aware visual representations and aligning visual-textual tokens via a dual-level loss. This approach significantly improves both standard natural language generation and clinical efficacy metrics, particularly for key diagnostic targets like BI-RADS and pathology, without requiring paired image-report supervision.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Breast Cancer Screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20956v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20956v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20956v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20956v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20950v1"
                     data-domains="Neurology,Neurophysiology,Epileptology,Computational Neuroscience"
                     data-keywords="Epilepsy,Seizure suppression,Fractional dynamics,Intracranial EEG,Dynamical networks,Brain states,Refractory epilepsy,Computational neuroscience"
                     data-authors="Yaoyue Wang,Arian Ashourvan,Guilherme Ramos,Paul Bogdan,Emily Pereira">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20950v1.html">Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yaoyue Wang, Arian Ashourvan, Guilherme Ramos et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel method utilizing fractional dynamical networks, modeled from intracranial EEG (iEEG) data, to effectively suppress epileptic seizure activity. The approach successfully stabilized these networks, suppressing 34 out of 35 spontaneous seizure episodes and achieving a 49% average amplitude reduction in simulated controlled signals. Furthermore, the analysis of fractal behavior and stability properties of these networks can distinguish between all four epileptic brain states: interictal, pre-ictal, ictal, and post-ictal.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurophysiology</span>
                    
                    <span class="domain-tag">Epileptology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20950v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20950v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20950v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20950v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20941v1"
                     data-domains="Drug efficacy evaluation,Clinical trials,Biostatistics,Personalized medicine,Biomarker discovery"
                     data-keywords="Two-sample tests,Kernel methods,Quantum kernels,Maximum Mean Discrepancy (MMD),Hybrid kernels,Statistical power,Small datasets,Clinical data"
                     data-authors="Yu Terada,Yugo Ogio,Ken Arai,Hiroyuki Tezuka,Yu Tanaka">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20941v1.html">Fusion of classical and quantum kernels enables accurate and robust two-sample tests</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ quant-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu Terada, Yugo Ogio, Ken Arai et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MMD-FUSE, a novel hybrid framework for two-sample tests that fuses classical and quantum kernels to improve statistical power and robustness. The method demonstrates superior performance, particularly for small and high-dimensional datasets, by combining the inductive biases of classical kernels with the expressive power of quantum kernels. Evaluated on synthetic and clinical datasets, the approach enhances the reliability of discriminating between data distributions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug efficacy evaluation</span>
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Biomarker discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20941v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20941v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20941v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20941v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20926v1"
                     data-domains="Radiology,Neuroradiology,Otolaryngology,Medical Imaging"
                     data-keywords="Deep learning,MRI,Contrast agent reduction,Cerebellopontine angle,Vestibular schwannoma,Image restoration,Dose reduction,Gadolinium"
                     data-authors="Yunjie Chen,Rianne A. Weber,Olaf M. Neve,Stephan R. Romeijn,Erik F. Hensen,Jelmer M. Wolterink,Qian Tao,Marius Staring,Berit M. Verbist">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20926v1.html">A deep learning model to reduce agent dose for contrast-enhanced MRI of the cerebellopontine angle cistern</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yunjie Chen, Rianne A. Weber, Olaf M. Neve et al.
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a deep learning (DL) model to reduce the contrast agent dose for T1-weighted contrast-enhanced MRI (T1ce) of the cerebellopontine angle (CPA) cistern. The DL model successfully restored image quality and segmentation performance from simulated low-dose MRI, enabling diagnostic characterization with only 10% to 30% of the standard contrast agent dose.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Otolaryngology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20926v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20926v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20926v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20926v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20913v1"
                     data-domains="Critical Care Medicine,Intensive Care Unit (ICU),Sepsis Management,Clinical Informatics"
                     data-keywords="Reinforcement Learning,Sepsis Treatment,Time-step Size,Offline RL,Healthcare AI,Patient Dynamics,Clinical Decision Support,Policy Optimization"
                     data-authors="Yingchuan Sun,Shengpu Tang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20913v1.html">Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yingchuan Sun, Shengpu Tang
                </div>

                <div class="paper-summary">
                    This paper investigates the impact of time-step size on reinforcement learning (RL) models designed for sepsis treatment, challenging the conventional 4-hour data aggregation. Through controlled empirical experiments across four time-step sizes (1h, 2h, 4h, 8h), the study found that finer granularities (1h and 2h), particularly when employing a static behavior policy, yield superior and more stable treatment policies. The findings underscore the critical role of time-step size in offline RL for healthcare, advocating for a re-evaluation of current practices in sepsis management.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Sepsis Management</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20913v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20913v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20913v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20913v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20883v1"
                     data-domains="Oncology,Immunology,Metabolism,Cancer Prevention,Personalized Medicine,Geriatric Oncology"
                     data-keywords="Immunometabolism,Peto's Paradox,T-cell infiltration,Cancer prognosis,Tissue metabolism,Immune exhaustion,Host-tumor interaction,Cancer prevention"
                     data-authors="Naomi Iris van den Berg,Matou≈° Elphick,Kevin Mulder,Omar Bouricha,Omid Sadeghi-Alavijeh,Xiao Fu,Samra Turajlic">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20883v1.html">Immunometabolic Gatekeeping: Reconciling Peto's & the T-cell Infiltration Prognostic Paradox</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Naomi Iris van den Berg, Matou≈° Elphick, Kevin Mulder et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the 'immunometabolic gatekeeping' framework, proposing that a tissue's intrinsic metabolic intensity and waste-handling capacity are upstream determinants of anti-tumour immunity, influencing whether immune infiltration translates into effective function. It reconciles several paradoxes, including Peto's paradox and the T-cell infiltration prognostic paradox, by positing that high-metabolism tissues with poor waste clearance create immune-exhausting niches even before malignant transformation. This framework shifts focus from tumor-intrinsic mutations to host tissue metabolism as a critical factor in cancer vulnerability and immune failure.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Metabolism</span>
                    
                    <span class="domain-tag">Cancer Prevention</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20883v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20883v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20883v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20883v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20835v1"
                     data-domains="Neurorehabilitation,Assistive Technology,Augmentative and Alternative Communication (AAC),Neurology,Human-Computer Interaction (HCI) in healthcare"
                     data-keywords="Brain-Computer Interface (BCI),Steady-State Visual Evoked Potentials (SSVEP),Non-invasive EEG,Mind-drawing,Stable Diffusion,Human-AI interaction,Bit-rate,Visual intent"
                     data-authors="Gao Wang,Yingying Huang,Lars Muckli,Daniele Faccio">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20835v1.html">Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gao Wang, Yingying Huang, Lars Muckli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel non-invasive Brain-Computer Interface (BCI) for "mind-drawing" that reconstructs simple imagined shapes by inferring a subject's internal visual intent. It leverages adaptive flicker-frequency encoded visual probes and Steady-State Visual Evoked Potentials (SSVEPs) from single-channel EEG, dynamically guided by AI policies, to achieve rapid and high-fidelity mental image reconstruction, significantly boosting BCI bit-rates.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurorehabilitation</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Augmentative and Alternative Communication (AAC)</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Human-Computer Interaction (HCI) in healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20835v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20835v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20835v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20835v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20823v1"
                     data-domains="Cardiology,Pulmonology,Radiology,Vascular Surgery,Interventional Radiology"
                     data-keywords="vascular tree,centerline detection,3D medical imaging,Transformer,recurrent refinement,image-to-graph,deep learning,topology,blood vessels"
                     data-authors="Roman Naeem,David Hagerman,Jennifer Alv√©n,Fredrik Kahl">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20823v1.html">RefTr: Recurrent Refinement of Confluent Trajectories for 3D Vascular Tree Centerline Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Naeem, David Hagerman, Jennifer Alv√©n et al.
                </div>

                <div class="paper-summary">
                    RefTr is a novel 3D image-to-graph model for generating centerlines of vascular and tubular trees by recurrently refining confluent trajectories using a Producer-Refiner Transformer architecture. It achieves superior recall and comparable precision to previous state-of-the-art methods, while significantly reducing model parameters and inference time. This approach is crucial for clinical applications where accurate detection of all branches, even small ones, is vital to prevent misdiagnosis or incomplete assessments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20823v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20823v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20823v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20823v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20819v1"
                     data-domains="Infectious disease epidemiology,Public health,Biostatistics,Outbreak investigation,Mathematical epidemiology"
                     data-keywords="Epidemic forests,transmission trees,outbreak analysis,PERMANOVA,chi-square test,statistical framework,infectious disease modeling,mixtree"
                     data-authors="Cyril Geismar,Peter J. White,Anne Cori,Thibaut Jombar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20819v1.html">A statistical framework for comparing epidemic forests</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cyril Geismar, Peter J. White, Anne Cori et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel statistical framework, utilizing chi-square and PERMANOVA tests, to robustly compare different "epidemic forests"‚Äîcollections of plausible transmission trees‚Äîderived from outbreak data. The framework addresses the critical gap of lacking formal methods to assess statistically significant differences between these forests, demonstrating PERMANOVA's superior sensitivity in distinguishing forests generated under varying transmission dynamics. It provides the first robust tool for quantitatively comparing epidemic forests.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious disease epidemiology</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Outbreak investigation</span>
                    
                    <span class="domain-tag">Mathematical epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20819v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20819v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20819v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20819v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20793v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Hepatology"
                     data-keywords="Liver tumor,Segmentation,Dynamic MRI,Multi-task learning,Adversarial learning,Deep learning,Classification,Regression"
                     data-authors="Xiaojiao Xiao,Qinmin Vivian Hu,Tae Hyun Kim,Guanghui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20793v1.html">Adversarial Multi-Task Learning for Liver Tumor Segmentation, Dynamic Enhancement Regression, and Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaojiao Xiao, Qinmin Vivian Hu, Tae Hyun Kim et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTI-Net, a novel end-to-end adversarial multi-task learning framework designed to simultaneously perform liver tumor segmentation, dynamic enhancement regression, and classification. By integrating multi-domain information fusion and task interaction modules, MTI-Net effectively leverages dynamic MRI data and inter-task dependencies, demonstrating high performance on a dataset of 238 subjects for clinical liver tumor assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20793v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20793v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20793v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20793v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20650v1"
                     data-domains="Radiology,Medical Diagnostics,Pathology,Imaging AI,Anatomy detection"
                     data-keywords="Open-vocabulary detection,Medical imaging,Real-time AI,Foundation models,Contrastive learning,Pseudo-labeling,Multi-modal data,Object detection"
                     data-authors="Tooba Tehreem Sheikh,Jean Lahoud,Rao Muhammad Anwer,Fahad Shahbaz Khan,Salman Khan,Hisham Cholakkal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20650v1.html">MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer et al.
                </div>

                <div class="paper-summary">
                    MedROV introduces the first real-time open-vocabulary object detection model for diverse medical imaging, addressing the critical limitation of traditional closed-set detectors in identifying novel pathologies. It achieves this by curating a large multi-modal dataset (Omnis), employing pseudo-labeling for data heterogeneity, and leveraging pre-trained foundation models with contrastive learning. The model effectively detects both known and novel medical structures, setting a new benchmark for speed and accuracy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Imaging AI</span>
                    
                    <span class="domain-tag">Anatomy detection</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20650v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20650v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20601v1"
                     data-domains="Endocrinology,Diabetology,Metabolic health,Digital health,Predictive analytics in medicine"
                     data-keywords="Blood glucose forecasting,Deep sequence models,Driver-Blindness,Autocorrelation,Insulin,Meals,Activity,Diabetes management,Physiological modeling,Causal regularization"
                     data-authors="Heman Shakeri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20601v1.html">The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Heman Shakeri
                </div>

                <div class="paper-summary">
                    This paper identifies and formalizes the 'Driver-Blindness Phenomenon' in deep sequence models for blood glucose forecasting, where these models consistently fail to leverage clinically informative drivers like insulin, meals, and activity. It introduces $Œî_{	ext{drivers}}$, a metric to quantify the performance gain from incorporating drivers, and observes that this gain is typically near zero across the literature. The authors attribute this to architectural biases, data fidelity issues, and physiological heterogeneity, proposing mitigation strategies and recommending routine reporting of $Œî_{	ext{drivers}}$ to ensure models are truly leveraging clinical insights.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Metabolic health</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Predictive analytics in medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20601v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20601v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20601v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20601v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20526v1"
                     data-domains="Pharmacy,Clinical Pharmacology,Health Education,Medical Licensure,Digital Health,Medical Informatics"
                     data-keywords="Large Language Models,LLMs,Pharmacist Examination,ChatGPT-4o,DeepSeek-R1,Medical Education,AI Assessment,Clinical Competency"
                     data-authors="Xinran Wang,Boran Zhu,Shujuan Zhou,Ziwen Long,Dehua Zhou,Shu Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20526v1.html">Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinran Wang, Boran Zhu, Shujuan Zhou et al.
                </div>

                <div class="paper-summary">
                    This study compared ChatGPT-4o and DeepSeek-R1's performance on real Chinese Pharmacist Licensing Examination questions, finding DeepSeek-R1 significantly outperformed ChatGPT-4o with 90.0% accuracy versus 76.1%. The results suggest that domain-specific LLMs can align robustly with high-stakes medical assessments, highlighting their potential for AI-enabled formative evaluation while emphasizing the continued necessity of human oversight.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacy</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Health Education</span>
                    
                    <span class="domain-tag">Medical Licensure</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20526v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20526v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20526v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20526v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20514v1"
                     data-domains="Interventional Radiology,Oncology,Diagnostic Imaging"
                     data-keywords="3D ultrasound tracking,photoacoustic beacon,needle guidance,interventional radiology,core needle biopsy,real-time visualization,time-of-flight,ex vivo"
                     data-authors="Christian Baker,Weidong Liang,Richard Colchester,Peng Lei,Francois Joubert,Sebastien Ourselin,Simeon West,Adrien Desjardins,Athanasios Diamantopoulos,Wenfeng Xia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20514v1.html">Real-time 3D Ultrasonic Needle Tracking with a Photoacoustic Beacon</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christian Baker, Weidong Liang, Richard Colchester et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel interventional ultrasound system that enables simultaneous 3D tracking and B-mode guidance of a core biopsy needle equipped with a photoacoustic beacon. The system addresses critical limitations of current 2D ultrasound guidance, which suffers from poor needle visibility and confusion over true tip location, by providing real-time, quantitative 3D visualization of the needle tip. Its performance was assessed in water and ex vivo tissue, and usability was evaluated by clinicians.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20514v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20514v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20514v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20514v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20510v2"
                     data-domains="Oncology,Pharmacology,Medicinal Chemistry,Drug Discovery"
                     data-keywords="Drug discovery,Molecule generation,Generative AI,Fragment-based design,Q-learning,Agentic AI,Lead optimization,Cancer drug discovery"
                     data-authors="Yuto Suzuki,Paul Awolade,Daniel V. LaBarbera,Farnoush Banaei-Kashani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20510v2.html">FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuto Suzuki, Paul Awolade, Daniel V. LaBarbera et al.
                </div>

                <div class="paper-summary">
                    FRAGMENTA is an end-to-end framework for drug lead optimization designed to overcome challenges of sparse datasets and slow model tuning. It integrates a novel generative model that uses dynamic Q-learning for joint fragmentation and generation, alongside an agentic AI system that automates objective refinement via conversational expert feedback. This approach significantly outperformed baselines in cancer drug discovery, with the fully autonomous Agent-Agent system surpassing traditional human-human tuning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20510v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20510v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20510v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20510v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20507v1"
                     data-domains="Neurology,Speech-Language Pathology,Cognitive Neuroscience,Rehabilitation Medicine"
                     data-keywords="aphasia,large language models,LLMs,language deficits,clinical assessment,benchmark,Quick Aphasia Battery,computational linguistics,neurology,speech-language pathology"
                     data-authors="Nathan Roll,Jill Kries,Flora Jin,Catherine Wang,Ann Marie Finley,Meghan Sumner,Cory Shain,Laura Gwilliams">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20507v1.html">The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery (QAB) designed to assess aphasia-like deficits in large language models (LLMs). It details the TAB's design, subtests (Connected Text, Word Comprehension, Sentence Comprehension, and Repetition), and scoring criteria. The authors validate an automated evaluation protocol using Gemini 2.5 Flash, demonstrating its reliability is comparable to expert human raters, providing a scalable and clinically-grounded framework for studying language deficits in artificial systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20507v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20507v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20503v1"
                     data-domains="Medical Imaging,Drug Discovery,Computational Biology,Synthetic Data Generation,Clinical Decision Support,Disease Modeling"
                     data-keywords="Generative Models,Manifold Learning,Continuum Percolation,Random Geometric Graphs,Topological Data Analysis,Mode Collapse,Hyper-Generalization,Machine Learning Evaluation"
                     data-authors="Rui Tong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20503v1.html">Generative Modeling with Manifold Percolation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Tong
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework for generative modeling by reframing the task as disentangling geometric support from probability distribution using Continuum Percolation. It proposes a new metric, "Percolation Shift," to robustly evaluate generative models, demonstrating its superiority over FID in detecting structural pathologies like implicit mode collapse, and translates this topological insight into a differentiable loss function to guide training towards "Hyper-Generalization."
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Synthetic Data Generation</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20503v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20503v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20503v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20503v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20501v1"
                     data-domains="Cerebrovascular diseases,Neuroradiology,Interventional Radiology,Diagnostic Imaging"
                     data-keywords="Cerebral artery segmentation,Digital Subtraction Angiography (DSA),Physics-Informed Loss (PIL),Deep learning,Vascular boundaries,Dislocation theory,U-Net,F1 score"
                     data-authors="Muhammad Irfan,Nasir Rahim,Khalid Mahmood Malik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20501v1.html">A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Irfan, Nasir Rahim, Khalid Mahmood Malik
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Physics-Informed Loss (PIL) function designed for accurate and robust cerebral artery segmentation in Digital Subtraction Angiography (DSA) sequences. PIL models boundary interactions as an elastic process, drawing from materials physics, to enforce geometric consistency and smooth contour evolution. This approach significantly improves segmentation precision and robustness compared to conventional loss functions across various deep learning architectures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cerebrovascular diseases</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20501v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20501v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20501v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20501v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20490v1"
                     data-domains="Oncology,Precision Medicine,Computational Pathology,Medical Imaging,Digital Health,Medical AI"
                     data-keywords="Multimodal LLMs,Clinical Decision-Making,Oncology,Molecular Tumor Boards,Benchmarking,Agentic Framework,Precision Oncology,Longitudinal Data"
                     data-authors="Kiril Vasilev,Alexandre Misrahi,Eeshaan Jain,Phil F Cheng,Petros Liakopoulos,Olivier Michielin,Michael Moor,Charlotte Bunne">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20490v1.html">MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTBBench, a novel agentic benchmark designed to simulate complex, multimodal, and longitudinal clinical decision-making in oncology, specifically within Molecular Tumor Boards (MTBs). It reveals that current LLMs demonstrate significant reliability issues, struggling with time-resolved data and conflicting evidence, but proposes an agentic framework within MTBBench that substantially improves reasoning performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20490v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20490v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20472v1"
                     data-domains="Radiation Oncology,Medical Physics,Radiotherapy"
                     data-keywords="In vivo dosimetry,Scintillation imaging,External beam radiotherapy,Surface dosimetry,Conformal array,Cherenkov imaging,Gamma analysis,Treatment verification"
                     data-authors="Roman Vasyltsiv,Allison L. Matous,Natasha Mulenga,Megan A. Clark,Brian W. Pogue,David J. Gladstone,Lesley A. Jarvis,Petr Bruza">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20472v1.html">Wide Area Surface Dosimetry with Conformal Scintillator Array for External Beam Radiotherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Vasyltsiv, Allison L. Matous, Natasha Mulenga et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel conformable scintillator array imaging system designed for wide-area surface dosimetry in external beam radiotherapy. The system successfully provides spatially resolved, dynamic, and accurate dose maps across complex anatomical surfaces, directly addressing key limitations of current in vivo dosimetry techniques such as spatiotemporal resolution and performance on non-uniform anatomy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiotherapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20472v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20472v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20472v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20472v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-30 06:25:56</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>