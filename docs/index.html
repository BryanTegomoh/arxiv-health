<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">148</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (8), Neurology (6), Pathology (5)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Neurology">Neurology (6)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Radiology">Radiology (5)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (4)</option>
                        
                        <option value="Genomics">Genomics (3)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (3)</option>
                        
                        <option value="Pediatrics">Pediatrics (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.13705v1"
                     data-domains="Oncology,Genomics,Computational Biology,Precision Medicine,Urology (Kidney Cancer)"
                     data-keywords="RNA-seq,Autoencoder,Clustering,Genomic Subtypes,Cancer,KIRC,Stability Analysis,Precision Medicine,Differential Expression"
                     data-authors="Alaa Mezghiche">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13705v1.html">Rare Genomic Subtype Discovery from RNA-seq via Autoencoder Embeddings and Stability-Aware Clustering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alaa Mezghiche
                </div>

                <div class="paper-summary">
                    This paper introduces a novel unsupervised learning approach combining autoencoder-based dimensionality reduction with stability-aware clustering to identify rare but reproducible genomic subtypes from RNA-seq data. Applied to Kidney Renal Clear Cell Carcinoma (KIRC), the method successfully discovered a rare (6.85% of patients), highly stable (Jaccard = 0.787) subtype, C0, characterized by coherent differentially expressed gene markers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Urology (Kidney Cancer)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13705v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13705v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13705v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13705v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13703v1"
                     data-domains="hospital administration,patient flow management,healthcare economics,quality improvement,risk prediction,clinical informatics,medical coding,insurance claims processing"
                     data-keywords="foundation models,LLMs,EHR,hospital operations,clinical predictions,finetuning,pretraining,AUROC,ReMedE,healthcare AI"
                     data-authors="Lavender Y. Jiang,Angelica Chen,Xu Han,Xujin Chris Liu,Radhika Dua,Kevin Eaton,Frederick Wolff,Robert Steele,Jeff Zhang,Anton Alyakin,Qingkai Pan,Yanbing Chen,Karl L. Sangwon,Daniel A. Alber,Jaden Stryker,Jin Vivian Lee,Yindalon Aphinyanaphongs,Kyunghyun Cho,Eric Karl Oermann">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13703v1.html">Generalist Foundation Models Are Not Clinical Enough for Hospital Operations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lavender Y. Jiang, Angelica Chen, Xu Han et al.
                </div>

                <div class="paper-summary">
                    This paper demonstrates that generalist foundation models are insufficient for critical hospital operational tasks, proposing Lang1, a family of specialized models pretrained on a blend of clinical EHR and internet data. Lang1, especially after supervised finetuning on real-world clinical benchmarks, significantly outperforms generalist models in accuracy and efficiency, underscoring the necessity of in-domain pretraining and practical evaluation for effective healthcare AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">hospital administration</span>
                    
                    <span class="domain-tag">patient flow management</span>
                    
                    <span class="domain-tag">healthcare economics</span>
                    
                    <span class="domain-tag">quality improvement</span>
                    
                    <span class="domain-tag">risk prediction</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13703v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13703v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13703v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13703v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13680v1"
                     data-domains="Infectious disease epidemiology,Rare disease research,Personalized medicine (with limited patient data),Clinical diagnostics (for conditions with scarce imaging or biomarker data)"
                     data-keywords="Cross-learning,Multi-task learning,Data scarcity,Constrained optimization,Parameter estimation,Knowledge transfer,Infectious diseases,Machine learning"
                     data-authors="Leopoldo Agorio,Juan Cervi√±o,Miguel Calvo-Fullana,Alejandro Ribeiro,Juan Andr√©s Bazerque">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13680v1.html">Cross-Learning from Scarce Data via Multi-Task Constrained Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Leopoldo Agorio, Juan Cervi√±o, Miguel Calvo-Fullana et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a multi-task cross-learning framework designed to overcome the challenges of data scarcity by jointly estimating deterministic parameters across multiple, related tasks. It formulates this joint estimation as a constrained optimization problem, where constraints dictate the similarity between model parameters, enabling knowledge transfer from data-rich tasks to data-scarce ones. This approach leads to more accurate and reliable parameter estimates, particularly critical in scenarios with limited available data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious disease epidemiology</span>
                    
                    <span class="domain-tag">Rare disease research</span>
                    
                    <span class="domain-tag">Personalized medicine (with limited patient data)</span>
                    
                    <span class="domain-tag">Clinical diagnostics (for conditions with scarce imaging or biomarker data)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13680v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13680v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13680v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13680v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13668v1"
                     data-domains="Psychiatry,Clinical Neuroscience,Affective Neuroscience,Computational Psychiatry,Neurology"
                     data-keywords="Predictive coding,Interoception,Exteroception,Precision weighting,Anxiety,PTSD,Anterior insula,Anterior cingulate cortex"
                     data-authors="Pranjal Balar,Sundeep Kapila">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13668v1.html">Integrative Model for Interoception and Exteroception: predictive coding, points of modulation, and testable predictions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pranjal Balar, Sundeep Kapila
                </div>

                <div class="paper-summary">
                    This paper presents an integrative predictive coding model for interoceptive and exteroceptive integration, where relative precision weights arbitrate between the two streams in the AIC and ACC. Computational simulations replicated stable integration and modeled how dysregulated precision weighting, characteristic of anxiety (interoceptive overweighting) and PTSD (exteroceptive overweighting), creates rigid imbalances and slowed recalibration. Empirical validation with EEG-fMRI data supports the model, which offers a unifying framework for these psychiatric conditions and outlines testable predictions for targeted therapies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Neuroscience</span>
                    
                    <span class="domain-tag">Affective Neuroscience</span>
                    
                    <span class="domain-tag">Computational Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13668v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13668v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13668v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13668v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13637v1"
                     data-domains="Paediatrics,Nephrology,Clinical Informatics,Predictive Medicine,Computational Health"
                     data-keywords="paediatric kidney disease,recurrent neural networks,temporal modeling,electronic health records,serum creatinine,renal function,predictive analytics,machine learning"
                     data-authors="Ana Durica,John Booth,Ivana Drobnjak">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13637v1.html">Towards Multimodal Representation Learning in Paediatric Kidney Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ana Durica, John Booth, Ivana Drobnjak
                </div>

                <div class="paper-summary">
                    This pilot study explores a temporal modeling approach using a recurrent neural network on electronic health record (EHR) data from paediatric kidney disease patients at Great Ormond Street Hospital. It successfully demonstrated that integrating longitudinal laboratory sequences with demographic information can capture useful patterns to predict abnormal serum creatinine within 30 days, laying the groundwork for future multimodal extensions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Paediatrics</span>
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                    <span class="domain-tag">Computational Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13637v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13637v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13637v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13637v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13634v1"
                     data-domains="physics.ins-det"
                     data-keywords="physics.ins-det,nucl-ex,nucl-th,physics.med-ph"
                     data-authors="Fernando Cozim Melges,Jhonatha Ricardo Santos,Luiz Paulo de Oliveira,Alexandre Pinho dos Santos Souza,Carlos Gabriel Santos da Silva,Iber√™ Souza Ribeiro J√∫nior,Barbara Perez Gon√ßalves Silva,Marco Antonio Stanojev Pereira,Frederico Antonio Genezini">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13634v1.html">Exploring the production of Terbium-161 in the Brazilian Multipurpose Reactor</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.ins-det</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fernando Cozim Melges, Jhonatha Ricardo Santos, Luiz Paulo de Oliveira et al.
                </div>

                <div class="paper-summary">
                    The Brazilian Multipurpose Reactor (RMB) was conceived to meet national needs for radioisotope production, materials irradiation testing, and neutron beam applications. In addition to its 30~MW pool-type reactor, the RMB complex will include additional facilities for radioisotope production and rela...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">physics.ins-det</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13634v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13634v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13634v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13634v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13615v1"
                     data-domains="Pathology,Oncology,Histology,Digital Pathology"
                     data-keywords="Computational Pathology,Nuclei Detection,Nuclei Classification,Tissue Context,Deep Learning,Point-level Supervision,Histopathology,Spatial-FiLM"
                     data-authors="Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13615v1.html">Tissue Aware Nuclei Detection and Classification Model for Histopathology Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kesi Xu, Eleni Chiou, Ali Varamesh et al.
                </div>

                <div class="paper-summary">
                    Tissue-Aware Nuclei Detection (TAND) is a novel deep learning framework designed for joint nuclei detection and classification in histopathology images, addressing limitations of extensive expert annotations and insufficient tissue context. It integrates a ConvNeXt encoder-decoder with a frozen Virchow-2 tissue segmentation branch, leveraging semantic tissue probabilities via a multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM) to condition per-cell classification using only point-level supervision. TAND achieves state-of-the-art performance on the PUMA benchmark, particularly improving classification of tissue-dependent cell types, and offers a practical approach to reduce annotation burden.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13615v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13615v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13615v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13615v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13609v1"
                     data-domains="Neuroradiology,Neurology,Neuroscience,Computational Medicine,Geriatrics,Pediatrics"
                     data-keywords="Deformable templates,Medical imaging,Brain MRI,Machine learning,Convolutional neural networks,Image registration,Anatomical segmentation,Computational anatomy,Atlases"
                     data-authors="Marianne Rakic,Andrew Hoopes,S. Mazdak Abulnaga,Mert R. Sabuncu,John V. Guttag,Adrian V. Dalca">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13609v1.html">AtlasMorph: Learning conditional deformable templates for brain MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marianne Rakic, Andrew Hoopes, S. Mazdak Abulnaga et al.
                </div>

                <div class="paper-summary">
                    This paper introduces AtlasMorph, a novel machine learning framework utilizing convolutional registration neural networks to address the scarcity and sub-optimality of medical image templates (atlases) due to their high computational cost. The framework efficiently learns to generate high-quality, deformable brain MRI templates conditioned on subject-specific attributes like age and sex, while also incorporating anatomical segmentation maps. The authors demonstrate that these annotated conditional templates enable superior image registration compared to existing methods and their unconditional counterparts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13609v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13609v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13609v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13609v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13586v1"
                     data-domains="Pathology,Oncology,Immunology,Histology,Diagnostic Medicine,Computational Pathology"
                     data-keywords="Histopathology,Cell Annotation,Multi-scale Integration,Deep Learning,Spatial Transcriptomics,Nuclear Morphology,Microenvironment,Uncertainty-aware Fusion"
                     data-authors="Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13586v1.html">Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yinuo Xu, Yan Cui, Mingyao Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces NuClass, a novel deep learning framework designed to overcome limitations in cell annotation from histopathology images by integrating multi-scale information. NuClass combines detailed nuclear morphology with broader microenvironmental context using an adaptive, uncertainty-aware fusion mechanism. Evaluated on a new, high-quality spatial transcriptomics-derived dataset, NuClass achieves significantly improved performance, enabling robust and interpretable cell-level phenotype prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13586v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13586v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13586v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13586v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13565v1"
                     data-domains="Precision Medicine,Preventive Healthcare,Personalized Medicine,Digital Health,Chronic Disease Management,Rehabilitation Medicine"
                     data-keywords="Artificial Intelligence,Wearable Systems,Precision Medicine,Human-Symbiotic Health Intelligence,Multi-modal Sensors,Edge-Cloud Computing,Reinforcement Learning,Digital Twins"
                     data-authors="Jingyi Zhao,Daqian Shi,Zhengda Wang,Xiongfeng Tang,Yanguo Qin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13565v1.html">Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingyi Zhao, Daqian Shi, Zhengda Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Human-Symbiotic Health Intelligence (HSHI), a novel full-stack framework for AI-driven intelligent wearable systems designed to overcome limitations of traditional devices. HSHI integrates multi-modal sensing, edge-cloud computing, and hybrid data/knowledge modeling to provide dynamic, personalized health management, shifting healthcare from passive monitoring to active, preventive, and adaptable care.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Preventive Healthcare</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13565v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13565v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13565v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13565v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13526v1"
                     data-domains="Clinical Decision Support,Disease Diagnosis,Treatment Decision-making,Biomedical Research,Medical Informatics"
                     data-keywords="Medical Knowledge Graphs,Large Language Models (LLMs),Retrieval Augmented Generation (RAG),Clinical Decision Support,AI in Healthcare,Automated Knowledge Construction,Medical Indicators,Ontology"
                     data-authors="Zhengda Wang,Daqian Shi,Jingyi Zhao,Xiaolei Diao,Xiongfeng Tang,Yanguo Qin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13526v1.html">Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhengda Wang, Daqian Shi, Jingyi Zhao et al.
                </div>

                <div class="paper-summary">
                    This paper proposes an automated framework leveraging Retrieval Augmented Generation (RAG) with Large Language Models (LLMs) for constructing medical indicator knowledge graphs. This approach aims to overcome the limitations of manual and rule-based methods by enabling scalable, accurate, and clinically reliable extraction of structured knowledge from complex medical texts. The resulting knowledge graphs are designed to integrate into advanced AI-driven healthcare solutions, such as intelligent diagnosis and question-answering systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Disease Diagnosis</span>
                    
                    <span class="domain-tag">Treatment Decision-making</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13526v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13526v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13526v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13526v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13457v1"
                     data-domains="Cardiology,Pulmonology,Critical Care Medicine,Nephrology,Geriatrics"
                     data-keywords="Right Heart Failure,Spirometry,Artificial Intelligence,Self-supervised Learning,Cor Pulmonale,Early Detection,CatBoost,UK Biobank"
                     data-authors="Bin Liu,Qinghao Zhao,Yuxi Zhou,Zhejun Sun,Kaijie Lei,Deyun Zhang,Shijia Geng,Shenda Hong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13457v1.html">Artificial Intelligence-Enabled Spirometry for Early Detection of Right Heart Failure</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bin Liu, Qinghao Zhao, Yuxi Zhou et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel AI-enabled approach for the early detection of Right Heart Failure (RHF) in patients with cor pulmonale, utilizing self-supervised representation learning on spirogram time series data. The model combines spirogram embeddings with demographic information and a CatBoost classifier, achieving strong predictive performance, particularly in high-risk clinical subgroups. This non-invasive method offers promising potential for improving early RHF screening in clinical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13457v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13457v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13457v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13457v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13381v1"
                     data-domains="Pediatrics,Clinical Medicine,Medical Ethics,Diagnostic Reasoning,Treatment Planning,Medical Education,Patient Communication"
                     data-keywords="Large Language Models,LLMs,Pediatrics,Clinical Evaluation,PEDIASBench,AI in Medicine,Medical Ethics,Dynamic Diagnosis,Decision Support,Human-AI Collaboration"
                     data-authors="Siyu Zhu,Mouxiao Bian,Yue Xie,Yongyu Tang,Zhikang Yu,Tianbin Li,Pengcheng Chen,Bing Han,Jie Xu,Xiaoyan Dong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13381v1.html">Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Siyu Zhu, Mouxiao Bian, Yue Xie et al.
                </div>

                <div class="paper-summary">
                    This paper systematically evaluated 12 large language models (LLMs) as potential pediatricians using a novel framework called PEDIASBench, tailored for real-world clinical contexts. While LLMs demonstrated strong foundational knowledge, they exhibited significant limitations in complex reasoning, dynamic diagnosis adaptation, and humanistic sensitivity. The findings suggest current LLMs cannot independently perform pediatric care but hold promise for supportive roles in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Clinical Medicine</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                    <span class="domain-tag">Diagnostic Reasoning</span>
                    
                    <span class="domain-tag">Treatment Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13381v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13381v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13381v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13381v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13373v1"
                     data-domains="Distributed healthcare AI,Medical natural language processing,Telemedicine,Resource-constrained medical devices (IoT),Federated Learning in Medicine"
                     data-keywords="LLM merging,Distributed AI,Medical LLM,Parameter merging,Optimal Transport,Task Arithmetic,Computational efficiency,Edge AI,Catastrophic forgetting"
                     data-authors="Prakrit Timilsina,Anuj Nepal,Rajan Kadel,Robin Doss">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13373v1.html">A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Prakrit Timilsina, Anuj Nepal, Rajan Kadel et al.
                </div>

                <div class="paper-summary">
                    This paper addresses critical challenges in distributed healthcare LLMs, such as knowledge consolidation, computational overhead, and catastrophic forgetting, by evaluating six parameter-space merging techniques, including a novel hierarchical method. It demonstrates that for architecturally compatible medical LLMs (derived from Mistral-7B), simple averaging methods like Task Arithmetic significantly outperform complex approaches, achieving 45.80% accuracy on MedQA. This establishes simple averaging as a robust and computationally efficient baseline for scalable medical AI in resource-constrained IoT environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Distributed healthcare AI</span>
                    
                    <span class="domain-tag">Medical natural language processing</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Resource-constrained medical devices (IoT)</span>
                    
                    <span class="domain-tag">Federated Learning in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13373v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13373v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13373v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13373v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13361v1"
                     data-domains="Health Information Management,Medical Billing and Reimbursement,Hospital Administration,Clinical Documentation Improvement,Medical Research Data Management"
                     data-keywords="Medical coding,Agentic LLMs,Workflow learning,Closed-loop framework,Automated coding,Healthcare operations,AI in medicine,Diagnostic codes"
                     data-authors="Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13361v1.html">MedDCR: Learning to Design Agentic Workflows for Medical Coding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiyang Zheng, Islam Nassar, Thanh Vu et al.
                </div>

                <div class="paper-summary">
                    MedDCR introduces a novel closed-loop framework for learning to design adaptive agentic workflows for medical coding, overcoming the limitations of rigid, manually crafted approaches. It leverages a Designer, Coder, and Reflector with a memory archive to systematically refine coding workflows, achieving state-of-the-art performance and generating interpretable, adaptable solutions that mirror real-world practice. This approach enhances the reliability and trustworthiness of automated medical coding systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Information Management</span>
                    
                    <span class="domain-tag">Medical Billing and Reimbursement</span>
                    
                    <span class="domain-tag">Hospital Administration</span>
                    
                    <span class="domain-tag">Clinical Documentation Improvement</span>
                    
                    <span class="domain-tag">Medical Research Data Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13361v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13361v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13361v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13361v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13353v1"
                     data-domains="Ophthalmology,Diagnostic Imaging,Telemedicine,Preventive Medicine (Eye Health Screening)"
                     data-keywords="Retinal Image Quality Assessment,Semi-Supervised Learning,Multi-Task Learning,Pseudo-Labeling,Fundus Images,Interpretable AI,Ophthalmology,Deep Learning"
                     data-authors="Lucas Gabriel Telesco,Danila Nejamkin,Estefan√≠a Mata,Francisco Filizzola,Kevin Wignall,Luc√≠a Franco Troilo,Mar√≠a de los Angeles Cenoz,Melissa Thompson,Mercedes Legu√≠a,Ignacio Larrabide,Jos√© Ignacio Orlando">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13353v1.html">Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lucas Gabriel Telesco, Danila Nejamkin, Estefan√≠a Mata et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a hybrid semi-supervised multi-task learning approach to enhance retinal image quality assessment (RIQA) by providing interpretable feedback on specific acquisition defects without extensive manual labeling. The method combines manual overall quality labels with pseudo-labels for detailed quality attributes, generated by a Teacher model, to improve overall quality assessment and offer actionable insights into issues like illumination, clarity, and contrast. This approach aims to make RIQA models more useful in clinical settings by guiding image recapture processes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Preventive Medicine (Eye Health Screening)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13353v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13353v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13353v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13353v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13351v1"
                     data-domains="nutrition science,dietetics,preventive medicine,chronic disease management,public health,personalized medicine"
                     data-keywords="continual learning,multimodal AI,food analysis,catastrophic forgetting,LoRA,pseudo replay,personalized nutrition,chronic disease prevention"
                     data-authors="Xinlan Wu,Bin Zhu,Feng Han,Pengkun Jiao,Jingjing Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13351v1.html">Dual-LoRA and Quality-Enhanced Pseudo Replay for Multimodal Continual Food Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinlan Wu, Bin Zhu, Feng Han et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel continual learning framework, integrating a Dual-LoRA architecture with Quality-Enhanced Pseudo Replay, to address catastrophic forgetting in large multimodal models (LMMs) used for food analysis. The approach enables LMMs to learn new food-related tasks without forgetting previously acquired knowledge, crucial for health applications like personalized nutrition and chronic disease prevention. Experiments on the Uni-Food dataset demonstrate superior performance in mitigating forgetting, establishing the first effective continual learning method for complex food tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">nutrition science</span>
                    
                    <span class="domain-tag">dietetics</span>
                    
                    <span class="domain-tag">preventive medicine</span>
                    
                    <span class="domain-tag">chronic disease management</span>
                    
                    <span class="domain-tag">public health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13351v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13351v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13351v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13351v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13295v1"
                     data-domains="Oncology,Genetics,Pharmacogenomics,Diagnostics,Personalized Medicine,Systems Biology"
                     data-keywords="Biomarker Discovery,Causal Inference,Graph Neural Network (GNN),Transcriptomics,Precision Medicine,Feature Selection,Gene Regulatory Networks,Stability"
                     data-authors="Chaowang Lan,Jingxin Wu,Yulong Yuan,Chuxun Liu,Huangyi Kang,Caihua Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13295v1.html">Causal Inference, Biomarker Discovery, Graph Neural Network, Feature Selection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chaowang Lan, Jingxin Wu, Yulong Yuan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Causal-GNN, a novel method for stable biomarker discovery from high-throughput transcriptomic data, addressing the limitations of existing methods that often neglect gene-gene regulatory relationships and lack stability. By integrating causal inference with multi-layer graph neural networks, particularly through GNN-based propensity scoring, the method achieves consistently high predictive accuracy and identifies more stable and biologically interpretable biomarkers. This robust tool holds strong potential for advancing precision medicine by providing more reliable insights into disease mechanisms.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Genetics</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13295v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13295v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13295v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13295v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13293v1"
                     data-domains="General Healthcare Prediction,Clinical Decision Support,Medical AI"
                     data-keywords="Healthcare Prediction,Large Language Models (LLMs),Retrieval-Augmented Generation (RAG),Agentic AI,Markov Decision Process (MDP),Clinical Decision Support,Factual Accuracy"
                     data-authors="Chuang Zhao,Hui Tang,Hongke Zhao,Xiaofang Zhou,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13293v1.html">Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chuang Zhao, Hui Tang, Hongke Zhao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GHAR, a generative hierarchical agentic Retrieval-Augmented Generation (RAG) framework designed to enhance healthcare prediction accuracy by addressing limitations in Large Language Models (LLMs). GHAR resolves when to retrieve external knowledge and how to optimize collaboration between its components through a novel dual-agent architecture and Markov Decision Process (MDP)-based optimization. The framework demonstrates superior performance against state-of-the-art baselines on benchmark healthcare prediction tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Healthcare Prediction</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13293v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13293v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13293v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13293v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13276v1"
                     data-domains="Elderly care,Critical care,Patient safety,Telemedicine,Psychiatry,Hospital security"
                     data-keywords="Anomaly detection,Surveillance video analysis,Weakly supervised learning,Dual-encoder models,Convolutional neural networks,Transformers,Patient monitoring,Healthcare safety"
                     data-authors="Noam Tsfaty,Avishai Weizman,Liav Cohen,Moshe Tshuva,Yehudit Aperstein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13276v1.html">Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Noam Tsfaty, Avishai Weizman, Liav Cohen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a weakly supervised dual-encoder model designed for detecting rare and diverse abnormal events within surveillance videos. The framework effectively combines convolutional and transformer representations using a top-k pooling mechanism, achieving a notable performance of 90.7% Area Under the Curve (AUC) on the UCF-Crime dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Elderly care</span>
                    
                    <span class="domain-tag">Critical care</span>
                    
                    <span class="domain-tag">Patient safety</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13232v1"
                     data-domains="Neonatology,Pediatric Neurology,Medical Imaging,Radiology,Biomedical Engineering"
                     data-keywords="ultra-low-field MRI,diffusion model,image quality transfer,neonatal neuroimaging,deep learning,signal-to-noise ratio,brain MRI,physics-aware"
                     data-authors="Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13232v1.html">MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Malek Al Abed, Sebiha Demir, Anne Groteklaes et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MRIQT, a 3D conditional diffusion model designed for image quality transfer (IQT) to enhance ultra-low-field (uLF) neonatal MRI scans to the quality of high-field (HF) MRI. By employing physics-aware K-space degradation, v-prediction with classifier-free guidance, and an SNR-weighted perceptual loss, MRIQT significantly improves image quality. The model outperforms existing baselines and enables reliable brain assessment in neonates, as validated by both quantitative metrics and physician ratings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neonatology</span>
                    
                    <span class="domain-tag">Pediatric Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13232v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13232v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13232v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13232v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13185v1"
                     data-domains="Medical diagnostics,Chemical pathology,Biomedical imaging,Biophysics,Spectroscopy in medicine"
                     data-keywords="CARS spectroscopy,Raman spectroscopy,Uncertainty Quantification (UQ),Physics-informed Neural Networks (PINNs),Signal Reconstruction,Kramers-Kronig,Biomedical applications,Deep Learning"
                     data-authors="Aishwarya Venkataramanan,Sai Karthikeya Vemuri,Adithya Ashok Chalain Valapil,Joachim Denzler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13185v1.html">Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aishwarya Venkataramanan, Sai Karthikeya Vemuri, Adithya Ashok Chalain Valapil et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of reconstructing true Raman signals from CARS spectroscopy data, which is often distorted by a non-resonant background. It evaluates various uncertainty quantification (UQ) techniques integrated within physics-informed neural networks (PINNs) to provide robust signal reconstruction, demonstrating that incorporating physics constraints significantly improves model calibration for more trustworthy analysis in biomedical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical diagnostics</span>
                    
                    <span class="domain-tag">Chemical pathology</span>
                    
                    <span class="domain-tag">Biomedical imaging</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                    <span class="domain-tag">Spectroscopy in medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13185v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13185v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13185v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13185v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13170v1"
                     data-domains="Pathology,Oncology,Diagnostic Imaging,Computational Pathology"
                     data-keywords="Topological Data Analysis,Persistent Homology,Betti Numbers,Histopathological Image Retrieval,Breast Cancer,Unsupervised Learning,Digital Pathology,Content-Based Medical Image Retrieval"
                     data-authors="Zahra Tabatabaei,Jon Sporring">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13170v1.html">THIR: Topological Histopathological Image Retrieval</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zahra Tabatabaei, Jon Sporring
                </div>

                <div class="paper-summary">
                    THIR (Topological Histopathological Image Retrieval) is a novel unsupervised Content-Based Medical Image Retrieval (CBMIR) framework that leverages Betti numbers from persistent homology, a topological data analysis method, to characterize histopathological images based on their intrinsic structural patterns. It demonstrates superior performance compared to state-of-the-art supervised and unsupervised methods on the BreaKHis dataset, offering a fast, scalable, and training-free solution for clinical image retrieval without requiring extensive data annotation or powerful GPU resources.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13170v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13170v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13170v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13170v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13169v1"
                     data-domains="Traditional Chinese Medicine,Clinical Informatics,Medical Artificial Intelligence,Pharmacology (TCM)"
                     data-keywords="Traditional Chinese Medicine (TCM),Large Language Models (LLMs),Clinical Evaluation,Benchmark,Positional Bias,Inference Fragility,Medical AI,Materia Medica"
                     data-authors="Tianai Huang,Jiayuan Chen,Lu Lu,Pengcheng Chen,Tianbin Li,Bing Han,Wenchao Tang,Jie Xu,Ming Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13169v1.html">TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tianai Huang, Jiayuan Chen, Lu Lu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TCM-5CEval, an extended and more granular benchmark designed for a deep evaluation of large language models' (LLMs) comprehensive clinical research competence in Traditional Chinese Medicine (TCM). The evaluation of fifteen prominent LLMs revealed significant performance disparities, identified top models, and critically exposed widespread fragilities in inference stability, particularly a pervasive sensitivity to positional bias from varied question option ordering.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Traditional Chinese Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Pharmacology (TCM)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13169v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13169v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13169v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13169v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13160v1"
                     data-domains="cs.AI"
                     data-keywords="cs.AI,cs.LG"
                     data-authors="TC Singh,Sougata Mukherjea">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13160v1.html">InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> TC Singh, Sougata Mukherjea
                </div>

                <div class="paper-summary">
                    Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque "black boxes". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduc...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13160v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13160v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13160v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13160v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13135v1"
                     data-domains="Radiology,Medical Imaging,Clinical Diagnosis,Pathology (implied by imaging modalities and diagnostic tasks)"
                     data-keywords="Medical AI,Vision-Language Models,Multimodal Generation,Medical Imaging,Benchmarking,Clinical Workflow,Cross-modal Reasoning,Diagnostic AI"
                     data-authors="Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13135v1.html">MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junjie Yang, Yuhao Yan, Gang Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedGEN-Bench, a comprehensive multimodal benchmark designed to overcome limitations in existing medical visual benchmarks, which often feature ambiguous queries and oversimplified reasoning. It comprises 6,422 expert-validated image-text pairs across six imaging modalities and 16 clinical tasks, specifically structured for open-ended, contextually intertwined generation requiring sophisticated cross-modal reasoning. The benchmark, along with a novel three-tier assessment framework, systematically evaluates various Vision-Language Models to advance medical AI research towards generating integrated textual diagnoses and corresponding medical images for authentic clinical workflows.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Diagnosis</span>
                    
                    <span class="domain-tag">Pathology (implied by imaging modalities and diagnostic tasks)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13135v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13135v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13135v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13135v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13124v1"
                     data-domains="Pharmacology,Genomics,Drug Discovery,Systems Biology,Precision Medicine,Computational Biomedicine"
                     data-keywords="Single-cell perturbation,Schr√∂dinger Bridge,Optimal Transport,Gene expression prediction,Drug discovery,Cellular heterogeneity,Machine learning,Computational biology"
                     data-authors="Changxi Chi,Yufei Huang,Jun Xia,Jiangbin Zheng,Yunfan Liu,Zelin Zang,Stan Z. Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13124v1.html">Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schr√∂dinger Bridges</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Changxi Chi, Yufei Huang, Jun Xia et al.
                </div>

                <div class="paper-summary">
                    This paper introduces "Departures," a novel framework utilizing Neural Schr√∂dinger Bridges (SB) with Minibatch-Optimal Transport (Minibatch-OT) to predict single-cell perturbation outcomes, overcoming the challenge of unpaired single-cell data. The method directly aligns control and perturbed cell populations, modeling both discrete gene activation and continuous expression distributions. It achieves state-of-the-art performance on public genetic and drug perturbation datasets, accurately capturing single-cell heterogeneity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13124v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13124v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13124v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13124v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13106v1"
                     data-domains="Medical Imaging,Radiology,Diagnostic Imaging,Computational Healthcare"
                     data-keywords="Medical Image Enhancement,Dataset Distillation (DD),Low-Level Vision,Pixel-Level Fidelity,Privacy Preservation,Anatomical Prior,Gradient Alignment,Structure-Preserving Generation"
                     data-authors="Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13106v1.html">Low-Level Dataset Distillation for Medical Image Enhancement</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fengzhi Xu, Ziyuan Yang, Mengyu Sun et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the first low-level Dataset Distillation (DD) method tailored for medical image enhancement, addressing the challenges of large dataset requirements, computational costs, and the inherent difficulty of applying DD to pixel-level tasks. It achieves this by leveraging a shared anatomical prior, personalized via a Structure-Preserving Personalized Generation (SPG) module, and injecting patient-specific knowledge through gradient alignment, all while sharing only abstract, privacy-preserving training information.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13106v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13106v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13106v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13106v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13103v1"
                     data-domains="Public Health,Epidemiology,Infectious Disease Control,Health Systems Management,Biosecurity"
                     data-keywords="Multi-Agent Reinforcement Learning,Transformer Networks,Graph Neural Networks,Epidemic Control,Network Generalization,Scalability,Long-Range Dependencies,Counterfactual Advantage"
                     data-authors="Vidur Sinha,Muhammed Ustaomeroglu,Guannan Qu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13103v1.html">Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vidur Sinha, Muhammed Ustaomeroglu, Guannan Qu
                </div>

                <div class="paper-summary">
                    This paper introduces STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a novel transformer-based Multi-Agent Reinforcement Learning (MARL) framework addressing key limitations in network control. STACCA effectively captures long-range dependencies and achieves generalizability across diverse network topologies, utilizing a Graph Transformer Actor-Critic architecture and an improved credit assignment mechanism. Evaluated on epidemic containment and rumor spreading, it demonstrates superior performance, network generalization, and scalability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Disease Control</span>
                    
                    <span class="domain-tag">Health Systems Management</span>
                    
                    <span class="domain-tag">Biosecurity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13103v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13103v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13103v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13103v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13099v1"
                     data-domains="Pathology,Oncology,Digital Pathology,Computational Pathology"
                     data-keywords="Lifelong Learning,Whole Slide Images,WSI,Model Merging,Continual Learning,Vision-Language Models,Pathology,Cancer,Prompt Learning,Catastrophic Forgetting"
                     data-authors="Doanh C. Bui,Ba Hung Ngo,Hoai Luan Pham,Khang Nguyen,Ma√Ø K. Nguyen,Yasuhiko Nakashima">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13099v1.html">MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Doanh C. Bui, Ba Hung Ngo, Hoai Luan Pham et al.
                </div>

                <div class="paper-summary">
                    MergeSlide introduces a novel framework for lifelong learning on Whole Slide Images (WSIs) by treating it as a model merging problem leveraging a vision-language pathology foundation model. It enables continuous integration of new cancer-related tasks through class-aware prompts, brief fine-tuning, and an orthogonal merging strategy, while employing a unique Task-to-Class Prompt-aligned (TCP) inference for class-incremental settings. The framework significantly outperforms existing continual learning and zero-shot baselines on TCGA datasets, effectively mitigating catastrophic forgetting.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13099v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13099v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13099v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13099v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13082v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Surgical Navigation,Medical AI"
                     data-keywords="breast cancer,biopsy,graph neural network,finite element model,real-time prediction,MRI-guided,tumor displacement,deformation-aware"
                     data-authors="Kyunghyun Lee,Yong-Min Shin,Minwoo Shin,Jihun Kim,Sunghwan Lim,Won-Yong Shin,Kyungho Yoon">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13082v1.html">Real-time prediction of breast cancer sites using deformation-aware graph neural network</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kyunghyun Lee, Yong-Min Shin, Minwoo Shin et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel graph neural network (GNN)-based model for real-time, accurate prediction of breast cancer tumor displacement during indirect MRI-guided biopsy procedures. By integrating individual-specific finite element (FE) models derived from MR images with a GNN trained on surface displacement and distance data, the model precisely predicts tissue and tumor deformation, significantly enhancing the precision and efficiency of breast cancer diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Surgical Navigation</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13082v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13082v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13082v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13082v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13078v1"
                     data-domains="Emergency Medicine,Pre-hospital Care,Paramedicine,Critical Care Transport"
                     data-keywords="Smart glasses,Emergency Medical Services,Multimodal learning,Multitask learning,Artificial intelligence,Real-time inference,Decision support systems,Pre-hospital care"
                     data-authors="Liuyi Jin,Pasan Gunawardena,Amran Haroon,Runzhi Wang,Sangwoo Lee,Radu Stoleru,Michael Middleton,Zepeng Huo,Jeeeun Kim,Jason Moats">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13078v1.html">A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Liuyi Jin, Pasan Gunawardena, Amran Haroon et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EMSGlass, a smart-glasses system for Emergency Medical Services (EMS) designed to alleviate cognitive load and improve decision-making for EMTs. It leverages EMSNet, the first multimodal multitask AI model for EMS, and EMSServe, a low-latency serving framework, to integrate text, vital signs, and images for real-time situational understanding and decision support. User studies demonstrate EMSGlass enhances situational awareness, decision-making speed, and operational efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Pre-hospital Care</span>
                    
                    <span class="domain-tag">Paramedicine</span>
                    
                    <span class="domain-tag">Critical Care Transport</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13078v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13078v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13078v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13078v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13020v1"
                     data-domains="Medical Diagnostics,Disease Monitoring,Biomedical Imaging,Surgical Guidance,Dermatology"
                     data-keywords="Hyperspectral Imaging,Semi-Supervised Domain Adaptation,Spectral Reconstruction,Healthcare,Spectral Priors,Spectral Density Masking,Endmember Alignment,Medical Imaging"
                     data-authors="Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13020v1.html">SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yufei Wen, Yuting Zhang, Jingdan Kang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework designed to reconstruct hyperspectral images (HSI) from accessible RGB data. Its primary goal is to bridge the significant domain gap between general and human-centered HSI datasets, thereby enabling practical applications in healthcare despite the scarcity of labeled medical HSI. The framework significantly enhances spectral fidelity and cross-domain generalization, making HSI reconstruction more viable for medical use.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Disease Monitoring</span>
                    
                    <span class="domain-tag">Biomedical Imaging</span>
                    
                    <span class="domain-tag">Surgical Guidance</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13020v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13020v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13020v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13020v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.13018v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG"
                     data-authors="Sairam S,Sara Girdhar,Shivam Soni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.13018v1.html">The Final-Stage Bottleneck: A Systematic Dissection of the R-Learner for Network Causal Inference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sairam S, Sara Girdhar, Shivam Soni
                </div>

                <div class="paper-summary">
                    The R-Learner is a powerful, theoretically-grounded framework for estimating heterogeneous treatment effects, prized for its robustness to nuisance model errors. However, its application to network data, where causal heterogeneity is often graph-dependent, presents a critical challenge to its core a...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.13018v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.13018v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.13018v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.13018v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12990v1"
                     data-domains="Neuroscience,Psychiatry,Addiction Medicine,Neurology,Computational Biology"
                     data-keywords="Brain Networks,Functional Connectivity,Network Topology,Hodge Decomposition,Wasserstein Distance,Persistence Diagrams,ADHD,Cannabis Use"
                     data-authors="Sixtus Dakurah">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12990v1.html">Brain Networks Flow-Topology via Variance Minimization in the Wasserstein Space</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sixtus Dakurah
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework for robustly analyzing topological variability in weighted brain networks by combining combinatorial Hodge decomposition with Wasserstein variance minimization. The method quantifies topological disparity using the 2-Wasserstein distance between persistence diagrams, demonstrating superior noise suppression and heightened sensitivity to genuine structural differences compared to traditional raw-edge weight analysis. It was successfully applied to differentiate functional brain networks between cannabis users and non-users in an ADHD dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Addiction Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12990v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12990v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12990v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12990v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12969v1"
                     data-domains="Oncology,Pathology,Genomics,Immunology,Precision Medicine,Disease Diagnostics"
                     data-keywords="Spatial transcriptomics,Deep learning,Histopathology,Gene expression prediction,H&E staining,Computational pathology,Tissue microenvironment,Precision medicine"
                     data-authors="Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12969v1.html">HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziqiao Weng, Yaoyu Fang, Jiahe Qian et al.
                </div>

                <div class="paper-summary">
                    HiFusion is a novel deep learning framework designed to accurately predict spatial gene expression from H&E-stained whole-slide images, addressing the limitations of existing computational methods in capturing intra-spot heterogeneity and integrating contextual information. It achieves this by combining hierarchical intra-spot modeling with context-aware cross-scale fusion, demonstrating state-of-the-art performance on benchmark spatial transcriptomics datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12969v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12969v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12969v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12969v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12963v1"
                     data-domains="Pharmacology,Drug Discovery,Toxicology,Metabolic Science,Medicinal Chemistry"
                     data-keywords="Knowledge Graph,Large Language Models (LLMs),Drug Discovery,Constrained Inference,Biomedical Reasoning,Toxicity Screening,Metabolic Compatibility,Domain Consistency"
                     data-authors="Crystal Su">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12963v1.html">MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Crystal Su
                </div>

                <div class="paper-summary">
                    This paper introduces MedRule-KG, a novel system designed to impose domain-consistent structure on large language models (LLMs) for scientific reasoning and early-stage drug discovery. By combining a knowledge-graph scaffold with a lightweight verifier, MedRule-KG steers LLM generation towards mathematically and biomedically valid outputs. The system significantly reduces violation counts by 83.2% while improving exact match across tasks like reaction feasibility, metabolic compatibility, and toxicity screening, making LLM-based drug discovery more reliable and practical.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Metabolic Science</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12963v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12963v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12963v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12963v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12962v1"
                     data-domains="Gastroenterology,Diagnostic Imaging,Oncology (prevention),Medical Artificial Intelligence"
                     data-keywords="deep learning,gastrointestinal polyps,endoscopy,polyp detection,polyp segmentation,real-time AI,Hyper-Kvasir,colorectal cancer prevention"
                     data-authors="Daniel Cavadia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12962v1.html">EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Cavadia
                </div>

                <div class="paper-summary">
                    EndoSight AI is a deep learning system developed for real-time gastrointestinal polyp detection and segmentation during endoscopic procedures. Leveraging the Hyper-Kvasir dataset, it achieves 88.3% mean Average Precision for detection and up to 69% Dice coefficient for segmentation, all while maintaining real-time inference speeds over 35 FPS on GPU hardware. This integrated AI solution aims to significantly enhance diagnostic accuracy and clinical decision-making for early colorectal cancer prevention.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (prevention)</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12962v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12962v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12962v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12962v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12920v1"
                     data-domains="Pediatrics,Obstetrics and Gynecology (Ob/Gyn),Public Health,Maternal-Fetal Medicine"
                     data-keywords="AI Overviews,Featured Snippets,Medical Information Quality,Public Health,Algorithm Audit,Pregnancy Care,Baby Care,Medical Safeguards"
                     data-authors="Desheng Hu,Joachim Baumann,Aleksandra Urman,Elsa Lichtenegger,Robin Forsberg,Aniko Hannak,Christo Wilson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12920v1.html">Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Desheng Hu, Joachim Baumann, Aleksandra Urman et al.
                </div>

                <div class="paper-summary">
                    This research systematically audited Google's AI Overviews (AIO) and Featured Snippets (FS) for baby care and pregnancy queries, revealing significant information inconsistencies and a critical lack of medical safeguards. The study highlights concerning gaps in AI-generated health information quality, urging stronger controls due to high user reliance and potential public health implications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Obstetrics and Gynecology (Ob/Gyn)</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Maternal-Fetal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12920v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12920v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12920v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12920v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12907v1"
                     data-domains="Neurology,Neurosurgery,Rehabilitation Medicine,Biomedical Engineering,Neurotechnology"
                     data-keywords="ECoG,Brain-Computer Interface,minimally invasive,guidewire deployment,high-density electrodes,neural signals,chronic monitoring,neuroprosthetics"
                     data-authors="Tao Zou,Na Xiao,Ruihong Weng,Yifan Guo,Danny Tat Ming Chan,Gilberto Ka Kit Leung,Paddy Kwok Leung Chan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12907v1.html">Guidewire-driven deployment of high density ECoG arrays for large area brain-computer interface</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tao Zou, Na Xiao, Ruihong Weng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel guidewire-driven ECoG Brain-Computer Interface (BCI) device designed for minimally invasive, epidural deployment. The device, an ultra-flexible thin-film array with 256 electrodes in 4 cm¬≤, successfully captured high-quality auditory neural signals in canine brains, achieving over 80% accuracy in sound type classification and addressing critical trade-offs in current BCI technologies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Neurotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12907v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12907v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12907v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12907v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12899v1"
                     data-domains="Radiology,Neurology,Medical Imaging,Neurosurgery"
                     data-keywords="Unsupervised Anomaly Detection,Brain MRI,Frequency Decomposition,Preprocessing,Medical Imaging,Pathology Detection,Generative Models,Neurological Disorders"
                     data-authors="Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12899v1.html">FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao Li, Zhenfeng Zhuang, Jingyu Lin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FDP, a novel Frequency-Decomposition Preprocessing pipeline designed to enhance Unsupervised Anomaly Detection (UAD) in brain MRI by leveraging insights from frequency-domain analysis. FDP addresses the limitations of current UAD methods, which rely on simulated anomalies lacking biophysical fidelity, by enabling simultaneous pathology suppression and anatomical preservation through frequency-domain reconstruction, leading to consistent performance improvements across various UAD architectures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12899v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12899v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12899v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12899v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12853v1"
                     data-domains="Neuro-oncology,Neurosurgery,Diagnostic Radiology,Radiation Oncology,Medical Imaging Informatics"
                     data-keywords="Brain Tumors,Pseudo-Healthy Reconstruction,Diffusion Models,ControlNet,Medical Image Synthesis,Anatomical Deformation,MRI,Treatment Planning"
                     data-authors="Min Gu Kwak,Yeonju Lee,Hairong Wang,Jing Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12853v1.html">BrainNormalizer: Anatomy-Informed Pseudo-Healthy Brain Reconstruction from Tumor MRI via Edge-Guided ControlNet</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Min Gu Kwak, Yeonju Lee, Hairong Wang et al.
                </div>

                <div class="paper-summary">
                    BrainNormalizer introduces an anatomy-informed diffusion framework that reconstructs pseudo-healthy MRIs directly from tumorous brain scans. By conditioning a ControlNet model on boundary cues derived from the patient's own contralateral anatomy, it provides a subject-specific reference of the brain without tumor-induced deformation, which is crucial for precise diagnosis and treatment planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12853v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12853v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12853v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12853v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12851v1"
                     data-domains="Neurology,Clinical Neurophysiology,Artificial Intelligence in Medicine,Biomedical Informatics"
                     data-keywords="NeuroLex,EEG reports,language model,domain adaptation,clinical neurophysiology,natural language processing,brain-computer interface,biomedical informatics"
                     data-authors="Kang Yin,Hye-Bin Shin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12851v1.html">NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kang Yin, Hye-Bin Shin
                </div>

                <div class="paper-summary">
                    NeuroLex is a novel, lightweight domain-adaptive language model specifically developed for understanding and generating clinical electroencephalogram (EEG) reports, addressing the limitations of general-purpose LMs in capturing specialized linguistic conventions. Trained purely on EEG report text, it achieves superior performance in EEG-specific tasks such as summarization, information extraction, and robustness to negation compared to general models of the same scale. This model serves as a foundation for interpretable and language-driven neural decoding in brain-computer interface applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12851v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12851v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12851v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12851v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12843v1"
                     data-domains="Environmental Health,Public Health,Toxicology,Water Safety"
                     data-keywords="Electro-Fenton,Phenol,Wastewater treatment,Gas diffusion electrode,Photocatalysis,Oxidative degradation,Environmental health,Hydroxyl radical"
                     data-authors="Zhang Junye,Zheng Hongyu,Cheng Jingran,Zhang Shengli">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12843v1.html">Treatment of phenol wastewater by electro-Fenton oxidative degradation based on efficient iron-based-gas diffusion-photocatalysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-17</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhang Junye, Zheng Hongyu, Cheng Jingran et al.
                </div>

                <div class="paper-summary">
                    This study introduces a novel iron-based gas diffusion electrode-photocatalytic system designed for the enhanced degradation of toxic phenolic compounds in wastewater. The dual-chamber electro-Fenton setup achieved 92% phenol degradation efficiency within 3 hours while remarkably reducing energy consumption by 40% compared to traditional methods. These findings highlight a sustainable and highly efficient solution for mitigating environmental pollution caused by persistent phenolic substances.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Water Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12843v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12843v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12843v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12843v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12821v1"
                     data-domains="General Medicine,Biomedical Research,Health Informatics,Public Health (Pandemic Analysis),Clinical Research"
                     data-keywords="Journal Impact,AI Engagement,Biomedical Journals,Collaboration Networks,LLM Pipeline,Scientometrics,PubMed Central,Citation Analysis"
                     data-authors="Ruiyu Wang,Yuzhang Xie,Xiao Hu,Carl Yang,Jiaying Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12821v1.html">BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-16</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruiyu Wang, Yuzhang Xie, Xiao Hu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces BioMedJImpact, a large-scale biomedical dataset comprising 1.74 million PubMed Central articles to analyze scientific impact and AI engagement of 2,744 journals. It proposes a reproducible three-stage LLM pipeline to derive AI engagement features and uses the dataset to reveal consistent trends: higher collaboration intensity leads to greater citation impact, and AI engagement is an increasingly strong correlate of journal prestige.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Public Health (Pandemic Analysis)</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12821v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12821v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12821v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12821v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.12817v1"
                     data-domains="General Medicine,Clinical Decision Support,Medical Information Retrieval,Health Informatics"
                     data-keywords="Automated Fact-Checking,Medical LLMs,Knowledge Graphs (KGs),Factuality Evaluation,Healthcare AI,Clinical Verification,Natural Language Processing (NLP),Explainable AI"
                     data-authors="Shasha Zhou,Mingyu Huang,Jack Cole,Charles Britton,Ming Yin,Jan Wolber,Ke Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.12817v1.html">Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-16</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shasha Zhou, Mingyu Huang, Jack Cole et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FAITH, a novel framework that leverages medical knowledge graphs (KGs) for automated factuality assessment of large language model (LLM) responses in healthcare, addressing the critical need for rigorous verification in high-stakes medical settings. FAITH decomposes LLM responses into atomic claims, links them to a medical KG, and scores them based on evidence paths, demonstrating significantly higher correlations with clinician judgments, robustness to textual variance, and the ability to distinguish LLMs of varying capabilities. Its inherent explainability further aids in understanding and mitigating LLM limitations, positioning KGs as a prominent direction for reliable LLM deployment in medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Information Retrieval</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.12817v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.12817v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.12817v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.12817v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-18 06:28:11</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>