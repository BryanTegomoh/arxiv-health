<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">11</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">11</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">33</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Medical Imaging (2), Personalized Medicine (2), cs.CV (2)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Medical Imaging">Medical Imaging (2)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (2)</option>
                        
                        <option value="cs.CV">Cs.cv (2)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (2)</option>
                        
                        <option value="Dermatology">Dermatology (1)</option>
                        
                        <option value="Artificial Intelligence in Medicine">Artificial Intelligence In Medicine (1)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (1)</option>
                        
                        <option value="Patient Safety">Patient Safety (1)</option>
                        
                        <option value="Emergency Medicine">Emergency Medicine (1)</option>
                        
                        <option value="Medical Diagnostics">Medical Diagnostics (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.11791v1"
                     data-domains="Dermatology,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Vitiligo segmentation,Domain adaptation,Uncertainty-aware,ConvNeXt V2,High-Frequency Spectral Gating,Clinical photographs,Deep learning,Medical image analysis"
                     data-authors="Wentao Jiang,Vamsi Varra,Caitlin Perez-Stable,Harrison Zhu,Meredith Apicella,Nicole Nyamongo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11791v1.html">Uncertainty-Aware Domain Adaptation for Vitiligo Segmentation in Clinical Photographs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wentao Jiang, Vamsi Varra, Caitlin Perez-Stable et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a trustworthy and frequency-aware segmentation framework for accurately quantifying vitiligo extent in clinical photographs. The framework achieves superior performance (85.05% Dice, significantly reduced boundary error), consistently outperforming strong baselines, and provides interpretable pixel-wise uncertainty maps to identify ambiguous regions for clinician review. Its high reliability, marked by zero catastrophic failures, suggests a robust standard for automated vitiligo assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11791v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11791v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11791v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11791v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11776v1"
                     data-domains="Medical Imaging,Radiology,Computational Anatomy,Digital Pathology,Image-Guided Surgery,Biomedical Signal Processing"
                     data-keywords="Neural Networks,Implicit Neural Representations,Spectral Bias,Curse of Dimensionality,Vekua Cascade,Differentiable Solver,Physics-Informed Machine Learning,Medical Image Reconstruction"
                     data-authors="Vladimer Khasia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11776v1.html">The Adaptive Vekua Cascade: A Differentiable Spectral-Analytic Solver for Physics-Informed Representation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vladimer Khasia
                </div>

                <div class="paper-summary">
                    The Adaptive Vekua Cascade (AVC) is a novel hybrid neural network architecture addressing spectral bias and dimensionality issues in coordinate-based networks for representing continuous physical fields. It integrates deep learning for diffeomorphic domain warping with classical approximation theory using generalized analytic functions, notably employing a differentiable linear solver for optimal, closed-form spectral coefficient resolution. AVC achieves state-of-the-art accuracy, significantly reduces parameter counts (orders of magnitude), and accelerates convergence (2-3x) on rigorous physics benchmarks, including sparse medical reconstruction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Computational Anatomy</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Image-Guided Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11776v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11776v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11776v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11776v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11750v1"
                     data-domains="Autonomous Surgery,Medical Robotics,Intelligent Drug Delivery,AI-driven Diagnostics,Personalized Medicine,Patient Monitoring Systems"
                     data-keywords="Stochastic Dynamical Systems,Formal Verification,Safety Certification,Black-box AI,Control Barrier Certificates,Reproducing Kernel Hilbert Space (RKHS),Fourier Kernel Expansion,Distributionally Robust Optimization"
                     data-authors="Ernesto Casablanca,Oliver Sch√∂n,Paolo Zuliani,Sadegh Soudjani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11750v1.html">LUCID: Learning-Enabled Uncertainty-Aware Certification of Stochastic Dynamical Systems</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ eess.SY</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ernesto Casablanca, Oliver Sch√∂n, Paolo Zuliani et al.
                </div>

                <div class="paper-summary">
                    LUCID introduces a novel verification engine for certifying the safety of black-box stochastic dynamical systems, particularly those with opaque AI components, using only a finite dataset of random state transitions. It leverages a data-driven methodology based on learned control barrier certificates, enabling quantified safety guarantees for systems in high-stakes domains like healthcare, where traditional formal verification falls short. A key innovation involves a finite Fourier kernel expansion to transform a complex non-convex optimization into a tractable linear program, offering a scalable and distributionally robust framework.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Autonomous Surgery</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Intelligent Drug Delivery</span>
                    
                    <span class="domain-tag">AI-driven Diagnostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11750v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11750v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11750v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11750v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11682v1"
                     data-domains="Clinical Pharmacology,Medical Informatics,Drug Discovery and Development,Personalized Medicine,Clinical Decision Support"
                     data-keywords="TxAgent,Agentic AI,RAG,Llama-3.1-8B,CURE-Bench,Therapeutic Reasoning,Drug Recommendation,Clinical Decision Support"
                     data-authors="Tim Cofala,Christian Kalfar,Jingge Xiao,Johanna Schrader,Michelle Tang,Wolfgang Nejdl">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11682v1.html">MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tim Cofala, Christian Kalfar, Jingge Xiao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedAI's TxAgent, an agentic AI system leveraging a fine-tuned Llama-3.1-8B model with iterative retrieval-augmented generation (RAG) for therapeutic decision-making by dynamically integrating biomedical tool calls. Their participation in the NeurIPS CURE-Bench Challenge demonstrated that retrieval quality for function calls significantly influences overall model performance, with improved tool-retrieval strategies yielding notable performance gains. The work was awarded the Excellence Award in Open Science for its contribution to robust, multi-step reasoning in clinical medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11682v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11682v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11682v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11682v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11651v1"
                     data-domains="cond-mat.mtrl-sci"
                     data-keywords="cond-mat.mtrl-sci,q-bio.TO"
                     data-authors="Connie M. Wang,Roberta M. Sabino,Aditya Garg,Ahmed E. Salih,Loza F. Tadesse,Elazer R. Edelman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11651v1.html">Nano-engineered surface enhanced Raman spectroscopy substrates for probing tissue-material interactions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cond-mat.mtrl-sci</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Connie M. Wang, Roberta M. Sabino, Aditya Garg et al.
                </div>

                <div class="paper-summary">
                    Innovation in biomaterials has brought both breakthroughs and new challenges in medicine, as implant materials have become increasingly multifunctional and complex. One of the greatest issues is the difficulty in assessing the temporal and multidimensional dynamics of tissue-implant interactions. Im...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cond-mat.mtrl-sci</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11651v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11651v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11651v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11651v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11624v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Maik Dannecker,Steven Jia,Nil Stolt-Ans√≥,Nadine Girard,Guillaume Auzias,Fran√ßois Rousseau,Daniel Rueckert">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11624v1.html">Fast and Explicit: Slice-to-Volume Reconstruction via 3D Gaussian Primitives with Analytic Point Spread Function Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Maik Dannecker, Steven Jia, Nil Stolt-Ans√≥ et al.
                </div>

                <div class="paper-summary">
                    Recovering high-fidelity 3D images from sparse or degraded 2D images is a fundamental challenge in medical imaging, with broad applications ranging from 3D ultrasound reconstruction to MRI super-resolution. In the context of fetal MRI, high-resolution 3D reconstruction of the brain from motion-corru...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11624v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11624v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11624v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11624v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11582v1"
                     data-domains="Neurology,Psychiatry,Cognitive Neuroscience,Neurodevelopmental Disorders,Diagnostic Imaging"
                     data-keywords="fMRI,Foundation Models,Self-supervised Learning,Brain Dynamics,Semantic Tokens,Self-distillation,Neuroimaging,Machine Learning"
                     data-authors="Sam Gijsen,Marc-Andre Schulz,Kerstin Ritter">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11582v1.html">Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sam Gijsen, Marc-Andre Schulz, Kerstin Ritter
                </div>

                <div class="paper-summary">
                    Brain-Semantoks is a novel self-supervised foundation model designed to learn abstract and robust representations of brain dynamics from fMRI time series. It achieves this by employing a semantic tokenizer to aggregate noisy regional signals into functional network tokens and a self-distillation objective stabilized by a novel training curriculum. The model demonstrates strong performance on various downstream tasks with minimal fine-tuning and shows improved out-of-distribution generalization with increased unlabeled data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Neurodevelopmental Disorders</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11558v1"
                     data-domains="Dentistry,Oral & Maxillofacial Radiology,Diagnostic Imaging"
                     data-keywords="dental AI,multimodal LLM,dentistry,oral healthcare,medical imaging,disease classification,VQA,deep learning,reinforcement learning"
                     data-authors="Zhenyang Cai,Jiaming Zhang,Junjie Zhao,Ziyi Zeng,Yanchao Li,Jingyi Liang,Junying Chen,Yunjin Yang,Jiajun You,Shuzhi Deng,Tongfei Wang,Wanting Chen,Chunxiu Hao,Ruiqi Xie,Zhenwei Wen,Xiangyi Feng,Zou Ting,Jin Zou Lin,Jianquan Li,Guangjun Yu,Liangyi Chen,Junwen Wang,Shan Jiang,Benyou Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11558v1.html">DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhenyang Cai, Jiaming Zhang, Junjie Zhao et al.
                </div>

                <div class="paper-summary">
                    DentalGPT introduces a specialized Multimodal Large Language Model (MLLM) designed to overcome current MLLM limitations in capturing fine-grained dental visual details and performing complex reasoning for precise diagnoses. Leveraging the largest annotated multimodal dental dataset to date (over 120k images with detailed descriptions) and a staged training approach including domain knowledge injection and reinforcement learning, DentalGPT achieves superior performance in dental disease classification and VQA tasks. This 7B-parameter model outperforms many state-of-the-art MLLMs on key dental benchmarks, showcasing an effective pathway for domain-specialized MLLM development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Oral & Maxillofacial Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11558v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11558v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11558v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11558v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11548v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Zhendi Gong,Xin Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11548v1.html">SSL-MedSAM2: A Semi-supervised Medical Image Segmentation Framework Powered by Few-shot Learning of SAM2</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhendi Gong, Xin Chen
                </div>

                <div class="paper-summary">
                    Despite the success of deep learning based models in medical image segmentation, most state-of-the-art (SOTA) methods perform fully-supervised learning, which commonly rely on large scale annotated training datasets. However, medical image annotation is highly time-consuming, hindering its clinical ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11548v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11548v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11548v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11548v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11544v1"
                     data-domains="Clinical Informatics,Patient Safety,Emergency Medicine,Medical Diagnostics,AI in Medicine"
                     data-keywords="AI-MASLD,Large Language Models,Clinical Narratives,Medical Information Extraction,Metabolic Dysfunction,Patient Safety,Artificial Intelligence in Healthcare"
                     data-authors="Yuan Shen,Xiaojun Wu,Linghua Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11544v1.html">AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuan Shen, Xiaojun Wu, Linghua Yu
                </div>

                <div class="paper-summary">
                    This study systematically evaluated four mainstream Large Language Models (LLMs) for their ability to extract core medical information from noisy clinical narratives, identifying a functional decline termed "AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)". It revealed that all tested LLMs exhibited significant functional defects, with most experiencing a complete collapse under extreme noise, posing crucial safety warnings for AI application in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11544v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11544v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11544v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11544v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.11519v1"
                     data-domains="q-bio.OT"
                     data-keywords="q-bio.OT"
                     data-authors="Matthew Cannon,Wesley Goar,In-Hee Lee,James Stevenson,Amy Heiser,Nathan Sheffield,James Eddy,Monica Munoz-Torres,Sek Wong Kong,Alex H Wagner">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.11519v1.html">Bridge2AI Recommendations for AI-Ready Genomic Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Matthew Cannon, Wesley Goar, In-Hee Lee et al.
                </div>

                <div class="paper-summary">
                    Rapid advancements in technology have led to an increased use of artificial intelligence (AI) technologies in medicine and bioinformatics research. In anticipation of this, the National Institutes of Health (NIH) assembled the Bridge to Artificial Intelligence (Bridge2AI) consortium to coordinate de...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.OT</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.11519v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.11519v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.11519v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.11519v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-15 06:16:34</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>