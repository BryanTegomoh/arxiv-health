<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">158</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (14), Oncology (10), Cardiology (8)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (14)</option>
                        
                        <option value="Oncology">Oncology (10)</option>
                        
                        <option value="Cardiology">Cardiology (8)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (5)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Preventive Medicine">Preventive Medicine (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.11564v1"
                     data-domains="Public Health,Epidemiology,Health Services Research,Behavioral Health,Network Medicine,Clinical Trials (with network components)"
                     data-keywords="Randomized experiments,Bipartite networks,Interference,Spillovers,Causal inference,Total treatment effects,Machine learning,Partial eligibility"
                     data-authors="Albert Tan,Mohsen Bayati,James Nordlund,Roman Istomin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11564v1.html">Estimating Total Effects in Bipartite Experiments with Spillovers and Partial Eligibility</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Albert Tan, Mohsen Bayati, James Nordlund et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of estimating total treatment effects in randomized experiments conducted within bipartite systems, where only a subset of treatment-side units are eligible for intervention, but all units interact and generate spillovers. The authors formalize this setting, define key estimands (PTTE and STTE), and develop interference-aware ensemble estimators that leverage machine learning and a novel projection method to accurately quantify direct and indirect effects, showing significant improvements over methods that ignore interference.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Services Research</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Network Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11564v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11564v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11564v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11564v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11510v1"
                     data-domains="Radiology,Cardiology,Obstetrics and Gynecology,Emergency Medicine,General Surgery,Point-of-Care Ultrasound"
                     data-keywords="Ultrasound,Foundation Model,Vision Mamba,Self-Adaptive Masking,Contrastive Learning,Medical Imaging AI,Label-Efficient Learning,Open-Source"
                     data-authors="Xiaoyu Zheng,Xu Chen,Awais Rauf,Qifan Fu,Benedetta Monosi,Felice Rivellese,Myles J. Lewis,Shaogang Gong,Gregory Slabaugh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11510v1.html">OpenUS: A Fully Open-Source Foundation Model for Ultrasound Image Analysis via Self-Adaptive Masked Contrastive Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoyu Zheng, Xu Chen, Awais Rauf et al.
                </div>

                <div class="paper-summary">
                    This paper introduces OpenUS, the first reproducible, open-source ultrasound foundation model designed to overcome challenges like operator dependence and data variability in US image analysis. It leverages a Vision Mamba backbone with a novel self-adaptive masked contrastive learning framework, pre-trained on the largest public ultrasound dataset, enabling label-efficient adaptation for diverse downstream tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Obstetrics and Gynecology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">General Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11510v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11510v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11510v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11510v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11486v1"
                     data-domains="Oncology,Pathology,Immunotherapy,Precision Medicine"
                     data-keywords="PD-L1,H&E images,segmentation,immunotherapy,deep learning,uncertainty estimation,Bayesian neural networks,computational pathology"
                     data-authors="Roman Kinakh,Gonzalo R. R√≠os-Mu√±oz,Arrate Mu√±oz-Barrutia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11486v1.html">Multimodal Posterior Sampling-based Uncertainty in PD-L1 Segmentation from H&E Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Kinakh, Gonzalo R. R√≠os-Mu√±oz, Arrate Mu√±oz-Barrutia
                </div>

                <div class="paper-summary">
                    This paper introduces nnUNet-B, a Bayesian segmentation framework that leverages Multimodal Posterior Sampling (MPS) within nnUNet-v2 to directly infer PD-L1 expression from H&E-stained histology images. It achieves competitive segmentation performance while also providing pixel-wise epistemic uncertainty estimates that correlate with segmentation errors, aiming to deliver a more scalable and interpretable biomarker assessment for immunotherapy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Immunotherapy</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11486v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11486v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11486v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11486v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11472v1"
                     data-domains="Ophthalmology,Medical Imaging,Diagnostics,Clinical Decision Support"
                     data-keywords="Conformal Prediction,Adaptivity,Uncertainty Quantification,Prediction Sets,Input Transformations,Machine Learning,Medical Imaging,Visual Acuity"
                     data-authors="Sooyong Jang,Insup Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11472v1.html">Quantifying and Improving Adaptivity in Conformal Prediction through Input Transformations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sooyong Jang, Insup Lee
                </div>

                <div class="paper-summary">
                    This paper introduces novel methods to quantify and improve adaptivity in conformal prediction, addressing limitations of existing evaluation techniques. It proposes a new binning strategy using input transformations and uniform-mass binning, along with two new metrics for adaptivity assessment. Furthermore, the authors develop a new adaptive prediction set algorithm that leverages group-conditional conformal prediction based on estimated difficulty, demonstrating superior performance on both image classification and a medical visual acuity prediction task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11472v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11472v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11472v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11472v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11452v1"
                     data-domains="Oncology,Pathology,Radiology,Urology,Medical Imaging"
                     data-keywords="Multimodal Deep Learning,Prostate Cancer,Biochemical Recurrence,Modality Fusion,Computational Pathology,Histopathology,Radiology,Clinical Data"
                     data-authors="Seth Alain Chang,Muhammad Mueez Amjad,Noorul Wahab,Ethar Alzaid,Nasir Rajpoot,Adam Shephard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11452v1.html">Synergy vs. Noise: Performance-Guided Multimodal Fusion For Biochemical Recurrence-Free Survival in Prostate Cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Seth Alain Chang, Muhammad Mueez Amjad, Noorul Wahab et al.
                </div>

                <div class="paper-summary">
                    This paper challenges the assumption that combining modalities universally improves Multimodal Deep Learning (MDL) performance in computational pathology. It hypothesizes that multimodal gains depend on the individual predictive quality of modalities, with weak ones potentially introducing noise. Using prostate cancer data to predict biochemical recurrence, the study found that fusing high-performing modalities yields superior results, while integrating a poor-performing modality degrades predictive accuracy, advocating for selective, performance-guided fusion.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11452v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11452v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11452v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11452v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11450v1"
                     data-domains="Radiology,Oncology,Neurology,Cardiology,Gastroenterology,Anatomy,Pathology,Medical Imaging Informatics"
                     data-keywords="3D medical image segmentation,vision-language model,text-prompted,zero-shot learning,multi-modality imaging,CT,MRI,PET,deep learning"
                     data-authors="Maximilian Rokuss,Moritz Langenberg,Yannick Kirchhoff,Fabian Isensee,Benjamin Hamm,Constantin Ulrich,Sebastian Regnery,Lukas Bauer,Efthimios Katsigiannopulos,Tobias Norajitra,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11450v1.html">VoxTell: Free-Text Promptable Universal 3D Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Maximilian Rokuss, Moritz Langenberg, Yannick Kirchhoff et al.
                </div>

                <div class="paper-summary">
                    VoxTell introduces a novel vision-language model capable of performing free-text prompted universal 3D medical image segmentation, translating natural language descriptions directly into 3D masks. Trained on a diverse dataset of over 62K CT, MRI, and PET volumes spanning 1K+ anatomical and pathological classes, it achieves state-of-the-art zero-shot performance across modalities. The model excels on familiar concepts, generalizes effectively to related unseen classes, and demonstrates strong robustness to linguistic and clinical variations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11450v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11450v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11450v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11450v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11436v1"
                     data-domains="Cardiology,Radiology,Medical Imaging Physics"
                     data-keywords="Cardiac MRI,CMR reconstruction,Implicit Neural Representations (INR),Motion Compensation (MoCo),Unsupervised learning,Accelerated imaging,K-t space,Medical imaging"
                     data-authors="Xuanyu Tian,Lixuan Chen,Qing Wu,Xiao Wang,Jie Feng,Yuyao Zhang,Hongjiang Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11436v1.html">Unsupervised Motion-Compensated Decomposition for Cardiac MRI Reconstruction via Neural Representation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xuanyu Tian, Lixuan Chen, Qing Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MoCo-INR, a novel unsupervised method for accelerating Cardiac Magnetic Resonance (CMR) imaging by reconstructing high-quality spatiotemporal images from highly undersampled k-t space data. It integrates implicit neural representations (INR) with a motion-compensated (MoCo) framework to enable accurate cardiac motion decomposition and superior reconstruction quality, even at ultra-high acceleration factors. MoCo-INR addresses the limitations of existing techniques, particularly the scarcity of ground truth data, making it clinically practical for real-time imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11436v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11436v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11436v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11436v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11423v1"
                     data-domains="chronic disease management,clinical decision support systems,predictive analytics in healthcare,population health management,preventative medicine"
                     data-keywords="electronic health records,multimodal learning,chronic disease prediction,large language models (LLMs),transformer encoders,clinical decision support,time-series data,precision medicine"
                     data-authors="Cong-Tinh Dao,Nguyen Minh Thao Phan,Jun-En Ding,Chenwei Wu,David Restrepo,Dongsheng Luo,Fanyi Zhao,Chun-Chieh Liao,Wen-Chih Peng,Chi-Te Wang,Pei-Fu Chen,Ling Chen,Xinglong Ju,Feng Liu,Fang-Ming Hung">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11423v1.html">CURENet: Combining Unified Representations for Efficient Chronic Disease Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cong-Tinh Dao, Nguyen Minh Thao Phan, Jun-En Ding et al.
                </div>

                <div class="paper-summary">
                    CURENet introduces a multimodal deep learning framework designed to integrate diverse Electronic Health Record (EHR) data for efficient chronic disease prediction. By leveraging Large Language Models (LLMs) and transformer encoders, the model effectively captures complex interactions across clinical notes, lab tests, and time-series visit data. This comprehensive approach achieved over 94% accuracy in predicting top chronic conditions, demonstrating its potential to enhance clinical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">chronic disease management</span>
                    
                    <span class="domain-tag">clinical decision support systems</span>
                    
                    <span class="domain-tag">predictive analytics in healthcare</span>
                    
                    <span class="domain-tag">population health management</span>
                    
                    <span class="domain-tag">preventative medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11423v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11423v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11423v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11423v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11347v1"
                     data-domains="Clinical workflows,Biomedical informatics,Patient data privacy and security,Digital health,Healthcare AI implementation"
                     data-keywords="Retrieval-Augmented Generation (RAG),Large Language Models (LLMs),Healthcare Chatbots,Protected Health Information (PHI),Data Privacy,Clinical Workflows,Privacy Preservation,Threat Models"
                     data-authors="Shaowei Guan,Hin Chi Kwok,Ngai Fong Law,Gregor Stiglic,Vivian Hui">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11347v1.html">Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaowei Guan, Hin Chi Kwok, Ngai Fong Law et al.
                </div>

                <div class="paper-summary">
                    This review paper meticulously analyzes privacy challenges and solutions for Retrieval-Augmented Generation (RAG)-enhanced Large Language Models (LLMs) in healthcare chatbots, highlighting the inconsistent mitigation of Protected Health Information (PHI) exposure. It synthesizes 23 articles on RAG applications and 17 on privacy strategies, proposing a structured pipeline framework to understand vulnerabilities and a roadmap for robust privacy preservation in clinical RAG systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical workflows</span>
                    
                    <span class="domain-tag">Biomedical informatics</span>
                    
                    <span class="domain-tag">Patient data privacy and security</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Healthcare AI implementation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11347v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11347v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11347v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11347v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11303v1"
                     data-domains="Cardiology,Radiology,Nuclear Medicine,Rheumatology,Vascular Surgery"
                     data-keywords="aorta segmentation,CT,large-vessel vasculitis,FDG-PET/CT,minimal path,Lagrangian curve evolution,GSUBSURF,Hausdorff distance"
                     data-authors="Konan A. Allaly,Jozef Urban,Karol Mikula">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11303v1.html">Mathematical and numerical methods for accurate aorta segmentation from non-enhanced CT Data yielding reliable identification and evaluation of large vessel vasculitis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Konan A. Allaly, Jozef Urban, Karol Mikula
                </div>

                <div class="paper-summary">
                    This paper introduces a semi-automatic mathematical and numerical framework for accurate aorta segmentation from non-enhanced CT data, crucial for diagnosing and treating cardiovascular diseases. The method employs a three-step process involving minimal path extraction, 3D Lagrangian curve evolution for centerline approximation, and final accurate segmentation using the Generalized Subjective Surface (GSUBSURF) method. Its utility is demonstrated in reliably identifying and evaluating large-vessel vasculitis from FDG-PET/CT data, showing promising results in inflammation assessment before and after treatment, aligning with expert medical opinions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11303v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11303v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11303v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11303v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11293v1"
                     data-domains="Oncology,Preventive Medicine,Public Health,Biomedical Informatics,Clinical Decision Support"
                     data-keywords="Early cancer detection,EHR-based predictive models,Risk stratification,Cancer screening guidelines,Foundation models,All of Us Research Program,Longitudinal data,Oncology"
                     data-authors="Jiheum Park,Chao Pang,Tristan Y. Lee,Jeong Yun Yang,Jacob Berkowitz,Alexander Z. Wei,Nicholas Tatonetti">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11293v1.html">Toward Scalable Early Cancer Detection: Evaluating EHR-Based Predictive Models Against Traditional Screening Criteria</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiheum Park, Chao Pang, Tristan Y. Lee et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates the efficacy of EHR-based predictive models for early cancer detection against traditional screening criteria. It demonstrates that these models significantly outperform traditional risk factors, achieving a 3- to 6-fold higher enrichment of true cancer cases in high-risk groups, and an advanced EHR foundation model further improves prediction across multiple cancer types. The findings highlight the clinical potential of leveraging comprehensive patient data for more precise and scalable early cancer detection strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11293v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11293v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11293v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11293v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11276v1"
                     data-domains="Radiology,Oncology,Neurology,Cardiology,Medical Imaging Analysis"
                     data-keywords="volumetric medical image segmentation,coordinative learning,ordinal priors,relational priors,contrastive learning,anatomical learning,limited annotation,deep learning"
                     data-authors="Haoyi Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11276v1.html">Coordinative Learning with Ordinal and Relational Priors for Volumetric Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haoyi Wang
                </div>

                <div class="paper-summary">
                    This paper introduces Coordinative Ordinal-Relational Anatomical Learning (CORAL) to address the challenges of volumetric medical image segmentation, particularly the reliance on limited annotations and the failure of existing methods to capture continuous anatomical information and global directional consistency. CORAL employs a contrastive ranking objective for local, continuous similarity and an ordinal objective for global, directional consistency, leading to anatomically informed representations. The framework achieves state-of-the-art performance on benchmark datasets under limited-annotation settings, while learning representations with meaningful anatomical structure for improved downstream segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11274v1"
                     data-domains="Ophthalmology,Dermatology,Oncology,Cardiology,Neurology,Biomedical Imaging"
                     data-keywords="Polarization-Sensitive OCT,PS-OCT,Optical Coherence Tomography,Tissue Birefringence,Jones Matrix,Half-Wave Plate,Retina Imaging,Biomedical Diagnostics"
                     data-authors="Po-Yi Lee,Chuan-Bor Chueh,Milen Shishkov,Tai-Ang Wang,Teresa Chen,Brett E. Bouma,Martin Villiger">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11274v1.html">Polarization-Sensitive Module for Optical Coherence Tomography Instruments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ physics.optics</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Po-Yi Lee, Chuan-Bor Chueh, Milen Shishkov et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel modular framework for Polarization-Sensitive Optical Coherence Tomography (PS-OCT) that significantly enhances its compatibility with standard commercial OCT systems. By integrating a detachable rotating achromatic half-wave plate in the sample arm, the system reconstructs tissue polarization properties from multiple measurements, reliably quantifying retardance and optic axis orientation. This innovation aims to overcome existing technical barriers, facilitating the widespread adoption of PS-OCT in both research and clinical environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11274v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11274v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11274v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11274v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11212v1"
                     data-domains="Radiology,Oncology,Chest Imaging,Diagnostic Imaging"
                     data-keywords="Foundation Models,Medical Imaging,Multi-Modal,Multi-Task,Modular Adaptation,Chest CT,PET Scan,Segmentation,Prognosis"
                     data-authors="Mohammad Areeb Qazi,Munachiso S Nwadike,Ibrahim Almakky,Mohammad Yaqub,Numan Saeed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11212v1.html">MAFM^3: Modular Adaptation of Foundation Models for Multi-Modal Medical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Areeb Qazi, Munachiso S Nwadike, Ibrahim Almakky et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MAFM^3, a novel framework designed to adapt a single medical imaging foundation model to diverse tasks, domains, and modalities through lightweight modular components. This approach enables dynamic activation of specialized capabilities at inference, addressing data scarcity by avoiding separate pre-training for every scenario. Empirically, MAFM^3 improved performance on prognosis and segmentation tasks when adapting a chest CT model, and achieved a 5% Dice score improvement in multimodality segmentation by incorporating PET scans.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Chest Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11212v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11212v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11212v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11212v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11169v1"
                     data-domains="Medical Imaging,Clinical Decision Support,Diagnostic AI,Radiology,Pathology"
                     data-keywords="VQA,Confidence Calibration,Multi-Agent Systems,Vision-Language Models,Medical Diagnostics,AI Reliability,Differentiable Loss,AlignVQA"
                     data-authors="Ayush Pandey,Jai Bardhan,Ishita Jain,Ramya S Hebbalaguppe,Rohan Raju Dhanakshirur,Lovekesh Vig">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11169v1.html">Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ayush Pandey, Jai Bardhan, Ishita Jain et al.
                </div>

                <div class="paper-summary">
                    This paper introduces `AlignVQA`, a multi-agent framework that uses debate-based interactions among specialized and generalist Vision-Language Models (VLMs) to improve confidence calibration in Visual Question Answering (VQA) systems. It also proposes `aligncal`, a novel differentiable loss function for fine-tuning agents to reduce calibration errors, leading to more reliable confidence estimates crucial for high-stakes applications like medical diagnostics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11169v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11169v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11169v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11169v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11165v1"
                     data-domains="Radiology (lesion characterization, fracture typing),Pathology (histopathological grading, cell differentiation),Dermatology (skin lesion sub-typing),Ophthalmology (retinal disease classification),Endoscopy/Colonoscopy (polyp morphology, ulcer identification),Point-of-Care Diagnostics"
                     data-keywords="Anomaly Detection,Explainable AI,Deep Learning,Convolutional Neural Networks,Multi-Type Classification,Medical Imaging,Real-Time Systems,Resource-Constrained Devices"
                     data-authors="Alex George,Lyudmila Mihaylova,Sean Anderson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11165v1.html">Explainable Deep Convolutional Multi-Type Anomaly Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alex George, Lyudmila Mihaylova, Sean Anderson
                </div>

                <div class="paper-summary">
                    This paper introduces MultiTypeFCDD, a lightweight convolutional framework designed for explainable multi-type anomaly detection, addressing the crucial limitation of current methods that identify anomalies without differentiating their specific types. By using only image-level labels, MultiTypeFCDD generates multi-channel heatmaps where each channel corresponds to a unique anomaly type, functioning as a single, unified model across multiple object categories. It achieves competitive performance with state-of-the-art complex models while significantly reducing computational load and inference times, making it practical for real-world applications with constrained resources.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology (lesion characterization, fracture typing)</span>
                    
                    <span class="domain-tag">Pathology (histopathological grading, cell differentiation)</span>
                    
                    <span class="domain-tag">Dermatology (skin lesion sub-typing)</span>
                    
                    <span class="domain-tag">Ophthalmology (retinal disease classification)</span>
                    
                    <span class="domain-tag">Endoscopy/Colonoscopy (polyp morphology, ulcer identification)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11165v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11165v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11165v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11165v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11128v1"
                     data-domains="Orthodontics,Dentistry,Laser Therapy,Oral Surgery,Inflammation Management"
                     data-keywords="diode laser,photobiomodulation,orthodontic mini-implants,peri-implant inflammation,interleukin-1 beta,randomized controlled trial,peri-implant mucositis,clinical outcomes"
                     data-authors="Jun Liu,Linlin Li,Xiaofei Sun,Qiang Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11128v1.html">Effects of diode laser photobiomodulation on peri-implant inflammation and stability in orthodontic mini-implants: A randomized controlled trial</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jun Liu, Linlin Li, Xiaofei Sun et al.
                </div>

                <div class="paper-summary">
                    This randomized controlled trial investigated the efficacy of diode laser photobiomodulation (650 nm, 25 mW) as an adjunctive therapy to mitigate peri-implant inflammation in orthodontic mini-implants. The study found that laser therapy significantly reduced clinical signs of inflammation, inflammatory biomarker (IL-1Œ≤) levels, and the incidence of mucositis, thereby enhancing peri-implant health. While improving inflammatory markers, it did not significantly affect implant stability within the observed period.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthodontics</span>
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Laser Therapy</span>
                    
                    <span class="domain-tag">Oral Surgery</span>
                    
                    <span class="domain-tag">Inflammation Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11128v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11128v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11128v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11128v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11093v1"
                     data-domains="Cardiology,Radiology,Preventive Medicine,Public Health"
                     data-keywords="Coronary Artery Calcification (CAC),Chest X-rays (CXR),Digitally Reconstructed Radiographs (DRRs),Machine Learning,Deep Learning,Cardiovascular Disease,Image Synthesis,Super-resolution"
                     data-authors="Dylan Saeed,Ramtin Gharleghi,Susann Bier,Sonit Singh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11093v1.html">Machine-Learning Based Detection of Coronary Artery Calcification Using Synthetic Chest X-Rays</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dylan Saeed, Ramtin Gharleghi, Susann Bier et al.
                </div>

                <div class="paper-summary">
                    This paper pioneers the systematic evaluation of Digitally Reconstructed Radiographs (DRRs) as a synthetic, label-rich training domain for machine learning models to detect Coronary Artery Calcification (CAC) from chest X-ray-like images. The study demonstrates that lightweight Convolutional Neural Networks, when optimized with super-resolution, contrast enhancement, and curriculum learning, achieve a mean AUC of 0.754, establishing DRRs as a scalable foundation for CAC detection competitive with or exceeding prior real CXR-based methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11093v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11093v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11093v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11093v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11066v1"
                     data-domains="Radiology,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Radiology Report Generation,Multimodal Large Language Models,Supervised Fine-Tuning,Anatomically-Grounded Alignment,Auxiliary Learning,Medical Imaging,Deep Learning,Natural Language Generation"
                     data-authors="Jiechao Gao,Chang Liu,Yuangang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11066v1.html">S2D-ALIGN: Shallow-to-Deep Auxiliary Learning for Anatomically-Grounded Radiology Report Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiechao Gao, Chang Liu, Yuangang Li
                </div>

                <div class="paper-summary">
                    This paper introduces S2D-ALIGN, a novel Supervised Fine-Tuning (SFT) paradigm designed to enhance Radiology Report Generation (RRG) by establishing anatomically-grounded alignment between medical images and reports. It achieves this by employing a shallow-to-deep strategy, integrating auxiliary signals of varying granularities, from coarse image-report pairings to fine-grained key phrases, facilitated by a memory-based adapter. S2D-ALIGN demonstrates state-of-the-art performance on benchmark datasets, significantly improving the quality and anatomical precision of AI-generated radiology reports.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11066v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11066v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11066v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11066v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11065v1"
                     data-domains="Ophthalmology,Endocrinology,Public Health,Preventative Medicine"
                     data-keywords="Diabetic Retinopathy,Deep Learning,AI,Medical Imaging,Screening,Retinal Imaging,Computer Vision,Preventable Blindness"
                     data-authors="Muskaan Chopra,Lorenz Sparrenberg,Armin Berger,Sarthak Khanna,Jan H. Terheyden,Rafet Sifa">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11065v1.html">From Retinal Pixels to Patients: Evolution of Deep Learning Research in Diabetic Retinopathy Screening</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muskaan Chopra, Lorenz Sparrenberg, Armin Berger et al.
                </div>

                <div class="paper-summary">
                    This paper offers the first systematic synthesis of deep learning research in Diabetic Retinopathy (DR) screening from 2016-2025, consolidating insights from over 50 studies and 20 datasets. It details the evolution of AI methodologies from basic CNNs to advanced pipelines addressing real-world challenges like data scarcity and domain shift, while outlining a practical agenda for clinically deployable DR AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Preventative Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11065v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11065v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11065v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11065v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11048v1"
                     data-domains="Cardiology,Cardiovascular Imaging,Diagnostic Radiology"
                     data-keywords="4D flow MRI,Super-resolution,Gaussian Splatting,Physics-Informed,Cardiovascular Imaging,Blood Flow,Stenosis,Aneurysm"
                     data-authors="Sun Jo,Seok Young Hong,JinHyun Kim,Seungmin Kang,Ahjin Choi,Don-Gwan An,Simon Song,Je Hyeong Hong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11048v1.html">PINGS-X: Physics-Informed Normalized Gaussian Splatting with Axes Alignment for Efficient Super-Resolution of 4D Flow MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sun Jo, Seok Young Hong, JinHyun Kim et al.
                </div>

                <div class="paper-summary">
                    PINGS-X addresses the critical trade-off between high spatiotemporal resolution and prolonged scan times in 4D flow MRI, which is essential for cardiovascular diagnostics. It proposes a novel super-resolution framework leveraging axes-aligned spatiotemporal Gaussian representations, significantly extending 3D Gaussian splatting with innovations like normalized Gaussians and a merging procedure. This approach substantially reduces training time while achieving superior super-resolution accuracy on both computational fluid dynamics and real 4D flow MRI datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11048v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11048v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11048v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11048v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11034v1"
                     data-domains="Radiology,Diagnostic Imaging,Chest Imaging,Brain Imaging,Oncology,Pulmonology,AI in Medicine"
                     data-keywords="medical imaging,multimodal LLMs,compositional generalization,visual question answering,benchmark,cross-task transfer,zero-shot learning,vision-language models"
                     data-authors="Pooja Singh,Siddhant Ujjain,Tapan Kumar Gandhi,Sandeep Kumar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11034v1.html">CrossMed: A Multimodal Cross-Task Benchmark for Compositional Generalization in Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pooja Singh, Siddhant Ujjain, Tapan Kumar Gandhi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CrossMed, a novel benchmark designed to evaluate the compositional generalization capabilities of multimodal large language models (LLMs) in medical imaging. By reformulating four public datasets into a unified visual question answering (VQA) format based on a Modality-Anatomy-Task (MAT) schema, the authors demonstrate that while LLMs perform well on related tasks, their performance significantly declines under unrelated or zero-overlap conditions, highlighting the challenge of compositional generalization in medicine. The benchmark also reveals unique cross-task transfer abilities and superior compositional generalization of LLMs compared to traditional models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Chest Imaging</span>
                    
                    <span class="domain-tag">Brain Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11034v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11034v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11034v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11034v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11032v1"
                     data-domains="Gastroenterology,Oncology,Diagnostic Imaging,Preventive Medicine,Medical Artificial Intelligence"
                     data-keywords="Polyp Segmentation,Deep Learning,Convolutional Neural Networks,Multiscale Feature Extraction,Feature Aggregation,Coupling Gates,Colorectal Cancer,Computer-aided Diagnosis"
                     data-authors="Wei Wang,Feng Jiang,Xin Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11032v1.html">MPCGNet: A Multiscale Feature Extraction and Progressive Feature Aggregation Network Using Coupling Gates for Polyp Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei Wang, Feng Jiang, Xin Wang
                </div>

                <div class="paper-summary">
                    MPCGNet addresses key challenges in automatic polyp segmentation, including missed small polyps, ambiguous boundaries, and image noise, through a novel deep learning architecture. It employs "coupling gates" within specialized modules for effective multiscale feature extraction, noise suppression, and progressive feature aggregation, achieving superior performance on benchmark datasets. This improved accuracy is crucial for enhancing colorectal cancer screening and diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11032v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11032v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11032v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11032v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11030v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.AI"
                     data-authors="Chi-Yu Chen,Rawan Abulibdeh,Arash Asgari,Leo Anthony Celi,Deirdre Goode,Hassan Hamidi,Laleh Seyyed-Kalantari,Po-Chih Kuo,Ned McCague,Thomas Sounack">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11030v1.html">Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chi-Yu Chen, Rawan Abulibdeh, Arash Asgari et al.
                </div>

                <div class="paper-summary">
                    Artificial intelligence is revealing what medicine never intended to encode. Deep vision models, trained on chest X-rays, can now detect not only disease but also invisible traces of social inequality. In this study, we show that state-of-the-art architectures (DenseNet121, SwinV2-B, MedMamba) can p...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11030v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11030v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11030v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11030v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11020v1"
                     data-domains="organ transplantation,crisis triage,medical documentation,clinical decision support"
                     data-keywords="data poisoning,healthcare AI,cybersecurity,adversarial attacks,federated learning,HIPAA,GDPR,supply chain"
                     data-authors="Farhad Abtahi,Fernando Seoane,Iv√°n Pau,Mario Vega-Barbas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11020v1.html">Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Farhad Abtahi, Fernando Seoane, Iv√°n Pau et al.
                </div>

                <div class="paper-summary">
                    This paper reveals severe data poisoning vulnerabilities in healthcare AI systems that current defenses and regulations are ill-equipped to handle. Analyzing eight attack scenarios across various AI architectures and infrastructure, the authors demonstrate how attackers can compromise critical medical AI with minimal effort, leading to potentially undetected and widespread harm.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">organ transplantation</span>
                    
                    <span class="domain-tag">crisis triage</span>
                    
                    <span class="domain-tag">medical documentation</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11020v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11020v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11020v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11020v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.11004v1"
                     data-domains="Computational Pathology,Digital Pathology,Oncology,Diagnostic Imaging"
                     data-keywords="Multiple Instance Learning,Whole Slide Imaging,Causal Inference,Fairness,Interpretability,Demographic Bias,Computational Pathology,Do-Calculus"
                     data-authors="Yiran Song,Yikai Zhang,Shuang Zhou,Guojun Xiong,Xiaofeng Yang,Nian Wang,Fenglong Ma,Rui Zhang,Mingquan Lin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.11004v1.html">MeCaMIL: Causality-Aware Multiple Instance Learning for Fair and Interpretable Whole Slide Image Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiran Song, Yikai Zhang, Shuang Zhou et al.
                </div>

                <div class="paper-summary">
                    MeCaMIL introduces a causality-aware Multiple Instance Learning (MIL) framework for Whole Slide Image (WSI) analysis that addresses critical limitations of existing MIL methods: lack of causal interpretability and failure to integrate patient demographics, which leads to fairness concerns. By explicitly modeling demographic confounders through structured causal graphs and leveraging do-calculus, MeCaMIL disentangles disease-relevant signals from spurious demographic correlations, achieving state-of-the-art diagnostic performance and significantly superior fairness across diverse populations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.11004v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.11004v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.11004v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.11004v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10993v1"
                     data-domains="otitis media,general medical imaging,specialized medical fields,diagnostics"
                     data-keywords="generative model,text-to-image synthesis,data augmentation,Stable Diffusion,medical imaging,otitis media,latent space,diversity management"
                     data-authors="Keunwoo Park,Jihye Chae,Joong Ho Ahn,Jihoon Kweon">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10993v1.html">CLUE: Controllable Latent space of Unprompted Embeddings for Diversity Management in Text-to-Image Synthesis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Keunwoo Park, Jihye Chae, Joong Ho Ahn et al.
                </div>

                <div class="paper-summary">
                    CLUE (Controllable Latent space of Unprompted Embeddings) is a novel generative model framework designed to produce diverse and stable images from limited datasets, particularly for specialized medical fields. By integrating a Style Encoder into a modified Stable Diffusion architecture, CLUE achieves prompt-independent control over style embeddings, significantly improving image generation quality and the performance of classifiers trained on synthetic medical data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">otitis media</span>
                    
                    <span class="domain-tag">general medical imaging</span>
                    
                    <span class="domain-tag">specialized medical fields</span>
                    
                    <span class="domain-tag">diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10993v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10993v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10993v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10993v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10991v1"
                     data-domains="Radiology,Pathology,Medical Imaging Informatics,Digital Microscopy,Telemedicine"
                     data-keywords="Autoregressive Models,Lossless Image Compression,Hierarchical Parallelism,Progressive Adaptation,Deep Learning,Medical Imaging,Computational Efficiency,State-of-the-Art"
                     data-authors="Daxin Li,Yuanchao Bai,Kai Wang,Wenbo Zhao,Junjun Jiang,Xianming Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10991v1.html">Rethinking Autoregressive Models for Lossless Image Compression via Hierarchical Parallelism and Progressive Adaptation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daxin Li, Yuanchao Bai, Kai Wang et al.
                </div>

                <div class="paper-summary">
                    This paper re-evaluates autoregressive (AR) models for lossless image compression, proposing a novel framework built on hierarchical parallelism and progressive adaptation to overcome their traditional computational drawbacks. The authors introduce the Hierarchical Parallel Autoregressive ConvNet (HPAC), which, combined with optimizations like Cache-then-Select Inference (CSI) and Adaptive Focus Coding (AFC), achieves state-of-the-art compression ratios with competitive speeds and a small parameter count on diverse datasets, including medical images.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                    <span class="domain-tag">Digital Microscopy</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10991v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10991v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10991v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10991v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10945v1"
                     data-domains="Radiology,Medical Imaging Diagnostics,Pathology (if applicable to broader image types)"
                     data-keywords="Federated Learning,Medical Image Segmentation,Feature Heterogeneity,Prototype Alignment,Style Recalibration,Domain Invariance,Multi-level Features,Deep Learning"
                     data-authors="Xingyue Zhao,Wenke Huang,Xingguang Wang,Haoyu Zhao,Linghao Zhuang,Anwen Jiang,Guancheng Wan,Mang Ye">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10945v1.html">Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xingyue Zhao, Wenke Huang, Xingguang Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FedBCS, a novel federated learning approach for medical image segmentation that tackles feature heterogeneity arising from diverse scanners and protocols. FedBCS aligns domain-invariant contextual prototypes by incorporating frequency-domain adaptive style recalibration and a context-aware dual-level prototype alignment across encoder-decoder layers, demonstrating remarkable performance on public datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnostics</span>
                    
                    <span class="domain-tag">Pathology (if applicable to broader image types)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10945v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10945v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10945v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10945v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10930v1"
                     data-domains="Clinical Cardiology,Biomedical Natural Language Processing,Medical Informatics,Medical Education"
                     data-keywords="Cardiology,Text Embeddings,Clinical Natural Language Processing,Contrastive Learning,Information Retrieval,Domain Specialization,Qwen3-Embedding-8B,MedTE"
                     data-authors="Richard J. Young,Alice M. Matthews">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10930v1.html">CardioEmbed: Domain-Specialized Text Embeddings for Clinical Cardiology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Richard J. Young, Alice M. Matthews
                </div>

                <div class="paper-summary">
                    This study introduces CardioEmbed, a novel domain-specialized text embedding model for clinical cardiology, designed to overcome the limitations of existing models primarily trained on general biomedical research literature. By utilizing contrastive learning on a curated corpus of comprehensive cardiology textbooks, CardioEmbed achieved near-perfect (99.60%) retrieval accuracy on cardiac-specific semantic tasks. This represents a significant 15.94 percentage point improvement over MedTE, the current state-of-the-art medical embedding model.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Cardiology</span>
                    
                    <span class="domain-tag">Biomedical Natural Language Processing</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10930v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10930v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10930v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10930v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10919v1"
                     data-domains="Rare Disease Diagnosis,Oncology (cancer screening/detection),Pharmacovigilance (adverse event detection),Infectious Disease Surveillance,Public Health Screening Programs,Electronic Health Record (EHR) analysis"
                     data-keywords="Positive-Unlabeled Learning,Transfer Learning,Model Averaging,Heterogeneous Data,Logistic Regression,Kullback-Leibler Divergence,Medical Diagnosis,Data Scarcity"
                     data-authors="Jialei Liu,Jun Liao,Kuangnan Fang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10919v1.html">Heterogeneous Multisource Transfer Learning via Model Averaging for Positive-Unlabeled Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jialei Liu, Jun Liao, Kuangnan Fang
                </div>

                <div class="paper-summary">
                    This paper introduces a novel heterogeneous multisource transfer learning framework that utilizes model averaging to address the challenges of Positive-Unlabeled (PU) data, particularly in high-stakes domains like medical diagnosis, where labeled negative samples are scarce. By integrating knowledge from fully binary labeled, semi-supervised, and PU datasets through tailored logistic regression models and optimally weighted averaging, the method achieves superior predictive accuracy and robustness. Crucially, it accomplishes this without direct data sharing, overcoming privacy and data scarcity constraints.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Disease Diagnosis</span>
                    
                    <span class="domain-tag">Oncology (cancer screening/detection)</span>
                    
                    <span class="domain-tag">Pharmacovigilance (adverse event detection)</span>
                    
                    <span class="domain-tag">Infectious Disease Surveillance</span>
                    
                    <span class="domain-tag">Public Health Screening Programs</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10919v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10919v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10919v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10919v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10912v1"
                     data-domains="Rare Diseases,Clinical Diagnostics,Internal Medicine,Medical Education,Computational Health"
                     data-keywords="Large Language Models,Rare Disease Diagnosis,Narrative Medicine,AI-assisted Diagnosis,Diagnostic Reasoning,Medical Education,Benchmarking"
                     data-authors="Arsh Gupta,Ajay Narayanan Sridhar,Bonam Mingole,Amulya Yadav">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10912v1.html">Evaluating Large Language Models on Rare Disease Diagnosis: A Case Study using House M.D</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Arsh Gupta, Ajay Narayanan Sridhar, Bonam Mingole et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the underexplored performance of Large Language Models (LLMs) in rare disease diagnosis from narrative medical cases. It introduces a novel, educationally validated dataset of 176 symptom-diagnosis pairs derived from House M.D. and evaluates four state-of-the-art LLMs, revealing low initial accuracy (16.48% to 38.64%) but a significant 2.3 times improvement in newer model generations, establishing a crucial baseline for future AI-assisted diagnosis research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Computational Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10912v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10912v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10912v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10912v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10900v1"
                     data-domains="Emergency Medical Services (EMS),Trauma,Airway Management,Pre-hospital Care"
                     data-keywords="Large Language Models (LLMs),Retrieval-Augmented Generation (RAG),Chain-of-Thought (CoT),Emergency Medical Services (EMS),Medical Question Answering,Domain-Specific AI,Certification Simulation"
                     data-authors="Xueren Ge,Sahil Murtaza,Anthony Cortez,Homa Alemzadeh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10900v1.html">Expert-Guided Prompting and Retrieval-Augmented Generation for Emergency Medical Service Question Answering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xueren Ge, Sahil Murtaza, Anthony Cortez et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the limitation of large language models (LLMs) in medical question answering, which often overlook domain-specific expertise like clinical subject areas and certification levels. The authors introduce EMSQA, a new medical dataset, and propose Expert-CoT prompting and ExpertRAG, a retrieval-augmented generation pipeline, both designed to leverage this structured context. Their methods significantly improve accuracy and enable a 32B expertise-augmented LLM to pass simulated EMS certification exams.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medical Services (EMS)</span>
                    
                    <span class="domain-tag">Trauma</span>
                    
                    <span class="domain-tag">Airway Management</span>
                    
                    <span class="domain-tag">Pre-hospital Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10900v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10900v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10900v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10900v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10890v1"
                     data-domains="Neurology,Neuroscience,Diagnostic Imaging,Computational Biology,Geriatrics"
                     data-keywords="Large Language Models,Disease Progression,Neurodegenerative Disease,Alzheimer's Disease,Graph Inference,Biomarker Interactions,Tau-PET,Brain Connectivity"
                     data-authors="Tiantian He,An Zhao,Elinor Thompson,Anna Schroder,Ahmed Abdulaal,Frederik Barkhof,Daniel C. Alexander">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10890v1.html">LLM enhanced graph inference for long-term disease progression modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tiantian He, An Zhao, Elinor Thompson et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that leverages Large Language Models (LLMs) to enhance graph inference for long-term disease progression modeling, specifically in neurodegenerative diseases like Alzheimer's Disease. By using LLMs as expert guides to synthesize multi-modal relationships, the method simultaneously optimizes individual disease trajectories and learns a biologically-constrained graph structure, leading to superior prediction accuracy and interpretability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10890v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10890v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10890v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10890v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10888v1"
                     data-domains="q-bio.OT"
                     data-keywords="q-bio.OT"
                     data-authors="Bolin Liu,Alexander Fulton,Hector Zenil">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10888v1.html">Multiomic Enriched Blood-Derived Digital Signatures Reveal Mechanistic and Confounding Disease Clusters for Differential Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bolin Liu, Alexander Fulton, Hector Zenil
                </div>

                <div class="paper-summary">
                    Understanding disease relationships through blood biomarkers offers a pathway toward data driven taxonomy and precision medicine. We constructed a digital blood twin from 103 disease signatures comprising longitudinal hematological and biochemical analytes. Profiles were standardized into a unified ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.OT</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10888v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10888v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10888v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10888v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10887v1"
                     data-domains="Clinical Informatics,Pharmacology,Biomedical Research,Medical Ontology,Health IT,Diagnostic Medicine,Public Health"
                     data-keywords="Biomedical Entity Linking,UMLS,Ontological Paths,NLP Datasets,Explainable AI,Clinical NLP,Cross-Vocabulary,Hierarchical Semantics"
                     data-authors="Nishant Mishra,Wilker Aziz,Iacer Calixto">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10887v1.html">MedPath: Multi-Domain Cross-Vocabulary Hierarchical Paths for Biomedical Entity Linking</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nishant Mishra, Wilker Aziz, Iacer Calixto
                </div>

                <div class="paper-summary">
                    MedPath introduces a novel, large-scale, multi-domain biomedical Entity Linking (EL) dataset designed to address the fragmentation of data and the lack of explainable models in biomedical NLP. It unifies and normalizes entities from nine existing datasets using UMLS, enriching them with extensive cross-vocabulary mappings and hierarchical ontological paths. This dataset is poised to enable the development of semantic-rich, interpretable, and interoperable clinical NLP systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Medical Ontology</span>
                    
                    <span class="domain-tag">Health IT</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10887v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10887v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10887v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10887v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10878v1"
                     data-domains="Rehabilitation Medicine,Orthopedics,Biomedical Engineering,Prosthetics and Orthotics,Sports Medicine"
                     data-keywords="Deep Learning,Inverse Dynamics,Muscle Activation,Multi-Joint Systems,Physics-Informed,Kinematics,Assistive Devices,Biomechanics"
                     data-authors="Shuhao Ma,Zeyi Huang,Yu Cao,Wesley Doorsamy,Chaoyang Shi,Jun Li,Zhi-Qiang Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10878v1.html">Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shuhao Ma, Zeyi Huang, Yu Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Multi-Joint Physics-Informed Deep Learning (PI-DL) framework, PI-MJCA-BiGRU, for time-efficient estimation of muscle activations and forces across multi-joint systems. It addresses the challenges of high computational cost and lack of labeled datasets in conventional inverse dynamics methods by leveraging a novel Multi-Joint Cross-Attention (MJCA) module with BiGRU layers and embedding multi-joint dynamics into the loss function. The framework achieves physiologically consistent predictions comparable to supervised methods, but without requiring ground-truth labels, while enabling faster inference.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Prosthetics and Orthotics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10878v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10878v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10878v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10878v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10866v1"
                     data-domains="Psychiatric Care,Elder Care Facilities,Emergency Departments,Forensic Psychiatry,Patient Safety,Hospital Security,Assisted Living"
                     data-keywords="Violence Detection,Real-Time,LLM,Auto-Labeling,CCTV,Intelligent Surveillance,Short-Window Learning,Behavioral Monitoring"
                     data-authors="Seoik Jung,Taekyung Song,Yangro Lee,Sungjun Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10866v1.html">Short-Window Sliding Learning for Real-Time Violence Detection via LLM-based Auto-Labeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-14</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Seoik Jung, Taekyung Song, Yangro Lee et al.
                </div>

                <div class="paper-summary">
                    The paper introduces a Short-Window Sliding Learning (SW-SL) framework designed for real-time violence detection in CCTV footage, departing from conventional long-video training methods. It leverages LLM-based auto-caption labeling to construct fine-grained datasets from 1-2 second video clips, ensuring temporal continuity for precise recognition of rapid violent events. The proposed method achieves a high accuracy of 95.25% on the RWF-2000 dataset and significantly improves performance on long videos (83.25% on UCF-Crime), demonstrating strong generalization and real-time applicability for intelligent surveillance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatric Care</span>
                    
                    <span class="domain-tag">Elder Care Facilities</span>
                    
                    <span class="domain-tag">Emergency Departments</span>
                    
                    <span class="domain-tag">Forensic Psychiatry</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10866v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10866v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10866v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10866v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10848v1"
                     data-domains="Neurology,Clinical Neurophysiology,Epileptology,Sleep Medicine,Psychiatry,Cognitive Neuroscience"
                     data-keywords="EEG,Time Series Foundation Models,Spatial-Temporal Adapter,Multi-Head Pooling,Clinical Tasks,Classification,Deep Learning,Neuroscience"
                     data-authors="Brad Shook,Abby Turner,Jieshi Chen,Micha≈Ç Wili≈Ñski,Mononito Goswami,Jonathan Elmer,Artur Dubrawski">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10848v1.html">STAMP: Spatial-Temporal Adapter with Multi-Head Pooling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Brad Shook, Abby Turner, Jieshi Chen et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the lack of comparative analysis between general Time Series Foundation Models (TSFMs) and specialized EEG-specific Foundation Models (EEGFMs) for EEG tasks. It introduces STAMP (Spatial-Temporal Adapter with Multi-Head Pooling), a novel adapter that leverages univariate embeddings from general TSFMs to implicitly model EEG's spatial-temporal characteristics. STAMP achieves performance comparable to state-of-the-art EEGFMs on 8 clinical EEG classification benchmarks while being lightweight and flexible.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Epileptology</span>
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10848v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10848v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10848v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10848v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10809v1"
                     data-domains="Precision Medicine,Clinical Trial Design,Biomarker Discovery,Patient Stratification,Pharmacogenomics,Disease Progression Modeling"
                     data-keywords="Linear Predictive Clustering,Mixed-Integer Programming,Quadratic Pseudo-Boolean Optimization,Non-separable Spaces,Global Optimization,Machine Learning,Patient Stratification,Scalability"
                     data-authors="Jiazhou Liang,Hassan Khurram,Scott Sanner">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10809v1.html">Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiazhou Liang, Hassan Khurram, Scott Sanner
                </div>

                <div class="paper-summary">
                    This paper introduces novel, near-optimal approximation methods for Linear Predictive Clustering (LPC) that significantly improve the scalability of globally optimal solutions, particularly in non-separable (overlapping) data spaces. By refining the Mixed-Integer Program (MIP) formulation and leveraging Quadratic Pseudo-Boolean Optimization (QPBO), the authors achieve near-optimal results with substantially lower regression errors and superior scalability compared to existing methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Patient Stratification</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10809v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10809v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10809v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10809v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10807v1"
                     data-domains="Epidemiology,Immunology,Microbiology,Infectious Diseases,Oncology (cell population dynamics),Systems Biology"
                     data-keywords="Stochastic extinction,Population dynamics,Excitable systems,Immigration flux,Spreading activity fronts,System resilience,Epidemiological models,Finite-size effects"
                     data-authors="Kenneth A. V. Distefano,Sara Shabani,Uwe C. T√§uber">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10807v1.html">Invading activity fronts stabilize excitable systems against stochastic extinction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kenneth A. V. Distefano, Sara Shabani, Uwe C. T√§uber
                </div>

                <div class="paper-summary">
                    This paper demonstrates a generic mechanism to prevent stochastic extinction in finite excitable systems. It shows that in inhomogeneous settings, a vulnerable subsystem diffusively coupled to an adjacent stable patch can be reanimated and stabilized through continuous immigration flux from the interface, provided the absorbing region sustains spreading activity fronts. This process effectively eliminates finite-size extinction instabilities, ensuring population persistence.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Microbiology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Oncology (cell population dynamics)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10807v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10807v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10807v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10807v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10768v1"
                     data-domains="general medicine,patient communication,health informatics,medical natural language processing"
                     data-keywords="consumer health queries,LLMs,faithful summarization,medical named entity recognition,cross-lingual,healthcare communication,TextRank,LLaMA-2"
                     data-authors="Ajwad Abrar,Nafisa Tabassum Oeshy,Prianka Maheru,Farzana Tabassum,Tareque Mohmud Chowdhury">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10768v1.html">Faithful Summarization of Consumer Health Queries: A Cross-Lingual Framework with LLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ajwad Abrar, Nafisa Tabassum Oeshy, Prianka Maheru et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel cross-lingual framework combining TextRank-based sentence extraction and medical named entity recognition (NER) with large language models (LLMs) to generate faithful summaries of consumer health questions (CHQs). The approach specifically fine-tunes LLaMA-2-7B on English (MeQSum) and Bangla (BanglaCHQ-Summ) datasets, achieving consistent improvements across quality and faithfulness metrics. This framework significantly outperforms zero-shot baselines and prior systems, demonstrating enhanced reliability for LLM deployment in healthcare by ensuring critical medical information is preserved.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">general medicine</span>
                    
                    <span class="domain-tag">patient communication</span>
                    
                    <span class="domain-tag">health informatics</span>
                    
                    <span class="domain-tag">medical natural language processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10768v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10768v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10768v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10768v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10619v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,stat.ML"
                     data-authors="Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10619v1.html">Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Avrim Blum, Marten Garicano, Kavya Ravichandran et al.
                </div>

                <div class="paper-summary">
                    The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10591v1"
                     data-domains="Dermatology,Wound Management,Telemedicine,Nursing Informatics,Artificial Intelligence in Medicine"
                     data-keywords="Wound Care,Visual Question Answering,Mined Prompting,Metadata-Guided Generation,Clinical Precision,Remote Care,AI in Healthcare,Natural Language Generation"
                     data-authors="Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10591v1.html">Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bavana Durgapraveen, Sornaraj Sivasankaran, Abhinand Balachandran et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the growing demand for AI in asynchronous remote care by proposing two complementary approaches for wound care visual question answering (VQA). It introduces a mined prompting strategy to improve response relevance and a metadata-guided generation method, leveraging predicted attributes, to enhance clinical precision, thereby contributing to more efficient and reliable wound care support systems for clinicians.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Wound Management</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Nursing Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10591v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10591v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10591v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10591v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10590v2"
                     data-domains="Drug Discovery,Pharmaceutical Research,Medicinal Chemistry,Pharmacology,Oncology (specifically for EGFR inhibitors)"
                     data-keywords="Batch Bayesian Optimization,Epistemic Neural Networks,molecular design,drug discovery,binding affinity,foundation models,pretrained networks,scalable surrogates"
                     data-authors="Miles Wang-Henderson,Benjamin Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10590v2.html">Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Miles Wang-Henderson, Benjamin Kaufman, Edward Williams et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel approach utilizing Epistemic Neural Networks (ENNs) with pretrained prior networks to enhance Batch Bayesian Optimization (Batch BO) for molecular design. By obtaining scalable joint predictive distributions of binding affinity, the method significantly accelerates the discovery of potent drug candidates. It demonstrates its efficacy by reducing iterations needed to rediscover EGFR inhibitors and find potent small-molecule inhibitors from real-world libraries, offering a promising solution for large-scale drug discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Oncology (specifically for EGFR inhibitors)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10590v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10590v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10590v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10590v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10583v1"
                     data-domains="Clinical Informatics,Patient Safety,Medical Documentation,Healthcare Operations,Natural Language Processing in Medicine"
                     data-keywords="MedGemma,medical order extraction,prompting strategies,one-shot prompting,ReAct,agentic workflow,clinical information extraction,language models"
                     data-authors="Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10583v1.html">Evaluating Prompting Strategies with MedGemma for Medical Order Extraction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abhinand Balachandran, Bavana Durgapraveen, Gowsikkan Sikkan Sudhagar et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates MedGemma, a new domain-specific language model, for structured medical order extraction from doctor-patient conversations, addressing clinical documentation burdens. It systematically compares one-shot, ReAct, and agentic prompting strategies, finding that the simpler one-shot method achieved the highest performance on the validation set, potentially due to complex reasoning introducing noise in manually annotated data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Medical Documentation</span>
                    
                    <span class="domain-tag">Healthcare Operations</span>
                    
                    <span class="domain-tag">Natural Language Processing in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10583v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10583v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10583v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10583v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10573v1"
                     data-domains="Serious Mental Illness,Substance Use Disorders,Depression,Behavioral Health,Digital Therapeutics"
                     data-keywords="Reinforcement Learning,Responsible AI,Affective Computing,Constrained Markov Decision Process,Personalized Healthcare,Behavioral Health,Digital Therapeutics,Emotional Intelligence"
                     data-authors="Garapati Keerthana,Manik Gupta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10573v1.html">Towards Emotionally Intelligent and Responsible Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Garapati Keerthana, Manik Gupta
                </div>

                <div class="paper-summary">
                    This paper proposes a Responsible Reinforcement Learning (RRL) framework designed to enhance personalized decision systems in healthcare by explicitly integrating users' emotional context and ethical considerations. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), optimizing for engagement and adherence while ensuring emotional alignment and ethical safety through a multi-objective reward function and emotion-informed state representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Serious Mental Illness</span>
                    
                    <span class="domain-tag">Substance Use Disorders</span>
                    
                    <span class="domain-tag">Depression</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10573v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10573v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10573v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10573v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10572v2"
                     data-domains="Public Health,Healthcare Management,Precision Medicine,Chronic Disease Management,Clinical Trial Design"
                     data-keywords="Bi-level bandits,Contextual bandits,Resource allocation,Delayed feedback,Individualized treatment,Fairness,Neural networks,Healthcare"
                     data-authors="Mohammadsina Almasi,Hadis Anahideh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10572v2.html">Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammadsina Almasi, Hadis Anahideh
                </div>

                <div class="paper-summary">
                    This paper introduces a novel bi-level contextual bandit framework designed for individualized resource allocation in high-stakes domains like healthcare, specifically addressing challenges posed by delayed feedback, hidden heterogeneity, and ethical constraints. The framework optimizes subgroup-level budget allocations while identifying the most responsive individuals within those groups, accounting for temporal dynamics and treatment delays. Validated on real-world datasets, the approach demonstrates superior cumulative outcomes, better adaptation to delay structures, and equitable resource distribution.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Healthcare Management</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10572v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10572v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10572v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10572v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10484v1"
                     data-domains="Endocrinology,Radiology,Diabetology,Preventive Medicine,Medical Artificial Intelligence"
                     data-keywords="Type 2 Diabetes Mellitus,Pancreatic Surface Lobularity,CT Biomarker,Deep Learning,Opportunistic Screening,Pancreas Segmentation,Medical Imaging,Early Detection"
                     data-authors="Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10484v1.html">Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tejas Sudharshan Mathai, Anisa V. Prasad, Xinya Wang et al.
                </div>

                <div class="paper-summary">
                    This pilot study introduces an automated deep learning-based approach to identify Pancreatic Surface Lobularity (PSL) from CT scans as a novel biomarker for opportunistic screening of Type 2 Diabetes Mellitus (T2DM). The research demonstrates that diabetic patients exhibit significantly higher PSL compared to non-diabetic individuals, and a multivariate model incorporating CT biomarkers can effectively screen for T2DM with high accuracy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10484v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10484v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10484v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10484v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-17 06:28:49</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>