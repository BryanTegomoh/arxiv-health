<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">44</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">44</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">131</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Neurology (10), Radiology (7), Oncology (6)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Neurology">Neurology (10)</option>
                        
                        <option value="Radiology">Radiology (7)</option>
                        
                        <option value="Oncology">Oncology (6)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Diagnostic Medicine">Diagnostic Medicine (6)</option>
                        
                        <option value="Geriatrics">Geriatrics (4)</option>
                        
                        <option value="Psychiatry">Psychiatry (4)</option>
                        
                        <option value="Pharmacology">Pharmacology (4)</option>
                        
                        <option value="Cardiology">Cardiology (4)</option>
                        
                        <option value="Patient Safety">Patient Safety (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.02826v1"
                     data-domains="Pathology,Dermatopathology,Oncology,Histopathology"
                     data-keywords="Pathology,Foundation Models,Vision Transformers,Self-supervised Learning,Digital Pathology,Whole Slide Imaging,Histopathology,Dermatopathology"
                     data-authors="Harshith Padigela,Shima Nofallah,Atchuth Naveen Chilaparasetti,Ryun Han,Andrew Walker,Judy Shen,Chintan Shah,Blake Martin,Aashish Sood,Elliot Miller,Ben Glass,Andy Beck,Harsha Pokkalla,Syed Ashar Javed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02826v1.html">PLUTO-4: Frontier Pathology Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti et al.
                </div>

                <div class="paper-summary">
                    PLUTO-4 introduces next-generation pathology foundation models, including compact PLUTO-4S and frontier-scale PLUTO-4G Vision Transformers, designed for diverse histopathology tasks. These models are self-supervisedly pretrained on an extensive multi-institutional whole slide image corpus, achieving state-of-the-art performance across various diagnostic and analytical benchmarks. Notably, PLUTO-4 demonstrates an 11% improvement in dermatopathology diagnosis, positioning it as a transformative tool for translational research and clinical diagnostics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Dermatopathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02826v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02826v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02826v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02826v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02769v1"
                     data-domains="Medicinal Chemistry,Pharmacology,Drug Design,Computational Biology,Bioinformatics"
                     data-keywords="molecular generation,drug discovery,generative models,VAE,Transformers,SELFIES,conditional generation,LoRA,binding affinity,cheminformatics"
                     data-authors="Bum Chul Kwon,Ben Shapira,Moshiko Raboh,Shreyans Sethi,Shruti Murarka,Joseph A Morrone,Jianying Hu,Parthasarathy Suryanarayanan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02769v1.html">STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bum Chul Kwon, Ben Shapira, Moshiko Raboh et al.
                </div>

                <div class="paper-summary">
                    STAR-VAE is a novel Transformer-based Variational AutoEncoder designed for scalable and controllable molecular generation, trained on 79 million drug-like molecules using SELFIES to ensure chemical validity. It introduces a principled conditional latent-variable formulation and efficient LoRA finetuning, achieving competitive performance on benchmarks and demonstrating property-guided generation of molecules with improved predicted binding affinity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Design</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02766v1"
                     data-domains="Neurology,Gastroenterology,Psychiatry,Endocrinology,Immunology,Sleep Medicine,Metabolic Health"
                     data-keywords="gut microbiota,sleep physiology,gut-microbiota-brain axis,dysbiosis,neurotransmitters,circadian rhythms,probiotics,FMT,chrononutrition"
                     data-authors="Enso Onill Torres Alegre">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02766v1.html">Microbes in the Moonlight: How the Gut Microbiota Influences Sleep</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Enso Onill Torres Alegre
                </div>

                <div class="paper-summary">
                    This review synthesizes current understanding of how the gut microbiota fundamentally regulates sleep physiology via the gut-microbiota-brain axis (GMBA), influencing neural, endocrine, and immune pathways. It highlights how microbial dysbiosis contributes to sleep disturbances by altering key neurotransmitter and metabolic pathways (e.g., serotonin, GABA, SCFAs), with significant implications for neurodegenerative, metabolic, and mood disorders, and explores microbiota-targeted interventions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02766v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02766v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02766v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02766v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02754v1"
                     data-domains="Medical informatics,Clinical phenotyping,Population health,Personalized medicine,Multi-institutional research,Data privacy in healthcare,Computational epidemiology"
                     data-keywords="Ising model,Markov Random Field,distributed learning,representation learning,EHR,federated learning,patient phenotyping,privacy-preserving,high-dimensional data,bi-factored gradient descent"
                     data-authors="Zebin Wang,Ziming Gan,Weijing Tang,Zongqi Xia,Tianrun Cai,Tianxi Cai,Junwei Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02754v1.html">DANIEL: A Distributed and Scalable Approach for Global Representation Learning with EHR Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zebin Wang, Ziming Gan, Weijing Tang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DANIEL, a distributed and scalable framework based on the Ising model, designed for global representation learning from large-scale, low-rank binary data, particularly Electronic Health Records (EHRs). It addresses challenges of high-dimensionality, source heterogeneity, and stringent data-sharing constraints prevalent in modern healthcare data by optimizing a non-convex surrogate loss function via bi-factored gradient descent. The framework demonstrates superior performance in global representation learning and downstream clinical tasks across multi-institutional EHR datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical informatics</span>
                    
                    <span class="domain-tag">Clinical phenotyping</span>
                    
                    <span class="domain-tag">Population health</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Multi-institutional research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02754v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02754v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02754v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02754v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02735v1"
                     data-domains="Neurology,Neuroscience,Brain-Computer Interfaces,Geriatrics (Alzheimer's),Neuroimaging Diagnostics"
                     data-keywords="EEG,P300,Brain-Computer Interface (BCI),eLORETA,Functional Connectivity,Regions of Interest (ROIs),Alzheimer's Disease,Neurodegenerative Disease Detection"
                     data-authors="Eva Guttmann-Flury,Jian Zhao,Mohamad Sawan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02735v1.html">Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan
                </div>

                <div class="paper-summary">
                    This paper presents a novel framework combining eLORETA source localization with cross-subject functional connectivity to identify stable, task-relevant regions of interest (ROIs) for P300 classification. The method effectively probes deeper cortical-subcortical structures relevant to Alzheimer's disease, significantly enhancing single-trial P300 classification accuracy by up to 5.4% compared to whole-brain approaches, while maintaining millisecond temporal precision. The framework's robustness and portability offer significant potential for early neurodegenerative disease detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Brain-Computer Interfaces</span>
                    
                    <span class="domain-tag">Geriatrics (Alzheimer's)</span>
                    
                    <span class="domain-tag">Neuroimaging Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02735v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02735v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02735v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02735v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02722v1"
                     data-domains="Psychiatry,Neurology,Cognitive Neuroscience"
                     data-keywords="Schizophrenia,Cortical hierarchy,Functional gradients,Recurrent Neural Networks,Neural timescales,Fixed point stability,Working memory,Functional MRI"
                     data-authors="Subati Abulikemu,Puria Radmard,Michail Mamalakis,John Suckling">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02722v1.html">Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Subati Abulikemu, Puria Radmard, Michail Mamalakis et al.
                </div>

                <div class="paper-summary">
                    This study investigates the sensory-to-association (AS) cortical hierarchy in schizophrenia using fMRI data and computational modeling. It reveals that schizophrenia patients exhibit a compressed AS hierarchy, indicating reduced functional differentiation and attenuated neural timescales, which mechanistically contributes to destabilized neural computations as evidenced by less stable fixed points in gradient-regularized recurrent neural networks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02722v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02722v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02722v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02722v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02587v1"
                     data-domains="Public Health,Pharmacology,Vaccinology,Patient Safety,Infectious Diseases (Covid-19),Regulatory Affairs (Pharmaceutical)"
                     data-keywords="Machine Translation,Lexical Errors,Medical Translation,Covid-19,Patient Information Leaflet,Google Translate,Error Analysis,Romanian Language"
                     data-authors="Angela Stamatie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02587v1.html">The Analysis of Lexical Errors in Machine Translation from English into Romanian</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Angela Stamatie
                </div>

                <div class="paper-summary">
                    This research analyzes lexical errors in machine translation (MT) performed by Google Translate when translating Covid-19 related medical and official health information from English into Romanian. It investigates 230 texts from sources such as the World Health Organization (WHO), Gavi, and patient information leaflets, with the ultimate goal of improving lexical selection and reducing errors to enhance overall MT quality in medical contexts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Infectious Diseases (Covid-19)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02587v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02587v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02587v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02587v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02576v1"
                     data-domains="Radiology,Orthopedics,Medical Imaging,Computational Anatomy"
                     data-keywords="Weak supervision,Segmentation refinement,Medical image analysis,CT scans,Deep learning,Anatomical delineation,Resource-efficient"
                     data-authors="Alix de Langlais,Benjamin Billot,Th√©o Aguilar Vidal,Marc-Olivier Gauci,Herv√© Delingette">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02576v1.html">Resource-efficient Automatic Refinement of Segmentations via Weak Supervision from Light Feedback</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alix de Langlais, Benjamin Billot, Th√©o Aguilar Vidal et al.
                </div>

                <div class="paper-summary">
                    SCORE (Segmentation COrrection from Regional Evaluations) is a novel weakly supervised framework designed to refine automated medical image segmentations using only light feedback during training, significantly reducing the need for dense annotations. It introduces a unique loss function leveraging region-wise quality scores and over/under-segmentation error labels, demonstrating considerable improvement over initial predictions from foundation models like TotalSegmentator while matching existing refinement methods' performance with much less supervision.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02576v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02576v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02576v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02576v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02565v1"
                     data-domains="Neurology,Neurosurgery,Rehabilitation Medicine,Neuroimaging,Psychiatry"
                     data-keywords="Brain decoding,fMRI,Visual reconstruction,Subject-agnostic,Ventral-dorsal stream,Cognitive process,Contrastive learning,Clinical application"
                     data-authors="Jingyu Lu,Haonan Wang,Qixiang Zhang,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02565v1.html">A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingyu Lu, Haonan Wang, Qixiang Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Visual Cortex Flow Architecture (VCFlow), a novel hierarchical framework for subject-agnostic brain visual decoding that reconstructs continuous visual experiences from fMRI without subject-specific training. By explicitly modeling the human visual system's ventral-dorsal architecture and employing feature-level contrastive learning, VCFlow achieves fast (10 seconds per video), clinically scalable reconstruction with minimal accuracy sacrifice (7%) and no per-subject retraining.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02565v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02565v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02565v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02565v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02564v1"
                     data-domains="Hospital Management,Patient Safety,Geriatric Care,Healthcare Operations,Clinical Security,Remote Patient Monitoring"
                     data-keywords="Person Re-identification,Cross-View Learning,Video Analytics,Deep Learning,Computer Vision,Patient Tracking,Real-time Systems,Surveillance"
                     data-authors="Md Rashidunnabi,Kailash A. Hambarde,Vasco Lopes,Joao C. Neves,Hugo Proenca">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02564v1.html">Seeing Across Time and Views: Multi-Temporal Cross-View Learning for Robust Video Person Re-Identification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.65</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md Rashidunnabi, Kailash A. Hambarde, Vasco Lopes et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTF-CVReID, a parameter-efficient deep learning framework designed to enhance robust video-based person re-identification in challenging cross-view environments with extreme viewpoint shifts and scale disparities. By integrating seven specialized adapter-based modules over a ViT backbone, the framework achieves state-of-the-art performance on relevant benchmarks while maintaining real-time efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Hospital Management</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Geriatric Care</span>
                    
                    <span class="domain-tag">Healthcare Operations</span>
                    
                    <span class="domain-tag">Clinical Security</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02564v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02564v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02564v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02564v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02558v1"
                     data-domains="Neuroimaging,Neurology,Geriatrics,Neurodegenerative Diseases,Radiology"
                     data-keywords="brain MRI,neurodegeneration,Alzheimer's disease,deep learning,image prediction,longitudinal study,prognosis,voxel-level"
                     data-authors="Ali Farki,Elaheh Moradi,Deepika Koundal,Jussi Tohka">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02558v1.html">Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ali Farki, Elaheh Moradi, Deepika Koundal et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning approach for predicting an individual's entire future brain MRI from a baseline scan, shifting focus from traditional cognitive score predictions to direct anatomical forecasting. Evaluating five deep learning architectures on ADNI and AIBL longitudinal cohorts, the study demonstrates high-fidelity, voxel-level predictions that generalize robustly across datasets, opening new avenues for individualized neurodegenerative disease prognosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02558v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02558v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02558v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02558v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02531v1"
                     data-domains="Psychiatry,Oncology,Continuous Physiological Monitoring,Pharmacology,Precision Medicine,Diagnostics"
                     data-keywords="Causal Graph Neural Networks,Healthcare AI,Causal Inference,Digital Twins,Distribution Shift,Personalized Medicine,Multi-omics,Interpretability"
                     data-authors="Munib Mesinovic,Max Buhlan,Tingting Zhu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02531v1.html">Causal Graph Neural Networks for Healthcare</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Munib Mesinovic, Max Buhlan, Tingting Zhu
                </div>

                <div class="paper-summary">
                    This review paper proposes Causal Graph Neural Networks (CGNNs) as a solution to critical failures in healthcare AI, such as distribution shift, discrimination, and inscrutability, by learning invariant causal mechanisms instead of mere statistical associations. It explores their methodological foundations, demonstrates clinical value across various applications, and envisions their role in creating patient-specific Causal Digital Twins for in silico clinical experimentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Continuous Physiological Monitoring</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02531v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02531v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02531v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02531v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02490v1"
                     data-domains="Neurology,Geriatrics,Diagnostic Imaging,Public Health,Cognitive Neuroscience"
                     data-keywords="Alzheimer's Disease,Large Language Models,Retrieval-Augmented Generation,Cognitive Decline,Neuroimaging,Early Detection,Disease Monitoring,Artificial Intelligence in Medicine"
                     data-authors="Rajan Das Gupta,Md Kishor Morol,Nafiz Fahad,Md Tanzib Hosain,Sumaya Binte Zilani Choya,Md Jakir Hossen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02490v1.html">BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rajan Das Gupta, Md Kishor Morol, Nafiz Fahad et al.
                </div>

                <div class="paper-summary">
                    BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) is a novel retrieval-augmented system designed for early and accurate Alzheimer's disease (AD) detection and monitoring, particularly in regions with limited diagnostic tools. It leverages Large Language Models (LLMs) within a dual-module architecture that combines cognitive diagnostics with case retrieval. The system demonstrates effectiveness in classifying disease severity and identifying early signs of cognitive decline using real-world datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02490v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02490v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02490v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02490v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02453v1"
                     data-domains="Medical Imaging,Radiology,Diagnostic Medicine,Clinical Decision Support"
                     data-keywords="Machine Learning,Medical Imaging,Statistical Robustness,Underspecification,Training Variance,False Positives,Model Superiority,Validation"
                     data-authors="Thomas Sanchez,Pedro M. Gordaliza,Meritxell Bach Cuadra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02453v1.html">Accounting for Underspecification in Statistical Claims of Model Superiority</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thomas Sanchez, Pedro M. Gordaliza, Meritxell Bach Cuadra
                </div>

                <div class="paper-summary">
                    This paper addresses the issue of statistically unreliable performance claims in machine learning models, particularly in medical imaging, by introducing the concept of "underspecification." It extends a statistical framework to incorporate underspecification (variability due to random initialization or training dynamics) as an additional variance component. The findings demonstrate that even modest seed variability substantially increases the evidence required to statistically claim model superiority, underscoring the necessity of explicitly modeling training variance in medical imaging system validation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02453v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02453v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02453v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02453v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02437v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Mathematical Biology"
                     data-keywords="epidemic modeling,rumor dynamics,coupled ODEs,asymptotic analysis,stability,dependency graphs,infectious disease,public health"
                     data-authors="K. M. D. Chan,D. T. Crommelin,M. R. H. Mandjes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02437v1.html">Asymptotic behavior for a general class of spreading models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> K. M. D. Chan, D. T. Crommelin, M. R. H. Mandjes
                </div>

                <div class="paper-summary">
                    This paper introduces a unified framework of coupled Ordinary Differential Equations (ODEs) for modeling the coevolution of infection and information spread, encompassing models like SIR epidemics and Daley-Kendall rumor dynamics. It derives a classification of asymptotic behavior for these models under specific graph-theoretic conditions, conjecturing exponential decay for vanishing states, while noting non-exponential decay when these conditions are violated.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Mathematical Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02437v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02437v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02437v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02437v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02400v1"
                     data-domains="Radiology,Breast Imaging,Medical AI,Diagnostic Imaging,Public Health (Equity)"
                     data-keywords="Mammography,Artificial Intelligence,Dataset Harmonization,Bias Quantification,Generalizability,Breast Density,Image Processing,Clinical Deployment"
                     data-authors="Yalda Zafari,Hongyi Pan,Gorkem Durak,Ulas Bagci,Essam A. Rashed,Mohamed Mabrok">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02400v1.html">MammoClean: Toward Reproducible and Bias-Aware AI in Mammography through Dataset Harmonization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yalda Zafari, Hongyi Pan, Gorkem Durak et al.
                </div>

                <div class="paper-summary">
                    MammoClean is a novel open-source framework designed to standardize and quantify bias in public mammography datasets, addressing the critical issue of data heterogeneity that compromises AI model generalizability. By harmonizing data quality, processing, and metadata, MammoClean facilitates the development of robust and reproducible AI systems, crucial for equitable performance across diverse patient populations. The framework demonstrably improves AI model performance by mitigating biases inherent in uncurated datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Breast Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Public Health (Equity)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02400v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02400v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02400v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02400v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02392v1"
                     data-domains="Oncology,Preventive Medicine,Diagnostic Medicine,Endocrinology,Public Health"
                     data-keywords="Breast Cancer,Risk Assessment,Fuzzy Soft Set Theory,Expert System,Early Diagnosis,Biomarkers,Machine Learning,Clinical Decision Support"
                     data-authors="Muhammad Sheharyar Liaqat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02392v1.html">Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Sheharyar Liaqat
                </div>

                <div class="paper-summary">
                    This paper introduces a novel fuzzy soft set theory-based expert system designed for the preliminary risk assessment of breast cancer in patients. The system utilizes readily measurable clinical and physiological parameters such as BMI, Insulin, Leptin, Adiponectin levels, and age, integrating fuzzy inference rules and soft set computations to estimate risk. Its primary aim is to assist healthcare professionals in early identification of high-risk patients, potentially reducing the need for invasive diagnostic procedures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02392v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02392v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02392v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02392v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02379v1"
                     data-domains="Cardiology,Cardiac Electrophysiology,Diagnostic Medicine,Preventive Medicine,Medical AI"
                     data-keywords="Arrhythmia detection,Heart sound analysis,Deep learning,CNN-LSTM,H-Infinity filter,Physiological signals,Cardiac monitoring,Biomedical AI"
                     data-authors="Rohith Shinoj Kumar,Rushdeep Dinda,Aditya Tyagi,Annappa B.,Naveen Kumar M. R">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02379v1.html">H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart Sound Recordings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rohith Shinoj Kumar, Rushdeep Dinda, Aditya Tyagi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel CNN-H-Infinity-LSTM architecture for robust and generalized arrhythmia detection from heart sound recordings. By integrating trainable parameters inspired by the H-Infinity filter from control theory, the model significantly enhances its ability to handle noisy and small datasets, a common challenge in biomedical applications. The proposed model achieves superior performance on the PhysioNet CinC Challenge 2016 dataset, demonstrating 99.42% test accuracy and an F1 score of 98.85%, outperforming existing benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiac Electrophysiology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02379v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02379v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02379v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02379v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02374v1"
                     data-domains="Ayurveda,Traditional Medicine,Integrative Medicine,Health Informatics,Clinical Decision Support"
                     data-keywords="Ayurveda,Language Model,Domain Adaptation,Bilingual AI,Traditional Medicine,Clinical Guidance,Natural Language Processing,Medical AI"
                     data-authors="Mohd Nauman,Sravan Gvm,Vijay Devane,Shyam Pawar,Viraj Thakur,Kundeshwar Pundalik,Piyush Sawarkar,Rohit Saluja,Maunendra Desarkar,Ganesh Ramakrishnan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02374v1.html">AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohd Nauman, Sravan Gvm, Vijay Devane et al.
                </div>

                <div class="paper-summary">
                    AyurParam-2.9B, a specialized bilingual language model for Ayurveda, was developed by fine-tuning Param-1-2.9B with an extensive, expertly curated dataset in English and Hindi. It significantly outperforms general LLMs in its size class and competes with much larger models on Ayurveda-specific benchmarks, demonstrating the critical need for authentic domain adaptation and high-quality supervision in specialized medical AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ayurveda</span>
                    
                    <span class="domain-tag">Traditional Medicine</span>
                    
                    <span class="domain-tag">Integrative Medicine</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02374v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02374v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02374v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02374v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02349v1"
                     data-domains="Cardiology,Telemedicine,Remote patient monitoring,Preventive medicine,Digital health"
                     data-keywords="Photoplethysmography,Video-PPG,Smartphone health,Dual-view sensing,Mamba model,Cardiovascular disease,Heart rate monitoring,Open dataset"
                     data-authors="Jiankai Tang,Tao Zhang,Jia Li,Yiru Zhang,Mingyu Zhang,Kegang Wang,Yuming Hao,Bolin Wang,Haiyang Li,Xingyao Wang,Yuanchun Shi,Yuntao Wang,Sichong Qian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02349v1.html">M3PD Dataset: Dual-view Photoplethysmography (PPG) Using Front-and-rear Cameras of Smartphones in Lab and Clinical Settings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiankai Tang, Tao Zhang, Jia Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the M3PD dataset, the first publicly available dual-view mobile photoplethysmography (PPG) dataset, which captures synchronized facial and fingertip videos from 60 participants (including 47 cardiovascular patients) using smartphone front and rear cameras. Building on this dataset, the authors propose F3Mamba, a novel model fusing these dual views through Mamba-based temporal modeling, achieving a 21.9-30.2% reduction in heart-rate error and improved robustness over single-view baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Remote patient monitoring</span>
                    
                    <span class="domain-tag">Preventive medicine</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02349v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02349v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02349v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02349v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02340v1"
                     data-domains="Nephrology,Internal Medicine,Medical Informatics,Predictive Analytics,Personalized Medicine"
                     data-keywords="Chronic Kidney Disease,CKD Prognosis,Transformer,Electronic Health Records,EHR,Machine Learning,Deep Learning,OMOP,Predictive Modeling,AI in Medicine"
                     data-authors="Yohan Lee,DongGyun Kang,SeHoon Park,Sa-Yoon Park,Kwangsoo Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02340v1.html">Chronic Kidney Disease Prognosis Prediction Using Transformer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yohan Lee, DongGyun Kang, SeHoon Park et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ProQ-BERT, a novel transformer-based framework for predicting Chronic Kidney Disease (CKD) progression using multi-modal electronic health records (EHR) from the Seoul National University Hospital OMOP Common Data Model. By integrating demographic, clinical, and laboratory data with quantization-based tokenization for continuous values, ProQ-BERT consistently outperformed existing models like CEHR-BERT, achieving high predictive accuracy for progression from CKD stage 3a to stage 5.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02340v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02340v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02340v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02340v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02314v1"
                     data-domains="Radiation Oncology,Medical Physics,Head and Neck Surgery,Oncology"
                     data-keywords="carbon-ion therapy,head and neck cancer,treatment planning,reinforcement learning,multi-agent reinforcement learning,OAR sparing,intensity-modulated,medical physics"
                     data-authors="Jueye Zhang,Chao Yang,Youfang Lai,Kai-Wen Li,Wenting Yan,Yunzhou Xia,Haimei Zhang,Jingjing Zhou,Gen Yang,Chen Lin,Tian Li,Yibao Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02314v1.html">Large-scale automatic carbon ion treatment planning for head and neck cancers via parallel multi-agent reinforcement learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jueye Zhang, Chao Yang, Youfang Lai et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel multi-agent reinforcement learning (MARL) framework for the automatic and parallel optimization of 45 treatment planning parameters in intensity-modulated carbon-ion therapy (IMCT) for head and neck cancers (HNC). The method successfully addresses the challenges of complex HNC planning and the limitations of prior deep learning and single-agent RL approaches, producing clinically competitive plans that significantly improve organ-at-risk (OAR) sparing compared to expert manual planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Head and Neck Surgery</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02314v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02314v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02314v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02314v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02271v1"
                     data-domains="Radiology,Diagnostic Medicine,Medical Imaging Informatics,Medical AI"
                     data-keywords="Medical Report Generation (MRG),Cross-Modal Learning,Causal Intervention,Hierarchical Task Structure,Radiological Images,Lesion Description,Deep Learning,Front-door Intervention"
                     data-authors="Yucheng Song,Yifan Ge,Junhao Li,Zhining Liao,Zhifang Liao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02271v1.html">Medical Report Generation: A Hierarchical Task Structure-Based Cross-Modal Causal Intervention Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yucheng Song, Yifan Ge, Junhao Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces HTSC-CIF, a novel framework designed to address three critical challenges in Medical Report Generation (MRG) ‚Äì insufficient domain knowledge, poor text-visual alignment, and spurious correlations ‚Äì through a hierarchical task decomposition and cross-modal causal intervention. The framework significantly outperforms state-of-the-art MRG methods by enhancing visual encoders, boosting cross-modal alignment, and reducing confounders for more reliable lesion descriptions from radiological images.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging Informatics</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02271v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02271v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02271v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02271v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02263v1"
                     data-domains="Rare Disease,Clinical Genomics,Medical Genetics,Diagnostic Medicine,Bioinformatics"
                     data-keywords="Rare Disease Diagnosis,Large Language Models,Gene Reranking,AI-MARRVEL,Phenotype-Driven Analysis,Genomic Variants,Clinical Decision Support,Explainable AI"
                     data-authors="Jaeyeon Lee,Hyun-Hwan Jeong,Zhandong Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02263v1.html">LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for AI-MARRVEL in Rare Disease Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jaeyeon Lee, Hyun-Hwan Jeong, Zhandong Liu
                </div>

                <div class="paper-summary">
                    LA-MARRVEL introduces a knowledge-grounded and language-aware Large Language Model (LLM) reranking layer for AI-MARRVEL, designed to improve rare disease diagnosis by enhancing gene prioritization. It leverages expert-engineered context and multiple LLM queries to produce stable, explainable gene rankings that consistently outperform existing tools. This system significantly improves recall, particularly for challenging cases, and provides interpretable reasoning to aid clinical review.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Disease</span>
                    
                    <span class="domain-tag">Clinical Genomics</span>
                    
                    <span class="domain-tag">Medical Genetics</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02263v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02263v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02263v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02263v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02246v1"
                     data-domains="Clinical Decision Support,Telehealth,Patient Education,Medical Informatics,AI in Healthcare,Health Equity"
                     data-keywords="LLM evaluation,medical chatbots,bias detection,hallucination,inter-rater agreement,generalizability,demographic factors,LLM-as-a-judge"
                     data-authors="Jonathan Liu,Haoling Qiu,Jonathan Lasko,Damianos Karakos,Mahsa Yarmohammadi,Mark Dredze">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02246v1.html">Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jonathan Liu, Haoling Qiu, Jonathan Lasko et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an infrastructure to automatically generate realistic medical queries and evaluate Large Language Models (LLMs) for biases, hallucinations, and omissions, particularly concerning demographic information. The study reveals that LLM-based evaluators show alarmingly low inter-rater agreement (average Cohen's Kappa $\kappa=0.118$), and statistically significant results on LLM biases are often contingent on specific LLM pairings, potentially leading to non-generalizable conclusions without robust evaluation practices.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Telehealth</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02246v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02246v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02246v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02246v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02228v1"
                     data-domains="Neurology,Neuroradiology,Geriatric Medicine,Cognitive Neuroscience"
                     data-keywords="Alzheimer's Disease,Multimodal Fusion,MRI,PET,Deep Learning,Early Diagnosis,Collaborative Attention,Consistency-Guided Fusion"
                     data-authors="Delin Ma,Menghui Zhou,Jun Qi,Yun Yang,Po Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02228v1.html">Collaborative Attention and Consistent-Guided Fusion of MRI and PET for Alzheimer's Disease Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Delin Ma, Menghui Zhou, Jun Qi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Collaborative Attention and Consistent-Guided Fusion (CA-CGF) framework for improved Alzheimer's Disease (AD) diagnosis using multimodal MRI and PET neuroimaging. The framework effectively integrates both cross-modal complementary features and crucial modality-specific features, while simultaneously mitigating the inherent distributional differences between modalities. Experimental validation on the ADNI dataset demonstrates that the proposed method achieves superior diagnostic performance compared to existing fusion strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Geriatric Medicine</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02228v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02228v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02228v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02228v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02223v1"
                     data-domains="Radiation Oncology,Medical Physics,Patient Safety,Healthcare Quality Improvement,Clinical Informatics"
                     data-keywords="Radiation Oncology,Risk Assessment,Large Language Models (LLM),Root Cause Analysis,Patient Safety,Incident Reports,Ordinal Logistic Regression,Association Rule Mining"
                     data-authors="Yuntao Wang,Siamak P. Najad-Davarani,Elizabeth Bossart,Matthew T. Studenski,Mariluz De Ornelas,Yunze Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02223v1.html">Quantitative Risk Assessment in Radiation Oncology via LLM-Powered Root Cause Analysis of Incident Reports</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuntao Wang, Siamak P. Najad-Davarani, Elizabeth Bossart et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an LLM-powered data-driven framework for quantitative risk assessment in radiation oncology, automating root cause analysis of safety incident reports. It leverages LLMs to classify incidents into structured taxonomies, followed by statistical methods like Ordinal Logistic Regression (OLR) and Association Rule Mining (ARM) to identify significant drivers of event severity and systemic vulnerabilities. The study demonstrates that this objective approach can pinpoint high-risk process steps and systemic failures, enabling targeted interventions for patient safety improvements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Healthcare Quality Improvement</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02223v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02223v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02223v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02223v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02217v1"
                     data-domains="None directly. Indirectly relevant to Public Health Infrastructure, Emergency Medical Services (EMS) Logistics, Environmental Health, and potentially Urban Planning for Health."
                     data-keywords="Traffic Signal Control,Graph Attention Networks,Soft Actor-Critic,Reinforcement Learning,Mixed Autonomy,Connected Autonomous Vehicles,Intelligent Transportation Systems,Traffic Optimization"
                     data-authors="Manonmani Sekar,Nasim Nezamoddini">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02217v1.html">Optimizing Multi-Lane Intersection Performance in Mixed Autonomy Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.65</span>
                        
                        <span class="category">üìÇ cs.MA</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manonmani Sekar, Nasim Nezamoddini
                </div>

                <div class="paper-summary">
                    This paper introduces a novel traffic signal control framework, GAT-SAC, combining Graph Attention Networks (GAT) with Soft Actor-Critic (SAC) reinforcement learning to optimize multi-lane intersection performance in mixed-autonomy environments. The framework effectively coordinates human-driven and autonomous vehicles, demonstrating significant reductions in average delay and traffic violations while improving fairness between vehicle types in simulations. Its findings suggest promising potential for real-world deployment in future traffic systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">None directly. Indirectly relevant to Public Health Infrastructure, Emergency Medical Services (EMS) Logistics, Environmental Health, and potentially Urban Planning for Health.</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02217v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02217v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02217v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02217v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02210v1"
                     data-domains="Cardiology,Echocardiography,Cardiac Imaging,Interventional Cardiology"
                     data-keywords="Transesophageal Echocardiography,Segmental Longitudinal Strain,Deep Learning,Myocardial Ischemia,Cardiac Function Assessment,Automated Analysis,Motion Estimation,Synthetic Data"
                     data-authors="Anders Austlid Task√©n,Thierry Judge,Erik Andreas Rye Berg,Jinyang Yu,Bj√∏rnar Grenne,Frank Lindseth,Svend Aakhus,Pierre-Marc Jodoin,Nicolas Duchateau,Olivier Bernard,Gabriel Kiss">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02210v1.html">Estimation of Segmental Longitudinal Strain in Transesophageal Echocardiography by Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anders Austlid Task√©n, Thierry Judge, Erik Andreas Rye Berg et al.
                </div>

                <div class="paper-summary">
                    This study introduces autoStrain, the first automated deep learning (DL) pipeline for Segmental Longitudinal Strain (SLS) estimation in Transesophageal Echocardiography (TEE), addressing the significant manual effort and expertise currently required. The pipeline compares two DL models, TeeFlow and TeeTracker, trained and evaluated on a unique synthetic TEE dataset, with TeeTracker demonstrating superior accuracy. Clinical validation on real patients confirmed the pipeline's alignment with clinical references, indicating its potential to enhance the precision and efficiency of cardiac function assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Echocardiography</span>
                    
                    <span class="domain-tag">Cardiac Imaging</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02210v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02210v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02210v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02210v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02206v1"
                     data-domains="Neurology,Radiology,Nuclear Medicine,Diagnostic Imaging,Geriatrics,Biomarker Research"
                     data-keywords="Alzheimer's Disease,PET Synthesis,Generative Models,Large Language Model (LLM),Multimodal Fusion,Blood Biomarkers,MRI,Amyloid-beta,Diagnostic Accuracy,Neuroimaging"
                     data-authors="Zhengjie Zhang,Xiaoxie Mao,Qihao Guo,Shaoting Zhang,Qi Huang,Mu Zhou,Fang Xie,Mianxin Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02206v1.html">Language-Enhanced Generative Modeling for PET Synthesis from MRI and Blood Biomarkers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhengjie Zhang, Xiaoxie Mao, Qihao Guo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel language-enhanced generative model that synthesizes realistic amyloid-beta PET images from T1-weighted MRI scans and blood-based biomarkers. The synthetic PET images demonstrate high fidelity to real scans and significantly improve Alzheimer's disease diagnostic accuracy within an automated pipeline, outperforming models based solely on MRI or blood biomarkers. This approach offers a potential solution to the high cost and limited accessibility of traditional Abeta-PET imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02206v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02206v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02206v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02206v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02194v1"
                     data-domains="Public Health,Behavioral Medicine,Personalized Medicine,Health Policy,Preventive Medicine"
                     data-keywords="Personalized decision-making,Utility Theory,Large Language Models (LLMs),Symbolic reasoning,Semantic adaptation,Vaccine uptake,Human-centric AI,Health behavior modeling"
                     data-authors="Yibo Zhao,Yang Zhao,Hongru Du,Hao Frank Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02194v1.html">Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yibo Zhao, Yang Zhao, Hongru Du et al.
                </div>

                <div class="paper-summary">
                    ATHENA (Adaptive Textual-symbolic Human-centric Reasoning) is a novel framework that integrates Utility Theory and Large Language Models to improve the prediction of individual decision-making, particularly in high-stakes scenarios like vaccine uptake. It achieves this by combining group-level symbolic utility function discovery with individual-level semantic adaptation. Validated on real-world tasks, ATHENA significantly outperforms existing utility-based, machine learning, and LLM-based models, demonstrating a new approach for modeling human-centric choices.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Behavioral Medicine</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02194v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02194v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02194v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02194v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02193v1"
                     data-domains="Ophthalmology,Diabetic Retinopathy Screening,Cardiology (indirect indicators),Neurology (microvasculature research),Medical Imaging Diagnosis"
                     data-keywords="Retinal vessel segmentation,Deep learning,U-Net,Mamba,State-space modeling,Ophthalmology,Medical imaging,Vascular morphology"
                     data-authors="Jiawen Liu,Yuanbo Zeng,Jiaming Liang,Yizhen Yang,Yiheng Zhang,Enhui Cai,Xiaoqi Sheng,Hongmin Cai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02193v1.html">MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiawen Liu, Yuanbo Zeng, Jiaming Liang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MM-UNet, a novel deep learning architecture designed to improve the accuracy and robustness of retinal vessel segmentation, particularly addressing the challenges of thin, branching, and globally variable vascular structures. By incorporating Morph Mamba Convolution layers and Reverse Selective State Guidance modules, MM-UNet enhances topological perception and geometric boundary awareness, achieving superior F1-score gains on public datasets compared to existing methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diabetic Retinopathy Screening</span>
                    
                    <span class="domain-tag">Cardiology (indirect indicators)</span>
                    
                    <span class="domain-tag">Neurology (microvasculature research)</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02193v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02193v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02193v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02193v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02175v1"
                     data-domains="Public Health,Environmental Health,Epidemiology,Preventative Medicine,Risk Assessment"
                     data-keywords="Air quality prediction,Incomplete data,Bayesian deep learning,Uncertainty quantification,Spatiotemporal forecasting,Public health,Exposure assessment,Environmental health"
                     data-authors="Yuzhuang Pian,Taiyu Wang,Shiqi Zhang,Rui Xu,Yonghong Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02175v1.html">Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep Learning Framework for Uncertainty Quantification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuzhuang Pian, Taiyu Wang, Shiqi Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CGLUBNF (Channel Gated Learning Unit based Spatiotemporal Bayesian Neural Field), an end-to-end Bayesian deep learning framework designed to tackle the critical challenge of incomplete spatiotemporal data in air quality prediction. The framework delivers superior prediction accuracy and sharper, calibrated confidence intervals across various missing data patterns and prediction horizons on real-world datasets. This advancement provides more reliable air quality forecasts crucial for public health decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Preventative Medicine</span>
                    
                    <span class="domain-tag">Risk Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02175v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02175v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02175v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02175v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02152v1"
                     data-domains="Cardiology (ECG analysis, arrhythmia detection),Neurology (EEG interpretation, seizure detection),Critical Care (vital signs monitoring, patient deterioration prediction),Endocrinology (glucose monitoring, diabetes management),Remote Patient Monitoring (activity tracking, anomaly detection)"
                     data-keywords="Interpretable AI,Explainable AI (XAI),Multivariate Time Series,Classification,Prototypical Networks,Medical Diagnostics,Feature Importance,Group Convolutions"
                     data-authors="Bart≈Çomiej Ma≈Çkus,Szymon Bobek,Grzegorz J. Nalepa">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02152v1.html">ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bart≈Çomiej Ma≈Çkus, Szymon Bobek, Grzegorz J. Nalepa
                </div>

                <div class="paper-summary">
                    This paper introduces ProtoTSNet, a novel approach for interpretable multivariate time series classification, building upon and substantially enhancing the ProtoPNet architecture. It addresses the critical need for explainable AI in high-stakes domains like medicine by providing high accuracy alongside transparent, prototype-based explanations. ProtoTSNet integrates a modified convolutional encoder with group convolutions and autoencoder pre-training to capture dynamic patterns and quantify feature importance, achieving superior performance among ante-hoc explainable methods while remaining competitive with non-explainable baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology (ECG analysis, arrhythmia detection)</span>
                    
                    <span class="domain-tag">Neurology (EEG interpretation, seizure detection)</span>
                    
                    <span class="domain-tag">Critical Care (vital signs monitoring, patient deterioration prediction)</span>
                    
                    <span class="domain-tag">Endocrinology (glucose monitoring, diabetes management)</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring (activity tracking, anomaly detection)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02152v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02152v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02152v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02152v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02146v1"
                     data-domains="Oncology,Pharmacology,Drug Discovery,Precision Medicine,Therapeutics"
                     data-keywords="Drug synergy prediction,Causal inference,Molecular substructures,Combination therapy,Cancer treatment,Interpretable AI,Cold start problem,Out-of-distribution generalization"
                     data-authors="Yi Luo,Haochen Zhao,Xiao Liang,Yiwei Liu,Yuye Zhang,Xinyu Li,Jianxin Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02146v1.html">Disentangling Causal Substructures for Interpretable and Generalizable Drug Synergy Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yi Luo, Haochen Zhao, Xiao Liang et al.
                </div>

                <div class="paper-summary">
                    CausalDDS is a novel framework for drug synergy prediction that addresses the limitations of existing black-box methods by disentangling drug molecules into causal and spurious substructures. It leverages these causal representations, combined with conditional interventions and a sufficiency-independence optimization objective, to enhance prediction accuracy and provide molecular-level interpretability. The model demonstrates superior performance, especially in challenging cold-start and out-of-distribution scenarios, and effectively identifies key substructures responsible for synergistic effects.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02146v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02146v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02146v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02146v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02140v1"
                     data-domains="Cardiology,Diagnostic Medicine,Biomedical Signal Processing"
                     data-keywords="Quantum Convolutional Neural Network (QCNN),Phonocardiogram (PCG),Heart Sound Analysis,S3 Sound,Cardiac Murmur,Wavelet Feature Extraction,Quantum Machine Learning,Bioacoustic Signal Processing"
                     data-authors="Yasaman Torabi,Shahram Shirani,James P. Reilly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02140v1.html">QuPCG: Quantum Convolutional Neural Network for Detecting Abnormal Patterns in PCG Signals</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yasaman Torabi, Shahram Shirani, James P. Reilly
                </div>

                <div class="paper-summary">
                    This paper introduces QuPCG, a novel hybrid quantum-classical convolutional neural network (QCNN) designed to classify S3 and murmur abnormalities in heart sound signals. It transforms one-dimensional phonocardiogram (PCG) signals into compact 8-pixel two-dimensional images using wavelet feature extraction and adaptive threshold compression, requiring only 8 qubits. Preliminary results on the HLS-CMDS dataset demonstrate high classification accuracy, suggesting the efficiency of quantum models in capturing temporal-spectral correlations for bioacoustic signal processing.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Biomedical Signal Processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02140v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02140v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02140v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02140v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02137v1"
                     data-domains="Oncology,Personalized Medicine,Intensive Care Medicine,Chronic Disease Management,Pharmacogenomics,Treatment Optimization"
                     data-keywords="Causal Inference,Time-Series Forecasting,Generative Models,Continuous Normalizing Flows,Interventional Prediction,Counterfactuals,Anomaly Detection,Dynamic Systems"
                     data-authors="Dongze Wu,Feng Qiu,Yao Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02137v1.html">DoFlow: Causal Generative Flows for Interventional and Counterfactual Time-Series Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dongze Wu, Feng Qiu, Yao Xie
                </div>

                <div class="paper-summary">
                    DoFlow introduces a flow-based generative model that integrates causal reasoning into time-series forecasting, enabling accurate observational predictions, interventional forecasting, and counterfactual analysis by leveraging continuous normalizing flows over a causal DAG. Beyond prediction, it provides explicit trajectory likelihoods for principled anomaly detection, demonstrating robust performance on synthetic, hydropower, and real-world cancer treatment time series data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02137v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02137v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02137v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02137v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02102v1"
                     data-domains="Pulmonology,Allergy & Immunology,Health Informatics,Epidemiology,Internal Medicine"
                     data-keywords="Bayesian latent class model,electronic health records (EHR),phenotype discovery,asthma sub-phenotype,Type 2 inflammation,precision medicine,unsupervised learning,informative priors"
                     data-authors="Melanie Mayer,Kimberly Lactaoen,Gary E. Weissman,Blanca E. Himes,Rebecca A. Hubbard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02102v1.html">Enhancing Phenotype Discovery in Electronic Health Records through Prior Knowledge-Guided Unsupervised Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Melanie Mayer, Kimberly Lactaoen, Gary E. Weissman et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Bayesian latent class framework that integrates clinical domain knowledge via informative priors to enhance phenotype discovery from electronic health record (EHR) data. Applied to a large asthma cohort, it successfully identified an "uncontrolled T2-high" sub-phenotype (38.7% of patients) characterized by elevated eosinophils, allergy markers, and surprisingly high healthcare utilization/medication use. This demonstrates the model's utility for hypothesis generation and cohort identification in heterogeneous diseases lacking clear phenotype definitions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Allergy & Immunology</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02102v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02102v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02102v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02102v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02090v1"
                     data-domains="physics.med-ph"
                     data-keywords="physics.med-ph"
                     data-authors="Yuhao Yan,Jordan Slagowski,Jessica Miller,John Hayes,Carson Hoffman,Minglei Kang,Carri Glide-Hurst">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02090v1.html">Characterizing the Reliability of a Novel Upright CT for Proton Therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhao Yan, Jordan Slagowski, Jessica Miller et al.
                </div>

                <div class="paper-summary">
                    Purpose: To evaluate reliability of upright CT for proton dose calculation
and feasibility of a simplified phantom configuration for accelerated routine
QA. Methods: A calibration phantom was scanned on an upright CT following
consensus guidelines for 14 sessions/7 months. CT number repeatability wa...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">physics.med-ph</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02090v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02090v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02090v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02090v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02088v1"
                     data-domains="Neurology,Neurovascular Surgery,Stroke Medicine,Computational Biology,Pharmaceutical Development"
                     data-keywords="In silico trials,acute ischemic stroke,recanalization,functional independence,modified Rankin Scale,computational modeling,therapy development,odds ratio"
                     data-authors="Claire M. Miller,Raymond Padmos,Praneeta Konduri,Tam√°s Istv√°n J√≥zsa,Yidan Xue,Nerea Arrarte Terreros,Max van der Kolk,Stephen Payne,Henk Marquering,Charles Majoie Alfons Hoekstra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02088v1.html">In silico trials of acute ischemic stroke: predicting the total potential for improvement to patient functional outcomes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Claire M. Miller, Raymond Padmos, Praneeta Konduri et al.
                </div>

                <div class="paper-summary">
                    This study utilized in silico trials (ISTs) to model acute ischemic stroke (AIS) outcomes, quantifying the potential benefit of improved recanalization outcomes and shorter treatment times. It predicted a significant increase in functional independence for patients with full recanalization and early treatment, highlighting recanalization as more beneficial than faster treatment. This work establishes a novel proof-of-concept for ISTs as a tool to evaluate the maximum potential for improvement to patient outcomes, useful in early therapy development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurovascular Surgery</span>
                    
                    <span class="domain-tag">Stroke Medicine</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Pharmaceutical Development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02088v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02088v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02088v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02088v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02086v1"
                     data-domains="Plastic and Reconstructive Surgery,Maxillofacial Surgery,Orthopedic Surgery,Otolaryngology (ENT)"
                     data-keywords="Augmented Reality,Surgical Guidance,Markerless Registration,HoloLens 2,Depth Sensing,Clinical Accuracy,Fibula Free-Flap,Mandibular Reconstruction"
                     data-authors="Yue Yang,Fabian Necker,Christoph Leuze,Michelle Chen,Andrey Finegersh,Jake Lee,Vasu Divi,Bruce Daniel,Brian Hargreaves,Jie Ying Wu,Fred M Baik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02086v1.html">Markerless Augmented Reality Registration for Surgical Guidance: A Multi-Anatomy Clinical Accuracy Study</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yue Yang, Fabian Necker, Christoph Leuze et al.
                </div>

                <div class="paper-summary">
                    This paper develops and clinically evaluates a novel depth-only, markerless augmented reality (AR) registration pipeline using a head-mounted display (HMD) for surgical guidance on small or low-curvature anatomies. The system achieved a median intraoperative registration error of approximately 3-4 mm across feet, ear, and lower leg, approaching typical clinical thresholds for moderate-risk surgical tasks without the need for fiducials.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Plastic and Reconstructive Surgery</span>
                    
                    <span class="domain-tag">Maxillofacial Surgery</span>
                    
                    <span class="domain-tag">Orthopedic Surgery</span>
                    
                    <span class="domain-tag">Otolaryngology (ENT)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02086v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02086v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02086v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02086v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02051v1"
                     data-domains="Radiology,Pathology,Dermatology,Ophthalmology,General Medical Diagnosis"
                     data-keywords="Quantum Neural Networks,Continuous-variable quantum computing,Biomedical Imaging,Medical Image Classification,Photonic circuits,MedMNIST,Computer-Aided Diagnosis,Gaussian gates"
                     data-authors="Daniel Alejandro Lopez,Oscar Montiel,Oscar Castillo,Miguel Lopez-Montiel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02051v1.html">Towards Continuous-variable Quantum Neural Networks for Biomedical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ quant-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Alejandro Lopez, Oscar Montiel, Oscar Castillo et al.
                </div>

                <div class="paper-summary">
                    This paper presents a feasibility study on continuous-variable quantum neural networks (CV-QCNNs) for biomedical image classification, leveraging photonic circuit simulations and Gaussian gates to emulate convolutional behavior. Evaluated on the MedMNIST dataset, the research highlights the potential of CV-QCNNs in terms of classification accuracy, model expressiveness, and resilience to noise, suggesting their viability for future computer-aided diagnosis systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">General Medical Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02051v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02051v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02051v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02051v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02047v1"
                     data-domains="Neurology,Orthopedics,Rehabilitation Medicine,Geriatrics"
                     data-keywords="Gait analysis,Wearable sensors,Deep learning,Attention mechanism,Dataset bias,Data auditing,Sensor optimization,Parkinson's disease,Osteoarthritis,Cerebrovascular accident"
                     data-authors="Hamidreza Sadeghsalehi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02047v1.html">A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hamidreza Sadeghsalehi
                </div>

                <div class="paper-summary">
                    This paper introduces a multi-stream attention-based deep learning framework for clinical gait analysis, functioning as both a sensor optimizer and an automated data auditor. Applied to a multi-cohort gait dataset, the framework's attention mechanism critically revealed a severe laterality bias in the data, assigning over 70% attention to the Right Foot for tasks requiring bilateral assessment due to underlying dataset confound, thereby demonstrating its ability to audit dataset integrity. It also proposes novel sensor synergies for future optimized protocols.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02047v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02047v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02047v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02047v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02014v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Tuan Truong,Guillermo Jimenez Perez,Pedro Osorio,Matthias Lenga">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02014v1.html">Towards Selection of Large Multimodal Models as Engines for Burned-in Protected Health Information Detection in Medical Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-03</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tuan Truong, Guillermo Jimenez Perez, Pedro Osorio et al.
                </div>

                <div class="paper-summary">
                    The detection of Protected Health Information (PHI) in medical imaging is
critical for safeguarding patient privacy and ensuring compliance with
regulatory frameworks. Traditional detection methodologies predominantly
utilize Optical Character Recognition (OCR) models in conjunction with named
entit...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02014v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02014v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02014v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02014v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-05 06:28:19</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>