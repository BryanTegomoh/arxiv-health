<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">46</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">151</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (16), Diagnostic Imaging (9), Oncology (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (16)</option>
                        
                        <option value="Oncology">Oncology (9)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (9)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (6)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (4)</option>
                        
                        <option value="Medical Physics">Medical Physics (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.26783v1"
                     data-domains="Epidemiology,Public Health,Clinical Trials (observational extensions),Pharmacovigilance,Health Outcomes Research,Comparative Effectiveness Research,Personalized Medicine"
                     data-keywords="Causal Inference,Average Treatment Effect,Riesz Regression,Density Ratio Estimation,Targeted Maximum Likelihood Estimation,Covariate Balancing,Matching Estimator,Debiased Machine Learning"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26783v1.html">A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper introduces a unified theory for causal inference, specifically focusing on Average Treatment Effect (ATE) estimation, by integrating various statistical methodologies such as Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and matching estimators. It highlights the critical role of balancing weights (also known as Riesz representers or clever covariates) and establishes key equivalences and dual relationships among these diverse techniques, providing a cohesive framework for causal inference.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Clinical Trials (observational extensions)</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Health Outcomes Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26783v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26783v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26783v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26783v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26759v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical AI,Oncology"
                     data-keywords="CT reconstruction,Deep learning,Medical imaging,Dataset,Generalization,Multi-organ,Image processing,Radiology"
                     data-authors="Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26759v1.html">MORE: Multi-Organ Medical Image REconstruction Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Multi-Organ Medical Image REconstruction (MORE) dataset, designed to overcome the limited generalization capabilities of current deep learning CT reconstruction methods. Comprising CT scans across 9 diverse anatomies and 15 lesion types, MORE enables robust model training and rigorous evaluation of generalization for deep learning-based CT reconstruction. The authors also establish a strong baseline solution that demonstrates improved generalization and highlights the robustness of optimization-based methods for unseen anatomies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26723v1"
                     data-domains="Precision Medicine,Clinical Decision Support Systems,Oncology,Chronic Disease Management,Personalized Therapeutics,Pharmacogenomics,Public Health Interventions"
                     data-keywords="policy learning,empirical welfare maximization,conditional average treatment effect,CATE,personalized medicine,causal inference,optimal treatment regimes,machine learning,regularization"
                     data-authors="Masahiro Kato">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26723v1.html">Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Masahiro Kato
                </div>

                <div class="paper-summary">
                    This paper unifies two major approaches in policy learning‚ÄîEmpirical Welfare Maximization (EWM) and the plug-in approach based on Conditional Average Treatment Effect (CATE) estimation‚Äîby demonstrating their exact equivalence as essentially the same optimization problem. This theoretical bridge leads to a novel, computationally efficient regularization method for training personalized treatment policies, circumventing the NP-hard steps typically associated with EWM.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Personalized Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26723v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26723v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26723v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26723v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26715v1"
                     data-domains="clinical diagnostics,precision medicine,oncology,neurology,metabolomics,proteomics,biomarker discovery,pharmacology"
                     data-keywords="mass spectrometry,deep learning,foundation model,spectral identification,biological interpretation,isomeric compounds,spectral embeddings,disease diagnostics,clinical outcomes,biomarkers"
                     data-authors="Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26715v1.html">LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Asher, Devesh Shah, Amy A. Caudy et al.
                </div>

                <div class="paper-summary">
                    LSM-MS2 introduces a novel large-scale deep learning foundation model trained on millions of mass spectrometry (MS) spectra to create a semantic chemical space. It achieves state-of-the-art performance in spectral identification, significantly improving accuracy for challenging compounds and increasing identifications in complex biological samples. Beyond identification, LSM-MS2 generates rich spectral embeddings that enable direct biological interpretation, facilitating differentiation of disease states and prediction of clinical outcomes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">clinical diagnostics</span>
                    
                    <span class="domain-tag">precision medicine</span>
                    
                    <span class="domain-tag">oncology</span>
                    
                    <span class="domain-tag">neurology</span>
                    
                    <span class="domain-tag">metabolomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26703v1"
                     data-domains="Urology,Oncology,Diagnostic Imaging,Medical Artificial Intelligence,Radiology"
                     data-keywords="prostate cancer,micro-ultrasound,medical foundation models,deep learning,prospective study,diagnostic systems,AI in medicine,image analysis"
                     data-authors="Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26703v1.html">ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paul F. R. Wilson, Mohamed Harmanani, Minh Nguyen Nhat To et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ProstNFound+, a novel adaptation of medical foundation models (FMs) for prostate cancer (PCa) detection using micro-ultrasound (ŒºUS). It presents the first prospective validation of such a system, demonstrating strong generalization and consistent high performance five years later in a new clinical setting, aligning closely with expert clinical protocols.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26703v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26703v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26703v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26703v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26700v1"
                     data-domains="Personalized Medicine,Treatment Effect Research,Epidemiology,Clinical Decision Support,Health Outcomes Research,Pharmacoepidemiology"
                     data-keywords="causal inference,machine learning,individualized treatment effects,conditional exchangeability,unmeasured confounding,negative control outcomes,simulation study,observational studies"
                     data-authors="Gerard T. Portela,Jason B. Gibbons,Sebastian Schneeweiss,Rishi J. Desai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26700v1.html">Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gerard T. Portela, Jason B. Gibbons, Sebastian Schneeweiss et al.
                </div>

                <div class="paper-summary">
                    This study evaluated the performance of causal machine learning models (causal forest, X-learner) for individualized treatment effect (ITE) prediction under violations of the conditional exchangeability assumption, revealing their failure to accurately estimate ITEs and sometimes falsely indicating heterogeneity. It demonstrated the utility of negative control outcomes (NCOs) as a crucial empirical diagnostic tool for detecting subgroup-specific unmeasured confounding, even when NCO ideal assumptions are not perfectly met.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Treatment Effect Research</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Health Outcomes Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26700v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26700v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26700v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26700v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26685v1"
                     data-domains="Oncology,Immunology,Vaccinology,Bioinformatics,Health Economics,Regulatory Science"
                     data-keywords="AI-to-clinical translation,neoantigen vaccines,Algorithm-to-Outcome Concordance (AOC),personalized medicine,cancer immunotherapy,AUC,HR/ORR,health economics"
                     data-authors="Xiyao Yu,Kai Fu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26685v1.html">A Proposed Framework for Quantifying AI-to-Clinical Translation: The Algorithm-to-Outcome Concordance (AOC) Metric</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiyao Yu, Kai Fu
                </div>

                <div class="paper-summary">
                    This paper proposes the Algorithm-to-Outcome Concordance (AOC) metric, a quantitative framework to assess the translational fidelity between AI-based neoantigen prediction models and clinical outcomes in personalized cancer vaccines. Using simulated data from melanoma vaccine trials, the study found heterogeneous AOC values (0.42-0.79) and correlations with tumor mutational burden, suggesting that an AOC > 0.7 could significantly improve cost-effectiveness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26685v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26685v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26685v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26685v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26683v1"
                     data-domains="Medical Question Answering,Clinical Decision Support,Healthcare Informatics,Medical Knowledge Management"
                     data-keywords="Large Language Models,Ontology Rules,Domain Adaptation,Self-Evolution,Medical QA,Knowledge Extraction,Fine-tuning,Low-Resource Learning"
                     data-authors="Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26683v1.html">Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingchen Tu, Zhiqiang Liu, Juan Li et al.
                </div>

                <div class="paper-summary">
                    Evontree is a novel framework that enables Large Language Models (LLMs) to adapt to data-sensitive domains like healthcare by leveraging a small set of high-quality ontology rules. It systematically extracts, validates, and enhances domain knowledge within LLMs without extensive external datasets, addressing inconsistencies through self-distilled fine-tuning. This approach significantly outperforms existing baselines, achieving up to a 3.7% accuracy improvement on medical QA benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Question Answering</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                    <span class="domain-tag">Medical Knowledge Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26683v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26683v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26668v1"
                     data-domains="Diagnostic Imaging,Cardiology,Neurology,Vascular Medicine,AI in Medicine"
                     data-keywords="Zoeppritz equations,medical ultrasound,reflection coefficients,angle of incidence (AVA),tissue characterization,atherosclerosis,cerebrovascular accidents,artificial intelligence,subwavelength resolution"
                     data-authors="Harry G. Saavedra,Ramiro Moro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26668v1.html">Zoeppritz equations: from seismology to medical exploration</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Harry G. Saavedra, Ramiro Moro
                </div>

                <div class="paper-summary">
                    This paper proposes applying the full Zoeppritz equations, originally from seismology, to medical ultrasound for extracting richer information about tissue properties. It demonstrates that analyzing angle-dependent reflection coefficients (AVA), critical angles, and waveform distortion can separate density from speed of sound mismatch and determine subwavelength thickness of intermediate layers. This advanced physics-based approach promises enhanced medical imaging and AI-assisted diagnosis, particularly for early detection of arterial plaque to prevent cerebrovascular accidents.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Vascular Medicine</span>
                    
                    <span class="domain-tag">AI in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26668v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26668v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26668v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26668v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26635v1"
                     data-domains="Radiology,Oncology,Neurology,Cardiology,Gastroenterology,Urology,Orthopedics"
                     data-keywords="MRI segmentation,Segment Anything Model (SAM),Deep Learning,Medical Imaging,Generalization,Fine-tuning,Artificial Intelligence,Radiomics,Computer Vision"
                     data-authors="Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26635v1.html">SAMRI: Segment Anything Model for MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhao Wang, Wei Dai, Thuy Thanh Dao et al.
                </div>

                <div class="paper-summary">
                    SAMRI addresses the challenge of accurate and generalizable MRI segmentation, which is often hindered by MRI's inherent variability and the limitations of existing CNN and general SAM approaches. By specializing the Segment Anything Model (SAM) for MRI through a targeted two-stage fine-tuning of its mask decoder on a large dataset of 1.1 million MR slices, SAMRI achieves state-of-the-art accuracy (mean Dice of 0.87) and robust generalization across diverse, including unseen, anatomical and pathological structures, while significantly reducing training resource requirements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26582v1"
                     data-domains="Medical Imaging,Radiology"
                     data-keywords="Visual Question Answering,Domain Adaptation,Medical Imaging,Large Language Models,Plug-and-Play,Cross-domain,Deep Learning,VQA"
                     data-authors="Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26582v1.html">CATCH: A Modular Cross-domain Adaptive Template with Hook</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinjin Li, Yulie Lu, Jinghan Cao et al.
                </div>

                <div class="paper-summary">
                    CATCH addresses the significant performance degradation of Visual Question Answering (VQA) models, like LLaVA, when transferred to out-of-domain scenarios such as medical imaging. It introduces a plug-and-play framework that decouples visual and linguistic adaptation via a domain classifier and a dual adapter mechanism (Prompt and Visual Adapters) dynamically injected without backbone retraining. This approach achieves consistent performance gains across diverse VQA benchmarks, including a notable +2.6 VQA score on MedVQA-RAD.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26568v1"
                     data-domains="Orthopedics,Pediatric Orthopedics,Radiology,Diagnostic Imaging,Medical Image Analysis"
                     data-keywords="Spine segmentation,Ultrasound VPI,Scoliosis diagnosis,Deep learning,Scale-adaptive,Structure-affinity transformation,Transformer,Medical image analysis,Computer-aided diagnosis"
                     data-authors="Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26568v1.html">SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hao Xie, Zixun Huang, Yushen Zuo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SA¬≤Net, a novel scale-adaptive structure-aware network, for precise spine segmentation from ultrasound volume projection imaging (VPI). The method addresses key challenges in learning global contextual knowledge and encoding rich structural information of spinal bones, achieving superior performance for intelligent scoliosis diagnosis. By integrating a scale-adaptive complementary strategy and a Transformer-based structure-affinity transformation, SA¬≤Net significantly enhances segmentation accuracy and robustness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Pediatric Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26568v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26568v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26568v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26568v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26566v1"
                     data-domains="Clinical Decision Support,Diagnostic Imaging,Predictive Analytics,Precision Medicine,Rare Disease Diagnosis,Risk Stratification"
                     data-keywords="Machine Learning,Calibration,Multiclass Classification,Local Calibration,Proximity Bias,Jensen-Shannon Distance,Neural Networks,Healthcare AI"
                     data-authors="Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26566v1.html">Multiclass Local Calibration With the Jensen-Shannon Distance</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cesare Barbera, Lorenzo Perini, Giovanni De Toni et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical problem of proximity bias in multiclass calibration, where machine learning models miscalibrate predictions in sparse regions of the feature space, particularly problematic in high-stakes areas like healthcare. The authors introduce and formally define "multiclass local calibration," propose a novel method for Neural Networks that leverages the Jensen-Shannon distance to align predicted probabilities with local class frequency estimates, and empirically demonstrate its superiority over existing calibration techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Rare Disease Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26563v1"
                     data-domains="Radiation Oncology,Medical Physics,Gynecological Oncology,Head-and-Neck Oncology,Cancer Treatment"
                     data-keywords="VMAT,Fraction-variant,Radiotherapy,Dose Optimization,Gynecological Cancer,Head-and-Neck Cancer,Direct Aperture Optimization,Treatment Efficiency"
                     data-authors="Nathan Torelli,Madalyne Day,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26563v1.html">Fraction-variant VMAT planning for patients with complex gynecological and head-and-neck cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Madalyne Day, Jan Unkelbach
                </div>

                <div class="paper-summary">
                    This paper introduces a novel "fraction-variant" volumetric modulated arc therapy (VMAT) planning strategy, where different VMAT plans are delivered across individual treatment fractions. Evaluated in-silico for complex gynecological and head-and-neck cancers, this approach significantly improved dosimetric quality (target coverage, OAR sparing) and reduced treatment delivery times compared to traditional fraction-invariant VMAT. It demonstrates that superior dose distribution can be achieved without increasing the per-fraction delivery time.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Gynecological Oncology</span>
                    
                    <span class="domain-tag">Head-and-Neck Oncology</span>
                    
                    <span class="domain-tag">Cancer Treatment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26525v1"
                     data-domains="Regenerative Medicine,Drug Delivery Systems,Medical Device Development,Diagnostics,Personalized Medicine,Biopharmaceutical Production,Tissue Engineering"
                     data-keywords="Biological Engineering,Bioinspired,Biohybrid,Artificial Intelligence,Data-driven Design,Healthcare,Synthetic Biology,Regenerative Medicine"
                     data-authors="Ulrike A. Nuber,Viktor Stein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26525v1.html">Biological Engineering: What does it mean? Where does it -- need to -- go?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ulrike A. Nuber, Viktor Stein
                </div>

                <div class="paper-summary">
                    This paper provides a comprehensive analysis of biological engineering, an interdisciplinary field merging engineering and biology, highlighting its critical role in healthcare, agriculture, and environmental sustainability. The authors structure the domain into bioinspired, biological, and biohybrid approaches, addressing fundamental challenges like the absence of reductionist models and proposing data-driven discovery and artificial intelligence as key mitigators and future directions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Regenerative Medicine</span>
                    
                    <span class="domain-tag">Drug Delivery Systems</span>
                    
                    <span class="domain-tag">Medical Device Development</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26501v1"
                     data-domains="Cardiology,Preventive Medicine,Digital Health,Remote Patient Monitoring"
                     data-keywords="ECG,Unsupervised Anomaly Detection,Out-of-Distribution,Wearables,Deep Learning,Cardiovascular Disease,Deep SVDD,Neural Architecture Search"
                     data-authors="Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26501v1.html">Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mustafa Fuad Rifet Ibrahim, Maurice Meijer, Alexander Schlaefer et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical reliability challenge of Out-of-Distribution (OOD) data in deep learning-based ECG analysis for resource-constrained wearable devices, which can lead to erroneous high-confidence predictions and compromise patient safety. The authors propose and evaluate Unsupervised Anomaly Detection (UAD) as an independent, upstream filtering mechanism to improve robustness. Their optimized Deep SVDD filter, when integrated into a diagnostic pipeline, significantly enhanced classifier accuracy and enabled safer, more reliable continuous cardiovascular monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26501v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26501v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26501v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26501v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26498v1"
                     data-domains="Radiology,Neurology,Medical Informatics,Artificial Intelligence in Medicine"
                     data-keywords="Large Language Models,LLM ensemble,Clinical AI,AI triage,Intracranial Hemorrhage,CT head,Radiology,Performance assessment,Ground truth,Medical informatics"
                     data-authors="Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26498v1.html">A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Adam E. Flanders, Yifan Peng, Luciano Prevedello et al.
                </div>

                <div class="paper-summary">
                    This study demonstrates that an ensemble of multiple Large Language Model (LLM) agents can reliably and consistently assess the performance of a clinical AI triage tool, specifically an intracranial hemorrhage (ICH) detection tool. The research found that LLM ensembles provided a more robust retrospective evaluation and ground truth generation method compared to using a single LLM, leveraging radiology reports from a large cohort of head CT exams.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26444v1"
                     data-domains="Chronic Obstructive Pulmonary Disease (COPD),Precision Medicine,Rare Diseases,Patient Stratification"
                     data-keywords="personalized medicine,treatment outcome prediction,knowledge distillation,scarce data,chronic obstructive pulmonary disease,precision medicine,deep learning,attention mechanisms"
                     data-authors="Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26444v1.html">Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenjie Chen, Li Zhuang, Ziying Luo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Cross-Fidelity Knowledge Distillation and Adaptive Fusion Network (CFKD-AFN) to overcome data scarcity in personalized treatment outcome prediction for rare patient groups. CFKD-AFN enhances predictions by effectively combining abundant low-fidelity simulation data with scarce high-fidelity trial data, achieving significant accuracy improvements and robustness, particularly for Chronic Obstructive Pulmonary Disease (COPD).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Chronic Obstructive Pulmonary Disease (COPD)</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Patient Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26444v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26444v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26444v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26444v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26411v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Medicine,Chest Radiography"
                     data-keywords="mechanistic interpretability,sparse autoencoders,MedCLIP,vision-language models,chest radiographs,AI in healthcare,neuron monosemanticity,CheXpert"
                     data-authors="Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26411v1.html">MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riccardo Renzulli, Colas Lepoutre, Enrico Cassano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Medical Sparse Autoencoders (MedSAEs) to enhance the interpretability of MedCLIP, a vision-language model trained on chest radiographs. By applying MedSAEs to MedCLIP's latent space, the study demonstrates that the resulting MedSAE neurons achieve significantly higher monosemanticity and interpretability compared to raw MedCLIP features, evaluated on the CheXpert dataset.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Chest Radiography</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26411v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26411v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26411v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26411v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26390v1"
                     data-domains="Radiology,Oncology,Surgery,Diagnostic Imaging,Anatomy"
                     data-keywords="Multi-organ segmentation,Deep learning,Spatial prior,Dual encoder network,Cross-attention,Medical image analysis,Computer-aided diagnosis,Semantic segmentation"
                     data-authors="Xizhi Tian,Changjun Zhou,Yulin. Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26390v1.html">SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xizhi Tian, Changjun Zhou, Yulin. Yang
                </div>

                <div class="paper-summary">
                    SPG-CDENet introduces a novel two-stage deep learning framework for accurate multi-organ segmentation, specifically addressing challenges posed by variations in organ size and shape. It leverages a spatial prior network to guide a cross dual encoder network that processes global and local features, integrated with a symmetric cross-attention mechanism and a flow-based decoder for maximal feature preservation. The method demonstrates superior performance on public datasets, validating its effectiveness for critical computer-aided diagnostic tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26390v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26390v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26390v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26390v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26388v1"
                     data-domains="Medical Imaging,Nuclear Medicine,Neurology,Diagnostic Radiology,Medical Physics"
                     data-keywords="PET scanner,head movement,motion correction,22Na,44Sc,positron emission tomography,brain imaging,image quality,medical physics"
                     data-authors="Machiel Kolstein,Mokhtar Chmeissani,Andreu Pacheco">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26388v1.html">Monitoring Head Movement in a Brain PET Scanner</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Machiel Kolstein, Mokhtar Chmeissani, Andreu Pacheco
                </div>

                <div class="paper-summary">
                    This paper introduces a simulated head monitoring device, CrowN@22, designed for brain PET scanners to counteract motion artifacts during long acquisitions. By utilizing point sources of non-pure positron emitters like 22Na and detecting their unique accompanying gamma photons, the device achieves exceptional signal-to-noise ratio. The simulation demonstrates highly precise head movement detection, less than 0.5 mm or 0.3 degrees, at a 1 Hz sampling rate, even in the presence of high brain FDG activity, significantly improving PET image quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26388v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26388v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26388v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26388v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26350v1"
                     data-domains="Radiology,Pathology,Medical Image Analysis,Neuroimaging (hippocampus segmentation)"
                     data-keywords="Federated Learning,Architectural Heterogeneity,Statistical Heterogeneity,Graph Neural Networks,Medical Imaging,Privacy-Preserving AI,Radiology,Pathology"
                     data-authors="Furkan Pala,Islem Rekik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26350v1.html">UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Furkan Pala, Islem Rekik
                </div>

                <div class="paper-summary">
                    UnifiedFL is a novel federated learning framework designed to overcome significant challenges in collaborative model training, namely architectural heterogeneity (clients using fundamentally different network types) and the 'domain-fracture problem' where test data distributions differ markedly from training data. It achieves this by representing diverse local networks within a directed model graph, parameterized by a shared Graph Neural Network (GNN), and employing a unique clustering and two-tier aggregation policy. Experiments on MedMNIST classification and hippocampus segmentation benchmarks demonstrate its superior performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Neuroimaging (hippocampus segmentation)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26350v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26350v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26350v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26350v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26342v1"
                     data-domains="Systems Biology,Drug Discovery,Disease Mechanism Elucidation,Pharmacogenomics,Personalized Medicine"
                     data-keywords="Causal Discovery,Interventional Constraints,Total Causal Effects,Linear Causal Models,Constrained Optimization,Biological Networks,Systems Biology,Treatment Design"
                     data-authors="Zhigao Guo,Feng Dong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26342v1.html">Linear Causal Discovery with Interventional Constraints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhigao Guo, Feng Dong
                </div>

                <div class="paper-summary">
                    This paper introduces "interventional constraints," a novel concept in causal discovery that integrates high-level causal knowledge as inequality constraints on total causal effects between variables. Unlike existing methods that enforce structural paths, this approach ensures learned linear causal models accurately reflect known directions and magnitudes of influence, preventing incorrect conclusions (e.g., PIP3 activating Akt vs. inhibiting Akt). This integration demonstrably improves model accuracy, enhances explainability, and facilitates the discovery of new, otherwise costly, causal relationships in real-world biological networks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Disease Mechanism Elucidation</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26342v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26342v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26342v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26342v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26339v1"
                     data-domains="Medical Imaging (Radiology, Pathology, Ophthalmology),Digital Pathology,Electronic Health Records (EHR) Management,Medical Device Monitoring and Analytics,Laboratory Information Systems (LIS),Telemedicine and Remote Diagnostics"
                     data-keywords="Super-Resolution,Scene-Text,Text Recovery,Vision-Language Model,Latent Diffusion,Optical Character Recognition (OCR),Medical Imaging,Document Analysis,Image Enhancement"
                     data-authors="Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26339v1.html">GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingyu Sung, Seungjae Ham, Kangwoo Kim et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GLYPH-SR, a novel vision-language-guided latent diffusion framework designed to address the critical limitation of existing image super-resolution (SR) methods in accurately recovering scene-text while maintaining overall image quality. By integrating an OCR-guided Text-SR Fusion ControlNet and a dynamic ping-pong scheduler, GLYPH-SR significantly improves text legibility, achieving up to a +15.18 percentage point increase in OCR F1 scores, without compromising visual realism.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging (Radiology, Pathology, Ophthalmology)</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Management</span>
                    
                    <span class="domain-tag">Medical Device Monitoring and Analytics</span>
                    
                    <span class="domain-tag">Laboratory Information Systems (LIS)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26339v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26339v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26339v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26339v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26315v1"
                     data-domains="Ophthalmology,Diabetology,Medical Imaging Diagnostics"
                     data-keywords="Diabetic Retinopathy,CNN,ViT,Hybrid Model,Theory of Evidence,Feature Fusion,Medical Imaging,Automated Diagnosis"
                     data-authors="Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26315v1.html">A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel hybrid framework combining Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for more accurate and interpretable Diabetic Retinopathy (DR) grading. It addresses the limitations of single-backbone systems by employing an evidential fusion paradigm, based on the theory of evidence, to adaptively integrate their complementary local and global features. The method demonstrates improved DR grading accuracy over state-of-the-art techniques and offers excellent interpretability on publicly available datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26315v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26315v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26272v1"
                     data-domains="Radiation Oncology,Medical Physics,Thoracic Oncology,Pulmonology"
                     data-keywords="Reirradiation,Non-coplanar,NSCLC,EQD2,OAR sparing,Beam orientation optimization,VMAT,Direct aperture optimization"
                     data-authors="Nathan Torelli,Jonas Willmann,Katja Daehler,Madalyne Day,Nicolaus Andratschke,Jan Unkelbach">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26272v1.html">Simultaneous optimization of non-coplanar beam orientations and cumulative EQD2 distribution for high-dose reirradiation of locoregionally recurrent non-small cell lung cancer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Torelli, Jonas Willmann, Katja Daehler et al.
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a novel non-coplanar beam orientation optimization algorithm for high-dose reirradiation of locoregionally recurrent non-small cell lung cancer (NSCLC). The approach demonstrated the ability to reduce maximum cumulative equivalent dose in 2 Gy fractions (EQD2) to critical organs-at-risk (OARs) by at least 5 Gy2 in a significant subset of challenging cases, while maintaining comparable target coverage to standard coplanar techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Thoracic Oncology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26272v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26272v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26272v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26272v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26188v1"
                     data-domains="Health Informatics,Healthcare Management,Clinical Quality Improvement,Predictive Analytics in Medicine,Public Health"
                     data-keywords="Hospital Readmissions,Machine Learning,Medical Claims Data,Principal Component Analysis,Random Forest,Logistic Regression,Support Vector Machines,AUC"
                     data-authors="Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26188v1.html">Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Avinash Kadimisetty, Arun Rajagopalan, Vijendra SK
                </div>

                <div class="paper-summary">
                    This research paper developed and evaluated machine learning models (Logistic Regression, Random Forest, Support Vector Machines) to predict all-cause hospital readmissions using high-dimensional medical claims data. Principal Component Analysis was employed for dimension reduction, and models were compared using the Area Under Curve (AUC) metric. The Random Forest model achieved the highest predictive performance, offering a valuable tool for identifying at-risk patients and improving healthcare quality while reducing costs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Healthcare Management</span>
                    
                    <span class="domain-tag">Clinical Quality Improvement</span>
                    
                    <span class="domain-tag">Predictive Analytics in Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26188v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26188v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26188v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26188v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26151v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging,Preventive Medicine"
                     data-keywords="Breast Cancer,Mammography,Vision-Language Model (VLM),Multi-View Learning,Self-Supervision,Risk Prediction,Computer-Aided Diagnosis (CAD),Synthetic Reports"
                     data-authors="Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26151v1.html">MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shunjie-Fabian Zheng, Hyeonjun Lee, Thijs Kooi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MV-MLM, a novel Multi-View Mammography and Language Model designed for breast cancer diagnosis and risk prediction. MV-MLM leverages multi-view supervision and cross-modal self-supervision using paired mammograms and synthetic radiology reports, achieving state-of-the-art performance in malignancy, subtype, and risk classification tasks with strong data efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26151v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26151v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26151v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26151v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26148v1"
                     data-domains="Geriatric Care,Remote Patient Monitoring,Fall Detection,Rehabilitation Monitoring,Smart Hospitals,Assisted Living"
                     data-keywords="Wi-Fi CSI,Human Activity Recognition,Edge AI,Privacy-Preserving,Energy-Efficient,GRU,NPU,Healthcare Monitoring"
                     data-authors="Kexing Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26148v1.html">STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kexing Liu
                </div>

                <div class="paper-summary">
                    This paper introduces STAR, an edge-AI optimized framework for real-time, energy-efficient, and privacy-preserving Human Activity Recognition (HAR) using Wi-Fi Channel State Information (CSI) in mobile and pervasive computing environments. It achieves high recognition accuracy (93.52% for activities, 99.11% for presence) on low-power embedded devices through a lightweight GRU-based neural network, advanced signal processing, and NPU-accelerated inference. This framework offers a practical and scalable solution for applications like healthcare monitoring, overcoming the computational limitations of existing methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Geriatric Care</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Fall Detection</span>
                    
                    <span class="domain-tag">Rehabilitation Monitoring</span>
                    
                    <span class="domain-tag">Smart Hospitals</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26148v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26148v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26148v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26148v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26083v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Clinical Decision Support"
                     data-keywords="Specialized Generalist Models,Task-Aware Memory,Magnetic Resonance Imaging,Deep Learning,LLM,Medical Imaging,Clinical Reporting,Self-supervised Learning"
                     data-authors="Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26083v1.html">Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhua Jiang, Shuang Cheng, Yihao Liu et al.
                </div>

                <div class="paper-summary">
                    Nirvana is a novel Specialized Generalist Model (SGM) that integrates a unique task-aware memory mechanism, including a Task-Aware Memory Trigger and a Specialized Memory Updater, designed to maintain broad capabilities while achieving expert-level performance. It demonstrates competitive or superior results on general language tasks and achieves higher-quality MRI reconstruction and accurate preliminary clinical report generation on challenging medical imaging tasks, even when operating with a frozen backbone.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26083v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26083v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26083v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26083v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26049v1"
                     data-domains="Pediatrics,Orthopedics,Radiology,Emergency Medicine,Musculoskeletal Ultrasound"
                     data-keywords="In-Context Learning,Ultrasound Segmentation,Deep Learning,Pediatric Fractures,Musculoskeletal Imaging,Data Efficiency,Medical Imaging,Semantic Segmentation"
                     data-authors="Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26049v1.html">FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuyue Zhou, Jessica Knight, Shrimanti Ghosh et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FlexICL, a novel and flexible in-context learning (ICL) framework designed for efficient segmentation of bony regions in elbow and wrist ultrasound (US) images, particularly in pediatric populations. FlexICL addresses the challenge of scarce expert annotations by enabling intra-video segmentation with only a small subset of annotated frames, demonstrating significantly enhanced performance and data efficiency compared to existing models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Musculoskeletal Ultrasound</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26049v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26049v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26049v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26049v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26032v1"
                     data-domains="Endocrinology,Radiology,Oncology,Internal Medicine,Pathology,Public Health"
                     data-keywords="Incidental thyroid finding,Natural language processing,Radiology reports,Thyroid cancer,Overdiagnosis,Diagnostic cascade,Epidemiology,Artificial intelligence"
                     data-authors="Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26032v1.html">Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-30</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Felipe Larios, Mariana Borras-Osorio, Yuqi Wu et al.
                </div>

                <div class="paper-summary">
                    This study developed and deployed a transformer-based Natural Language Processing (NLP) pipeline to analyze radiology reports for Incidental Thyroid Findings (ITFs). It found that ITFs are common (7.8% of patients) and significantly associated with a cascade of downstream procedures and the diagnosis of mostly small, low-risk papillary thyroid cancers, highlighting a substantial role in overdiagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26032v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26032v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26032v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26032v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26014v1"
                     data-domains="Oncology,Clinical research,Biomedical research,Prognostics"
                     data-keywords="Survival analysis,Discrete-time,Mixture-of-Experts (MoE),Patient heterogeneity,Temporal dynamics,Deep learning,Breast cancer,C-index"
                     data-authors="Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26014v1.html">Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hyeonjun Lee, Hyungseob Shin, Gunhee Nam et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel dual Mixture-of-Experts (MoE) framework designed for discrete-time survival analysis, aiming to better model patient heterogeneity and temporal dynamics. The framework integrates a feature-encoder MoE for subgroup-aware representation learning with a hazard MoE that uses patient features and time embeddings to capture dynamic risks. Evaluated on METABRIC and GBSG breast cancer datasets, the method consistently improved the time-dependent C-index by up to 0.04 and showed further gains when combined with the Consurv framework.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Clinical research</span>
                    
                    <span class="domain-tag">Biomedical research</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26014v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26014v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26014v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26014v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.26004v1"
                     data-domains="emergency medicine,trauma care,public health (injury prevention),paramedicine/EMS"
                     data-keywords="traffic incident detection,drones,artificial intelligence,deep learning,real-time,thermal imaging,emergency response,transportation management"
                     data-authors="Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.26004v1.html">DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.RO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bai Li, Achilleas Kourtellis, Rong Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DARTS, a drone-based, AI-powered real-time traffic incident detection system designed to overcome the limitations of conventional methods. DARTS integrates drones for adaptive aerial surveillance, thermal imaging for robust low-visibility performance and privacy, and a lightweight deep learning framework for accurate incident detection and vehicle trajectory extraction. It achieved 99% detection accuracy and demonstrated the ability to detect and verify incidents significantly faster than existing systems, supporting quicker emergency response and proactive traffic control.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">emergency medicine</span>
                    
                    <span class="domain-tag">trauma care</span>
                    
                    <span class="domain-tag">public health (injury prevention)</span>
                    
                    <span class="domain-tag">paramedicine/EMS</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.26004v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.26004v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.26004v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.26004v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25998v1"
                     data-domains="Neurology,Neuroscience,Intensive Care Medicine,Anesthesiology,Psychiatry,Developmental Pediatrics,Bioethics"
                     data-keywords="Integrated Information Theory,Consciousness,Phenomenal Experience,Cause-Effect Structure,Qualia,Disorders of Consciousness,Consciousness Assessment,Intrinsic Existence"
                     data-authors="Giulio Tononi,Melanie Boly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25998v1.html">Integrated Information Theory: A Consciousness-First Approach to What Exists</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Giulio Tononi, Melanie Boly
                </div>

                <div class="paper-summary">
                    Integrated Information Theory (IIT) proposes a 'consciousness-first' approach, asserting that the essential properties of phenomenal experience (axioms of phenomenal existence) can be formulated operationally to define physical existence. The theory claims that an entity's intrinsic cause-effect structure, characterized by specific, unitary, definite, and structured self-causation, accounts for all properties of experience, from qualia to spatio-temporal feelings, without additional components. This framework offers a principled method for assessing consciousness in patients, infants, other species, and artificial intelligences.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Anesthesiology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25998v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25998v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25998v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25998v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25962v1"
                     data-domains="Medical Imaging,Image Reconstruction,Radiology,Rare Diseases,Personalized Medicine,Computational Biology"
                     data-keywords="Dataless Training,Neural Networks,Optimization,Re-parameterization,Medical Image Reconstruction,Data Scarcity,Zero-shot Learning,Combinatorial Optimization"
                     data-authors="Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25962v1.html">On the Dataless Training of Neural Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvaro Velasquez, Susmit Jha, Ismail R. Alkhouri
                </div>

                <div class="paper-summary">
                    This paper provides a comprehensive survey of dataless training methods for neural networks (NNs) applied to optimization problems, a paradigm where NNs re-parameterize problems without needing external training data. It categorizes existing approaches into architecture-agnostic and architecture-specific methods and highlights the critical motivations for this setting, particularly the scarcity of training data in scientific and medical applications like image reconstruction, and the limitations of traditional data-driven learning in certain optimization domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Image Reconstruction</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25962v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25962v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25962v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25962v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25954v1"
                     data-domains="Public Health,Epidemiology,Global Health,Health Informatics,Infectious Diseases (HIV, TB),Maternal and Child Health"
                     data-keywords="Geospatial Foundation Models,LMICs,health data prediction,Malawi,XGBoost,public health surveillance,HIV,child vaccinations,Call Detail Records"
                     data-authors="Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25954v1.html">Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lynn Metz, Rachel Haggard, Michael Moszczynski et al.
                </div>

                <div class="paper-summary">
                    This study evaluates the utility of Geospatial Foundation Model (GeoFM) embeddings, derived from sources like Google Population Dynamics and mobile Call Detail Records, for predicting 15 routine health programmatic outputs in Malawi. The research demonstrates that GeoFM-based XGBoost models, particularly a Multi-GeoFM approach, significantly improve predictive performance over traditional geostatistical methods for most indicators, offering a valuable tool to enhance constrained health information systems in Low and Middle-Income Countries (LMICs).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Infectious Diseases (HIV, TB)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25954v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25954v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25954v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25954v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25944v1"
                     data-domains="Radiation Oncology,Urology,Medical Education,Medical Physics,Surgical Training"
                     data-keywords="Virtual Reality,HDR Brachytherapy,Prostate Cancer,Medical Education,Simulator,Oncology Training,Confidence,Radiation Oncology"
                     data-authors="Anton Varlukhin,Mackenzie Smith,Fahad Alam,Amandeep Tagger,Gerard Morton,Moti Paudel,Andrew Loblaw,Lucas Mendez,Douglas Hoover,Raffi Karshafian,Humza Nusrat">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25944v1.html">Development and pilot evaluation of a virtual reality simulator for HDR prostate brachytherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anton Varlukhin, Mackenzie Smith, Fahad Alam et al.
                </div>

                <div class="paper-summary">
                    This paper details the development and pilot evaluation of a virtual reality (VR) simulator designed for high dose rate (HDR) prostate brachytherapy. The study demonstrates that participation in two VR modules‚Äîpatient preparation and template guided needle insertion‚Äîis associated with immediate, statistically significant gains in self-reported confidence among oncology staff and trainees across key procedural domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Surgical Training</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25944v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25944v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25944v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25944v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25924v1"
                     data-domains="Epidemiology,Pharmacology,Personalized medicine,Public health,Clinical trials,Health outcomes research,Precision medicine"
                     data-keywords="Causal inference,Unobserved confounders,Proxy variables,Multi-domain learning,Identifiability,Treatment effects,Statistical estimation,Machine learning"
                     data-authors="Manuel Iglesias-Alonso,Felix Schur,Julius von K√ºgelgen,Jonas Peters">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25924v1.html">Transferring Causal Effects using Proxies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manuel Iglesias-Alonso, Felix Schur, Julius von K√ºgelgen et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the problem of estimating causal effects in multi-domain settings where an unobserved confounder exists and the effect may vary across domains. It proposes a novel methodology that leverages an observable proxy for the hidden confounder, demonstrating identifiability of the causal effect and introducing two consistent estimation techniques with derived confidence intervals.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25924v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25924v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25924v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25924v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25908v1"
                     data-domains="Drug Discovery,Clinical Research,Public Health,Biodefense,Biosecurity,Toxicology,Medical Ethics"
                     data-keywords="Large Language Models (LLMs),Trustworthiness,Scientific Applications,AI Safety,AI Ethics,Biosecurity,Adversarial Robustness,Truthfulness"
                     data-authors="Emily Herron,Junqi Yin,Feiyi Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25908v1.html">SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Emily Herron, Junqi Yin, Feiyi Wang
                </div>

                <div class="paper-summary">
                    This paper introduces SciTrust 2.0, a comprehensive framework for evaluating the trustworthiness of Large Language Models (LLMs) in scientific applications across four dimensions: truthfulness, adversarial robustness, scientific safety, and scientific ethics. The evaluation of seven prominent LLMs revealed that general-purpose industry models generally outperformed science-specialized models, with the latter demonstrating significant deficiencies, particularly concerning safety in high-risk areas like biosecurity and chemical weapons.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biodefense</span>
                    
                    <span class="domain-tag">Biosecurity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25908v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25908v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25908v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25908v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25867v1"
                     data-domains="Radiology,Pathology,Medical Imaging,Anatomy,Clinical Diagnosis,Medical Education"
                     data-keywords="Large Multimodal Models,Medical VQA,Data Synthesis,Generator-Verifier,Reinforcement Learning,PubMed Central,Imaging Modalities,Clinical Validity"
                     data-authors="Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25867v1.html">MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoke Huang, Ningsen Wang, Hui Liu et al.
                </div>

                <div class="paper-summary">
                    MedVLSynther is a novel rubric-guided generator-verifier framework designed to synthesize high-quality multiple-choice Visual Question Answering (VQA) data for the medical domain from open biomedical literature. This addresses the critical lack of large, openly usable, high-quality medical VQA corpora, significantly improving the performance of open-weight Large Multimodal Models (LMMs) on various medical VQA benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Clinical Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25867v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25867v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25867v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25867v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25759v1"
                     data-domains="Radiology,Pathology,Diagnostic Imaging,Medical Image Analysis,Digital Pathology"
                     data-keywords="Multiple Instance Learning,Correlated MIL,Generalization Gap,Synthetic Data,Medical Imaging,Contextual Learning,Bayes Estimator,Computational Pathology"
                     data-authors="Ethan Harvey,Dennis Johan Loevlie,Michael C. Hughes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25759v1.html">Synthetic Data Reveals Generalization Gaps in Correlated Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ethan Harvey, Dennis Johan Loevlie, Michael C. Hughes
                </div>

                <div class="paper-summary">
                    This research paper identifies a significant generalization gap in Multiple Instance Learning (MIL) methods, particularly when contextual relationships between instances are crucial for classification, as often occurs in medical imaging. By designing a synthetic task where adjacent instance features are essential for accurate prediction and comparing MIL performance against an optimal Bayes estimator, the authors demonstrate that both conventional and newer correlated MIL approaches struggle to achieve optimal generalization, even with substantial training data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25758v1"
                     data-domains="Clinical Psychology,Psychiatry,Mental Health,Digital Therapeutics,AI in Healthcare"
                     data-keywords="Large Language Models,Psychological Counseling,AI Agents,Longitudinal Therapy,Adaptive Strategies,Emotional Understanding,Mental Health,Dual-Loop Architecture"
                     data-authors="He Hu,Yucheng Zhou,Chiyuan Ma,Qianning Wang,Zheng Zhang,Fei Ma,Laizhong Cui,Qi Tian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25758v1.html">TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> He Hu, Yucheng Zhou, Chiyuan Ma et al.
                </div>

                <div class="paper-summary">
                    TheraMind introduces a strategic and adaptive AI agent for longitudinal psychological counseling, addressing critical gaps in existing LLM approaches such as lack of emotional understanding, adaptive strategies, and long-term memory. Its core is a novel dual-loop architecture that decouples tactical intra-session dialogue management from strategic cross-session therapeutic planning. Validated in a high-fidelity simulation, TheraMind outperforms other methods on multi-session metrics, demonstrating effective emulation of strategic, adaptive, and longitudinal therapeutic behavior.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25758v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25758v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25758v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25758v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25816v1"
                     data-domains="Clinical Informatics,Health Information Technology,Medical AI,Diagnostic Support,Public Health Surveillance,Clinical Research"
                     data-keywords="Clinical NLP,EHR,Question Answering,Entity-aware Retrieval,FHIR,Semantic Similarity,Computational Efficiency,Large Language Models"
                     data-authors="Tarun Kumar Chawdhury,Jon D. Duke">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25816v1.html">Beyond Long Context: When Semantics Matter More than Tokens</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tarun Kumar Chawdhury, Jon D. Duke
                </div>

                <div class="paper-summary">
                    This paper introduces the Clinical Entity Augmented Retrieval (CLEAR) method, which uses entity-aware retrieval to overcome the challenges of semantic question answering from unstructured clinical documentation within EHRs. CLEAR demonstrated significant improvements in both accuracy and computational efficiency, outperforming traditional methods and offering particular advantages for long clinical notes. The study also developed a reusable evaluation platform for clinical QA systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Diagnostic Support</span>
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25816v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25816v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25816v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25816v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25628v1"
                     data-domains="Clinical Informatics,Medical Decision Making,Healthcare Data Analytics,Patient Management,Predictive Medicine,Digital Health"
                     data-keywords="Electronic Health Records,Large Language Models,Clinical Decision Support,Medical AI,Reasoning,Foundational Models,Medical Informatics,Healthcare Analytics"
                     data-authors="Yusheng Liao,Chaoyi Wu,Junwei Liu,Shuyang Jiang,Pengcheng Qiu,Haowen Wang,Yun Yue,Shuai Zhen,Jian Wang,Qianrui Fan,Jinjie Gu,Ya Zhang,Yanfeng Wang,Yu Wang,Weidi Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25628v1.html">EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yusheng Liao, Chaoyi Wu, Junwei Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EHR-R1, a series of reasoning-enhanced foundational language models (LLMs) specifically designed for Electronic Health Record (EHR) analysis, addressing the limitations of existing LLMs in this domain. It leverages EHR-Ins, a novel, large-scale instruction dataset generated through a thinking-graph-driven framework, and employs a multi-stage training paradigm to acquire diverse reasoning capabilities. Evaluated against the new EHR-Bench benchmark, EHR-R1 significantly outperforms state-of-the-art commercial and open-source LLMs, establishing a new benchmark for automated clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Decision Making</span>
                    
                    <span class="domain-tag">Healthcare Data Analytics</span>
                    
                    <span class="domain-tag">Patient Management</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25628v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25628v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25628v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25628v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.25588v1"
                     data-domains="Psychiatry,Mental Health,Clinical Diagnostics,eHealth"
                     data-keywords="Psychiatric Diagnosis,Large Language Models (LLMs),Decision Support System,Mental Health,AI in Medicine,Diagnostic Standardization,Reasoning LLM,eHealth"
                     data-authors="Eranga Bandara,Ross Gore,Atmaram Yarlagadda,Anita H. Clayton,Preston Samuel,Christopher K. Rhea,Sachin Shetty">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.25588v1.html">Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-29</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eranga Bandara, Ross Gore, Atmaram Yarlagadda et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel AI-powered decision support system designed to standardize psychiatric diagnoses, which traditionally suffer from subjectivity and variability. The system integrates a consortium of fine-tuned Large Language Models (LLMs) trained on psychiatrist-patient dialogues with an OpenAI-gpt-oss reasoning LLM, orchestrated by specialized LLM agents. Experimental results indicate its transformative potential in creating a robust and highly accurate diagnostic platform for mental health.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">eHealth</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.25588v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.25588v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.25588v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.25588v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-10-31 06:31:57</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>