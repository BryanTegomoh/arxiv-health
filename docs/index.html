<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">161</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (9), Oncology (8), Diagnostic Imaging (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (9)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (7)</option>
                        
                        <option value="Public Health">Public Health (5)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (5)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Pharmacology">Pharmacology (4)</option>
                        
                        <option value="Preventive Medicine">Preventive Medicine (4)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.07406v1"
                     data-domains="Pharmacology,Computational Biology,Systems Biology,Cell Biology,Biophysics,Oncology (for cell population studies)"
                     data-keywords="Molecular Dynamics,Drug Discovery,Schr√∂dinger Bridge,Multi-particle Systems,Stochastic Dynamics,Biomolecular Systems,Cell Populations,Rare Transitions"
                     data-authors="Sophia Tang,Yinuo Zhang,Pranam Chatterjee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07406v1.html">Entangled Schr√∂dinger Bridge Matching</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sophia Tang, Yinuo Zhang, Pranam Chatterjee
                </div>

                <div class="paper-summary">
                    This paper introduces Entangled Schr√∂dinger Bridge Matching (EntangledSBM), a novel framework designed to simulate trajectories of multi-particle systems with dynamically evolving interactions, addressing a limitation of prior methods that rely on static snapshots. EntangledSBM learns the first- and second-order stochastic dynamics of particles whose paths are mutually dependent, accurately simulating complex behaviors in systems like heterogeneous cell populations and high-dimensional biomolecular systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Cell Biology</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07406v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07406v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07406v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07406v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07392v1"
                     data-domains="Robotic Surgery,Minimally Invasive Surgery,Surgical Planning,Intraoperative Imaging,Digital Health"
                     data-keywords="Robotic surgery,Da Vinci surgical system,Voice control,Large Language Models (LLMs),Multi-agent system,Minimally invasive surgery,Patient data interaction,Surgical workflow optimization,Human-computer interaction"
                     data-authors="Hyeryun Park,Byung Mo Gu,Jun Hee Lee,Byeong Hyeon Choi,Sekeun Kim,Hyun Koo Kim,Kyungsang Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07392v1.html">Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hyeryun Park, Byung Mo Gu, Jun Hee Lee et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Surgical Agent Orchestrator Platform (SAOP), a voice-directed system for da Vinci robotic surgeons to access and manipulate multimodal patient data without interrupting procedures. Built on a hierarchical multi-agent framework powered by Large Language Models (LLMs), SAOP autonomously interprets and executes voice commands for tasks like retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models. The platform demonstrated high accuracy and robustness against speech recognition errors and ambiguous commands, showcasing its strong potential to enhance minimally invasive robotic surgery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Robotic Surgery</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Intraoperative Imaging</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07392v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07392v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07392v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07392v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07390v1"
                     data-domains="Biotechnology,Protein therapeutics,Drug delivery,Synthetic biology,Diagnostics,Vaccinology"
                     data-keywords="Protein engineering,Diffusion model,Protein shrinkage,Functional motifs,Generative AI,Evolutionary sequences,Drug discovery,Bioengineering"
                     data-authors="Ethan Baron,Alan N. Amin,Ruben Weitzman,Debora Marks,Andrew Gordon Wilson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07390v1.html">A Diffusion Model to Shrink Proteins While Maintaining Their Function</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ethan Baron, Alan N. Amin, Ruben Weitzman et al.
                </div>

                <div class="paper-summary">
                    SCISOR introduces a novel discrete diffusion model designed to computationally shrink long protein sequences while preserving their function. By training a de-noiser to reverse random insertions, SCISOR generates realistic, shorter proteins that competitively fit evolutionary data and achieve state-of-the-art predictions for deletion effects. This advancement offers a more efficient and less costly alternative to traditional experimental methods for protein optimization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                    <span class="domain-tag">Protein therapeutics</span>
                    
                    <span class="domain-tag">Drug delivery</span>
                    
                    <span class="domain-tag">Synthetic biology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07390v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07390v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07390v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07390v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07318v1"
                     data-domains="Clinical Decision Support,Diagnostic Assistance,Medical Information Retrieval,Patient Education,Medical Research,Public Health Informatics"
                     data-keywords="LLMs,hallucinations,spurious correlations,hallucination detection,confidence-based filtering,inner-state probing,model bias,AI safety"
                     data-authors="Shaowen Wang,Yiqi Dong,Ruinian Chang,Tansheng Zhu,Yuebo Sun,Kaifeng Lyu,Jian Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07318v1.html">When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shaowen Wang, Yiqi Dong, Ruinian Chang et al.
                </div>

                <div class="paper-summary">
                    This paper identifies a new class of LLM hallucinations driven by spurious correlations in training data, where superficial associations (e.g., surnames and nationality) lead to plausible but incorrect outputs. These hallucinations are confidently generated, resistant to model scaling and fine-tuning, and critically, evade existing detection methods like confidence-based filtering and inner-state probing. The research highlights an urgent need for novel detection approaches specifically designed for these robust, undetected biases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic Assistance</span>
                    
                    <span class="domain-tag">Medical Information Retrieval</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07318v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07318v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07318v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07318v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07313v1"
                     data-domains="Neurology,Neuroscience,Diagnostic Imaging,Alzheimer's Disease Research,Computational Psychiatry"
                     data-keywords="fMRI,Functional Connectivity,Mahalanobis Whitening,Bures Geometry,De-Individualization,Alzheimer's Diagnosis,Neuroimaging,Dimensionality Reduction"
                     data-authors="Aaron Jacobson,Tingting Dan,Martin Styner,Guorong Wu,Shahar Kovalsky,Caroline Moosmueller">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07313v1.html">De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures Geometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aaron Jacobson, Tingting Dan, Martin Styner et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel method for analyzing fMRI signals by applying Mahalanobis data whitening prior to dimensionality reduction, which effectively de-individualizes the data. This approach, motivated by Bures geometry and its connection to quantum mechanics, aims to distill meaningful information about subjects and stimuli from functional connectivity patterns. The methodology promises to enhance our understanding of brain function-cognition links and improve the accuracy of Alzheimer's disease diagnosis, particularly in preclinical stages.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Alzheimer's Disease Research</span>
                    
                    <span class="domain-tag">Computational Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07313v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07313v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07313v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07313v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07311v1"
                     data-domains="Clinical Informatics,Health Information Management,Medical Billing and Coding,Clinical Documentation Improvement,Natural Language Processing in Healthcare"
                     data-keywords="Automated ICD Coding,Data Augmentation,Large Language Models,Medical Acronyms,Consistency Training,Clinical Documentation,Electronic Medical Records,MIMIC-III"
                     data-authors="Tuan-Dung Le,Shohreh Haddadan,Thanh Q. Thieu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07311v1.html">ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tuan-Dung Le, Shohreh Haddadan, Thanh Q. Thieu
                </div>

                <div class="paper-summary">
                    This paper introduces ACE-ICD, a novel data augmentation technique for automated ICD coding that tackles the underexplored challenge of medical acronyms in clinical notes. It leverages large language models (LLMs) to expand acronyms into their full forms, training models on these richer representations, and incorporates consistency training to regularize predictions between original and augmented documents. The approach achieves new state-of-the-art performance on the MIMIC-III dataset across common, rare, and full-code assignments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Information Management</span>
                    
                    <span class="domain-tag">Medical Billing and Coding</span>
                    
                    <span class="domain-tag">Clinical Documentation Improvement</span>
                    
                    <span class="domain-tag">Natural Language Processing in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07311v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07311v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07311v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07311v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07298v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Physics,Oncology (for screening applications)"
                     data-keywords="Low-dose CT,Image Quality Assessment,Large Language Models,Medical Imaging,Diagnostic Quality,Noise Reduction,Clinical Workflow"
                     data-authors="Kagan Celik,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07298v1.html">LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kagan Celik, Mehmet Ozan Unal, Metin Ertas et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an LLM-based image quality assessment (IQA) system for low-dose computed tomography (CT) imaging, addressing the inherent trade-off between reduced radiation exposure and potential diagnostic quality degradation. The system uniquely generates both quantitative numerical quality scores and qualitative textual descriptions of degradations, with performance enhanced by systematically integrated inference strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Oncology (for screening applications)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07298v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07298v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07298v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07298v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07281v1"
                     data-domains="Neurology,Neuroradiology,Medical Imaging,Stroke Medicine"
                     data-keywords="ischemic stroke,lesion segmentation,MRI,deep learning,transfer learning,Res-Unet,medical image analysis,stroke diagnosis"
                     data-authors="R. P. Chowdhury,T. Rahman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07281v1.html">Segmentation of Ischemic Stroke Lesions using Transfer Learning on Multi-sequence MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> R. P. Chowdhury, T. Rahman
                </div>

                <div class="paper-summary">
                    This paper presents a novel deep learning framework using a Res-Unet architecture to quickly and automatically segment ischemic stroke lesions on multi-sequence MRI. By leveraging transfer learning and integrating a Majority Voting Classifier, the method achieved a Dice score of 80.5% and an accuracy of 74.03% on the ISLES 2015 dataset, demonstrating effective automation for crucial diagnostic tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Stroke Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07281v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07281v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07281v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07281v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07277v1"
                     data-domains="Health Equity,Primary Care,Public Health,Patient Navigation,Digital Health,Medical Ethics,Health Informatics"
                     data-keywords="Limited English Proficiency,AI in healthcare,patient navigators,health equity,sociotechnical systems,trust in AI,language barriers,human-computer interaction"
                     data-authors="Michelle Huang,Violeta J. Rodriguez,Koustuv Saha,Tal August">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07277v1.html">Designing Beyond Language: Sociotechnical Barriers in AI Health Technologies for Limited English Proficiency</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Michelle Huang, Violeta J. Rodriguez, Koustuv Saha et al.
                </div>

                <div class="paper-summary">
                    This paper investigates sociotechnical barriers to AI health technologies for Limited English Proficiency (LEP) patients, extending beyond mere language to encompass systemic procedural and institutional constraints. Through interviews with patient navigators, it identifies critical tensions like linguistic/cultural misunderstandings, privacy concerns, and trust issues, while proposing design considerations for AI to equitably support LEP individuals and care teams.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Equity</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Patient Navigation</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07277v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07277v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07277v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07277v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07264v1"
                     data-domains="Nutrition,Gastroenterology,Pharmacology (Drug Delivery),Food Science,Preventive Medicine"
                     data-keywords="edible polysaccharides,microencapsulation,phenolic compounds,pigments,bioaccessibility,bioavailability,food formulations,nutraceuticals"
                     data-authors="Liliane Siqueira de Oliveira,Davi Vieira Teixeira da Silva,Lucileno Rodrigues da Trindade,Diego dos Santos Bai√£o,Cristine Couto de Almeida,Vitor Francisco Ferreira,Vania Margaret Flosi Paschoalin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07264v1.html">edible polysaccharides as stabilizers and carriers for the delivery of phenolic compounds and pigments in food formulations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Liliane Siqueira de Oliveira, Davi Vieira Teixeira da Silva, Lucileno Rodrigues da Trindade et al.
                </div>

                <div class="paper-summary">
                    This review paper analyzes the use of edible polysaccharides as versatile stabilizers and carriers for microencapsulating phenolic compounds and pigments in food and nutraceutical formulations. It details how various polysaccharides and encapsulation techniques improve the stability, bioaccessibility, and bioavailability of these bioactive substances by forming protective matrices through specific physical interactions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nutrition</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Pharmacology (Drug Delivery)</span>
                    
                    <span class="domain-tag">Food Science</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07264v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07264v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07264v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07264v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07231v1"
                     data-domains="Public Health,Humanitarian Medicine,Epidemiology,Global Health,Environmental Health"
                     data-keywords="WASH accessibility,Refugee camps,Remote sensing,Machine learning,Satellite imagery,Humanitarian aid,Public health,Gender inequality"
                     data-authors="Kyeongjin Ahn,YongHun Suh,Sungwon Han,Jeasurk Yang,Hannes Taubenb√∂ck,Meeyoung Cha">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07231v1.html">Mapping Reduced Accessibility to WASH Facilities in Rohingya Refugee Camps with Sub-Meter Imagery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kyeongjin Ahn, YongHun Suh, Sungwon Han et al.
                </div>

                <div class="paper-summary">
                    This study develops a remote sensing-driven framework using sub-meter satellite imagery and a semi-supervised segmentation model to quantify Water, Sanitation, and Hygiene (WASH) accessibility in dense Rohingya refugee camps. The research reveals declining WASH accessibility over time, with an increase from 25 to 29.4 people per facility between 2022 and 2025, and highlights significant gender disparities where women and girls face reduced access due to inadequate safety segregation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Humanitarian Medicine</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07231v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07231v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07231v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07231v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07219v1"
                     data-domains="Oncology,Geriatric Oncology,Precision Medicine,Biomarker Discovery,Epigenetics,Prognostics"
                     data-keywords="Biological age,Cancer,Epigenetics,Phenotype,Multimodal learning,Age acceleration,Mortality risk,Oncology"
                     data-authors="Shuyue Jiang,Wenjing Ma,Shaojun Yu,Chang Su,Runze Yan,Jiaying Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07219v1.html">Integrating Epigenetic and Phenotypic Features for Biological Age Estimation in Cancer Patients via Multimodal Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shuyue Jiang, Wenjing Ma, Shaojun Yu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EpiCAge, a novel multimodal learning framework that integrates epigenetic and phenotypic data to enhance biological age prediction in cancer patients. EpiCAge consistently outperforms existing age clocks across multiple cancer cohorts, identifies biologically relevant markers, and its derived age acceleration is significantly associated with mortality risk. These findings position EpiCAge as a promising tool for biological age assessment in oncology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Geriatric Oncology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Epigenetics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07219v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07219v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07219v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07219v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07213v1"
                     data-domains="Pain management,Rehabilitation medicine,Physical therapy,Digital health,Chronic disease management"
                     data-keywords="Chronic pain,Treatment evaluation,Activities of Daily Life (ADL),Smartphone sensors,Classification Transformers,Objective assessment,Clinical decision-making,Personalized medicine"
                     data-authors="Yuanheng Mao,Lillian Yang,Stephen Yang,Ethan Shao,Zihan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07213v1.html">DETECT: Data-Driven Evaluation of Treatments Enabled by Classification Transformers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuanheng Mao, Lillian Yang, Stephen Yang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DETECT, a data-driven framework leveraging Classification Transformers to objectively evaluate the success of chronic pain treatments. By comparing patient Activities of Daily Life (ADL) before and after treatment, using data from public benchmarks and simulated smartphone sensors, DETECT provides an objective and lightweight alternative to subjective self-reported metrics. This novel approach aims to enhance clinical decision-making and personalize patient care.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pain management</span>
                    
                    <span class="domain-tag">Rehabilitation medicine</span>
                    
                    <span class="domain-tag">Physical therapy</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Chronic disease management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07213v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07213v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07213v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07213v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07163v1"
                     data-domains="Epidemiology,Public Health,Infectious Diseases,Disease Surveillance,Preventive Medicine"
                     data-keywords="Real-time outbreak detection,Epidemic networks,Digital data streams,Machine learning,COVID-19,Public health surveillance,Interpretable AI,Disease trajectory"
                     data-authors="Ruiqi Lyu,Alistair Turcan,Bryan Wilder">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07163v1.html">Combining digital data streams and epidemic networks for real time outbreak detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruiqi Lyu, Alistair Turcan, Bryan Wilder
                </div>

                <div class="paper-summary">
                    This paper introduces LRTrend, an interpretable machine learning framework designed for real-time detection of disease outbreaks. It achieves this by aggregating diverse health and behavioral digital data streams within regions and learning disease-specific epidemic networks to synthesize information across regions. The framework successfully detected COVID-19 Delta and Omicron waves early, revealing novel epidemic connections across the United States that are distinct from standard human mobility patterns.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Disease Surveillance</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07163v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07163v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07163v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07163v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07148v1"
                     data-domains="Traditional Chinese Medicine,Medical Education,Artificial Intelligence in Healthcare,Clinical Informatics"
                     data-keywords="Traditional Chinese Medicine,Large Language Models,Benchmark,Data Augmentation,Chain-of-Thought,AI in Medicine,Medical Education,ZhiMingTang"
                     data-authors="Zihao Cheng,Yuheng Lu,Huaiqian Ye,Zeming Liu,Minqi Wang,Jingjing Liu,Zihan Li,Wei Fan,Yuanfang Guo,Ruiji Fu,Shifeng She,Gang Wang,Yunhong Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07148v1.html">TCM-Eval: An Expert-Level Dynamic and Extensible Benchmark for Traditional Chinese Medicine</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihao Cheng, Yuheng Lu, Huaiqian Ye et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TCM-Eval, the first dynamic and extensible benchmark for Traditional Chinese Medicine (TCM), curated from national medical licensing examinations and validated by experts, to address the severe limitations of Large Language Models (LLMs) in TCM due to a lack of standardized benchmarks and high-quality data. Utilizing a novel Self-Iterative Chain-of-Thought Enhancement (SI-CoTE) method for data enrichment, the authors developed ZhiMingTang (ZMT), a state-of-the-art TCM-specific LLM that significantly surpasses the passing threshold for human practitioners.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Traditional Chinese Medicine</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Healthcare</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07148v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07148v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07148v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07148v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07127v1"
                     data-domains="Clinical Decision Making,Prognostics,Risk Assessment,Predictive Medicine"
                     data-keywords="LLM,Causal Learning,Clinical Prognosis,Risk Prediction,Benchmarking,Causal Discovery,Healthcare AI,Machine Learning"
                     data-authors="Linna Wang,Zhixuan You,Qihui Zhang,Jiunan Wen,Ji Shi,Yimin Chen,Yusen Wang,Fanqi Ding,Ziliang Feng,Li Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07127v1.html">REACT-LLM: A Benchmark for Evaluating LLM Integration with Causal Features in Clinical Prognostic Tasks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Linna Wang, Zhixuan You, Qihui Zhang et al.
                </div>

                <div class="paper-summary">
                    REACT-LLM introduces a novel benchmark to systematically evaluate the integration of Large Language Models (LLMs) with causal features for enhancing clinical prognostic performance. The study reveals that while LLMs perform reasonably well in clinical prognostics, they currently do not outperform traditional machine learning models, and direct integration of causal features derived from discovery algorithms yields limited performance gains, primarily due to violated causal assumptions in complex clinical data. The benchmark, however, points towards a more promising, yet unspecified, synergy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Making</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Risk Assessment</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07127v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07127v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07127v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07127v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07094v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging,Medical Image Analysis,Radiation Oncology"
                     data-keywords="Low-dose CT,Deep Learning,Image Reconstruction,Task-Adaptive,Segmentation,Regularization,Diagnostic Quality,Medical Imaging"
                     data-authors="Necati Sefercioglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07094v1.html">Task-Adaptive Low-Dose CT Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Necati Sefercioglu, Mehmet Ozan Unal, Metin Ertas et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel task-adaptive deep learning framework for low-dose CT reconstruction, addressing the prevalent issue where existing methods achieve high standard image quality metrics but fail to preserve critical diagnostic anatomical details. By incorporating a frozen pre-trained task network as a regularization term in the reconstruction loss, the proposed method effectively guides the reconstruction process to maintain diagnostic quality relevant to specific clinical tasks. This approach significantly outperforms traditional and joint-training methods, approaching full-dose performance on segmentation tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07094v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07094v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07094v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07094v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07088v1"
                     data-domains="Breast Imaging,Radiology,Oncology,Medical Physics,Diagnostic Imaging"
                     data-keywords="Deep Learning,Fibroglandular Tissue,Background Parenchymal Enhancement,Breast MRI,Segmentation,Breast Cancer Risk,Quantitative Biomarkers,Radiology"
                     data-authors="Yu-Tzu Kuo,Anum S. Kazerouni,Vivian Y. Park,Wesley Surento,Suleeporn Sujichantararat,Daniel S. Hippe,Habib Rahbar,Savannah C. Partridge">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07088v1.html">Validation of Fully-Automated Deep Learning-Based Fibroglandular Tissue Segmentation for Efficient and Reliable Quantitation of Background Parenchymal Enhancement in Breast MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu-Tzu Kuo, Anum S. Kazerouni, Vivian Y. Park et al.
                </div>

                <div class="paper-summary">
                    This paper validates a fully-automated deep learning (DL)-based method for segmenting fibroglandular tissue (FGT) in breast MRI to quantify background parenchymal enhancement (BPE), a potential breast cancer risk marker. The DL method outperformed a semi-automated fuzzy c-means approach by yielding higher quality segmentations and stronger correlations with qualitative BPE assessments, promising more efficient and standardized breast cancer risk evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Breast Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07088v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07088v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07088v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07088v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07057v1"
                     data-domains="Medical Imaging,Radiology,Computational Pathology,Point-of-Care Diagnostics,Biomedical Engineering"
                     data-keywords="Medical image segmentation,Lightweight models,Edge computing,Dynamic feature response,ConvLTC,STDP,Brain-inspired AI,Deep learning"
                     data-authors="Zidong Chen,Fadratul Hafinaz Hassan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07057v1.html">TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zidong Chen, Fadratul Hafinaz Hassan
                </div>

                <div class="paper-summary">
                    TauFlow introduces a novel lightweight segmentation model designed for edge devices, effectively addressing challenges of stark contrast between lesion boundaries and backgrounds, and maintaining high accuracy with extremely low parameter counts (<0.5M). Its core innovation lies in a dynamic, brain-inspired feature response strategy, implemented via a Convolutional Long-Time Constant Cell (ConvLTC) for adaptive processing and an STDP Self-Organizing Module to significantly reduce encoder-decoder feature conflicts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Point-of-Care Diagnostics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07057v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07057v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07057v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07057v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07047v1"
                     data-domains="Oncology,Radiology,Nuclear Medicine,Medical Imaging"
                     data-keywords="lymphoma,lesion detection,PET/CT,deep learning,anatomical priors,nnDetection,Swin Transformer,cancer imaging"
                     data-authors="Simone Bendazzoli,Antonios Tzortzakakis,Andreas Abrahamsson,Bj√∂rn Engelbrekt Wahlin,√ñrjan Smedby,Maria Holstensson,Rodrigo Moreno">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07047v1.html">Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Simone Bendazzoli, Antonios Tzortzakakis, Andreas Abrahamsson et al.
                </div>

                <div class="paper-summary">
                    This study investigates the effect of integrating anatomical prior information, specifically organ segmentation masks, into deep learning models for lymphoma lesion detection in whole-body PET/CT images. It found that anatomical context substantially improves detection performance in CNN-based models like nnDetection, but had minimal impact on vision transformers (Swin Transformer). The research highlights the critical role of anatomical priors, particularly for CNN-based cancer lesion detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07047v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07047v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07047v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07047v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07044v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Health Informatics,Public Health,Telemedicine"
                     data-keywords="Mental Health Detection,Large Language Models (LLMs),Transformers,Anxiety,Depression,Stress,Synthetic Data,Automated Assessment,Natural Language Processing"
                     data-authors="Mihael Arcan,David-Paul Niland">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07044v1.html">Evaluating LLMs for Anxiety, Depression, and Stress Detection Evaluating Large Language Models for Anxiety, Depression, and Stress Detection: Insights into Prompting Strategies and Synthetic Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mihael Arcan, David-Paul Niland
                </div>

                <div class="paper-summary">
                    This study evaluates multiple language models, including LLMs (Llama, GPT) and transformer-based architectures (BERT, XLNet, Distil-RoBERTa), against classical machine learning for detecting anxiety, depression, and stress from clinical interview text. Using the DAIC-WOZ dataset and synthetic data augmentation, the research demonstrates that transformer models achieve high F1 scores, with Distil-RoBERTa excelling in anxiety detection and XLNet in depression. The findings highlight the significant potential of advanced language models combined with synthetic data to improve automated mental health assessment, enhancing recall and generalization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Health Informatics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07044v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07044v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07044v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07044v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07011v1"
                     data-domains="Psychiatry,Mental Health,Digital Health,Computational Psychiatry"
                     data-keywords="Major Depressive Disorder,spoken language,lexical features,PHQ-8,machine learning,linear mixed-effects models,longitudinal study,multilingual"
                     data-authors="Anastasiia Tokareva,Judith Dineley,Zoe Firth,Pauline Conde,Faith Matcham,Sara Siddi,Femke Lamers,Ewan Carr,Carolin Oetzmann,Daniel Leightley,Yuezhou Zhang,Amos A. Folarin,Josep Maria Haro,Brenda W. J. H. Penninx,Raquel Bailon,Srinivasan Vairavan,Til Wykes,Richard J. B. Dobson,Vaibhav A. Narayan,Matthew Hotopf,Nicholas Cummins,The RADAR-CNS Consortium">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07011v1.html">Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anastasiia Tokareva, Judith Dineley, Zoe Firth et al.
                </div>

                <div class="paper-summary">
                    This study explored the potential of multilingual lexical features in mobile-captured spoken language for objectively assessing Major Depressive Disorder (MDD) symptom severity. While some interpretable lexical associations were found in English and Dutch speech, the overall predictive power for MDD symptom severity across all languages tested was near chance level, indicating the need for further methodological advancements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Computational Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07011v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07011v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07011v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07011v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.07006v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Structural Biology,Drug Discovery and Development,Bioinformatics"
                     data-keywords="Virtual Screening,Drug Discovery,Protein-Ligand Interaction,Protein Sequence,3D Structure,Contrastive Learning,Deep Learning,Binding Site Prediction"
                     data-authors="Bowei He,Bowen Gao,Yankai Chen,Yanyan Lan,Chen Ma,Philip S. Yu,Ya-Qin Zhang,Wei-Ying Ma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.07006v1.html">S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bowei He, Bowen Gao, Yankai Chen et al.
                </div>

                <div class="paper-summary">
                    S$^2$Drug is a novel two-stage deep learning framework designed to improve virtual screening in drug discovery by explicitly bridging protein sequence information and 3D structural context. It addresses limitations of existing methods that primarily rely on structural data, achieving enhanced performance by combining sequence pretraining with structure-sequence fusion and an auxiliary binding site prediction task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.07006v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.07006v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.07006v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.07006v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06988v1"
                     data-domains="Psychiatry,Clinical Psychology,Behavioral Health,Telemedicine,Digital Therapeutics,Preventive Medicine"
                     data-keywords="anxiety detection,few-shot learning,hyperbolic embeddings,multimodal learning,machine learning,mental health,biometric data,diagnostic aid"
                     data-authors="Aditya Sneh,Nilesh Kumar Sahu,Anushka Sanjay Shelke,Arya Adyasha,Haroon R. Lone">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06988v1.html">HCFSLN: Adaptive Hyperbolic Few-Shot Learning for Multimodal Anxiety Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aditya Sneh, Nilesh Kumar Sahu, Anushka Sanjay Shelke et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Hyperbolic Curvature Few-Shot Learning Network (HCFSLN), a novel Few-Shot Learning (FSL) framework for multimodal anxiety detection using speech, physiological signals, and video data. HCFSLN employs hyperbolic embeddings, cross-modal attention, and an adaptive gating network to achieve robust classification with minimal data. Evaluated on a newly collected dataset from 108 participants, HCFSLN attained 88% accuracy, outperforming existing FSL baselines by 14%, demonstrating the effectiveness of hyperbolic space and FSL for anxiety detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06988v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06988v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06988v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06988v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06958v1"
                     data-domains="Oncology,Pathology,Histopathology,Cancer Research"
                     data-keywords="Histopathology,Whole-slide Images,Masked Autoencoders,Representation Learning,Wavelets,Digital Pathology,Cancer Diagnosis,Self-supervised Learning"
                     data-authors="Raneen Younis,Louay Hamdi,Lukas Chavez,Zahra Ahmadi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06958v1.html">Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Raneen Younis, Louay Hamdi, Lukas Chavez et al.
                </div>

                <div class="paper-summary">
                    This paper introduces WISE-MAE, a two-stage wavelet-driven masked autoencoder designed to improve histopathology representation learning from whole-slide images. By selectively focusing on structurally rich regions, mirroring pathologists' workflow, WISE-MAE achieves competitive representation quality and downstream classification performance across various cancer datasets while maintaining computational efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Cancer Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06958v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06958v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06958v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06958v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06948v1"
                     data-domains="Cardiology,Nuclear Medicine,Medical Imaging"
                     data-keywords="Attenuation Correction,SPECT,Cardiac MPI,Diffusion Model,Physics-aware,Generative AI,CT-free,Myocardial Perfusion Imaging"
                     data-authors="Trung Kien Pham,Hoang Minh Vu,Anh Duc Chu,Dac Thai Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Mai Hong Son,Thanh Trung Nguyen,Phi Le Nguyen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06948v1.html">PADM: A Physics-aware Diffusion Model for Attenuation Correction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Trung Kien Pham, Hoang Minh Vu, Anh Duc Chu et al.
                </div>

                <div class="paper-summary">
                    The paper introduces PADM, a novel CT-free Physics-aware Diffusion Model, to effectively correct attenuation artifacts in cardiac SPECT Myocardial Perfusion Imaging (MPI). Leveraging explicit physics priors via a teacher-student distillation mechanism, PADM accurately generates Attenuation-Corrected (AC) images solely from Non-Attenuation-Corrected (NAC) inputs. Supported by the new CardiAC dataset, extensive experiments demonstrate PADM's superior reconstruction fidelity compared to state-of-the-art generative models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06948v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06948v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06948v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06948v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06930v1"
                     data-domains="Neurodegenerative Diseases,Neurology,Neuropharmacology,Drug Discovery,Medicinal Chemistry,Circadian Biology"
                     data-keywords="Alzheimer's Disease,Salt-Inducible Kinase 3 (SIK3),Generative AI,Active Learning,Drug Discovery,Molecular Design,Variational Autoencoder,Circadian Rhythm"
                     data-authors="ShahZeb Khan,Chiara Pallara,Barbara Monti,Alexis Molina">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06930v1.html">De Novo Design of SIK3 Inhibitors via Feedback-Driven Fine-Tuning of Seq2Seq-VAE</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> ShahZeb Khan, Chiara Pallara, Barbara Monti et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel generative AI pipeline, employing a sequence-to-sequence Variational Autoencoder (Seq2Seq-VAE) guided by Active Learning (AL), for the *de novo* design of Salt-Inducible Kinase 3 (SIK3) inhibitors. The method iteratively optimizes molecular properties and predicted binding affinity towards SIK3, successfully generating high-affinity, drug-like small molecules relevant for Alzheimer's disease with minimal data requirements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuropharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06930v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06930v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06930v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06930v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06857v1"
                     data-domains="oncology,dermatology,radiology,pathology"
                     data-keywords="ambiguous medical image segmentation,flow matching,truncated diffusion models,accuracy,diversity,data-hierarchical inference,Gaussian truncation representation,semantic-aware transformation"
                     data-authors="Fanding Li,Xiangyu Li,Xianghe Su,Xingyu Qiu,Suyu Dong,Wei Wang,Kuanquan Wang,Gongning Luo,Shuo Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06857v1.html">Ambiguity-aware Truncated Flow Matching for Ambiguous Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fanding Li, Xiangyu Li, Xianghe Su et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Ambiguity-aware Truncated Flow Matching (ATFM), a novel approach designed to overcome the inherent trade-offs between prediction accuracy and diversity in ambiguous medical image segmentation (AMIS). ATFM achieves this by proposing a new inference paradigm called Data-Hierarchical Inference and incorporating dedicated components like Gaussian Truncation Representation (GTR) and Segmentation Flow Matching (SFM). Comprehensive evaluations demonstrate that ATFM significantly outperforms state-of-the-art methods, yielding superior segmentation performance and more efficient inference.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">oncology</span>
                    
                    <span class="domain-tag">dermatology</span>
                    
                    <span class="domain-tag">radiology</span>
                    
                    <span class="domain-tag">pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06857v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06857v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06857v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06857v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06853v1"
                     data-domains="Live cell studies,Clinical histopathology,Cellular biology,Tissue analysis,Pathology"
                     data-keywords="Deep learning,Fluorescence microscopy,Axial super-resolution,Background subtraction,EPI-TIRF,ET2dNet,ET3dNet,Histopathology"
                     data-authors="Qiushi Li,Celi Lou,Yanfang Cheng,Bilang Gong,Xinlin Chen,Hao Chen,Baowan Li,Jieli Wang,Yulin Wang,Sipeng Yang,Yunqing Tang,Luru Dai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06853v1.html">Deep learning EPI-TIRF cross-modality enables background subtraction and axial super-resolution for widefield fluorescence microscopy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.optics</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qiushi Li, Celi Lou, Yanfang Cheng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ET2dNet, a deep learning-based EPI-TIRF cross-modality network that significantly enhances wide-field fluorescence microscopy by achieving TIRF-comparable background subtraction and axial super-resolution from a single image without hardware modifications. Utilizing a physics-informed hybrid architecture, ET2dNet exhibits exceptional generalization and can be adapted with few-shot learning. The framework is further extended to ET3dNet for artifact-reduced 3D volumetric reconstruction, making axial super-resolution imaging more accessible for live cell studies and clinical histopathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Live cell studies</span>
                    
                    <span class="domain-tag">Clinical histopathology</span>
                    
                    <span class="domain-tag">Cellular biology</span>
                    
                    <span class="domain-tag">Tissue analysis</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06853v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06853v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06853v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06853v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06826v1"
                     data-domains="Neurology,Geriatrics,Speech Pathology,Diagnostic Medicine,Cognitive Assessment"
                     data-keywords="Alzheimer's Disease Detection,In-Context Learning,Large Language Models,Narrative Transcripts,Demo-centric Anchoring,Out-of-Distribution Learning,Medical Diagnostics,Contextual Perception"
                     data-authors="Puzhen Su,Haoran Yin,Yongzhu Miao,Jintao Tang,Shasha Li,Ting Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06826v1.html">Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Puzhen Su, Haoran Yin, Yongzhu Miao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DA4ICL, a novel demo-centric anchoring framework designed to enhance in-context learning (ICL) in large language models (LLMs) for Alzheimer's disease (AD) detection from narrative transcripts. DA4ICL addresses the limitations of standard ICL and task vector methods by improving contextual perception through diverse and contrastive demo retrieval and deep signal anchoring, leading to significant and stable performance gains across AD benchmarks. This new paradigm is particularly effective for fine-grained, out-of-distribution, and low-resource LLM adaptation in specialized domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Speech Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Cognitive Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06826v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06826v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06826v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06826v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06769v1"
                     data-domains="Gastroenterology,Oncology,Medical Imaging,Pathology"
                     data-keywords="Colonoscopy,Polyp Detection,Computer-Aided Diagnosis (CAD),Medical Image Segmentation,Image Classification,Real-world Data,Resource-Limited Settings,Colorectal Cancer"
                     data-authors="Ridoy Chandra Shil,Ragib Abid,Tasnia Binte Mamun,Samiul Based Shuvo,Masfique Ahmed Bhuiyan,Jahid Ferdous">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06769v1.html">RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ridoy Chandra Shil, Ragib Abid, Tasnia Binte Mamun et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the BUET Polyp Dataset (BPD), a new colonoscopy image dataset collected in real-world, resource-limited clinical settings, featuring diverse artifacts and expert-annotated binary masks. Benchmarking deep learning models on BPD revealed lower performance compared to curated datasets, underscoring the challenges of real-world data for computer-aided diagnosis (CAD) research in polyp detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06761v1"
                     data-domains="Computational Neuroscience,Medical Robotics,Assistive Technology,Neurorehabilitation,Surgical Robotics,Smart Prosthetics"
                     data-keywords="Intuitive Physics,Spatiotemporal Reasoning,Relational Neural Networks,Brain-Inspired AI,Hebbian Learning,Computational Neuroscience,Medical Robotics,Explainable AI"
                     data-authors="Fei Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06761v1.html">SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fei Yang
                </div>

                <div class="paper-summary">
                    This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a brain-inspired model designed to enhance machine understanding of intuitive physics by mirroring human cognitive processes. SRNN employs a unified neural representation for object attributes, relations, and timeline, using Hebbian learning across 'What' and 'How' pathways to generate structured linguistic scene descriptions. The model achieves competitive performance on the CLEVRER benchmark while also revealing benchmark biases and demonstrating white-box utility for error diagnosis, confirming the feasibility of translating biological intelligence to AI for physical reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Neurorehabilitation</span>
                    
                    <span class="domain-tag">Surgical Robotics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06761v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06761v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06761v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06761v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06752v1"
                     data-domains="Radiology,Diagnostic Imaging,Gastroenterology,Emergency Medicine,Internal Medicine,Computational Pathology"
                     data-keywords="medical multimodal learning,symptom-to-organ reasoning,abdominal CT,deep learning,soft labeling,2D-3D cross-attention,clinical reasoning,medical imaging"
                     data-authors="You-Kyoung Na,Yeong-Jun Cho">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06752v1.html">Med-SORA: Symptom to Organ Reasoning in Abdomen CT Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> You-Kyoung Na, Yeong-Jun Cho
                </div>

                <div class="paper-summary">
                    Med-SORA is a novel framework designed for symptom-to-organ reasoning in abdominal CT images, aiming to overcome limitations of existing medical multimodal models that rely on simplistic one-to-one labeling and only 2D image features. It introduces RAG-based dataset construction, soft labeling with learnable organ anchors for complex symptom-organ relationships, and a 2D-3D cross-attention architecture to fuse local and global anatomical information. Experimental results indicate Med-SORA's superior performance over existing models in enabling accurate 3D clinical reasoning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06752v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06752v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06752v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06752v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06738v1"
                     data-domains="Medical Question Answering,Clinical Decision Support,Medical Education (USMLE-style queries),Patient Information Queries"
                     data-keywords="Retrieval-Augmented Generation,RAG,Large Language Models,LLMs,Medical AI,Expert Evaluation,Factuality,Evidence-based Medicine"
                     data-authors="Hyunjae Kim,Jiwoong Sohn,Aidan Gilson,Nicholas Cochran-Caggiano,Serina Applebaum,Heeju Jin,Seihee Park,Yujin Park,Jiyeong Park,Seoyoung Choi,Brittany Alexandra Herrera Contreras,Thomas Huang,Jaehoon Yun,Ethan F. Wei,Roy Jiang,Leah Colucci,Eric Lai,Amisha Dave,Tuo Guo,Maxwell B. Singer,Yonghoe Koo,Ron A. Adelman,James Zou,Andrew Taylor,Arman Cohan,Hua Xu,Qingyu Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06738v1.html">Rethinking Retrieval-Augmented Generation for Medicine: A Large-Scale, Systematic Expert Evaluation and Practical Insights</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hyunjae Kim, Jiwoong Sohn, Aidan Gilson et al.
                </div>

                <div class="paper-summary">
                    This paper presents the most comprehensive expert evaluation of Retrieval-Augmented Generation (RAG) in medicine, involving 18 medical experts and over 80,000 annotations. Contrary to expectations, standard RAG often degraded performance for medical queries, highlighting critical failure points in evidence retrieval and selection. However, the study also demonstrates that simple, targeted strategies like evidence filtering and query reformulation can substantially mitigate these issues, leading to significant performance improvements.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Question Answering</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Education (USMLE-style queries)</span>
                    
                    <span class="domain-tag">Patient Information Queries</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06738v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06738v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06738v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06738v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06681v1"
                     data-domains="Neurology,Geriatrics,Dementia Care,Diagnostic Imaging,Clinical Informatics,Health Economics"
                     data-keywords="Alzheimer's Disease,Mild Cognitive Impairment,Machine Learning,Predictive Modeling,Cost-Effectiveness,Triage,Biomarkers,ADNI"
                     data-authors="Richard Hou,Shengpu Tang,Wei Jin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06681v1.html">An Adaptive Machine Learning Triage Framework for Predicting Alzheimer's Disease Progression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Richard Hou, Shengpu Tang, Wei Jin
                </div>

                <div class="paper-summary">
                    This paper introduces a two-stage machine learning framework to address the cost-accuracy dilemma in predicting Alzheimer's Disease (AD) progression from Mild Cognitive Impairment (MCI). By selectively acquiring expensive advanced features like PET scans and CSF biomarkers based on their predicted "value of information," the framework reduces the need for such testing by 20%. It achieves a high predictive accuracy (AUROC 0.929) that is comparable to models using all advanced features, making early, reliable AD prediction more accessible and cost-effective.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Dementia Care</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06681v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06681v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06681v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06681v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06668v1"
                     data-domains="Pharmacology,Drug Safety,Evidence-Based Medicine,Clinical Informatics,Consumer Health Information"
                     data-keywords="Retrieval-Augmented Generation,medical RAG,contradictory evidence,temporal inconsistency,factual accuracy,consumer medicine information,large language models,healthcare AI"
                     data-authors="Saeedeh Javadi,Sara Mirabi,Manan Gangar,Bahadorreza Ofoghi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06668v1.html">When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation in Healthcare</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.IR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Saeedeh Javadi, Sara Mirabi, Manan Gangar et al.
                </div>

                <div class="paper-summary">
                    This paper investigates how contradictory medical evidence in source documents degrades Retrieval-Augmented Generation (RAG) performance in healthcare. It establishes a novel benchmark using Australian TGA consumer medicine information documents and temporally stratified PubMed abstracts to evaluate five LLMs. The study finds that contradictions between highly similar abstracts significantly reduce LLM consistency and factual accuracy, underscoring the necessity for advanced contradiction-aware filtering strategies in high-stakes domains.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Safety</span>
                    
                    <span class="domain-tag">Evidence-Based Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Consumer Health Information</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06668v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06668v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06668v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06668v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06665v1"
                     data-domains="Radiology,Pathology,General Medical Imaging"
                     data-keywords="Medical Diagnosis Segmentation,Vision-Language Models,Multimodal Medical Imaging,Region-Aware Similarity,Explainable AI,Image Segmentation,Medical Diagnosis,Deep Learning"
                     data-authors="Lingran Song,Yucheng Zhou,Jianbing Shen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06665v1.html">Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lingran Song, Yucheng Zhou, Jianbing Shen
                </div>

                <div class="paper-summary">
                    This paper introduces Medical Diagnosis Segmentation (MDS), a novel vision-language task that aims to provide both medical image segmentation masks and explainable diagnostic results in response to clinical queries. To facilitate this, the authors present the M3DS dataset and propose Sim4Seg, a framework leveraging a Region-Aware Vision-Language Similarity to Mask (RVLS2M) module and a test-time scaling strategy. Experimental results demonstrate Sim4Seg's superior performance over baselines in both segmentation and diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">General Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06665v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06665v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06665v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06665v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06662v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,q-bio.QM"
                     data-authors="Franklin Lee,Tengfei Ma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06662v1.html">Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen Drug-Drug Interactions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Franklin Lee, Tengfei Ma
                </div>

                <div class="paper-summary">
                    Drug-drug interactions (DDIs) remain a major source of preventable harm, and
many clinically important mechanisms are still unknown. Existing models either
rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on
electronic health records (EHRs), which are noisy, temporal, and...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06662v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06662v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06662v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06662v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06627v1"
                     data-domains="Cancer cell tracking,Lymph node mapping,Cell therapy monitoring,Preclinical imaging,Diagnostic imaging,Biomedical engineering"
                     data-keywords="Magnetic Particle Imaging (MPI),3D reconstruction,Field-Free Line (FFL),superparamagnetic iron oxide nanoparticles,spatial resolution,quantitative accuracy,high dynamic range imaging,preclinical imaging"
                     data-authors="Toby Sanders,Hayden Carlton,Preethi Korangath,Olivia C. Sehl,Robert Ivkov,Patrick W. Goodwill">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06627v1.html">A Field Free Line 3D Reconstruction Model for Magnetic Particle Imaging for Improved Sensitivity, Resolution, and High Dynamic Range Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Toby Sanders, Hayden Carlton, Preethi Korangath et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel 3D image reconstruction framework for multi-angle Field-Free Line (FFL) Magnetic Particle Imaging (MPI) that significantly enhances spatial resolution, quantitative accuracy, and high dynamic range imaging. By combining a physics-based FFL signal model with tomographic projection operators and harmonic-domain compression, the framework enables efficient, joint volumetric reconstructions on standard GPUs in minutes. It demonstrates substantially reduced background haze and an ~11x improvement in iron detection sensitivity in phantom and in vivo studies, boosting MPI image quality and reliability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cancer cell tracking</span>
                    
                    <span class="domain-tag">Lymph node mapping</span>
                    
                    <span class="domain-tag">Cell therapy monitoring</span>
                    
                    <span class="domain-tag">Preclinical imaging</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06627v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06627v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06627v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06627v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06625v1"
                     data-domains="Cardiology,Pulmonology,Radiology,Preventive Medicine,Thoracic Oncology,Public Health"
                     data-keywords="Explainable AI,Cross-Disease Reasoning,Cardiovascular Risk Assessment,LDCT,Cardiopulmonary,Medical Imaging,NLST,Deep Learning,Interpretable AI"
                     data-authors="Yifei Zhang,Jiashuo Zhang,Xiaofeng Yang,Liang Zhao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06625v1.html">Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yifei Zhang, Jiashuo Zhang, Xiaofeng Yang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an Explainable Cross-Disease Reasoning Framework that utilizes a single Low-Dose Chest Computed Tomography (LDCT) scan for integrated cardiopulmonary risk assessment. Emulating clinical diagnostic thinking, the framework accurately predicts cardiovascular disease (CVD) risk and mortality while providing interpretable explanations linking pulmonary abnormalities to cardiac health.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Thoracic Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06625v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06625v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06625v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06625v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06592v1"
                     data-domains="Clinical Decision Support,General Medicine,Surgery,Patient Assessment,Healthcare Equity,Medical AI Ethics"
                     data-keywords="audio LLMs,clinical decision-making,modality bias,healthcare disparities,paralinguistic cues,age bias,medical AI,AI ethics"
                     data-authors="Zhi Rui Tam,Yun-Nung Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06592v1.html">MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical Decision-Making</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhi Rui Tam, Yun-Nung Chen
                </div>

                <div class="paper-summary">
                    This paper investigates how audio large language models (LLMs) perform in clinical decision-making, revealing that paralinguistic cues in patient voices introduce significant biases. It demonstrates a severe modality bias and age disparities, indicating that these models can base clinical decisions on voice characteristics rather than medical evidence, thereby risking the perpetuation of healthcare disparities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Patient Assessment</span>
                    
                    <span class="domain-tag">Healthcare Equity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06592v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06592v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06592v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06592v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06492v1"
                     data-domains="Critical Care Medicine,Emergency Medicine,Infectious Diseases,Intensive Care Units (ICU),Internal Medicine"
                     data-keywords="Sepsis,Explainable AI,Machine Learning,Early Detection,Clinical Interpretability,Medical Diagnosis,Predictive Analytics,Critical Care"
                     data-authors="Atharva Thakur,Shruti Dhumal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06492v1.html">Explainable AI For Early Detection Of Sepsis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Atharva Thakur, Shruti Dhumal
                </div>

                <div class="paper-summary">
                    This paper introduces an interpretable AI approach for the early detection of sepsis, aiming to overcome the black-box limitations of traditional machine learning models. By integrating machine learning with clinical knowledge, the proposed method provides accurate predictions of sepsis onset while enabling clinicians to understand, validate, and align model outputs with established medical expertise.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Intensive Care Units (ICU)</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06492v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06492v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06492v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06492v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06433v1"
                     data-domains="Pathology,Histopathology,Digital Pathology,Anatomic Pathology"
                     data-keywords="Multiple Instance Learning,Histopathology,Uncertainty Quantification,Model Calibration,Multi-resolution Imaging,Digital Pathology,Trustworthy AI,Diagnostic Aid"
                     data-authors="Sungrae Hong,Sol Lee,Jisu Shin,Mun Yong Yi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06433v1.html">Diagnose Like A REAL Pathologist: An Uncertainty-Focused Approach for Trustworthy Multi-Resolution Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sungrae Hong, Sol Lee, Jisu Shin et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical gap in existing multi-resolution Multiple Instance Learning (MIL) for histopathological diagnosis, which often prioritizes performance over trustworthiness and calibration. The authors propose Uncertainty-Focused Calibrated MIL (UFC-MIL), a novel approach that mimics pathologists' examination behaviors by providing well-calibrated diagnostic predictions with quantified uncertainty. UFC-MIL achieves superior model calibration while maintaining classification accuracy comparable to state-of-the-art methods, thus enhancing the reliability of AI-centric diagnostic aids.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Anatomic Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06433v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06433v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06433v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06433v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06427v1"
                     data-domains="Oncology,Health Communication,Patient Education,Shared Decision-Making,Medical Informatics,Palliative Care"
                     data-keywords="Metaphor extraction,Large Language Models (LLMs),Cancer patients,Dutch language,Healthcare communication,Patient experience,Computational linguistics,HealthQuote.NL"
                     data-authors="Lifeng Han,David Lindevelt,Sander Puts,Erik van Mulligen,Suzan Verberne">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06427v1.html">Dutch Metaphor Extraction from Cancer Patients' Interviews and Forum Data using LLMs and Human in the Loop</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lifeng Han, David Lindevelt, Sander Puts et al.
                </div>

                <div class="paper-summary">
                    This paper focuses on extracting Dutch metaphors from cancer patient communication data (interviews and online forums) using state-of-the-art Large Language Models. It investigates various LLM prompting strategies and employs a human-in-the-loop verification process to compile the HealthQuote.NL corpus, aiming to enhance patient care and communication.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Health Communication</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Shared Decision-Making</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06427v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06427v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06427v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06427v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06425v1"
                     data-domains="Neuroimaging,Genomics,Alzheimer's Disease,Leukemia"
                     data-keywords="Interpretable ML,Representation Learning,Non-negative Matrix Factorization,Stiefel Manifold,Sparse Embeddings,Biomedical Data,Dimensionality Reduction,Orthogonalization"
                     data-authors="Brian B. Avants,Nicholas J. Tustison,James R Stone">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06425v1.html">Non-Negative Stiefel Approximating Flow: Orthogonalish Matrix Optimization for Interpretable Embeddings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Brian B. Avants, Nicholas J. Tustison, James R Stone
                </div>

                <div class="paper-summary">
                    This paper introduces Non-negative Stiefel Approximating Flow (NSA-Flow), a novel matrix estimation framework designed to create interpretable, sparse, and stable embeddings from high-dimensional data. NSA-Flow unifies concepts from sparse matrix factorization, orthogonalization, and constrained manifold learning, providing a geometrically intuitive mechanism to balance reconstruction fidelity and column-wise decorrelation. Empirical validation demonstrates that NSA-Flow improves interpretability and generalization in biomedical datasets like Golub leukemia and Alzheimer's disease, maintaining or enhancing performance with little additional effort.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Alzheimer's Disease</span>
                    
                    <span class="domain-tag">Leukemia</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06425v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06425v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06425v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06425v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06418v1"
                     data-domains="Drug Discovery,Pharmacology,Personalized Medicine,Therapeutics,Biomedical Research"
                     data-keywords="LLMs,Drug Mechanisms,Counterfactual Reasoning,Drug Development,Personalized Medicine,Knowledge Evaluation,Biomedical Reasoning,Pharmacology"
                     data-authors="Sunil Mohan,Theofanis Karaletsos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06418v1.html">How Well Do LLMs Understand Drug Mechanisms? A Knowledge + Reasoning Evaluation Dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sunil Mohan, Theofanis Karaletsos
                </div>

                <div class="paper-summary">
                    This paper introduces a novel dataset to rigorously evaluate Large Language Models' (LLMs) comprehension of drug mechanisms, focusing on both factual recall and counterfactual reasoning in unseen situations. The study reveals that o4-mini and Qwen3-4B-thinking models demonstrate superior performance among tested LLMs, and highlights that open-world reasoning and counterfactuals affecting internal links of drug mechanism chains pose significantly greater challenges.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Therapeutics</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06418v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06418v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06418v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06418v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06293v1"
                     data-domains="Eye Disease Diagnosis,Skin Cancer Diagnosis,X-ray Diagnosis"
                     data-keywords="Fairness in AI,Machine Learning,Bias Mitigation,Healthcare AI,Clinical Diagnosis,Demographic Experts,Group-specific Representations,No-Harm Constraint"
                     data-authors="Xuwei Tan,Yuanlong Wang,Thai-Hoang Pham,Ping Zhang,Xueru Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06293v1.html">Achieving Fairness Without Harm via Selective Demographic Experts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xuwei Tan, Yuanlong Wang, Thai-Hoang Pham et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a "fairness-without-harm" machine learning approach to address the critical trade-off between achieving fairness and maintaining high predictive performance, particularly in high-stakes domains like healthcare. The method involves learning distinct representations for different demographic groups and selectively applying "demographic experts" ‚Äì consisting of group-specific representations and personalized classifiers ‚Äì through a no-harm constrained selection mechanism. Evaluations on three real-world medical datasets (eye disease, skin cancer, X-ray diagnosis) and two face datasets demonstrate its effectiveness in ensuring fairness without degrading predictive accuracy for any specific demographic group.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Eye Disease Diagnosis</span>
                    
                    <span class="domain-tag">Skin Cancer Diagnosis</span>
                    
                    <span class="domain-tag">X-ray Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06293v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06293v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06293v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06293v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.06282v1"
                     data-domains="Gynecology,Radiology,Oncology,Diagnostic Imaging"
                     data-keywords="Ovarian-Adnexal Reporting and Data System,O-RADS v2022,Deep Learning,Convolutional Neural Networks,Vision Transformers,Hybrid AI,Adnexal Mass Characterization,Pelvic Ultrasound"
                     data-authors="Ali Abbasian Ardakani,Afshin Mohammadi,Alisa Mohebbi,Anushya Vijayananthan,Sook Sam Leong,Lim Yi Ting,Mohd Kamil Bin Mohamad Fabell,U Rajendra Acharya,Sepideh Hatamikia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.06282v1.html">From ACR O-RADS 2022 to Explainable Deep Learning: Comparative Performance of Expert Radiologists, Convolutional Neural Networks, Vision Transformers, and Fusion Models in Ovarian Masses</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-09</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ali Abbasian Ardakani, Afshin Mohammadi, Alisa Mohebbi et al.
                </div>

                <div class="paper-summary">
                    This study comprehensively compares the diagnostic performance of expert radiologists applying O-RADS v2022 with various deep learning (DL) models, including Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), along with hybrid human-AI frameworks, for classifying ovarian masses. The findings indicate that ViT models significantly outperform radiologists and other CNNs, achieving the highest individual performance, and that integrating expert scores with AI yields superior diagnostic accuracy, particularly enhancing CNNs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gynecology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.06282v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.06282v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.06282v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.06282v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-11 06:27:53</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>