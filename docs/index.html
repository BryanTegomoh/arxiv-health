<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">48</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">138</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (11), Diagnostic Imaging (10), Medical Imaging (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (11)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (10)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (9)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Public Health">Public Health (8)</option>
                        
                        <option value="Pharmacology">Pharmacology (6)</option>
                        
                        <option value="Cardiology">Cardiology (6)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.10877v1"
                     data-domains="medical natural language processing,genomics,drug discovery,proteomics,clinical decision support,biomarker discovery,synthetic data generation (healthcare)"
                     data-keywords="discrete diffusion models,transfer learning,guided sampling,language modeling,sequential data,computational efficiency,generative AI,deep learning"
                     data-authors="Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10877v1.html">Guided Transfer Learning for Discrete Diffusion Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Julian Kleutgens, Claudio Battiloro, Lingkai Kong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Guided Transfer Learning (GTL) for discrete diffusion models, enabling adaptation to new domains without computationally expensive fine-tuning of large pretrained denoisers. GTL allows sampling from a target distribution via a ratio-based guidance mechanism, leaving the original denoiser untouched. Furthermore, an efficient guided sampler is presented to overcome the high computational cost of GTL, making it practical for large vocabularies and long sequences in applications like language modeling.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">medical natural language processing</span>
                    
                    <span class="domain-tag">genomics</span>
                    
                    <span class="domain-tag">drug discovery</span>
                    
                    <span class="domain-tag">proteomics</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10877v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10877v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10877v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10877v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10780v1"
                     data-domains="Maternal and Newborn Healthcare,Public Health,Digital Health,Telemedicine,Clinical Decision Support"
                     data-keywords="LLMs,Triage,Romanization,Indian Languages,Maternal Health,Newborn Health,Orthographic Variation,F1 Score"
                     data-authors="Manurag Khullar,Utkarsh Desai,Poorva Malviya,Aman Dalmia,Zheyuan Ryan Shi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10780v1.html">Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manurag Khullar, Utkarsh Desai, Poorva Malviya et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates the performance of Large Language Models (LLMs) in maternal and newborn healthcare triage when processing Indian languages presented in native versus romanized scripts. It uncovers a consistent and significant degradation (5-12 F1 points) in LLM performance for romanized messages compared to native scripts, using a real-world dataset. Crucially, this performance gap is attributed not to a failure in clinical reasoning or semantic understanding, but to brittle classification outputs despite the LLMs inferring the correct intent.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Maternal and Newborn Healthcare</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10780v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10780v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10780v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10780v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10765v1"
                     data-domains="Cardiology,Cardiovascular Radiology,Interventional Cardiology"
                     data-keywords="Coronary Artery Disease (CAD),Coronary Computed Tomography Angiography (CCTA),Blood Pressure Prediction,Computational Fluid Dynamics (CFD),Diffusion-based Regression,Hemodynamics,Non-invasive Diagnosis,Artificial Intelligence (AI)"
                     data-authors="Rene Lisasi,Michele Esposito,Chen Zhao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10765v1.html">Blood Pressure Prediction for Coronary Artery Disease Diagnosis using Coronary Computed Tomography Angiography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rene Lisasi, Michele Esposito, Chen Zhao
                </div>

                <div class="paper-summary">
                    This paper introduces an end-to-end pipeline for automated coronary geometry extraction and simulation data generation, coupled with a novel diffusion-based regression model, to predict coronary blood pressure directly from CCTA-derived features. This approach aims to overcome the computational and time-intensive limitations of traditional CFD for diagnosing Coronary Artery Disease (CAD). The model achieved state-of-the-art performance on simulated hemodynamic data, offering a rapid, non-invasive method for CAD assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Radiology</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10765v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10765v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10765v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10765v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10750v1"
                     data-domains="Gastroenterology,Oncology (Colorectal Cancer),Diagnostic Imaging"
                     data-keywords="Multimodal LLM,Polyp Diagnosis,Colonoscopy,Parameter-Efficient Fine-Tuning,LoRA,DPO,Medical Report Generation,Colorectal Cancer"
                     data-authors="Tianyu Zhou,Junyi Tang,Zehui Li,Dahong Qian,Suncheng Xiang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10750v1.html">LDP: Parameter-Efficient Fine-Tuning of Multimodal LLM for Medical Report Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tianyu Zhou, Junyi Tang, Zehui Li et al.
                </div>

                <div class="paper-summary">
                    The paper introduces LDP, a novel framework leveraging multimodal large language models (MLLMs) for generating professional colonoscopic polyp diagnosis reports. It addresses inconsistencies and hallucinations in traditional automated reporting by curating a new multimodal endoscopic dataset (MMEndo) and fine-tuning the Qwen2-VL-7B backbone using LoRA and DPO. LDP significantly outperforms existing baselines on automated metrics and expert evaluations while drastically reducing training computational costs, offering a scalable solution for primary healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Oncology (Colorectal Cancer)</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10750v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10750v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10750v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10750v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10741v1"
                     data-domains="Emergency Medicine,Pre-hospital Care,Public Health,Disaster Management,Triage"
                     data-keywords="Emergency Speech Recognition,Caribbean Accents,Emergency Triage,Automatic Speech Recognition (ASR),Large Language Models (LLMs),Bio-acoustic Distress Detection,Dispatcher Support,Code-switching,Emergency Medical Services (EMS)"
                     data-authors="Elroy Galbraith,Chadwick Sutherland,Donahue Morgan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10741v1.html">TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elroy Galbraith, Chadwick Sutherland, Donahue Morgan
                </div>

                <div class="paper-summary">
                    TRIDENT addresses critical service gaps in emergency speech recognition for Caribbean populations by proposing a three-layer dispatcher-support architecture. It integrates Caribbean-accent-tuned ASR, LLM-based entity extraction, and bio-acoustic distress detection to provide dispatchers with complementary signals (transcription confidence, structured clinical entities, vocal stress indicators). This architecture enables human application of established triage protocols (ESI, START) even when automatic speech recognition performance is compromised due to accent. The system leverages low ASR confidence and vocal distress as queue prioritization signals, while also using semantic analysis to capture clinical indicators from composed callers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Pre-hospital Care</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Disaster Management</span>
                    
                    <span class="domain-tag">Triage</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10741v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10741v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10741v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10741v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10715v1"
                     data-domains="Radiology,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Uncertainty Estimation,Landmark Segmentation,Chest X-ray,Deep Learning,Variational Autoencoders,Anatomical Segmentation,Medical Imaging,CheXmask-U"
                     data-authors="Matias Cosarinsky,Nicolas Gaggion,Rodrigo Echeveste,Enzo Ferrante">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10715v1.html">CheXmask-U: Quantifying uncertainty in landmark-based anatomical segmentation for X-ray images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Matias Cosarinsky, Nicolas Gaggion, Rodrigo Echeveste et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical need for uncertainty quantification in medical image segmentation, specifically for landmark-based anatomical segmentation in chest X-rays, which offers inherent topological guarantees but has been underexplored from an uncertainty perspective. Leveraging hybrid neural networks with variational latent spaces, the authors derive two complementary uncertainty measures (latent and predictive) and demonstrate their effectiveness in identifying unreliable predictions, reflecting perturbation severity, and supporting out-of-distribution detection. A significant contribution is the release of CheXmask-U, a large-scale dataset of chest X-ray landmark segmentations with per-node uncertainty estimates to facilitate further research and safer clinical deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10715v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10715v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10715v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10715v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10702v1"
                     data-domains="Cardiology,Interventional Cardiology,Medical Imaging,Medical Artificial Intelligence,Biomedical Engineering"
                     data-keywords="Percutaneous Coronary Intervention (PCI),Optical Coherence Tomography (OCT),Artificial Intelligence (AI),Large Language Models (LLM),RAG-Enhanced AI,Decision Support System,Interventional Cardiology,Stent Optimization"
                     data-authors="Wei Fang,Chiyao Wang,Wenshuai Ma,Hui Liu,Jianqiang Hu,Xiaona Niu,Yi Chu,Mingming Zhang,Jingxiao Yang,Dongwei Zhang,Zelin Li,Pengyun Liu,Jiawei Zheng,Pengke Zhang,Chaoshi Qin,Wangang Guo,Bin Wang,Yugang Xue,Wei Zhang,Zikuan Wang,Rui Zhu,Yihui Cao,Quanmao Lu,Rui Meng,Yan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10702v1.html">COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei Fang, Chiyao Wang, Wenshuai Ma et al.
                </div>

                <div class="paper-summary">
                    This study introduces CA-GPT, a specialized RAG-enhanced AI model integrated into an AI-OCT system, demonstrating superior performance in OCT-guided percutaneous coronary intervention (PCI) planning and assessment. It significantly outperformed both the general-purpose ChatGPT-5 and junior physicians in decision-making agreement when compared against expert-derived procedural records. The system offers a standardized and reliable method for intravascular imaging interpretation, promising to augment operator expertise and optimize PCI outcomes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10702v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10702v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10702v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10702v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10691v1"
                     data-domains="Radiology,Diagnostic Imaging,Pulmonology,Medical Informatics"
                     data-keywords="Reinforcement Learning,Vision-Language Models,Chest X-ray,Radiology Report Generation,Visual Grounding,Supervised Fine-tuning,GRPO,Qwen3-VL,Medical AI"
                     data-authors="Benjamin Gundersen,Nicolas Deperrois,Samuel Ruiperez-Campillo,Thomas M. Sutter,Julia E. Vogt,Michael Moor,Farhad Nooralahzadeh,Michael Krauthammer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10691v1.html">Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Benjamin Gundersen, Nicolas Deperrois, Samuel Ruiperez-Campillo et al.
                </div>

                <div class="paper-summary">
                    This paper demonstrates that reinforcement learning (RL) with clinically grounded rewards significantly enhances the performance of medical Vision-Language Models (VLMs) for Chest X-ray (CXR) report generation and visual grounding. By combining strong supervised fine-tuning (SFT) with Group Relative Policy Optimization (GRPO), the RL-optimized RadVLM achieves state-of-the-art results. This positions clinically aligned RL as a powerful complement to SFT for medical VLMs, even though explicit intermediate reasoning ("thinking") did not provide further improvements in this context.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10691v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10691v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10691v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10691v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10612v1"
                     data-domains="Public Health,Infectious Disease Epidemiology,Behavioral Epidemiology,Health Policy,Social Determinants of Health"
                     data-keywords="opinion dynamics,epidemiology,SIS model,q-voter model,complex systems,social interventions,behavioral change,disease transmission"
                     data-authors="Thomas Goetz,Tyll Krueger,Karol Niedzielewski,Jan Schneider,Barbara Pabjan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10612v1.html">Coupling opinion dynamics and epidemiology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.soc-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thomas Goetz, Tyll Krueger, Karol Niedzielewski et al.
                </div>

                <div class="paper-summary">
                    This research develops a mathematical model coupling a two-state q-voter opinion process with SIS-type infection dynamics to investigate the interplay between human behavior and infectious disease spread. It reveals complex system dynamics, including alternative stable states (endemic fixed points or limit cycles) and non-monotonic relationships between infectivity and epidemiological outcomes, emphasizing the profound and often underestimated role of social interventions in epidemic control.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Behavioral Epidemiology</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Social Determinants of Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10612v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10612v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10612v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10612v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10608v1"
                     data-domains="Ophthalmology,Medical Imaging,Diagnostic Medicine,Public Health Screening"
                     data-keywords="Retinal Classification,Deep Learning,Xception,Transfer Learning,Vessel Segmentation,W-Net,Interpretability,Ocular Diseases"
                     data-authors="Mohammad Sadegh Gholizadeh,Amir Arsalan Rezapour">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10608v1.html">Robust Multi-Disease Retinal Classification via Xception-Based Transfer Learning and W-Net Vessel Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Sadegh Gholizadeh, Amir Arsalan Rezapour
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning pipeline for robust multi-disease retinal classification, addressing the 'black-box' nature of standard CNNs. It combines Xception-based transfer learning for deep feature extraction with interpretable W-Net vessel segmentation, using the latter as an auxiliary task to guide and ground classification predictions in clinically relevant morphological features.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Public Health Screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10608v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10608v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10608v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10608v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10515v1"
                     data-domains="Protein Engineering,Drug Discovery,Biotechnology,Therapeutic Protein Development,Synthetic Biology"
                     data-keywords="Non-canonical amino acids,Protein engineering,Diffusion models,Generative models,Amino acid substitution,Inverse folding,Structure-based drug design,E(3)-equivariant"
                     data-authors="Han Tang,Wouter Boomsma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10515v1.html">UNAAGI: Atom-Level Diffusion for Generating Non-Canonical Amino Acid Substitutions</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Han Tang, Wouter Boomsma
                </div>

                <div class="paper-summary">
                    UNAAGI is a novel diffusion-based generative model addressing the limitation of current inverse folding methods that are restricted to designing natural amino acid (NAA) substitutions. By modeling protein side chains at the atomic level, UNAAGI enables the exploration and generation of both NAAs and non-canonical amino acids (NCAAs), demonstrating substantially improved performance for NCAA substitutions and suggesting a unified methodological foundation for protein engineering and structure-based drug design.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Protein Engineering</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                    <span class="domain-tag">Therapeutic Protein Development</span>
                    
                    <span class="domain-tag">Synthetic Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10515v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10515v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10515v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10515v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10377v1"
                     data-domains="Oncology,Gastroenterology,Medical Diagnostics,Biomarker Detection,Personalized Medicine"
                     data-keywords="KRAS G12D,Pancreatic Cancer,PDAC,HEMT biosensor,AlGaN/GaN,Early Detection,Biomarker Screening,Oncology"
                     data-authors="Sheng-Ting Hung,Cheng Yan Lee,Chen-Yu Lien,Cheng-Hsuan Chan,Ya-Han Yang,Quark Yungsung Chen,Kuang-Hung Cheng,Kung-Kai Kuo,Li-Wei Tu,Ching-Wen Chang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10377v1.html">KRAS G12D protein screening for pancreatic cancer clinical trials using an AlGaN/GaN high electron mobility transistor biosensor</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sheng-Ting Hung, Cheng Yan Lee, Chen-Yu Lien et al.
                </div>

                <div class="paper-summary">
                    This research paper describes a clinical trial screening for the KRAS G12D protein in pancreatic ductal adenocarcinoma (PDAC) patients and healthy donors using an AlGaN/GaN high electron mobility transistor (HEMT) biosensor. The study demonstrated the biosensor's effectiveness by showing that all PDAC patients exhibited significantly higher resistance change ratios compared to healthy controls, indicating its potential for early detection of pancreatic cancer.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Biomarker Detection</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10377v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10377v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10377v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10377v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10370v1"
                     data-domains="cs.AI"
                     data-keywords="cs.AI"
                     data-authors="Ziying Zhang,Quanming Yao,Yaqing Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10370v1.html">LLM-Empowered Representation Learning for Emerging Item Recommendation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ziying Zhang, Quanming Yao, Yaqing Wang
                </div>

                <div class="paper-summary">
                    In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the pro...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10370v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10370v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10370v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10370v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10353v1"
                     data-domains="Medical Imaging,Radiology,Pathology Analysis,Diagnostic Imaging,Computational Pathology"
                     data-keywords="Weakly supervised learning,Volumetric medical segmentation,Transformer,Mamba,Hybrid architecture,State space models,3D context,Label efficiency"
                     data-authors="Yiheng Lyu,Lian Xu,Mohammed Bennamoun,Farid Boussaid,Coen Arrow,Girish Dwivedi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10353v1.html">Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiheng Lyu, Lian Xu, Mohammed Bennamoun et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TranSamba, a novel hybrid Transformer-Mamba architecture for weakly supervised volumetric medical image segmentation. It addresses the limitation of 2D encoders by effectively capturing 3D context through a combination of within-slice Transformer attention and efficient cross-plane Mamba-based information exchange. TranSamba achieves state-of-the-art performance across diverse datasets and modalities while maintaining linear time complexity and constant memory usage.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology Analysis</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10353v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10353v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10353v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10353v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10331v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Network Science in Health"
                     data-keywords="Network epidemiology,SIR model,Curvature-weighted networks,Basic reproduction number,Global stability,Geometric regularization,Perron-Frobenius theory,Lyapunov functionals"
                     data-authors="Marcilio Ferreira dos Santos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10331v1.html">Curvature-Weighted Contact Networks: Spectral Reduction and Global Stability in a Markovian SIR Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ math.DS</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marcilio Ferreira dos Santos
                </div>

                <div class="paper-summary">
                    This paper introduces a novel network-based SIR epidemic model where disease transmission is modulated by a curvature-weighted contact matrix that encodes structural and geometric features of the underlying graph. It rigorously derives the basic reproduction number ($R_0$) based on this operator and proves the global asymptotic stability of both disease-free and endemic equilibria. Critically, the study demonstrates that network curvature acts as a geometric regularizer, effectively lowering spectral radii, raising epidemic thresholds, and organizing long-term disease dynamics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Network Science in Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10331v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10331v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10331v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10331v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10326v1"
                     data-domains="Pathology,Histopathology,Oncology"
                     data-keywords="Computational pathology,Foundation models,Self-supervised learning,Special stains,Immunohistochemistry,Vision Transformer,Whole-slide imaging,Digital pathology"
                     data-authors="Jiawen Li,Jiali Hu,Xitong Ling,Yongqiang Lv,Yuxuan Chen,Yizhi Wang,Tian Guan,Yifei Liu,Yonghong He">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10326v1.html">StainNet: A Special Staining Self-Supervised Vision Transformer for Computational Pathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiawen Li, Jiali Hu, Xitong Ling et al.
                </div>

                <div class="paper-summary">
                    This paper introduces StainNet, a specialized Vision Transformer-based foundation model designed for computational pathology analysis of special staining images. Unlike existing models pre-trained primarily on H&E stains, StainNet utilizes a self-distillation self-supervised learning approach on a vast dataset of over 1.4 million special stain patches. It demonstrates strong performance in various tasks, including liver malignancy classification, ROI analysis, few-shot learning, and retrieval, outperforming H&E-centric models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10326v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10326v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10326v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10326v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10316v1"
                     data-domains="Pathology,Digital Pathology,Computational Pathology,Oncology"
                     data-keywords="Weakly Supervised Segmentation,Histopathology,Prototype Learning,Foundation Models,Semantic Segmentation,Structural Distillation,Digital Pathology,Computational Pathology"
                     data-authors="Khang Le,Ha Thach,Anh M. Vu,Trang T. K. Vo,Han H. Huynh,David Yang,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10316v1.html">ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Khang Le, Ha Thach, Anh M. Vu et al.
                </div>

                <div class="paper-summary">
                    ConStruct proposes a novel prototype learning framework for weakly supervised semantic segmentation (WSSS) in histopathology, integrating morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment. This approach generates high-quality, semantically discriminative, and spatially coherent prototypes, leading to improved localization completeness and semantic consistency without pixel-level annotations. The framework outperforms existing WSSS methods while maintaining computational efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10316v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10316v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10316v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10316v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10314v1"
                     data-domains="Pathology,Oncology,Histology,Diagnostic Imaging"
                     data-keywords="Weakly Supervised Semantic Segmentation,Histopathology,Prototype Learning,Vision-Language Alignment,Digital Pathology,Text-Guided Segmentation,Transformers (ViT),Multi-scale Feature Learning"
                     data-authors="Anh M. Vu,Khang P. Le,Trang T. K. Vo,Ha Thach,Huy Hung Nguyen,David Yang,Han H. Huynh,Quynh Nguyen,Tuan M. Pham,Tuan-Anh Le,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10314v1.html">DualProtoSeg: Simple and Efficient Design with Text- and Image-Guided Prototype Learning for Weakly Supervised Histopathology Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anh M. Vu, Khang P. Le, Trang T. K. Vo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DualProtoSeg, a novel weakly supervised semantic segmentation (WSSS) framework designed for histopathology images, which tackles common issues like region shrinkage and feature heterogeneity. It achieves this by integrating a dual-modal prototype bank that combines text-guided and image-based prototypes with a multi-scale pyramid module for enhanced spatial precision. The method demonstrates state-of-the-art performance on the BCSS-WSSS benchmark, showcasing the effectiveness of leveraging vision-language alignment for improved region discovery in digital pathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10314v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10314v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10314v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10314v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10313v1"
                     data-domains="Public Health,Epidemiology,Emergency Preparedness,Healthcare Administration"
                     data-keywords="EpiPlanAgent,epidemic response planning,agent-based system,large language models (LLMs),public health preparedness,AI automation,emergency response,simulation"
                     data-authors="Kangkun Mao,Fang Xu,Jinru Ding,Yidong Jiang,Yujun Yao,Yirong Chen,Junming Liu,Xiaoqin Wu,Qian Wu,Xiaoyan Huang,Jie Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10313v1.html">EpiPlanAgent: Agentic Automated Epidemic Response Planning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kangkun Mao, Fang Xu, Jinru Ding et al.
                </div>

                <div class="paper-summary">
                    EpiPlanAgent is an LLM-powered multi-agent system designed to automate the generation and validation of digital emergency response plans for epidemics. It significantly improves plan completeness and guideline alignment while drastically reducing development time compared to manual methods, with expert evaluation confirming high consistency and strong perceived utility.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Emergency Preparedness</span>
                    
                    <span class="domain-tag">Healthcare Administration</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10313v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10313v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10313v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10313v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10309v1"
                     data-domains="Systems Biology,Computational Biology,Pharmacology,Epidemiology,Oncology,Cell Biology,Pathophysiology"
                     data-keywords="Chemical Master Equation,Neural Networks,Stochastic Dynamics,Reaction Networks,Rare Events,MAPK Cascade,Systems Biology,Epidemiology"
                     data-authors="Jiayu Weng,Xinyi Zhu,Jing Liu,Linyuan L√º,Pan Zhang,Ying Tang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10309v1.html">Tracking large chemical reaction networks and rare events by neural networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.MN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiayu Weng, Xinyi Zhu, Jing Liu et al.
                </div>

                <div class="paper-summary">
                    This paper significantly advances neural network approaches for solving the chemical master equation, a critical challenge in modeling stochastic dynamics in complex systems. By incorporating faster optimization techniques and enhanced-sampling strategies, the authors achieve a 5- to 22-fold speedup and higher accuracy. This enables efficient and accurate simulation of large-scale biological networks, such as the MAPK cascade, and spatially extended reaction-diffusion systems with rare events, pushing the boundaries of what was previously possible.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10309v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10309v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10309v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10309v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10308v1"
                     data-domains="Cardiology,Cardiovascular Surgery,Interventional Cardiology,Structural Heart Disease"
                     data-keywords="interpretable AI,SAVR,TAVR,aortic stenosis,prescriptive analytics,counterfactual modeling,mortality reduction,precision medicine"
                     data-authors="Vasiliki Stoumpou,Maciej Tysarowski,Talhat Azemi,Jawad Haider,Howard L. Haronian,Robert C. Hagberg,Dimitris Bertsimas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10308v1.html">An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vasiliki Stoumpou, Maciej Tysarowski, Talhat Azemi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an interpretable AI-driven prescriptive framework to optimize treatment selection between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement for low to intermediate risk patients with severe aortic stenosis. By integrating prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree, the tool recommends the treatment minimizing expected 5-year mortality. The framework demonstrated significant estimated reductions in 5-year mortality (20.3% internally, 13.8% externally) compared to real-life prescriptions, while maintaining clinical interpretability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Interventional Cardiology</span>
                    
                    <span class="domain-tag">Structural Heart Disease</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10308v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10308v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10308v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10308v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10293v1"
                     data-domains="Radiology,Surgical Planning,Interventional Medicine,Medical Robotics,Medical Visualization,Mixed Reality in Healthcare"
                     data-keywords="360-degree view synthesis,single-image reconstruction,disentangled scene embeddings,Gaussian Splatting,medical imaging,CT simulation,radiography,mixed reality"
                     data-authors="Karthikeya KV,Narendra Bandaru">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10293v1.html">Physically Aware 360$^\circ$ View Generation from a Single Image using Disentangled Scene Embeddings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Karthikeya KV, Narendra Bandaru
                </div>

                <div class="paper-summary">
                    Disentangled360 is an innovative 3D-aware technology that generates physically aware 360-degree views from a single image by disentangling isotropic and anisotropic light contributions within a Gaussian Splatting framework. It employs a dual-branch conditioning system for both CT intensity-driven volumetric data and real-world RGB scenes, addressing scale ambiguity and structural realism with a hybrid pose agnostic anchoring method. The framework demonstrates superior image quality (SSIM, LPIPS) and interactive runtime on medical and natural scene datasets, enabling rapid, photorealistic view synthesis for applications like mixed-reality medical supervision.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Interventional Medicine</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Medical Visualization</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10293v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10293v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10293v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10293v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10252v1"
                     data-domains="Cardiology,Cardiovascular Medicine,Diagnostic Imaging,Medical Image Analysis"
                     data-keywords="Echocardiography,Video Segmentation,Cardiac Function,Deep Learning,Spatiotemporal Memory,Gated Delta Rule,Medical Imaging,Cardiology"
                     data-authors="Rui Wang,Yimu Sun,Jingxing Guo,Huisi Wu,Jing Qin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10252v1.html">GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Wang, Yimu Sun, Jingxing Guo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GDKVM, a novel deep learning architecture for echocardiography video segmentation, designed to improve accuracy and efficiency in the face of imaging challenges. GDKVM employs Linear Key-Value Association (LKVA) for inter-frame correlation, Gated Delta Rule (GDR) for efficient memory storage, and Key-Pixel Feature Fusion (KPFF) for robust multi-scale feature integration. Experimental results demonstrate that GDKVM outperforms state-of-the-art methods in segmentation accuracy and robustness on CAMUS and EchoNet-Dynamic datasets, while ensuring real-time performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Cardiovascular Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10252v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10252v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10252v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10252v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10206v1"
                     data-domains="General Medicine,Clinical Decision Support,Diagnostic Medicine,Multidisciplinary Care,Medical Ethics,Healthcare Operations,Patient Management"
                     data-keywords="Clinical Pathways,Large Language Models (LLMs),Hospital Environment Simulation,Medical AI Agents,Clinical Evaluation,Healthcare Simulation,Diagnostic Reasoning,Agentic LLMs"
                     data-authors="Yakun Zhu,Zhongzhen Huang,Qianhan Feng,Linjie Mu,Yannian Gu,Shaoting Zhang,Qi Dou,Xiaofan Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10206v1.html">CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yakun Zhu, Zhongzhen Huang, Qianhan Feng et al.
                </div>

                <div class="paper-summary">
                    CP-Env is a novel, controllable agentic hospital environment designed to evaluate Large Language Models (LLMs) across complex, end-to-end clinical pathways, moving beyond static or isolated benchmarks. The evaluation reveals that most LLMs struggle significantly with pathway complexity, often exhibiting hallucinations and losing critical diagnostic details, with interesting insights into reasoning steps and tool dependency in top models. This benchmark aims to advance the development of robust medical AI agents for real-world healthcare applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Multidisciplinary Care</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10206v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10206v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10206v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10206v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10195v1"
                     data-domains="Clinical Medicine,Medical Informatics,Healthcare Technology,Patient Communication"
                     data-keywords="LLM evaluation,clinical conversational agents,multi-agent simulation,medical AI,automated evaluation,healthcare LLMs,dynamic interaction,CARE metric"
                     data-authors="Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10195v1.html">AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-11</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gyutaek Oh, Sangjoon Park, Byung-Hoon Kim
                </div>

                <div class="paper-summary">
                    AutoMedic introduces a multi-agent simulation framework for automated, multi-faceted evaluation of large language models (LLMs) as clinical conversational agents in dynamic, multi-turn scenarios. By transforming static medical QA datasets into virtual patient profiles, it enables realistic dialogues and assesses performance using the CARE metric, which was validated by human experts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Healthcare Technology</span>
                    
                    <span class="domain-tag">Patient Communication</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10195v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10195v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10195v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10195v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10156v1"
                     data-domains="Clinical trials,Pharmacology,Public health research,Personalized medicine,Health economics,Epidemiology"
                     data-keywords="Adaptive experiments,Causal inference,Batched experiments,Treatment effects,Heteroskedasticity,Confidence intervals,Statistical inference,Clinical trials"
                     data-authors="Jan Kemper,Davud Rostam-Afschar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10156v1.html">Inference for Batched Adaptive Experiments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ econ.EM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jan Kemper, Davud Rostam-Afschar
                </div>

                <div class="paper-summary">
                    This paper introduces the Batched Ordinary Least Squares (BOLS) test statistic to address challenges in causal inference for adaptive experiments, which are increasingly adopted across various fields, including medicine. The BOLS statistic offers a precision-equalizing aggregation of per-period treatment-control differences, effectively handling heteroskedasticity. It enables the construction of asymptotically valid confidence intervals for treatment effects and has been validated through simulations comparing rejection rates in common experimental settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Public health research</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Health economics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10156v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10156v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10156v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10156v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10151v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Preventive Medicine"
                     data-keywords="Breast Cancer,Mammography,Topological Data Analysis (TDA),Persistent Homology,Wavelet-Persistence,Deep Learning,Model Generalization,External Validation"
                     data-authors="Charles Fanning,Mehmet Emin Aktas">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10151v1.html">Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Charles Fanning, Mehmet Emin Aktas
                </div>

                <div class="paper-summary">
                    This paper introduces a novel conditioning signal, derived from wavelet-based vectorization of persistent homology, aimed at improving the external performance and generalizability of mammography models for breast cancer detection. By integrating these stable, multi-scale topological maps as input channels, the method significantly enhanced patient-level AUC from 0.55 to 0.75 on an independent digital mammography cohort (INbreast) when augmenting a ConvNeXt Tiny model, demonstrating increased robustness across diverse data sources.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10151v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10151v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10151v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10151v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10147v1"
                     data-domains="Infectious Disease Epidemiology,Public Health,Virology,Genomic Surveillance,Computational Biology in Medicine"
                     data-keywords="COVID-19,SARS-CoV-2,Spike protein,Viral sequencing,Embeddings,Hashing,Machine learning,Lineage classification"
                     data-authors="Sarwan Ali,Taslim Murad">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10147v1.html">Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sarwan Ali, Taslim Murad
                </div>

                <div class="paper-summary">
                    This paper introduces Murmur2Vec, a novel hashing-based method for generating highly compact, low-dimensional embeddings of SARS-CoV-2 spike protein sequences. These embeddings enable scalable and efficient supervised machine learning for lineage classification, addressing the computational limitations of existing phylogenetic and alignment-dependent approaches for large-scale viral sequence analysis. The method achieves high classification accuracy while drastically reducing the time required for embedding generation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Virology</span>
                    
                    <span class="domain-tag">Genomic Surveillance</span>
                    
                    <span class="domain-tag">Computational Biology in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10147v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10147v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10147v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10147v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10123v1"
                     data-domains="Diagnostic Imaging,Medical Diagnostics,Biomedical Optics,Ultrasound Imaging,Photoacoustic Imaging"
                     data-keywords="Inverse Scattering,Neural Networks,Differentiable Programming,Physics-Informed Machine Learning,Wave-based Imaging,Medical Imaging,Computational Physics,Nonlinear Problems"
                     data-authors="Olivia Tsang,Owen Melia,Vasileios Charisopoulos,Jeremy Hoskins,Yuehaw Khoo,Rebecca Willett">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10123v1.html">A Model-Guided Neural Network Method for the Inverse Scattering Problem</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ physics.comp-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Olivia Tsang, Owen Melia, Vasileios Charisopoulos et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Model-Guided Neural Network (MGNN) method to address the challenges of inverse medium scattering, particularly in highly nonlinear regimes where traditional machine learning struggles to incorporate explicit physics. The method integrates a differentiable forward solver directly into an ML framework and employs a progressive, multi-frequency approach to refine reconstructions. Empirically, it achieves high-quality imaging with significantly lower computational and sampling costs compared to existing techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Biomedical Optics</span>
                    
                    <span class="domain-tag">Ultrasound Imaging</span>
                    
                    <span class="domain-tag">Photoacoustic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10123v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10123v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10123v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10123v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10098v1"
                     data-domains="Neurology,Ophthalmology,Medical Imaging,Epilepsy,Diabetes"
                     data-keywords="Medical AI,Explainable AI (XAI),Domain Shift,Rare Disease Diagnosis,Knowledge-Guided,fMRI,Diabetic Retinopathy,Clinical Priors"
                     data-authors="Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10098v1.html">MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Midhat Urooj, Ayan Banerjee, Farhat Shaikh et al.
                </div>

                <div class="paper-summary">
                    MedXAI is a novel retrieval-augmented and self-verifying framework that integrates deep vision models with clinician-derived expert knowledge to enhance medical image analysis. It addresses key deep learning limitations such as poor generalization under domain shifts and rare-class bias, while providing human-understandable, clinically aligned explanations by localizing diagnostic features. The framework demonstrates superior performance in accuracy and interpretability, particularly for rare diseases and cross-domain applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Epilepsy</span>
                    
                    <span class="domain-tag">Diabetes</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10098v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10098v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10098v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10098v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10056v1"
                     data-domains="Diabetes Management,Hemodynamic Management,Intensive Care Medicine,Endocrinology,Cardiovascular Medicine"
                     data-keywords="autoregressive forecasting,exposure bias,soft tokens,risk-aware decoding,diabetes management,hemodynamic management,predictive control,uncertainty quantification"
                     data-authors="Alireza Namazi,Amirreza Dolatpour Fathkouhi,Heman Shakeri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10056v1.html">Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alireza Namazi, Amirreza Dolatpour Fathkouhi, Heman Shakeri
                </div>

                <div class="paper-summary">
                    This paper introduces Soft-Token Trajectory Forecasting (SoTra), a novel autoregressive forecasting method designed to mitigate exposure bias, a common issue in predictive control systems for medical applications. SoTra propagates continuous probability distributions ("soft tokens") to learn calibrated, uncertainty-aware trajectories, incorporating a risk-aware decoding module to minimize expected clinical harm. The method demonstrates significant reductions in average zone-based risk for glucose forecasting (18%) and effective clinical risk for blood-pressure forecasting (15%).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diabetes Management</span>
                    
                    <span class="domain-tag">Hemodynamic Management</span>
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Cardiovascular Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10056v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10056v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10056v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10056v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10048v1"
                     data-domains="Cardiovascular Surgery,Vascular Surgery,Neuroradiology,Interventional Radiology,Computational Medicine,Biomechanics"
                     data-keywords="in-silico modelling,aortic aneurysm repair,spinal cord ischemia,haemodynamics,SimVascular,endovascular repair,wall shear stress,computational fluid dynamics"
                     data-authors="Michael Greshan Rasiah,Tom J A J Konings,Amanda Nio,Stefano Moriconi,Ashish S Patel,Alberto Smith,Mohamed A Abdelhalim,Tammo Delhaas,M Jorge Cardoso,Pablo Lamata,Barend M E Mees,Bijan Modarai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10048v1.html">In silico modelling of changes in spinal cord blood flow after endovascular aortic aneurysm repair</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Michael Greshan Rasiah, Tom J A J Konings, Amanda Nio et al.
                </div>

                <div class="paper-summary">
                    This study developed an in-silico model of the aorta and its spinal cord-supplying branches to characterize haemodynamic changes following endovascular aortic aneurysm repair (EVAR). It found a significant 51.86% decrease in spinal cord blood flow post-EVAR due to vessel exclusion, alongside compensatory flow increases in non-spinal territories and changes in wall shear stress metrics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10048v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10048v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10048v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10048v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10041v1"
                     data-domains="Radiology,Neurology,Medical Informatics,Biomarker Discovery,Diagnostic Imaging"
                     data-keywords="MetaVoxel,Joint Diffusion Model,Medical Imaging AI,Clinical Metadata,Generative Models,MRI Analysis,Multimodal AI,Zero-shot Inference"
                     data-authors="Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10041v1.html">MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yihao Liu, Chenyu Gao, Lianrui Zuo et al.
                </div>

                <div class="paper-summary">
                    MetaVoxel introduces a novel generative joint diffusion modeling framework that learns a single diffusion process spanning both imaging data (T1-weighted MRI) and clinical metadata. This approach unifies multiple traditionally separate medical AI tasks, enabling flexible zero-shot inference without requiring task-specific retraining. The model demonstrates performance comparable to specialized baselines in image generation, age estimation, and sex prediction, showcasing a promising direction for broader clinical applicability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10041v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10041v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10041v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10041v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.10034v1"
                     data-domains="Pharmacology,Drug Discovery,Structural Biology,Biophysics,Computational Chemistry,Protein Engineering,Medicinal Chemistry"
                     data-keywords="Molecular Dynamics,Protein-Ligand Interactions,Drug Discovery,Autonomous Agent,Large Language Models (LLM),Binding Affinity,Computational Biology,Protein Engineering"
                     data-authors="Salom√© Guilbert,Cassandra Masschelein,Jeremy Goumaz,Bohdan Naida,Philippe Schwaller">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.10034v1.html">DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Salom√© Guilbert, Cassandra Masschelein, Jeremy Goumaz et al.
                </div>

                <div class="paper-summary">
                    DynaMate is a novel multi-agent LLM framework designed to autonomously manage and execute complex protein and protein-ligand molecular dynamics (MD) simulations. It effectively addresses the technical barriers associated with MD setup, reliably performing full simulations, correcting errors, and providing meaningful analyses of molecular interactions. This automation significantly streamlines biomolecular and drug design processes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                    <span class="domain-tag">Computational Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.10034v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.10034v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.10034v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.10034v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09867v1"
                     data-domains="Clinical Reasoning,Diagnosis Support,Medical Report Generation,Medical Imaging Analysis,Healthcare Informatics,Medical Ethics"
                     data-keywords="Medical AI,Multimodal LLMs,Machine Unlearning,Patient Privacy,HIPAA,GDPR,Right to be forgotten,Hierarchical data,Reconstruction attack"
                     data-authors="Fengli Wu,Vaidehi Patil,Jaehong Yoon,Yue Zhang,Mohit Bansal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09867v1.html">MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fengli Wu, Vaidehi Patil, Jaehong Yoon et al.
                </div>

                <div class="paper-summary">
                    MedForget is a novel hierarchy-aware multimodal unlearning testbed designed for medical AI, specifically addressing critical privacy challenges like the "right to be forgotten" for sensitive patient data under regulations such as HIPAA and GDPR. The research demonstrates that current state-of-the-art unlearning methods struggle to achieve complete, fine-grained hierarchical forgetting without compromising diagnostic performance, and can leave models vulnerable to reconstruction attacks via contextual cues.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Reasoning</span>
                    
                    <span class="domain-tag">Diagnosis Support</span>
                    
                    <span class="domain-tag">Medical Report Generation</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09867v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09867v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09867v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09867v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09801v1"
                     data-domains="Neuroradiology,Oncology,Medical Imaging,Diagnostic Imaging"
                     data-keywords="Semi-supervised learning,Multi-modal segmentation,Brain tumor,MRI,Channel attention,Information fusion,BraTS,Medical imaging"
                     data-authors="Tien-Dat Chung,Ba-Thinh Lam,Thanh-Huy Nguyen,Thien Nguyen,Nguyen Lan Vi Vu,Hoang-Loc Cao,Phat Kim Huynh,Min Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09801v1.html">Modality-Specific Enhancement and Complementary Fusion for Semi-Supervised Multi-Modal Brain Tumor Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tien-Dat Chung, Ba-Thinh Lam, Thanh-Huy Nguyen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel semi-supervised multi-modal framework for brain tumor segmentation, designed to effectively leverage complementary information across MRI modalities despite inherent semantic discrepancies. It proposes a Modality-specific Enhancing Module (MEM) and a Complementary Information Fusion (CIF) module, optimized with a hybrid loss, to improve segmentation performance under limited labeled data. Extensive experiments on the BraTS 2019 dataset demonstrate superior performance over strong baselines, confirming the modules' effectiveness in enhancing robustness.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09801v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09801v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09801v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09801v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09784v1"
                     data-domains="Pharmaceuticals,Drug Delivery,Biomedical Engineering,Pharmacology,Materials Science (applied to medicine)"
                     data-keywords="Polymer solubility,SMILES strings,Deep learning,Machine learning,Pharmaceutical formulation,Drug delivery,Solvent screening,Materials informatics"
                     data-authors="Andrew Reinhard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09784v1.html">Predicting Polymer Solubility in Solvents Using SMILES Strings</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Andrew Reinhard
                </div>

                <div class="paper-summary">
                    This paper introduces a deep learning framework for accurately predicting polymer solubility (wt%) in various solvents directly from their SMILES representations. Utilizing a dataset of over 8,000 simulated polymer-solvent pairs and validating with experimental data, the model demonstrates strong agreement and generalizability, offering a scalable solution for high-throughput solvent screening.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceuticals</span>
                    
                    <span class="domain-tag">Drug Delivery</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Materials Science (applied to medicine)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09784v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09784v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09784v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09784v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09779v1"
                     data-domains="Cardiology,Medical Imaging,Radiology,Medical AI"
                     data-keywords="Few-shot learning,Cardiac MRI segmentation,Synthetic data generation,Lattice-of-Experts,Zero-shot generalization,Pathology-constrained,Fully supervised,Medical image analysis"
                     data-authors="Mohamed Elbayumi,Mohammed S. M. Elbaz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09779v1.html">PathCo-LatticE: Pathology-Constrained Lattice-Of Experts Framework for Fully-supervised Few-Shot Cardiac MRI Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohamed Elbayumi, Mohammed S. M. Elbaz
                </div>

                <div class="paper-summary">
                    This paper introduces PathCo-LatticE, a novel fully supervised Few-Shot Learning (FSL) framework for cardiac MRI segmentation that overcomes data scarcity and domain shift issues by leveraging pathology-guided synthetic supervision. It employs a Virtual Patient Engine to generate physiologically plausible 3D cohorts, a Self-Reinforcing Interleaved Validation protocol for leakage-free evaluation, and a dynamic Lattice-of-Experts for robust zero-shot generalization, significantly outperforming state-of-the-art methods with minimal labeled real data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09779v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09779v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09779v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09779v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09757v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Discovery,Computational Biology,Bioinformatics,Pharmaceutical Sciences"
                     data-keywords="Molecular Transformers,Mechanistic Interpretability,Drug Discovery,Sparse Autoencoders,Chemical Representation,Generative Models,Medicinal Chemistry,Deep Learning"
                     data-authors="Kristof Varadi,Mark Marosi,Peter Antal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09757v1.html">Circuits, Features, and Heuristics in Molecular Transformers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kristof Varadi, Mark Marosi, Peter Antal
                </div>

                <div class="paper-summary">
                    This paper presents a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to elucidate how these models capture rules of molecular representation. It identifies computational patterns consistent with both low-level syntactic parsing and abstract chemical validity constraints. The study further utilizes sparse autoencoders (SAEs) to extract feature dictionaries associated with chemically relevant activation patterns, demonstrating that these mechanistic insights translate to improved predictive performance in various downstream molecular design tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09757v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09757v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09757v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09757v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09665v1"
                     data-domains="Medical imaging,Diagnostics,Radiology,AI in healthcare,Pathology"
                     data-keywords="Fair classification,Ensemble learning,Low-data regimes,Medical imaging,Demographic fairness,Data efficiency,Compute efficiency,AI ethics"
                     data-authors="Jonathan Rystr√∏m,Zihao Fu,Chris Russell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09665v1.html">OxEnsemble: Fair Ensembles for Low-Data Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jonathan Rystr√∏m, Zihao Fu, Chris Russell
                </div>

                <div class="paper-summary">
                    This paper introduces OxEnsemble, a novel approach for fair classification specifically designed for low-data regimes with unbalanced demographic groups, common in critical domains like medical imaging. OxEnsemble achieves fairness by training individual ensemble members with fairness constraints and then aggregating their predictions. It is presented as both data-efficient, through careful reuse of held-out data, and compute-efficient, demonstrating stronger fairness-accuracy trade-offs and more consistent outcomes than existing methods on medical imaging datasets, supported by theoretical guarantees.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">AI in healthcare</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09665v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09665v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09665v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09665v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09644v1"
                     data-domains="Radiology,Oncology,Cardiology,Neurology,Pathology,Biomedical Imaging,Clinical Research"
                     data-keywords="Medical Imaging,Artificial Intelligence,Open-Source Platform,Data Integration,Workflow Orchestration,Reproducibility,Multi-center Studies,Data Privacy"
                     data-authors="√únal Ak√ºnal,Markus Bujotzek,Stefan Denner,Benjamin Hamm,Klaus Kades,Philipp Schader,Jonas Scherer,Marco Nolden,Peter Neher,Ralf Floca,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09644v1.html">Kaapana: A Comprehensive Open-Source Platform for Integrating AI in Medical Imaging Research Environments</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> √únal Ak√ºnal, Markus Bujotzek, Stefan Denner et al.
                </div>

                <div class="paper-summary">
                    Kaapana is a comprehensive open-source platform designed to integrate AI into medical imaging research by addressing challenges like strict regulatory constraints, fragmented software infrastructure, and ad-hoc toolchains. It provides a modular, extensible framework that unifies data ingestion, cohort curation, processing workflows, and result inspection under a common user interface. This platform aims to enable reproducible, scalable, and collaborative multi-center studies while allowing institutions to maintain control over sensitive patient data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09644v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09644v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09644v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09644v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09636v1"
                     data-domains="Psychiatry,Clinical Psychology,Mental Healthcare,Digital Therapeutics,Public Health"
                     data-keywords="Mental Health,Large Language Models (LLMs),Clinical Reasoning,Benchmarking,Post-training,Reinforcement Learning,Psychiatric Assessment,AI Reliability"
                     data-authors="Mengxi Xiao,Kailai Yang,Pengde Zhao,Enze Zhang,Ziyan Kuang,Zhiwei Liu,Weiguang Han,Shu Liao,Lianting Huang,Jinpeng Hu,Min Peng,Qianqian Xie,Sophia Ananiadou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09636v1.html">MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mengxi Xiao, Kailai Yang, Pengde Zhao et al.
                </div>

                <div class="paper-summary">
                    MentraSuite addresses the critical need for reliable Large Language Models (LLMs) in mental health by proposing a unified framework that enhances clinically aligned reasoning. It introduces MentraBench, a comprehensive benchmark for evaluating LLM performance and reasoning quality, and Mindora, a post-trained LLM optimized through a hybrid SFT-RL framework with inconsistency detection. Mindora achieves the highest average performance on MentraBench and demonstrates superior reasoning reliability across complex mental health scenarios.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Mental Healthcare</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09636v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09636v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09636v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09636v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09610v1"
                     data-domains="Neurology,Speech-Language Pathology,Rehabilitation Medicine,Assistive Technology"
                     data-keywords="Motor Neuron Disease,Augmentative and Alternative Communication,Multimodal Communication,Image Recognition,Natural Language Generation,Assistive Technology,Speech Impairment,Human-Computer Interaction"
                     data-authors="Boyin Yang,Puming Jiang,Per Ola Kristensson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09610v1.html">ImageTalk: Designing a Multimodal AAC Text Generation System Driven by Image Recognition and Natural Language Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Boyin Yang, Puming Jiang, Per Ola Kristensson
                </div>

                <div class="paper-summary">
                    This paper introduces ImageTalk, a novel multimodal Augmentative and Alternative Communication (AAC) system designed for people living with Motor Neuron Disease (plwMND) to overcome the limited vocabulary of traditional symbol-based AACs and the low communication rates of text entry solutions. By integrating image recognition and natural language generation, ImageTalk significantly enhances communication efficiency, demonstrating 95.6% keystroke savings, consistent performance, and high user satisfaction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09610v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09610v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09610v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09610v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09591v1"
                     data-domains="Sleep Medicine,Neurology,Pulmonology,Cardiology (indirectly, via apnea and mortality links),Internal Medicine (for general disease/mortality)"
                     data-keywords="Polysomnography (PSG),Self-supervised Learning,Foundation Models,Sleep Analysis,Disease Prediction,Mortality Prediction,Contrastive Learning,Sleep Staging"
                     data-authors="Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09591v1.html">Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Magnus Ruud Kjaer, Rahul Thapa, Gauri Ganjoo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Stanford Sleep Bench, a large-scale Polysomnography (PSG) dataset and benchmark designed to overcome limitations in developing sleep foundation models. It systematically evaluates self-supervised representation learning (SSRL) pre-training methods across various sleep-related and clinical prediction tasks, revealing that contrastive learning significantly outperforms other approaches for complex mortality and disease prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Cardiology (indirectly, via apnea and mortality links)</span>
                    
                    <span class="domain-tag">Internal Medicine (for general disease/mortality)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09591v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09591v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09591v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09591v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09579v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Computational Pathology"
                     data-keywords="Vision Transformers,Convolutional Neural Networks,Object Recognition,Object Detection,Medical Image Classification,Self-Attention,Swin Transformer,Data Augmentation"
                     data-authors="Dimitrios N. Vlachogiannis,Dimitrios A. Koutsomitropoulos">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09579v1.html">Hands-on Evaluation of Visual Transformers for Object Recognition and Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios N. Vlachogiannis, Dimitrios A. Koutsomitropoulos
                </div>

                <div class="paper-summary">
                    This paper evaluates various Vision Transformer (ViT) architectures against traditional Convolutional Neural Networks (CNNs) across object recognition, detection, and medical image classification tasks. The study finds that hybrid and hierarchical ViTs, particularly Swin and CvT, achieve a strong balance of accuracy and computational efficiency, often outperforming CNNs, especially in medical imaging where understanding global visual contexts is crucial. Significant performance improvements were also noted when applying data augmentation to ViTs on medical datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09579v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09579v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09579v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09579v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09570v1"
                     data-domains="Public Health,Health Equity,Digital Health,Medical Ethics,Precision Medicine"
                     data-keywords="AI governance,gender bias,AI ethics,intersectionality,health equity,human rights,digital health,medical AI"
                     data-authors="Jelena Cupac">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09570v1.html">The Gender Code: Gendering the Global Governance of Artificial Intelligence</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CY</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jelena Cupac
                </div>

                <div class="paper-summary">
                    This paper meticulously analyzes how international AI governance frameworks address gender issues and gender-based harms, identifying both emerging trends and critical gaps. It argues for the necessity of intersectional, enforceable, and inclusive AI governance to prevent the reinforcement of existing inequalities and foster meaningful equity in a technologically advanced future.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Health Equity</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09570v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09570v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09570v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09570v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09566v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Development,Pharmaceutical Sciences,Structural Biology"
                     data-keywords="molecular discovery,drug design,generative models,reinforcement learning,Monte Carlo tree search,binding affinity,drug-likeness,synthetic accessibility"
                     data-authors="Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09566v1.html">Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junkai Ji, Zhangfan Yang, Dong Xu et al.
                </div>

                <div class="paper-summary">
                    Trio is a novel molecular generation framework that integrates fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search to address limitations in de novo drug design. It enables context-aware fragment assembly and strategic search for pharmacologically enhanced ligands, significantly outperforming state-of-the-art methods in binding affinity, drug-likeness, synthetic accessibility, and molecular diversity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Pharmaceutical Sciences</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.09525v1"
                     data-domains="Orthopedic Surgery,Trauma Surgery,Medical Imaging,Surgical Planning,Radiology"
                     data-keywords="Tibia Reconstruction,Surgical Planning,CT Imaging,Neural Registration,Spatial Transformer Network,Autoencoder,Masked Input,Bone Fracture"
                     data-authors="Hongyou Zhou,Cederic A√ümann,Alaa Bejaoui,Heiko Tzsch√§tzsch,Mark Heyland,Julian Zierke,Niklas Tuttle,Sebastian H√∂lzl,Timo Auer,David A. Back,Marc Toussaint">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.09525v1.html">Masked Registration and Autoencoding of CT Images for Predictive Tibia Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-10</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hongyou Zhou, Cederic A√ümann, Alaa Bejaoui et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel deep learning framework to predict a patient-specific healthy tibia reconstruction target from a fractured CT scan, addressing a critical challenge in surgical planning. It combines a 3D-adapted Spatial Transformer Network (STN) for neural registration with autoencoders (AEs) to model healthy bone variations, enabling robust prediction even with masked (fractured) input.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthopedic Surgery</span>
                    
                    <span class="domain-tag">Trauma Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.09525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.09525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.09525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.09525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-12 06:32:22</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>