<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">162</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (10), Oncology (7), Clinical Decision Support (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (10)</option>
                        
                        <option value="Oncology">Oncology (7)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (7)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (6)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (5)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (5)</option>
                        
                        <option value="Telemedicine">Telemedicine (5)</option>
                        
                        <option value="Epidemiology">Epidemiology (5)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.16635v1"
                     data-domains="Oncology,Pathology,Cancer Prognosis,Personalized Medicine"
                     data-keywords="survival analysis,multimodal prediction,hierarchical AI,chain-of-thought (CoT),multi-agent system,pathology images,gene expression,explainable AI,precision oncology"
                     data-authors="Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16635v1.html">SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guolin Huang, Wenting Chen, Jiaqi Yang et al.
                </div>

                <div class="paper-summary">
                    SurvAgent introduces a hierarchical CoT-enhanced multi-agent system designed for multimodal survival prediction in cancer, addressing limitations of existing methods in integrating diverse data, exploring regions of interest, and leveraging experiential learning. It establishes a new paradigm for explainable AI-driven survival prediction by constructing a comprehensive case bank and employing a dichotomy-based multi-expert inference mechanism, demonstrating superior performance across multiple TCGA cohorts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Cancer Prognosis</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16633v1"
                     data-domains="Radiology,Diagnostic Imaging,Oncology (for tissue characterization),Biomedical Engineering"
                     data-keywords="quantitative ultrasound tomography,ray-Born inversion,Hessian-free,sound speed reconstruction,single-scattering theory,high-frequency approximations,clinical ultrasound,computational efficiency"
                     data-authors="Ashkan Javaherian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16633v1.html">The First In Vitro and In Vivo Validation of the Hessian-Free Ray-Born Inversion for Quantitative Ultrasound Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ashkan Javaherian
                </div>

                <div class="paper-summary">
                    This study presents the first experimental validation of a novel Hessian-free ray-Born inversion technique for quantitative ultrasound tomography (QUS). The method, designed for clinical frequency ranges, reconstructs sound speed from transmission ultrasound data by combining single-scattering theory with high-frequency ray approximations. It demonstrates strong potential as a computationally efficient and accurate method suitable for clinical translation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (for tissue characterization)</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16633v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16633v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16633v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16633v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16625v1"
                     data-domains="Clinical Decision Support,Medical Diagnostics,Biomedical Question Answering,Healthcare AI,Patient Safety,Radiology,Pathology"
                     data-keywords="Bayesian uncertainty,clinical decision support,transformer models,uncertainty quantification,overconfidence,Monte Carlo dropout,medical AI,diagnostic errors,model calibration"
                     data-authors="Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16625v1.html">MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elias Hossain, Md Mehedi Hasan Nipu, Maleeha Sheikh et al.
                </div>

                <div class="paper-summary">
                    MedBayes-Lite is a novel, lightweight Bayesian framework designed to enhance existing transformer-based clinical language models by integrating uncertainty quantification without extensive retraining or architectural modifications. It addresses the critical issue of AI overconfidence in ambiguous medical scenarios, providing reliable, uncertainty-aware predictions for safe clinical decision support. The framework significantly improves model calibration, reduces overconfidence, and can prevent a substantial percentage of diagnostic errors by flagging uncertain predictions for human review.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Biomedical Question Answering</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16625v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16625v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16625v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16625v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16596v1"
                     data-domains="Diagnostic Radiology,Oncology (tumor detection),Surgery (tissue characterization),Physical Examination,Rehabilitation Medicine,Pathology (tissue analysis)"
                     data-keywords="Artificial Palpation,Representation Learning,Self-Supervised Learning,Tactile Sensing,Medical Imaging,Change Detection,Soft Robotics,Medical Diagnostics"
                     data-authors="Zohar Rimon,Elisei Shafer,Tal Tepper,Efrat Shimron,Aviv Tamar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16596v1.html">Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zohar Rimon, Elisei Shafer, Tal Tepper et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel proof-of-concept for artificial palpation using a self-supervised learning framework, specifically an encoder-decoder model, to learn a rich representation of tactile measurements on soft bodies. The learned representation, designed to capture intricate patterns beyond simple force maps, is demonstrated to be effective for downstream tasks such as tactile imaging and change detection, moving toward more objective and automated medical examinations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Oncology (tumor detection)</span>
                    
                    <span class="domain-tag">Surgery (tissue characterization)</span>
                    
                    <span class="domain-tag">Physical Examination</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16596v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16596v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16596v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16596v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16574v1"
                     data-domains="Dermatology (Skin Lesion Analysis - ISIC),Ophthalmology (Retinal Vessel Segmentation - CHASE)"
                     data-keywords="Machine Unlearning,Medical Segmentation,Low-Rank Adaptation (LoRA),Privacy Compliance,Teacher-Student Distillation,Responsible AI,Ethical Deployment,Deep Learning"
                     data-authors="Nirjhor Datta,Md. Golam Rabiul Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16574v1.html">Erase to Retain: Low Rank Adaptation Guided Selective Unlearning in Medical Segmentation Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nirjhor Datta, Md. Golam Rabiul Alam
                </div>

                <div class="paper-summary">
                    This paper introduces "Erase to Retain," a novel framework for controllable unlearning in medical segmentation networks that leverages a teacher-student distillation paradigm with Low-Rank Adaptation (LoRA). The method selectively erases lesion-specific or class-specific representations from low-rank decoder spaces through adversarial optimization on a designated forget subset, while preserving global anatomical understanding and overall performance on retained data. Experimental results demonstrate successful targeted forgetting across ISIC segmentation/classification and CHASE datasets, consistently lowering forget-set IoU/accuracy while maintaining or improving utility on retain and validation sets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology (Skin Lesion Analysis - ISIC)</span>
                    
                    <span class="domain-tag">Ophthalmology (Retinal Vessel Segmentation - CHASE)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16571v1"
                     data-domains="Disease Diagnostics,Prognosis Prediction,Risk Stratification,Rare Disease Research,Adverse Event Prediction,Personalized Medicine,Public Health Surveillance"
                     data-keywords="Tabular Data,Data Augmentation,Class Imbalance,Diffusion Models,Latent Space,Gradient-Boosted Trees,Minority Oversampling,Healthcare AI"
                     data-authors="Md. Tawfique Ihsan,Md. Rakibul Hasan Rafi,Ahmed Shoyeb Raihan,Imtiaz Ahmed,Abdullahil Azeem">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16571v1.html">Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md. Tawfique Ihsan, Md. Rakibul Hasan Rafi, Ahmed Shoyeb Raihan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a family of latent-space, tree-driven diffusion methods designed to boost predictive performance on tabular data suffering from severe class imbalance, particularly for rare but important minority classes. By leveraging conditional flow matching with gradient-boosted trees and operating in compact latent spaces, the proposed variants (PCAForest, EmbedForest, AttentionForest) generate high-fidelity synthetic data. AttentionForest demonstrates superior minority recall while maintaining competitive precision, calibration, and privacy across diverse datasets, including those from healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Disease Diagnostics</span>
                    
                    <span class="domain-tag">Prognosis Prediction</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                    <span class="domain-tag">Rare Disease Research</span>
                    
                    <span class="domain-tag">Adverse Event Prediction</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16571v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16571v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16571v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16571v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16566v1"
                     data-domains="Pediatrics,Public Health,Nutrition,Global Health,Telemedicine"
                     data-keywords="Child Malnutrition,Anthropometric Prediction,Deep Learning,Graph Attention Network,Retrieval-Augmented AI,Low-Resource Settings,Computer Vision,Digital Health"
                     data-authors="Misaal Khan,Mayank Vatsa,Kuldeep Singh,Richa Singh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16566v1.html">NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Misaal Khan, Mayank Vatsa, Kuldeep Singh et al.
                </div>

                <div class="paper-summary">
                    NutriScreener introduces a novel retrieval-augmented multi-pose graph attention network designed for robust child malnutrition detection and anthropometric prediction from images. By integrating CLIP-based visual embeddings, knowledge retrieval, and context awareness, the system achieves high accuracy and scalability, addressing generalizability and class imbalance. Clinically validated and showing strong performance across diverse populations, it offers a promising solution for early intervention in low-resource settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Nutrition</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16551v1"
                     data-domains="Oncology,Rare Diseases,Clinical Trial Design,Drug Development,Medical Statistics,Precision Medicine"
                     data-keywords="Generative AI,Clinical Trials,Synthetic Data,Survival Analysis,Variational Autoencoder,Time-to-Event,Oncology,Rare Diseases,Censoring,Data Utility"
                     data-authors="Perrine Chassat,Van Tuan Nguyen,Lucas Ducrot,Emilie Lanoy,Agathe Guilloux">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16551v1.html">Toward Valid Generative Clinical Trial Data with Survival Endpoints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Perrine Chassat, Van Tuan Nguyen, Lucas Ducrot et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Variational Autoencoder (VAE) designed to generate valid synthetic clinical trial data, specifically focusing on complex time-to-event (survival) outcomes alongside mixed-type covariates. Addressing limitations of existing generative AI methods like GANs, the VAE operates within a unified latent framework, does not assume independent censoring, and outperforms baselines in fidelity, utility, and privacy for scenarios like data sharing and control-arm augmentation. While revealing systematic miscalibration in generated survival data, the authors propose a post-generation selection procedure that significantly improves calibration, marking a step forward in generative survival modeling for clinical research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Medical Statistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16551v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16551v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16551v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16551v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16549v1"
                     data-domains="Diagnostic Imaging,Pathology,Genomics,Clinical Decision Support,Precision Medicine"
                     data-keywords="Fairness,Deep Learning,Singular Value Decomposition (SVD),Low Rank Factorization (LRF),Bias Mitigation,Medical Diagnosis,Group Disparity,Model Fairness"
                     data-authors="Yuanbo Guo,Jun Xia,Yiyu Shi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16549v1.html">FairLRF: Achieving Fairness through Sparse Low Rank Factorization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuanbo Guo, Jun Xia, Yiyu Shi
                </div>

                <div class="paper-summary">
                    This paper introduces FairLRF, a novel fairness-oriented low rank factorization (LRF) framework designed to enhance deep learning model fairness, particularly in sensitive domains like medical diagnosis. Unlike traditional applications of Singular Value Decomposition (SVD) for model compression, FairLRF uniquely leverages SVD to identify and selectively remove bias-inducing elements from the unitary matrices, effectively reducing group disparities. The method demonstrates superior performance over conventional LRF and state-of-the-art fairness techniques, addressing limitations of existing computationally expensive or accuracy-compromising debiasing strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16549v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16549v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16549v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16549v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16548v1"
                     data-domains="Biomedical Research,Clinical Informatics,Medical Ontology Management,Health Information Technology,Disease Classification,Precision Medicine"
                     data-keywords="Large Language Models,Medical Ontology Extension,Clinical Notes,Zero-Shot Learning,Protected Health Information (PHI),Biomedical Informatics,Entity Extraction,Hierarchical Relationships"
                     data-authors="Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16548v1.html">Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guanchen Wu, Yuzhang Xie, Huanwei Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CLOZE, a novel framework that utilizes Large Language Models (LLMs) to perform zero-shot medical ontology extension directly from unstructured clinical notes. CLOZE automatically extracts novel disease-related entities and their hierarchical relationships, addressing the challenge of integrating new concepts into existing ontologies while ensuring patient privacy. The framework proves to be accurate, scalable, and privacy-preserving, offering a cost-efficient solution for enhancing biomedical knowledge bases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Ontology Management</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Disease Classification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16548v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16548v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16548v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16548v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16544v1"
                     data-domains="Clinical Informatics,Medical Communication,Patient Safety,Primary Care,General Practice,Health Systems Engineering"
                     data-keywords="ASR,WER,Clinical Impact,LLM-as-a-Judge,Patient Safety,Medical Transcription,Clinical Dialogue,Evaluation Metrics"
                     data-authors="Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16544v1.html">WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zachary Ellis, Jared Joselowitz, Yash Deo et al.
                </div>

                <div class="paper-summary">
                    This paper challenges the conventional reliance on Word Error Rate (WER) for evaluating Automatic Speech Recognition (ASR) systems in clinical dialogue, demonstrating its poor correlation with the actual clinical impact of transcription errors. To address this, the authors introduce and validate an LLM-as-a-Judge, optimized with GEPA, which effectively replicates expert clinical assessments of ASR transcription discrepancies, offering a scalable solution for safety-focused evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Communication</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">General Practice</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16544v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16544v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16544v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16544v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16498v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging,Medical Artificial Intelligence"
                     data-keywords="Breast cancer,DCE-MRI,Tumor segmentation,Deep learning,Acquisition time,FiLM layers,Generalization,Medical imaging"
                     data-authors="Rui Wang,Yuexi Du,John Lewin,R. Todd Constable,Nicha C. Dvornek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16498v1.html">Acquisition Time-Informed Breast Tumor Segmentation from Dynamic Contrast-Enhanced MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Wang, Yuexi Du, John Lewin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning method for breast tumor segmentation from Dynamic Contrast-Enhanced MRI (DCE-MRI) that addresses image variability by incorporating acquisition time. The proposed approach uses feature-wise linear modulation (FiLM) layers to modulate model features based on the specific acquisition sequence, leading to improved segmentation performance. Evaluation demonstrated enhanced tumor segmentation accuracy and better model generalization across diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16471v1"
                     data-domains="Neurology,Neuroimaging,Neurodegenerative diseases,Clinical trials,Aging research,Neurosurgery"
                     data-keywords="Corpus callosum,Morphometry,Segmentation,Neuroimaging,Automation,Huntington's disease,Biomarkers,Neurological diseases"
                     data-authors="Clemens Pollak,Kersten Diers,Santiago Estrada,David K√ºgler,Martin Reuter">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16471v1.html">FastSurfer-CC: A robust, accurate, and comprehensive framework for corpus callosum morphometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Clemens Pollak, Kersten Diers, Santiago Estrada et al.
                </div>

                <div class="paper-summary">
                    FastSurfer-CC is an efficient, fully automated framework designed for comprehensive corpus callosum morphometry, addressing the gap in publicly available tools for this critical brain structure. It integrates various tasks, from segmentation to shape metric extraction, demonstrating superior performance over existing methods and revealing novel, statistically significant differences in Huntington's disease that current state-of-the-art tools miss.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Neurodegenerative diseases</span>
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                    <span class="domain-tag">Aging research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16471v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16471v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16471v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16471v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16427v1"
                     data-domains="Oncology (Lung Cancer),Intensive Care Unit (ICU),Pharmacokinetics-Pharmacodynamics (PKPD)"
                     data-keywords="Generative Modeling,Clinical Time Series,Stochastic Differential Equations,Variational Inference,Individual Treatment Effect,Probabilistic Forecasting,Uncertainty Estimation,Electronic Health Records"
                     data-authors="Muhammad Aslanimoghanloo,Ahmed ElGazzar,Marcel van Gerven">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16427v1.html">Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Aslanimoghanloo, Ahmed ElGazzar, Marcel van Gerven
                </div>

                <div class="paper-summary">
                    This paper introduces a generative modeling framework based on latent neural stochastic differential equations (SDEs) to address challenges in clinical time series data like irregular sampling, complex latent physiology, and inherent uncertainties. The approach models underlying dynamics probabilistically and demonstrates superior performance over baseline models (ODEs, LSTMs) in accuracy and uncertainty estimation, enabling precise, uncertainty-aware predictions for clinical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology (Lung Cancer)</span>
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Pharmacokinetics-Pharmacodynamics (PKPD)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16427v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16427v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16427v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16427v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16398v1"
                     data-domains="Chronic Disease Management,Psychiatry,Primary Care,Internal Medicine,Geriatrics,Digital Health,Telemedicine"
                     data-keywords="Chronic diseases,Depression,Multi-Task Learning,Wearable sensors,Heterogeneity,Collaborative care,Health information systems,Bayesian network"
                     data-authors="Yidong Chai,Haoxin Liu,Jiaheng Xie,Chaopeng Wang,Xiao Fang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16398v1.html">Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yidong Chai, Haoxin Liu, Jiaheng Xie et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical need for joint assessment of comorbid physical chronic diseases and depression, which is essential for collaborative chronic care. It proposes an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method to overcome challenges of disease and patient heterogeneity when using wearable sensor data. Empirical evaluations demonstrate that ADH-MTL significantly outperforms existing baselines, offering a computational solution for integrated physical and mental healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16398v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16398v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16398v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16398v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16346v1"
                     data-domains="Rehabilitation,Sports Medicine,Geriatrics,Orthopedics,Physical Therapy,Telemedicine,Preventative Health"
                     data-keywords="Capacitive Sensing,Textile Sensors,Motion Capture,Deep Learning,Wearable Technology,Rehabilitation,Smart Garments,Lower-Body Kinematics"
                     data-authors="Deniz Kasap,Taraneh Aminosharieh Najafi,J√©r√¥me Paul R√©my Thevenot,Jonathan Dan,Stefano Albini,David Atienza">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16346v1.html">VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deniz Kasap, Taraneh Aminosharieh Najafi, J√©r√¥me Paul R√©my Thevenot et al.
                </div>

                <div class="paper-summary">
                    VersaPants presents the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, integrating conductive patches and a compact acquisition unit into a pair of pants. Utilizing a lightweight Transformer-based deep learning model, the system accurately reconstructs hip, knee, and ankle joint angles with competitive performance. It offers a comfortable, privacy-preserving, and real-time embedded solution for motion analysis without requiring fitting adjustments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16346v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16346v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16346v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16346v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16333v1"
                     data-domains="Medical Imaging,Diagnostics,Oncology,Disease Progression Modeling,Electronic Health Records (EHR),Robotic Surgery,Surgical Planning"
                     data-keywords="World Models,Clinical Prediction,Counterfactuals,Planning,Healthcare AI,Temporal Reasoning,Causal Inference,Decision Support"
                     data-authors="Mohammad Areeb Qazi,Maryam Nadeem,Mohammad Yaqub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16333v1.html">Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Areeb Qazi, Maryam Nadeem, Mohammad Yaqub
                </div>

                <div class="paper-summary">
                    This paper reviews the application of "World Models" in healthcare AI, advocating for their superior ability over traditional generative AI to provide predictive, reliable, and data-efficient clinical decision support. It highlights how world models learn multimodal, temporally coherent, and action-conditioned representations crucial for clinical prediction, counterfactual evaluation, and planning in complex medical scenarios. The review outlines current capabilities, limitations, and a future research agenda for developing clinically robust prediction-first world models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16292v1"
                     data-domains="Health Informatics,Healthcare Administration,Clinical Decision Support,Secure Health Data Exchange,Medical Privacy"
                     data-keywords="Distributed Agents,Multi-Agent Systems,Data Locality,Privacy-Preserving,Natural Language Processing,Healthcare Interoperability,Secure Computation,Pseudonymisation"
                     data-authors="Daniel Vaughan,Kate≈ôina Vaughan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16292v1.html">Distributed Agent Reasoning Across Independent Systems With Strict Data Locality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Vaughan, Kate≈ôina Vaughan
                </div>

                <div class="paper-summary">
                    This paper presents a proof-of-concept for secure, distributed agent-to-agent communication across independent healthcare systems (Clinic, Insurer, Specialist Network) using only natural-language messages. It demonstrates feasibility for cooperative reasoning without shared identifiers, structured schemas, or centralized data exchange, ensuring strict data locality and patient privacy via pseudonymised tokens.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Healthcare Administration</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Secure Health Data Exchange</span>
                    
                    <span class="domain-tag">Medical Privacy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16292v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16292v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16292v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16292v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16283v1"
                     data-domains="Genomics,Precision Medicine,Clinical Decision Support,Biomedical Research,Pharmacogenomics,Disease Diagnostics"
                     data-keywords="Multi-intent Question Answering,Retrieval-Augmented Generation (RAG),Large Language Models (LLMs),Scientific Question Answering,Evidence Coverage,Reciprocal Rank Fusion (RRF),Biomedical Information Retrieval,Precision Medicine"
                     data-authors="Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16283v1.html">MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhiyuan Li, Haisheng Yu, Guangchuan Guo et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MuISQA, a new benchmark designed to evaluate Retrieval-Augmented Generation (RAG) systems on complex scientific questions that entail multiple intents and require heterogeneous evidence. To address the limitations of conventional single-intent RAG systems, the authors propose an intent-aware retrieval framework that leverages Large Language Models (LLMs) to decompose questions into intent-specific queries. The framework retrieves supporting evidence for each intent, aggregates, and re-ranks it using Reciprocal Rank Fusion (RRF), demonstrating superior performance in retrieval accuracy and evidence coverage compared to conventional approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16283v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16283v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16283v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16283v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16268v1"
                     data-domains="Neurodegeneration,Neuropathology,Neurology,Digital Pathology,Computational Neuroscience"
                     data-keywords="Parkinson's Disease,Alpha-Synuclein,Lewy Bodies,Neurodegeneration,Deep Learning,Weakly Supervised Learning,Histopathology,Image Segmentation,Image Classification"
                     data-authors="Erwan Dereure,Robin Louiset,Laura Parkkinen,David A Menassa,David Holcman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16268v1.html">Weakly Supervised Segmentation and Classification of Alpha-Synuclein Aggregates in Brightfield Midbrain Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Erwan Dereure, Robin Louiset, Laura Parkkinen et al.
                </div>

                <div class="paper-summary">
                    This paper presents an automated deep learning pipeline for the weakly supervised segmentation and classification of alpha-synuclein aggregates, including Lewy bodies and neurites, in brightfield whole-slide images of midbrain tissue from Parkinson's disease and incidental Lewy Body Disease cases. The method achieves a balanced accuracy of 80% in differentiating major aggregate morphologies and is robust to immunohistochemical labelling variability, paving the way for large-scale pathological characterization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurodegeneration</span>
                    
                    <span class="domain-tag">Neuropathology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16268v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16268v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16268v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16268v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16186v1"
                     data-domains="Cardiology,Neurology,Pulmonology,Medical Imaging,Computational Anatomy,Surgical Planning,Radiology"
                     data-keywords="3D organ reconstruction,mesh reconstruction,topology-preserving,template-based modeling,deep learning,anatomical substructures,shared interfaces,medical imaging,geometric accuracy,clinical use"
                     data-authors="Deniz Sayin Mercadier,Hieu Le,Yihong Chen,Jiancheng Yang,Udaranga Wickramasinghe,Pascal Fua">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16186v1.html">PrIntMesh: Precise Intersection Surfaces for 3D Organ Mesh Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deniz Sayin Mercadier, Hieu Le, Yihong Chen et al.
                </div>

                <div class="paper-summary">
                    PrIntMesh is a novel template-based, topology-preserving deep learning framework designed for 3D organ mesh reconstruction that treats organs as unified systems rather than independent parts. It jointly deforms all substructures from a connected template, explicitly preserving internal boundaries and ensuring smooth surfaces, leading to highly accurate, anatomically plausible, and robust reconstructions. The method demonstrates superior performance over existing approaches, particularly in reconstructing shared interfaces, and is data-efficient for clinical use.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16186v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16186v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16186v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16186v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16179v1"
                     data-domains="Infectious Diseases,Epidemiology,Public Health,Mathematical Biology,Tropical Medicine"
                     data-keywords="Dengue,Age-structured model,Transmission dynamics,Reproduction number,Time-varying parameters,Brazil,Vector dynamics,Climate"
                     data-authors="Ihtisham Ul Haq,Serge Richard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16179v1.html">Age-structured model of dengue transmission dynamics with time-varying parameters, and its application to Brazil</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ihtisham Ul Haq, Serge Richard
                </div>

                <div class="paper-summary">
                    This paper develops and analyzes an age-structured mathematical model with time-dependent parameters to investigate dengue transmission dynamics. It applies this model to Brazil using weekly time series data, evaluating medical and environmental parameters to estimate time-varying effective reproduction numbers and predict future trends, ultimately highlighting the critical roles of age distribution, vector dynamics, and climate.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Mathematical Biology</span>
                    
                    <span class="domain-tag">Tropical Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16179v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16179v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16179v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16179v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16162v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.GR"
                     data-authors="Yuting Lu,Ziliang Wang,Weixin Xu,Wei Zhang,Yongqiang Zhao,Yang Yu,Xiaohong Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16162v1.html">Layer-wise Noise Guided Selective Wavelet Reconstruction for Robust Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuting Lu, Ziliang Wang, Weixin Xu et al.
                </div>

                <div class="paper-summary">
                    Clinical deployment requires segmentation models to stay stable under distribution shifts and perturbations. The mainstream solution is adversarial training (AT) to improve robustness; however, AT often brings a clean--robustness trade-off and high training/tuning cost, which limits scalability and ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16162v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16162v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16162v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16162v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16139v1"
                     data-domains="General Medicine,Clinical Decision Support,Medical Education,Healthcare Informatics"
                     data-keywords="Large Language Models (LLMs),Medical AI,Reward Model Learning,Clinical Alignment,Multidimensional Evaluation,Geometric Projection,Healthbench,Medical Standards"
                     data-authors="Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16139v1.html">Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yongnan Jin, Xurui Li, Feng Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC, a novel alignment framework designed to integrate structured medical standards and cognitive logic into large language models (LLMs). The method significantly improves LLM performance on medical benchmarks, achieving state-of-the-art results among open-source models and outperforming most closed-source counterparts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Healthcare Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16139v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16139v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16139v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16139v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16096v1"
                     data-domains="Infectious Disease Epidemiology,Public Health,Global Health,Health Policy,Preventive Medicine"
                     data-keywords="Hepatitis B,Agent-based model,Migrant health,Healthcare access,Disease elimination,Thai-Myanmar border,Public health policy,Epidemiological modelling"
                     data-authors="Anh D. Pham,Robert Moss,Wirichada Pan-ngum,Rose McGready,Nicholas Geard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16096v1.html">Modelling the impact of improving access to healthcare on Hepatitis B prevalence in the Thai-Myanmar border region</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anh D. Pham, Robert Moss, Wirichada Pan-ngum et al.
                </div>

                <div class="paper-summary">
                    This study developed an Agent-based model to analyze Hepatitis B prevalence dynamics in the Thai-Myanmar border region, highlighting the disparity between Thai and migrant populations. It revealed that current interventions, while effective for Thai citizens, are insufficient for national elimination targets due to persistent high prevalence among migrants, underscoring the critical need for improved healthcare access in these communities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16096v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16096v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16096v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16096v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16087v1"
                     data-domains="Drug Discovery,Pharmacology,Medicinal Chemistry,Bioinformatics"
                     data-keywords="drug discovery,machine learning,data selection,bioactivity data,data attribution,language embeddings,assay compatibility,predictive modeling"
                     data-authors="Vincent Fan,Regina Barzilay">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16087v1.html">AssayMatch: Learning to Select Data for Molecular Activity Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vincent Fan, Regina Barzilay
                </div>

                <div class="paper-summary">
                    AssayMatch is a novel framework addressing the challenge of noisy, heterogeneous training data in machine learning for drug discovery. It improves model performance by selecting smaller, more homogenous training sets, which are specifically attuned to a target test set, even when the test set's labels are unknown. This method leverages data attribution to finetune language embeddings of assay descriptions, enabling more effective filtering of incompatible experiments and boosting predictive power.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16087v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16087v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16087v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16087v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16006v1"
                     data-domains="Intensive Care Unit (ICU),Critical Care Medicine,Personalized Treatment Optimization,Disease Progression Modeling,Drug Administration Timing,Clinical Decision Support Systems"
                     data-keywords="Counterfactual outcome estimation,Time-series,Deconfounding,Temporal generalization,Sub-treatment Group Alignment (SGA),Random Temporal Masking (RTM),Causal inference,Personalized medicine"
                     data-authors="Yiling Liu,Juncheng Dong,Chen Fu,Wei Shi,Ziyang Jiang,Zhigang Hua,David Carlson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16006v1.html">Synergizing Deconfounding and Temporal Generalization For Time-series Counterfactual Outcome Estimation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiling Liu, Juncheng Dong, Chen Fu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that synergistically combines Sub-treatment Group Alignment (SGA) and Random Temporal Masking (RTM) to address the significant challenges in estimating counterfactual outcomes from time-series observations. SGA enhances deconfounding by aligning fine-grained sub-treatment groups, while RTM promotes temporal generalization and robustness by mitigating reliance on noisy covariates. Their combined approach achieves state-of-the-art performance, offering improved accuracy for critical medical decision-making.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Personalized Treatment Optimization</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Drug Administration Timing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16006v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16006v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16006v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16006v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15994v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology,Medical Informatics"
                     data-keywords="Large Language Models (LLMs),Retrieval-Augmented Generation (RAG),Clinical Reasoning,Medical Guidelines,Written Exposure Therapy (WET),AI Evaluation,Healthcare AI"
                     data-authors="Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15994v1.html">CARE-RAG - Clinical Assessment and Reasoning in RAG</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deepthi Potluri, Aby Mammen Mathew, Jeffrey B DeWitt et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical gap between retrieval and reasoning in Large Language Models (LLMs) within clinical settings, using Written Exposure Therapy (WET) guidelines as a testbed. It proposes an evaluation framework to assess the accuracy, consistency, and fidelity of LLM reasoning, highlighting that errors persist even when authoritative information is provided. The research underscores that while Retrieval-Augmented Generation (RAG) can constrain outputs, safe clinical deployment mandates rigorous evaluation of reasoning capabilities, not just retrieval.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15994v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15994v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15994v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15994v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15986v1"
                     data-domains="Diagnostic Imaging,Radiology,General Medicine,Healthcare AI"
                     data-keywords="Fairness,In-Context Learning,Multimodal Large Language Models,Medical Imaging,Debiasing,Healthcare Disparities,AI Ethics,Diagnostic Imaging"
                     data-authors="Dawei Li,Zijian Gu,Peng Wang,Chuhan Song,Zhen Tan,Mohan Zhang,Tianlong Chen,Yu Tian,Song Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15986v1.html">Fairness in Multi-modal Medical Diagnosis with Demonstration Selection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dawei Li, Zijian Gu, Peng Wang et al.
                </div>

                <div class="paper-summary">
                    Multimodal large language models (MLLMs) show promise in medical image reasoning, but demographic fairness remains a critical concern. This paper introduces Fairness-Aware Demonstration Selection (FADS), a lightweight, tuning-free In-Context Learning (ICL) strategy that employs clustering-based sampling to create demographically balanced and semantically relevant demonstrations. FADS consistently reduces gender, race, and ethnicity disparities across medical imaging benchmarks while maintaining strong diagnostic accuracy, presenting an efficient path towards equitable medical AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">General Medicine</span>
                    
                    <span class="domain-tag">Healthcare AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15986v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15986v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15986v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15986v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15982v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Computational Epidemiology,Predictive Healthcare Analytics"
                     data-keywords="Machine Learning,Epidemic Prediction,Agent-based Modeling,SEIRV Model,Disease Dynamics,Public Health,Predictive Analytics,Infectious Diseases"
                     data-authors="Chukwunonso Henry Nwokoye,Blessing Oluchi,Sharna Waldron,Peace Ezzeh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15982v1.html">Machine Learning Epidemic Predictions Using Agent-based Wireless Sensor Network Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chukwunonso Henry Nwokoye, Blessing Oluchi, Sharna Waldron et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the fundamental challenge of insufficient epidemiological data in Wireless Sensor Networks (WSNs) for robust threat prediction by developing a machine learning framework for epidemic forecasting. It utilizes an agent-based implementation of the SEIRV model to generate synthetic datasets and applies various ML algorithms to predict the number of infected and recovered nodes. The study demonstrates effective predictive performance, particularly with ensemble methods, offering a methodological contribution transferable to broader epidemic modeling.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Computational Epidemiology</span>
                    
                    <span class="domain-tag">Predictive Healthcare Analytics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15982v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15982v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15982v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15982v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15977v1"
                     data-domains="Precision Medicine,Genomics,Bioinformatics,Clinical Diagnostics,Genetic Research"
                     data-keywords="Precision Medicine,Genomic Workflows,Chromosome Parallelization,Memory Optimization,Resource Management,Symbolic Regression,Dynamic Scheduling,Knapsack Problem"
                     data-authors="Daniel Mas Montserrat,Ray Verma,M√≠riam Barrab√©s,Francisco M. de la Vega,Carlos D. Bustamante,Alexander G. Ioannidis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15977v1.html">Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.DC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Mas Montserrat, Ray Verma, M√≠riam Barrab√©s et al.
                </div>

                <div class="paper-summary">
                    This paper introduces adaptive, RAM-efficient parallelization mechanisms for large-scale genomic workflows in precision medicine, addressing issues like memory spikes, out-of-memory errors, and poor resource utilization. By employing symbolic and polynomial regression models for memory prediction, alongside dynamic and static schedulers that optimize task batching (Knapsack problem) and processing order, the authors achieve reduced memory overruns, balanced computational loads, and significantly faster end-to-end execution of genomic pipelines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Genetic Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15977v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15977v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15977v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15977v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15974v1"
                     data-domains="Infectious Diseases,Clinical Pharmacology,Medical Informatics,Critical Care,Internal Medicine"
                     data-keywords="Large Language Models,Clinical Antimicrobial Therapy,Medical Decision Support,Knowledge Distillation,Reinforcement Learning,Data Augmentation,Privacy-preserving AI,Low-cost AI"
                     data-authors="Zhe Li,Yehan Qiu,Yujie Chen,Xiang Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15974v1.html">KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhe Li, Yehan Qiu, Yujie Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces KRAL (Knowledge and Reasoning Augmented Learning), a novel paradigm designed to address the limitations of Large Language Models (LLMs) in complex clinical antimicrobial therapy decision-making. KRAL proposes a low-cost, scalable, and privacy-preserving approach that leverages teacher-model reasoning, semi-supervised data augmentation, and agentic reinforcement learning to significantly enhance local LLMs' knowledge and reasoning capabilities. It demonstrably outperforms traditional RAG and SFT methods, achieving improved accuracy and reasoning pass rates at a fraction of the long-term training cost.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15974v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15974v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15974v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15974v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15963v1"
                     data-domains="Oncology,Diagnostic Radiology,Medical Imaging Analysis,Artificial Intelligence in Medicine,Quantitative Imaging"
                     data-keywords="radiomics,deep learning,Python,reproducibility,medical imaging,AI,precision medicine,biomarkers"
                     data-authors="Mohammad R. Salmanpour,Amir Hossein Pouria,Sirwan Barichin,Yasaman Salehi,Sonya Falahati,Isaac Shiri,Mehrdad Oveisi,Arman Rahmim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15963v1.html">PySERA: Open-Source Standardized Python Library for Automated, Scalable, and Reproducible Handcrafted and Deep Radiomics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad R. Salmanpour, Amir Hossein Pouria, Sirwan Barichin et al.
                </div>

                <div class="paper-summary">
                    PySERA is an open-source Python library designed to enhance reproducibility, scalability, and AI integration in radiomics by unifying handcrafted and deep learning feature extraction. It achieves over 94% reproducibility in IBSI benchmarks and demonstrates superior predictive accuracy compared to existing tools, providing a robust foundation for AI-ready medical imaging research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Quantitative Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15963v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15963v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15963v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15963v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15946v1"
                     data-domains="Cardiology,Medical Imaging,Diagnostic Ultrasound,Artificial Intelligence in Medicine"
                     data-keywords="3D echocardiography,2D view extraction,Deep learning,Cardiac ultrasound,Medical imaging,Image interpretation,Automated diagnosis,Echocardiography"
                     data-authors="Milos Vukadinovic,Hirotaka Ieki,Yuki Sahasi,David Ouyang,Bryan He">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15946v1.html">Automated Interpretable 2D Video Extraction from 3D Echocardiography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Milos Vukadinovic, Hirotaka Ieki, Yuki Sahasi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an automated deep learning-based method to extract standard 2D echocardiography views from complex 3D cardiac ultrasound volumes. The approach allows physicians to interpret comprehensive 3D data in their familiar 2D format, preserving critical diagnostic features and spatial calibration. Validation confirmed high accuracy in view identification and utility for AI-driven abnormality detection and measurement.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Ultrasound</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15946v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15946v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15946v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15946v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15943v1"
                     data-domains="General Medical Imaging,Radiology,Pathology,Clinical Decision Support,Disease Diagnosis"
                     data-keywords="Medical Imaging,Vision-Language Models,Contrastive Learning,Multi-Granularity,Multi-Label,CLIP,Deep Learning,Diagnostic Support"
                     data-authors="Zihan Li,Yiqing Wang,Sina Farsiu,Paul Kinahan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15943v1.html">Boosting Medical Visual Understanding From Multi-Granular Language Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihan Li, Yiqing Wang, Sina Farsiu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Multi-Granular Language Learning (MGLL), a contrastive learning framework designed to enhance visual understanding in complex domains like medical imaging. It addresses the limitations of existing models like CLIP, which struggle with multi-label and multi-granularity alignment, by integrating structured multi-label supervision, cross-granularity textual descriptions, and soft-label supervision. MGLL significantly outperforms state-of-the-art methods in downstream medical tasks, improving the alignment of visual and textual representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Disease Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15943v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15943v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15943v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15943v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15932v1"
                     data-domains="Oncology,Radiation Oncology,Medical Physics,Personalized Medicine,Computational Biology"
                     data-keywords="chemotherapy,radiotherapy,mathematical models,personalized medicine,model optimization,adaptive therapy,bias,uncertainty quantification,model selection"
                     data-authors="Changin Oh,Kathleen P. Wilkie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15932v1.html">How Mathematical Forms of Chemotherapy and Radiotherapy Bias Model-Optimized Predictions: Implications for Model Selection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Changin Oh, Kathleen P. Wilkie
                </div>

                <div class="paper-summary">
                    This study demonstrates how the choice of mathematical models for chemotherapy and radiotherapy significantly biases optimized treatment protocols and predictions, potentially leading to contradictory and non-generalizable recommendations. It highlights that inherent model assumptions critically influence dosing and sequencing, underscoring the urgent need for a more comprehensive and rigorous approach to model selection in personalized cancer therapy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15932v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15932v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15932v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15932v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15906v1"
                     data-domains="Drug Discovery,Immunology,Biologics Development,Structural Biology,Pharmacology,Protein Engineering"
                     data-keywords="Generative Models,Neural Fields,Score-based Models,Drug Design,Antibody Design,Macrocyclic Peptides,Structure-based Design,Therapeutics"
                     data-authors="Matthieu Kirchmeyer,Pedro O. Pinheiro,Emma Willett,Karolis Martinkus,Joseph Kleinhenz,Emily K. Makowski,Andrew M. Watkins,Vladimir Gligorijevic,Richard Bonneau,Saeed Saremi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15906v1.html">Unified all-atom molecule generation with neural fields</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Matthieu Kirchmeyer, Pedro O. Pinheiro, Emma Willett et al.
                </div>

                <div class="paper-summary">
                    FuncBind introduces a novel computer vision-based framework that utilizes neural fields and score-based generative models to achieve unified, target-conditioned, all-atom molecule generation across diverse atomic systems. This modality-agnostic approach overcomes limitations of existing models by effectively generating small molecules, macrocyclic peptides, and antibody CDR loops, validated by competitive in silico performance and successful in vitro generation of novel antibody binders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Biologics Development</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15906v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15906v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15906v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15906v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15904v1"
                     data-domains="Epidemiology,Pharmacoepidemiology,Health Economics,Public Health Research,Comparative Effectiveness Research,Clinical Informatics"
                     data-keywords="Bayesian inference,Causal inference,Average Treatment Effect (ATE),Semiparametric estimation,Double robustness,Debiasing,Observational studies,High-dimensional data,Potential outcomes"
                     data-authors="G√∂zde Sert,Abhishek Chakrabortty,Anirban Bhattacharya">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15904v1.html">Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> G√∂zde Sert, Abhishek Chakrabortty, Anirban Bhattacharya
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Bayesian semiparametric methodology for estimating the average treatment effect (ATE) from high-dimensional observational data within the potential outcomes framework. It achieves this through a Bayesian debiasing procedure and targeted modeling based on debiased summary statistics, which, combined with sample splitting, ensures robustness and asymptotic efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                    <span class="domain-tag">Public Health Research</span>
                    
                    <span class="domain-tag">Comparative Effectiveness Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15904v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15904v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15904v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15904v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15902v1"
                     data-domains="Mental Health,Psychiatry,Neurology,Geriatrics,Caregiving,Home Health,Telemedicine,Wellness"
                     data-keywords="EEG,Emotion Recognition,Deep Learning,CNN-Transformer,Mental Health,Passive Monitoring,Wearable EEG,Clinical Diagnostics"
                     data-authors="Roman Dolgopolyi,Antonis Chatzipanagiotou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15902v1.html">EEG Emotion Recognition Through Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Dolgopolyi, Antonis Chatzipanagiotou
                </div>

                <div class="paper-summary">
                    This paper introduces a novel CNN-Transformer deep learning model for EEG-based emotion recognition, capable of classifying positive, neutral, and negative emotional states with 91% accuracy. A key innovation is its ability to operate effectively with only 5 out of 62 EEG electrodes, significantly reducing hardware requirements and enabling accessible, at-home emotional monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Caregiving</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15902v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15902v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15902v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15902v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15896v1"
                     data-domains="Epidemiology,Pharmacoepidemiology,Health outcomes research,Clinical effectiveness research,Public health,Medical statistics"
                     data-keywords="Causal inference,Observational studies,Covariate adjustment,Outcome-informed design,Sample splitting,Cross-balancing,Asymptotic normality,Efficiency,Multiply robust"
                     data-authors="Ying Jin,Jos√© Zubizarreta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15896v1.html">Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ying Jin, Jos√© Zubizarreta
                </div>

                <div class="paper-summary">
                    This paper introduces cross-balancing, a novel method for designing and analyzing observational studies that allows for the incorporation of outcome data into the construction or selection of balancing features. By employing sample splitting, cross-balancing effectively separates errors in feature construction from weight estimation, leading to consistent, asymptotically normal, and efficient causal effect estimators. This approach significantly improves both estimation and inference while maintaining interpretability, addressing a long-standing challenge in valid outcome-informed causal inference.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Pharmacoepidemiology</span>
                    
                    <span class="domain-tag">Health outcomes research</span>
                    
                    <span class="domain-tag">Clinical effectiveness research</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15896v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15896v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15896v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15896v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15857v1"
                     data-domains="Public Health,Medical Ethics,Health Communication,Patient Education,Behavioral Health,Digital Health,Clinical Decision Support,Health Policy"
                     data-keywords="ChatBots,LLMs,Value-framing,Persuasion,Decision Making,Misinformation,Backfire Effect,Healthcare AI"
                     data-authors="Anthony Wise,Xinyi Zhou,Martin Reimann,Anind Dey,Leilani Battle">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15857v1.html">A Crowdsourced Study of ChatBot Influence in Value-Driven Decision Making Scenarios</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anthony Wise, Xinyi Zhou, Martin Reimann et al.
                </div>

                <div class="paper-summary">
                    This study demonstrates that Large Language Model (LLM)-based ChatBots can subtly persuade users to alter their behavior through value-framing alone, distinct from overt bias or misinformation. A crowdsourced experiment with 336 participants showed that exposure to value-framed ChatBots significantly changed individuals' budget allocation choices, and some even reinforced their original preferences (a backfire effect) when the framing misaligned with their values, revealing new risks for manipulative AI uses.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                    <span class="domain-tag">Health Communication</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15857v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15857v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15857v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15857v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15847v1"
                     data-domains="Critical Care Medicine,Intensive Care Medicine,Clinical Informatics,Hospital Management,Emergency Medicine"
                     data-keywords="Intensive Care Unit,Mortality Prediction,Multimodal AI,Clinical Transformer,Bidirectional LSTM,Interpretability,MIMIC-III,Early Warning Systems"
                     data-authors="Alexander Bakumenko,Janine Hoelscher,Hudson Smith">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15847v1.html">Transparent Early ICU Mortality Prediction with Clinical Transformer and Per-Case Modality Attribution</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alexander Bakumenko, Janine Hoelscher, Hudson Smith
                </div>

                <div class="paper-summary">
                    This paper presents a transparent and robust multimodal deep learning ensemble for early prediction of in-hospital mortality in intensive care unit (ICU) patients. By fusing physiological time-series data and unstructured clinical notes from the first 48 hours, the system achieves improved predictive performance and crucial multilevel interpretability, addressing key barriers to clinical adoption of AI in critical care.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Hospital Management</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15847v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15847v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15847v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15847v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15839v1"
                     data-domains="Epidemiology,Public Health,Infectious Disease Modeling,Biostatistics,Systems Biology"
                     data-keywords="Bayesian inference,Frequentist inference,epidemiological models,SEIUR model,COVID-19,mpox,identifiability,uncertainty quantification,forecasting,latent states"
                     data-authors="Mohammed A. Y. Mohammed,Hamed Karami,Gerardo Chowell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15839v1.html">Comparing Bayesian and Frequentist Inference in Biological Models: A Comparative Analysis of Accuracy, Uncertainty, and Identifiability</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammed A. Y. Mohammed, Hamed Karami, Gerardo Chowell
                </div>

                <div class="paper-summary">
                    This paper comparatively analyzes Bayesian and Frequentist inference frameworks across various biological models, including epidemiological ones, to assess their accuracy, uncertainty quantification, and identifiability. It concludes that Frequentist methods are superior for rich, fully observed data, while Bayesian methods excel with sparse data and high latent-state uncertainty, offering crucial guidance for model selection in health research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15839v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15839v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15839v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15839v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15778v1"
                     data-domains="Clinical Informatics,Pediatrics (specifically pediatric rehabilitation),Pharmacology (drug recognition),Public Health (demographic data extraction)"
                     data-keywords="Natural Language Processing,Large Language Models,Electronic Health Records,Information Extraction,Rule-based systems,Clinical NLP,Medical insights,Non-English EHR"
                     data-authors="Paulina Tworek,Mi≈Çosz Bargie≈Ç,Yousef Khan,Tomasz Pe≈Çech-Pilichowski,Marek Miko≈Çajczyk,Roman Lewandowski,Jose Sousa">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15778v1.html">Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paulina Tworek, Mi≈Çosz Bargie≈Ç, Yousef Khan et al.
                </div>

                <div class="paper-summary">
                    This study comparatively analyzes low-compute rule-based methods and Large Language Models (LLMs) for extracting structured medical insights from unstructured Polish Electronic Health Records (EHRs). It evaluates their performance in extracting patient demographics, clinical findings, and medications, while also assessing the impact of text normalisation absence and translation-induced information loss. The findings highlight accuracy-adaptability trade-offs, advocating for hybrid NLP approaches for efficient clinical deployment in non-English contexts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Pediatrics (specifically pediatric rehabilitation)</span>
                    
                    <span class="domain-tag">Pharmacology (drug recognition)</span>
                    
                    <span class="domain-tag">Public Health (demographic data extraction)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15778v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15778v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15778v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15778v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15771v1"
                     data-domains="Radiology,Obstetrics and Gynecology,Cardiology,Emergency Medicine,Interventional Radiology,Point-of-Care Ultrasound (POCUS)"
                     data-keywords="Ultrasound Segmentation,SAM2,Parameter-Efficient Fine-Tuning,Knowledge Distillation,Medical Imaging,Deep Learning,Resource-Constrained,Universal Segmentation"
                     data-authors="Yue Li,Qing Xu,Yixuan Zhang,Xiangjian He,Qian Zhang,Yuan Yao,Fiseha B. Tesem,Xin Chen,Ruili Wang,Zhen Chen,Chang Wen Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15771v1.html">UniUltra: Interactive Parameter-Efficient SAM2 for Universal Ultrasound Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yue Li, Qing Xu, Yixuan Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces UniUltra, a framework addressing the performance degradation of SAM2 on ultrasound images and its deployment challenges in resource-constrained clinical settings. UniUltra leverages a novel context-edge hybrid adapter for parameter-efficient fine-tuning and a deep-supervised knowledge distillation technique to create a lightweight, high-performing model for universal ultrasound segmentation. The final model significantly reduces parameter count while maintaining superior generalization capabilities, making it suitable for clinical deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Obstetrics and Gynecology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15771v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15771v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15771v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15771v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15640v1"
                     data-domains="Diagnostic Imaging,Radiology,Oncology (for tumor detection/characterization),Hepatology (for fibrosis assessment),General Pathology (tissue mechanical properties)"
                     data-keywords="Ultrasound Strain Elastography (USE),Deep Learning,Unsupervised Learning,Strain Estimation,Tissue Characterization,Multi-Stage Framework,Residual-Aware,Medical Imaging"
                     data-authors="Shourov Joarder,Tushar Talukder Showrav,Md. Kamrul Hasan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15640v1.html">Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shourov Joarder, Tushar Talukder Showrav, Md. Kamrul Hasan
                </div>

                <div class="paper-summary">
                    This paper introduces MUSSE-Net, a multi-stage, residual-aware, unsupervised deep learning framework designed to improve the consistency and accuracy of Ultrasound Strain Elastography (USE). It addresses limitations in USE such as tissue decorrelation noise, lack of ground truth, and inconsistent strain estimation by leveraging a novel multi-stream encoder-decoder architecture (USSE-Net) with attention mechanisms and a tailored consistency loss. The framework demonstrates state-of-the-art performance on simulation data and produces clinically interpretable strain maps with enhanced contrast and noise suppression on in vivo and clinical datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology (for tumor detection/characterization)</span>
                    
                    <span class="domain-tag">Hepatology (for fibrosis assessment)</span>
                    
                    <span class="domain-tag">General Pathology (tissue mechanical properties)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15640v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15640v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15640v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15640v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15632v1"
                     data-domains="Cardiology,Electrophysiology,Telemedicine,Clinical Decision Support Systems"
                     data-keywords="ECG,electrocardiogram,artificial intelligence,dataset,cardiology,telehealth,deep learning,diagnostic criteria"
                     data-authors="Petrus E. O. G. B. Abreu,Gabriela M. M. Paix√£o,Jiawei Li,Paulo R. Gomes,Peter W. Macfarlane,Ana C. S. Oliveira,Vinicius T. Carvalho,Thomas B. Sch√∂n,Antonio Luiz P. Ribeiro,Ant√¥nio H. Ribeiro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15632v1.html">CODE-II: A large-scale dataset for artificial intelligence in ECG analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Petrus E. O. G. B. Abreu, Gabriela M. M. Paix√£o, Jiawei Li et al.
                </div>

                <div class="paper-summary">
                    CODE-II is a groundbreaking large-scale dataset comprising over 2.7 million 12-lead ECGs from 2 million adult patients, featuring 66 clinically meaningful diagnostic classes meticulously annotated by cardiologists. A neural network pre-trained on CODE-II achieved superior transfer performance on external benchmarks, outperforming models trained on even larger datasets, thereby significantly advancing AI-based ECG analysis by addressing existing limitations in data quality and scope.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15632v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15632v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15632v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15632v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15617v1"
                     data-domains="Radiology,Orthopedics,Sports Medicine,Rheumatology,Point-of-Care Imaging,Emergency Medicine"
                     data-keywords="portable MRI,low-field MRI,Zero Echo Time (ZTE),Halbach scanner,musculoskeletal imaging,hard tissue imaging,T1 mapping,quantitative MRI"
                     data-authors="Jose Borreguero,Luiz G. C. Santos,Lorena Vega Cid,Elisa Casta√±√≥n,Marina Fern√°ndez-Garc√≠a,Pablo Benlloch,Rub√©n Bosch,Jes√∫s Conejero,Pablo Garc√≠a-Crist√≥bal,Alba Gonz√°lez-Cebri√°n,Teresa Guallart-Naval,Eduardo Pall√°s,Laia Porcar,Lucas Swistunow,Jose Miguel Algar√≠n,Fernando Galve,Joseba Alonso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15617v1.html">Qualitative and quantitative hard-tissue MRI with portable Halbach scanners</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jose Borreguero, Luiz G. C. Santos, Lorena Vega Cid et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a comprehensive framework for artifact-free Zero Echo Time (ZTE) imaging on low-cost, portable Halbach MRI scanners, demonstrating its feasibility for in vivo structural and quantitative T1 mapping of soft and hard tissues. The developed methodology successfully visualizes hard tissues like ligaments, tendons, cartilage, and bone, which are typically invisible in conventional spin-echo sequences, and provides the first in vivo T1 measurements of these tissues at ultra-low field strengths (B0 < 0.1 T).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Point-of-Care Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15617v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15617v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15617v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15617v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15603v1"
                     data-domains="Radiology,Diagnostic Imaging,Oncology,Anatomy,Surgery Planning,Gastroenterology"
                     data-keywords="medical image segmentation,deep learning,decoupled segmentation,transformer,deformable attention,AMOS 2022,BTCV,Dice score"
                     data-authors="Bin Xie,Gady Agam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15603v1.html">MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bin Xie, Gady Agam
                </div>

                <div class="paper-summary">
                    MaskMed introduces a novel architecture for medical image segmentation, addressing limitations of traditional point-wise convolutional heads by proposing a unified decoupled segmentation head and a Full-Scale Aware Deformable Transformer module. This approach separates class-agnostic mask prediction from class label prediction using shared object queries and enables memory-efficient, spatially aligned full-scale feature fusion. The method achieves state-of-the-art performance on challenging medical benchmarks, significantly outperforming nnUNet.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                    <span class="domain-tag">Surgery Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15603v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15603v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15603v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15603v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-23 06:25:37</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>