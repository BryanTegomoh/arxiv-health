<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">148</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (8), Radiology (8), Diagnostic Imaging (6)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Radiology">Radiology (8)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (6)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (6)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (6)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (4)</option>
                        
                        <option value="Cardiology">Cardiology (4)</option>
                        
                        <option value="Pathology">Pathology (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.16635v1"
                     data-domains="Oncology,Pathology,Cancer Genomics,Prognostics"
                     data-keywords="Survival Analysis,Multimodal AI,Explainable AI,Multi-Agent System,Chain-of-Thought (CoT),Pathology,Genomics,Precision Oncology"
                     data-authors="Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16635v1.html">SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guolin Huang, Wenting Chen, Jiaqi Yang et al.
                </div>

                <div class="paper-summary">
                    SurvAgent introduces the first hierarchical Chain-of-Thought (CoT)-enhanced multi-agent system designed for multimodal survival prediction in cancer, specifically addressing the lack of transparency, multimodal data integration, effective ROI exploration, and experiential learning in existing methods. It constructs a case bank with CoT-reasoned reports from WSI and gene data, followed by a multi-expert inference stage using retrieval-augmented generation (RAG) and progressive interval refinement, demonstrating superior performance and explainability in precision oncology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Cancer Genomics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16633v1"
                     data-domains="Diagnostic Imaging,Medical Physics,Radiology,Ultrasound Imaging,Biomedical Engineering"
                     data-keywords="Quantitative Ultrasound Tomography,Ray-Born Inversion,Hessian-Free,Sound Speed Reconstruction,Clinical Ultrasound,Medical Imaging,Computational Efficiency,In-vivo Validation"
                     data-authors="Ashkan Javaherian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16633v1.html">The First In Vitro and In Vivo Validation of the Hessian-Free Ray-Born Inversion for Quantitative Ultrasound Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ashkan Javaherian
                </div>

                <div class="paper-summary">
                    This study presents the inaugural experimental validation of a novel Hessian-free ray-Born inversion technique designed for quantitative reconstruction of sound speed from transmission ultrasound data. The method, which is computationally efficient and accurate, combines single-scattering theory with high-frequency approximations, demonstrating strong potential for clinical translation in diagnostic ultrasound applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Ultrasound Imaging</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16633v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16633v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16633v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16633v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16625v1"
                     data-domains="Clinical Diagnostics,Medical Imaging,Pathology,Intensive Care (ICU),General Clinical Practice"
                     data-keywords="Bayesian uncertainty quantification,Clinical decision support,Transformer models,Overconfidence,Calibration,Medical AI,Monte Carlo dropout,Diagnostic errors"
                     data-authors="Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16625v1.html">MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elias Hossain, Md Mehedi Hasan Nipu, Maleeha Sheikh et al.
                </div>

                <div class="paper-summary">
                    MedBayes-Lite introduces a lightweight Bayesian enhancement for existing transformer-based clinical language models, designed to provide reliable, uncertainty-aware predictions without significant architectural changes or retraining. By integrating Bayesian embedding calibration, uncertainty-weighted attention, and confidence-guided decision shaping, it effectively quantifies and propagates uncertainty. The framework significantly improves prediction calibration and trustworthiness, reducing overconfidence and preventing diagnostic errors in clinical decision support systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Intensive Care (ICU)</span>
                    
                    <span class="domain-tag">General Clinical Practice</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16625v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16625v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16625v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16625v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16596v1"
                     data-domains="oncology,surgery,dermatology,physical examination,diagnostics,rehabilitation"
                     data-keywords="artificial palpation,representation learning,self-supervised learning,tactile sensing,robotics,medical imaging,change detection,soft bodies"
                     data-authors="Zohar Rimon,Elisei Shafer,Tal Tepper,Efrat Shimron,Aviv Tamar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16596v1.html">Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zohar Rimon, Elisei Shafer, Tal Tepper et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a proof-of-concept for artificial palpation using a self-supervised learning framework to learn a rich representation of touch on soft bodies. An encoder-decoder model processes sequences of tactile measurements, aiming to capture intricate patterns beyond simple force maps for improved diagnostic tasks. The approach is validated through a simulation environment and a real-world dataset combining robotic palpation with MRI ground truth, demonstrating its potential for tactile imaging and change detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">oncology</span>
                    
                    <span class="domain-tag">surgery</span>
                    
                    <span class="domain-tag">dermatology</span>
                    
                    <span class="domain-tag">physical examination</span>
                    
                    <span class="domain-tag">diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16596v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16596v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16596v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16596v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16574v1"
                     data-domains="Dermatology (ISIC for skin lesion segmentation/classification),Ophthalmology (CHASE for retinal vessel segmentation)"
                     data-keywords="Medical Unlearning,Machine Unlearning,Low-Rank Adaptation (LoRA),Medical Segmentation,Privacy-Preserving AI,Ethical AI,Teacher-Student Distillation,Deep Learning"
                     data-authors="Nirjhor Datta,Md. Golam Rabiul Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16574v1.html">Erase to Retain: Low Rank Adaptation Guided Selective Unlearning in Medical Segmentation Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nirjhor Datta, Md. Golam Rabiul Alam
                </div>

                <div class="paper-summary">
                    This paper introduces "Erase to Retain," a novel framework for controllable selective unlearning in medical segmentation networks. It leverages a teacher-student distillation paradigm with Low-Rank Adaptation (LoRA) to enable targeted forgetting of lesion or class-specific representations while preserving global anatomical understanding. The method effectively reduces performance on designated "forget" subsets across segmentation and classification tasks (e.g., ISIC, CHASE) while maintaining or improving performance on "retain" and validation sets, offering a practical solution for privacy compliance and ethical AI in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology (ISIC for skin lesion segmentation/classification)</span>
                    
                    <span class="domain-tag">Ophthalmology (CHASE for retinal vessel segmentation)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16571v1"
                     data-domains="Healthcare"
                     data-keywords="Tabular data,Data augmentation,Class imbalance,Minority oversampling,Diffusion models,Latent space,Gradient-boosted trees,Conditional flow matching,Healthcare"
                     data-authors="Md. Tawfique Ihsan,Md. Rakibul Hasan Rafi,Ahmed Shoyeb Raihan,Imtiaz Ahmed,Abdullahil Azeem">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16571v1.html">Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md. Tawfique Ihsan, Md. Rakibul Hasan Rafi, Ahmed Shoyeb Raihan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces novel latent-space, tree-driven diffusion methods (PCAForest, EmbedForest, AttentionForest) for minority oversampling in severely imbalanced tabular data. By using conditional flow matching with gradient-boosted trees as vector-field learners, these methods significantly improve minority recall, particularly with the AttentionForest variant, while maintaining efficiency, calibration, and privacy. This approach offers a robust solution for high-fidelity tabular data augmentation under severe class imbalance, outperforming existing generative oversampling techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16571v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16571v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16571v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16571v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16566v1"
                     data-domains="Pediatrics,Public Health,Nutrition,Global Health,Diagnostic Medicine"
                     data-keywords="child malnutrition,anthropometry,deep learning,graph attention network,computer vision,retrieval-augmented,low-resource settings,early detection"
                     data-authors="Misaal Khan,Mayank Vatsa,Kuldeep Singh,Richa Singh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16566v1.html">NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Misaal Khan, Mayank Vatsa, Kuldeep Singh et al.
                </div>

                <div class="paper-summary">
                    NutriScreener is a novel retrieval-augmented, multi-pose graph attention network that leverages CLIP-based visual embeddings and class-boosted knowledge retrieval for robust child malnutrition detection and anthropometric prediction from images. It achieves high recall (0.79) and AUC (0.82) with significantly lower anthropometric RMSEs, earning high clinical ratings for accuracy and efficiency, making it a scalable solution for early intervention in low-resource settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Nutrition</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16551v1"
                     data-domains="Oncology,Rare Diseases,Clinical Research,Drug Development,Biostatistics"
                     data-keywords="Generative AI,Clinical Trials,Synthetic Control Arms,Survival Analysis,Variational Autoencoder,Censored Data,Oncology,Rare Diseases"
                     data-authors="Perrine Chassat,Van Tuan Nguyen,Lucas Ducrot,Emilie Lanoy,Agathe Guilloux">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16551v1.html">Toward Valid Generative Clinical Trial Data with Survival Endpoints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Perrine Chassat, Van Tuan Nguyen, Lucas Ducrot et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Variational Autoencoder (VAE) designed to generate synthetic clinical trial data, specifically addressing the complex task of modeling time-to-event survival outcomes alongside mixed-type covariates. The VAE operates within a unified latent variable framework and uniquely does not assume independent censoring, outperforming existing GAN-based approaches on fidelity, utility, and privacy, while identifying and partially mitigating critical miscalibration issues in type I error and power.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16551v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16551v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16551v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16551v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16549v1"
                     data-domains="Diagnostic Imaging,Clinical Decision Support Systems,Precision Medicine,Public Health Screening,Pathology"
                     data-keywords="Deep Learning,Fairness,Singular Value Decomposition (SVD),Low Rank Factorization (LRF),Bias Mitigation,Medical Diagnosis,Model Performance,Group Disparities"
                     data-authors="Yuanbo Guo,Jun Xia,Yiyu Shi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16549v1.html">FairLRF: Achieving Fairness through Sparse Low Rank Factorization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuanbo Guo, Jun Xia, Yiyu Shi
                </div>

                <div class="paper-summary">
                    This paper introduces FairLRF, a novel fairness-oriented low rank factorization framework that leverages Singular Value Decomposition (SVD) to enhance the fairness of deep learning models without significantly sacrificing performance. Unlike traditional SVD used for compression, FairLRF identifies and selectively removes bias-inducing elements from SVD's unitary matrices, thereby reducing group disparities. Extensive experiments demonstrate that FairLRF surpasses conventional LRF methods and state-of-the-art fairness techniques, making it particularly relevant for sensitive applications like medical diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Public Health Screening</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16549v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16549v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16549v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16549v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16548v1"
                     data-domains="Clinical Informatics,Biomedical Research,Medical Natural Language Processing (NLP),Precision Medicine"
                     data-keywords="Large Language Models,Medical Ontology Extension,Clinical Notes,Zero-Shot Learning,Entity Extraction,Hierarchical Relationships,Patient Privacy,Biomedical Informatics"
                     data-authors="Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16548v1.html">Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guanchen Wu, Yuzhang Xie, Huanwei Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CLOZE, a novel zero-shot framework that leverages Large Language Models (LLMs) to automatically extract medical entities and their hierarchical relationships from unstructured clinical notes. The framework aims to extend existing medical ontologies by integrating these newly identified concepts, thereby enhancing their coverage and utility. CLOZE offers an accurate, scalable, and privacy-preserving solution, addressing the challenge of utilizing rich, context-specific data from clinical notes for ontology development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing (NLP)</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16548v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16548v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16548v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16548v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16544v1"
                     data-domains="Clinical Informatics,Medical Artificial Intelligence,Patient Safety,Digital Health,Speech Recognition in Healthcare"
                     data-keywords="Automatic Speech Recognition,ASR evaluation,Clinical impact,Word Error Rate,Large Language Models,LLM-as-a-Judge,Patient safety,Clinical dialogue"
                     data-authors="Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16544v1.html">WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zachary Ellis, Jared Joselowitz, Yash Deo et al.
                </div>

                <div class="paper-summary">
                    This paper challenges the standard reliance on Word Error Rate (WER) for evaluating Automatic Speech Recognition (ASR) in clinical dialogue, demonstrating its poor correlation with the actual clinical impact of transcription errors. It introduces and validates an LLM-as-a-Judge, programmatically optimized using GEPA, which achieves human-comparable performance in replicating expert clinician assessment of error impact.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Speech Recognition in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16544v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16544v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16544v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16544v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16498v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Breast Imaging"
                     data-keywords="DCE-MRI,Breast Cancer,Tumor Segmentation,Deep Learning,Feature-wise Linear Modulation (FiLM),Acquisition Time,Medical Imaging,Generalization"
                     data-authors="Rui Wang,Yuexi Du,John Lewin,R. Todd Constable,Nicha C. Dvornek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16498v1.html">Acquisition Time-Informed Breast Tumor Segmentation from Dynamic Contrast-Enhanced MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Wang, Yuexi Du, John Lewin et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of automated breast tumor segmentation from Dynamic Contrast-Enhanced MRI (DCE-MRI) caused by variations in acquisition protocols and patient factors. It proposes a novel deep learning method that leverages image acquisition time, incorporated via Feature-wise Linear Modulation (FiLM) layers, to modulate model features. The study demonstrates that this time-informed approach significantly improves tumor segmentation performance and enhances model generalization across diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Breast Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16471v1"
                     data-domains="Neurology,Neuroscience,Aging Research,Clinical Trials,Medical Imaging,Neurodegenerative Diseases"
                     data-keywords="corpus callosum,morphometry,segmentation,neurological diseases,Huntington's disease,biomarker,automation,neuroimaging"
                     data-authors="Clemens Pollak,Kersten Diers,Santiago Estrada,David K√ºgler,Martin Reuter">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16471v1.html">FastSurfer-CC: A robust, accurate, and comprehensive framework for corpus callosum morphometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Clemens Pollak, Kersten Diers, Santiago Estrada et al.
                </div>

                <div class="paper-summary">
                    FastSurfer-CC is presented as an efficient, fully automated, and comprehensive framework for corpus callosum morphometry, developed to address the lack of such publicly available tools. It integrates multiple analysis steps, from segmentation to advanced shape metric extraction, demonstrating superior performance over existing tools and revealing previously undetected differences in Huntington's disease patients.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Aging Research</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16471v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16471v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16471v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16471v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16427v1"
                     data-domains="Oncology,Critical Care Medicine,Pharmacokinetics/Pharmacodynamics,Personalized Medicine,Medical Decision Support"
                     data-keywords="Generative Modeling,Stochastic Differential Equations,Clinical Time Series,Variational Inference,Treatment Effect Estimation,Pharmacokinetics-Pharmacodynamics,Intensive Care Unit,Uncertainty Quantification"
                     data-authors="Muhammad Aslanimoghanloo,Ahmed ElGazzar,Marcel van Gerven">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16427v1.html">Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Aslanimoghanloo, Ahmed ElGazzar, Marcel van Gerven
                </div>

                <div class="paper-summary">
                    This paper introduces a generative modeling framework based on latent neural Stochastic Differential Equations (SDEs) to analyze complex clinical time series data from electronic health records, addressing challenges like irregular sampling, non-linear dynamics, and inherent uncertainties. The framework effectively models underlying stochastic physiological processes and demonstrates superior performance in accuracy and uncertainty estimation compared to traditional methods for treatment effect estimation and physiological forecasting.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Pharmacokinetics/Pharmacodynamics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16427v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16427v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16427v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16427v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16398v1"
                     data-domains="Chronic Disease Management,Mental Health,Preventive Medicine,Digital Health,Geriatrics,Integrated Care"
                     data-keywords="Multi-Task Learning,Chronic Diseases,Depression,Wearable Sensors,Double Heterogeneity,Bayesian Network,Digital Health,Comorbidity"
                     data-authors="Yidong Chai,Haoxin Liu,Jiaheng Xie,Chaopeng Wang,Xiao Fang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16398v1.html">Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yidong Chai, Haoxin Liu, Jiaheng Xie et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method for the joint assessment of comorbid physical chronic diseases and depression using wearable sensor data. It addresses the unique challenges of variability across different diseases and individual patients by integrating group-level modeling, a decomposition strategy, and a Bayesian network. Empirical evaluations demonstrate that ADH-MTL significantly outperforms existing baselines, offering a robust computational solution for integrated physical and mental healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16398v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16398v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16398v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16398v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16346v1"
                     data-domains="Rehabilitation Medicine,Physical Therapy,Sports Medicine,Geriatrics,Orthopedics,Remote Patient Monitoring"
                     data-keywords="Capacitive sensing,Smart textiles,Motion capture,Deep learning,Wearable technology,Rehabilitation,Gait analysis,Remote patient monitoring"
                     data-authors="Deniz Kasap,Taraneh Aminosharieh Najafi,J√©r√¥me Paul R√©my Thevenot,Jonathan Dan,Stefano Albini,David Atienza">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16346v1.html">VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deniz Kasap, Taraneh Aminosharieh Najafi, J√©r√¥me Paul R√©my Thevenot et al.
                </div>

                <div class="paper-summary">
                    VersaPants introduces a novel loose-fitting, textile-based capacitive sensing system for lower-body motion capture, leveraging a lightweight Transformer-based deep learning model to reconstruct joint angles. This system offers a comfortable, privacy-preserving alternative to traditional IMU or camera-based methods, achieving competitive accuracy with high computational efficiency. Its ability to perform real-time inference on edge devices positions it as a promising solution for scalable motion capture in fitness, healthcare, and wellbeing applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16346v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16346v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16346v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16346v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16333v1"
                     data-domains="Medical Imaging,Diagnostics,Disease Progression Modeling,Electronic Health Records (EHR),Robotic Surgery,Surgical Planning"
                     data-keywords="World Models,Clinical Prediction,Counterfactuals,Planning,Healthcare AI,Temporal Reasoning,Causal Inference,Medical Decision Support"
                     data-authors="Mohammad Areeb Qazi,Maryam Nadeem,Mohammad Yaqub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16333v1.html">Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Areeb Qazi, Maryam Nadeem, Mohammad Yaqub
                </div>

                <div class="paper-summary">
                    This paper reviews World Models as a promising AI paradigm for healthcare, advocating their superiority over traditional generative models due to their capacity for learning multimodal, temporally coherent, and action-conditioned representations reflecting the physical and causal structure of care. It surveys applications across medical imaging, disease progression, and robotic surgery, while also introducing a capability rubric and identifying critical gaps for robust clinical deployment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR)</span>
                    
                    <span class="domain-tag">Robotic Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16292v1"
                     data-domains="Health informatics,Digital health,Interoperability,Patient data management,Health insurance,Clinical decision support"
                     data-keywords="Distributed agents,Multi-agent systems,Data locality,Privacy-preserving,Healthcare interoperability,Natural language processing,Secure communication,Pseudonymization"
                     data-authors="Daniel Vaughan,Kate≈ôina Vaughan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16292v1.html">Distributed Agent Reasoning Across Independent Systems With Strict Data Locality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Vaughan, Kate≈ôina Vaughan
                </div>

                <div class="paper-summary">
                    This paper presents a proof-of-concept demonstration for secure, distributed agent reasoning across independent systems in healthcare. It showcases how distinct organizations (Clinic, Insurer, Specialist) can cooperate using natural-language messages and local data lookups, without shared identifiers, centralized data, or reconstructing patient identity, thus maintaining strict data locality and privacy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health informatics</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Interoperability</span>
                    
                    <span class="domain-tag">Patient data management</span>
                    
                    <span class="domain-tag">Health insurance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16292v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16292v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16292v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16292v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16283v1"
                     data-domains="Genomics,Personalized Medicine,Disease Etiology,Clinical Decision Support,Biomedical Research,Pharmacogenomics,Bioinformatics"
                     data-keywords="retrieval-augmented generation (RAG),scientific question answering,multi-intent retrieval,large language models (LLMs),intent decomposition,reciprocal rank fusion (RRF),evidence coverage,biomedical informatics"
                     data-authors="Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16283v1.html">MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhiyuan Li, Haisheng Yu, Guangchuan Guo et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the limitations of conventional single-intent Retrieval-Augmented Generation (RAG) systems in handling complex scientific questions that require evidence from multiple intents and multi-hop reasoning. It introduces the Multi-Intent Scientific Question Answering (MuISQA) benchmark to evaluate heterogeneous evidence coverage and proposes an intent-aware retrieval framework. This framework leverages LLMs to decompose questions into intent-specific queries, retrieves diverse supporting passages, and aggregates them using Reciprocal Rank Fusion (RRF) to achieve superior retrieval accuracy and evidence coverage.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Disease Etiology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Biomedical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16283v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16283v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16283v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16283v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16268v1"
                     data-domains="Neurology,Neuropathology,Digital Pathology,Neurodegeneration,Computational Neuroscience"
                     data-keywords="Parkinson's disease,Alpha-synuclein,Lewy bodies,Neurites,Deep Learning,Weakly supervised segmentation,Immunohistochemistry,Whole-slide imaging,Neuropathology,Neurodegeneration"
                     data-authors="Erwan Dereure,Robin Louiset,Laura Parkkinen,David A Menassa,David Holcman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16268v1.html">Weakly Supervised Segmentation and Classification of Alpha-Synuclein Aggregates in Brightfield Midbrain Images</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Erwan Dereure, Robin Louiset, Laura Parkkinen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an automated deep learning pipeline for the segmentation and classification of alpha-synuclein aggregates, including Lewy bodies and neurites, in brightfield midbrain whole-slide images from Parkinson's disease and incidental Lewy Body Disease cases. The method leverages weakly supervised segmentation for robustness to immunohistochemical variability and a ResNet50 classifier, achieving an 80% balanced accuracy in differentiating aggregate morphologies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuropathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Neurodegeneration</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16268v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16268v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16268v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16268v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16186v1"
                     data-domains="Cardiology,Neurology,Pulmonology,Medical Imaging,Anatomy,Surgical Planning,Radiology"
                     data-keywords="3D reconstruction,organ mesh,deep learning,topology preservation,medical imaging,substructures,geometric accuracy,clinical use"
                     data-authors="Deniz Sayin Mercadier,Hieu Le,Yihong Chen,Jiancheng Yang,Udaranga Wickramasinghe,Pascal Fua">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16186v1.html">PrIntMesh: Precise Intersection Surfaces for 3D Organ Mesh Reconstruction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deniz Sayin Mercadier, Hieu Le, Yihong Chen et al.
                </div>

                <div class="paper-summary">
                    PrIntMesh is a novel template-based, topology-preserving deep learning framework designed to reconstruct organs as unified systems, addressing the issue of anatomically implausible reconstructions from independently processed substructures. It achieves high geometric accuracy and structural consistency by jointly deforming all substructures from a connected template, explicitly preserving internal boundaries, and enforcing smooth surfaces, demonstrating robust performance even with limited or noisy data. This approach offers a data-efficient solution suitable for clinical use, outperforming traditional methods in maintaining anatomical plausibility.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Anatomy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16186v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16186v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16186v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16186v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16179v1"
                     data-domains="Epidemiology,Public Health,Infectious Diseases,Mathematical Biology,Tropical Medicine"
                     data-keywords="Dengue,Age-structured model,Reproduction number,Brazil,Epidemiology,Climate factors,Vector-borne disease,Transmission dynamics"
                     data-authors="Ihtisham Ul Haq,Serge Richard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16179v1.html">Age-structured model of dengue transmission dynamics with time-varying parameters, and its application to Brazil</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ihtisham Ul Haq, Serge Richard
                </div>

                <div class="paper-summary">
                    This paper develops and analyzes a novel age-structured mathematical model with time-varying parameters to investigate the complex dynamics of dengue transmission. It provides comprehensive theoretical characterizations, including various reproduction numbers, and applies the model to Brazil using real-world epidemiological and climate data. The research highlights the critical influence of population age distribution, vector dynamics, and climate on dengue spread, offering valuable predictions and a deeper understanding of the disease in the region.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Mathematical Biology</span>
                    
                    <span class="domain-tag">Tropical Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16179v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16179v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16179v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16179v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16162v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.GR"
                     data-authors="Yuting Lu,Ziliang Wang,Weixin Xu,Wei Zhang,Yongqiang Zhao,Yang Yu,Xiaohong Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16162v1.html">Layer-wise Noise Guided Selective Wavelet Reconstruction for Robust Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuting Lu, Ziliang Wang, Weixin Xu et al.
                </div>

                <div class="paper-summary">
                    Clinical deployment requires segmentation models to stay stable under distribution shifts and perturbations. The mainstream solution is adversarial training (AT) to improve robustness; however, AT often brings a clean--robustness trade-off and high training/tuning cost, which limits scalability and ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16162v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16162v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16162v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16162v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16139v1"
                     data-domains="Clinical Decision Support,Medical Diagnostics,Medical Education,General Medicine"
                     data-keywords="Large Language Models,Medical AI,Reward Model Learning,Clinical Alignment,Multidimensional Evaluation,Geometric Projection,Healthbench,Medical Standards"
                     data-authors="Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16139v1.html">Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yongnan Jin, Xurui Li, Feng Cao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MR-RML (Multidimensional Rubric-oriented Reward Model Learning), a novel alignment framework designed to address critical challenges in integrating LLMs into medical practice. By leveraging a structured medical standard system and geometric projection constraints, MR-RML enables LLMs to capture nuanced, multi-dimensional medical quality criteria more effectively. The method significantly enhances LLM performance on medical benchmarks, achieving state-of-the-art results among open-source models and outperforming most closed-source counterparts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">General Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16139v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16139v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16139v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16139v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16096v1"
                     data-domains="Infectious Diseases,Public Health,Epidemiology,Health Policy,Global Health"
                     data-keywords="Hepatitis B,Agent-based model,Migrant health,Healthcare access,Disease elimination,Thai-Myanmar border,Public health policy,Epidemiology"
                     data-authors="Anh D. Pham,Robert Moss,Wirichada Pan-ngum,Rose McGready,Nicholas Geard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16096v1.html">Modelling the impact of improving access to healthcare on Hepatitis B prevalence in the Thai-Myanmar border region</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anh D. Pham, Robert Moss, Wirichada Pan-ngum et al.
                </div>

                <div class="paper-summary">
                    This study developed an Agent-based model to analyze Hepatitis B (HBV) prevalence in the Thai-Myanmar border region, explicitly differentiating between Thai and migrant populations. It found that current interventions, while effective for Thais, are insufficient for national HBV elimination targets due to high prevalence among migrants, and quantifies the necessary improvement in migrant healthcare access.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Policy</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16096v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16096v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16096v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16096v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16087v1"
                     data-domains="Drug Discovery,Medicinal Chemistry,Pharmacology,Computational Biology,Cheminformatics"
                     data-keywords="Drug Discovery,Machine Learning,Data Selection,Bioactivity Data,Assay Compatibility,Language Embeddings,Data Attribution,Molecular Activity Prediction"
                     data-authors="Vincent Fan,Regina Barzilay">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16087v1.html">AssayMatch: Learning to Select Data for Molecular Activity Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vincent Fan, Regina Barzilay
                </div>

                <div class="paper-summary">
                    AssayMatch is a novel framework that enhances the performance of machine learning models in drug discovery by intelligently selecting training data. It addresses the issue of noise and variability in aggregated bioactivity datasets by curating smaller, more homogenous training sets specifically attuned to a test set, even when test molecule labels are unknown. This is achieved by leveraging data attribution to finetune language embeddings of assay descriptions, capturing compatibility beyond mere semantic similarity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Cheminformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16087v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16087v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16087v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16087v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16020v1"
                     data-domains="Healthcare Security,Patient Privacy,Medical Informatics,Biomedical Engineering,Geriatric Care (monitoring systems),Hospital Management"
                     data-keywords="Adversarial Attacks,Human Detection,Computer Vision,Deep Learning,Wearable Technology,Privacy,Surveillance,Robust AI"
                     data-authors="Dingkun Zhou,Patrick P. K. Chan,Hengxu Wu,Shikang Zheng,Ruiqi Huang,Yuanjie Zhao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16020v1.html">Physically Realistic Sequence-Level Adversarial Clothing for Robust Human-Detection Evasion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dingkun Zhou, Patrick P. K. Chan, Hengxu Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel sequence-level optimization framework to generate physically realistic, printable adversarial textures for common clothing items (shirts, trousers, hats) that enable robust human-detection evasion. The generated garments maintain concealment throughout entire walking videos, demonstrating high stability, robustness to viewpoint changes, and cross-model transferability in both digital simulations and real-world physical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare Security</span>
                    
                    <span class="domain-tag">Patient Privacy</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Geriatric Care (monitoring systems)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16020v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16020v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16020v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16020v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16006v1"
                     data-domains="Critical Care,Precision Medicine,Chronic Disease Management,Treatment Optimization,Personalized Healthcare,Clinical Decision Support"
                     data-keywords="Time-series,Counterfactual Outcome Estimation,Deconfounding,Temporal Generalization,Causal Inference,Medical Decision-Making,Sub-treatment Group Alignment,Random Temporal Masking"
                     data-authors="Yiling Liu,Juncheng Dong,Chen Fu,Wei Shi,Ziyang Jiang,Zhigang Hua,David Carlson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16006v1.html">Synergizing Deconfounding and Temporal Generalization For Time-series Counterfactual Outcome Estimation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiling Liu, Juncheng Dong, Chen Fu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework combining Sub-treatment Group Alignment (SGA) and Random Temporal Masking (RTM) to improve time-series counterfactual outcome estimation. SGA enhances deconfounding by aligning fine-grained sub-treatment groups, while RTM promotes temporal generalization and robustness by encouraging reliance on stable historical patterns. Their synergistic application achieves state-of-the-art performance, enabling more effective decision-making in dynamic medical settings by better handling evolving confounders and improving temporal stability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Treatment Optimization</span>
                    
                    <span class="domain-tag">Personalized Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16006v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16006v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16006v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16006v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15994v1"
                     data-domains="cs.AI"
                     data-keywords="cs.AI,cs.CL"
                     data-authors="Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15994v1.html">CARE-RAG - Clinical Assessment and Reasoning in RAG</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deepthi Potluri, Aby Mammen Mathew, Jeffrey B DeWitt et al.
                </div>

                <div class="paper-summary">
                    Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therap...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15994v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15994v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15994v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15994v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15986v1"
                     data-domains="Medical Imaging,Diagnostic Radiology,Computational Pathology,Healthcare Equity"
                     data-keywords="Fairness,Multimodal LLMs,In-Context Learning,Medical Diagnosis,Bias Mitigation,Demonstration Selection,Demographic Disparity,Medical Imaging"
                     data-authors="Dawei Li,Zijian Gu,Peng Wang,Chuhan Song,Zhen Tan,Mohan Zhang,Tianlong Chen,Yu Tian,Song Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15986v1.html">Fairness in Multi-modal Medical Diagnosis with Demonstration Selection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dawei Li, Zijian Gu, Peng Wang et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical issue of fairness across demographic groups in medical image reasoning using Multimodal Large Language Models (MLLMs), proposing a novel tuning-free approach. The authors introduce Fairness-Aware Demonstration Selection (FADS), which constructs demographically balanced and semantically relevant in-context learning demonstrations using clustering-based sampling. FADS is shown to consistently reduce gender, race, and ethnicity disparities on medical imaging benchmarks while maintaining high accuracy, offering a scalable solution for equitable medical AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Healthcare Equity</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15986v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15986v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15986v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15986v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15977v1"
                     data-domains="Precision Medicine,Genomics,Bioinformatics,Genetic Diagnostics,Pharmacogenomics,Oncogenomics"
                     data-keywords="Precision Medicine,Genomic Workflows,Parallelization,Memory Optimization,Resource Allocation,Symbolic Regression,Knapsack Problem,Bioinformatics"
                     data-authors="Daniel Mas Montserrat,Ray Verma,M√≠riam Barrab√©s,Francisco M. de la Vega,Carlos D. Bustamante,Alexander G. Ioannidis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15977v1.html">Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.DC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Mas Montserrat, Ray Verma, M√≠riam Barrab√©s et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenges of high memory consumption and inefficient resource utilization in large-scale precision medicine genomic workflows by proposing adaptive, RAM-efficient parallelization mechanisms. It introduces symbolic and polynomial regression models for memory prediction, dynamic and static schedulers to optimize task packing and processing order, ultimately reducing memory overruns, balancing load, and accelerating end-to-end execution.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Genetic Diagnostics</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15977v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15977v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15977v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15977v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15974v1"
                     data-domains="Infectious Disease,Clinical Pharmacology,Diagnostic Medicine,Medical Informatics,AI in Healthcare"
                     data-keywords="LLM,Antimicrobial Therapy,Clinical Decision Support,Knowledge Augmentation,Reasoning,Reinforcement Learning,Semi-supervised Learning,Privacy-preserving AI"
                     data-authors="Zhe Li,Yehan Qiu,Yujie Chen,Xiang Zhou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15974v1.html">KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhe Li, Yehan Qiu, Yujie Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces KRAL (Knowledge and Reasoning Augmented Learning), a novel paradigm designed to overcome inherent limitations of LLMs in complex clinical antimicrobial therapy, such as knowledge gaps, privacy concerns, high costs, and limited reasoning. KRAL achieves this by distilling teacher-model reasoning, employing semi-supervised data augmentation, and utilizing agentic reinforcement learning. It significantly outperforms traditional RAG and SFT methods in both knowledge question-answering and reasoning capabilities at a fraction of the training cost, enabling safe and effective local LLM deployment in clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15974v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15974v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15974v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15974v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15963v1"
                     data-domains="Radiology,Oncology,Medical Imaging Research,Precision Medicine"
                     data-keywords="Radiomics,Deep Learning,Python,Reproducibility,Standardization,Medical Imaging,AI,Biomarkers"
                     data-authors="Mohammad R. Salmanpour,Amir Hossein Pouria,Sirwan Barichin,Yasaman Salehi,Sonya Falahati,Isaac Shiri,Mehrdad Oveisi,Arman Rahmim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15963v1.html">PySERA: Open-Source Standardized Python Library for Automated, Scalable, and Reproducible Handcrafted and Deep Radiomics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad R. Salmanpour, Amir Hossein Pouria, Sirwan Barichin et al.
                </div>

                <div class="paper-summary">
                    PySERA is an open-source, Python-native library designed to standardize and automate both handcrafted and deep learning radiomics, addressing issues of reproducibility and scalability in medical image analysis. It provides a robust framework for extracting quantitative biomarkers from medical images, integrating seamlessly with AI ecosystems, and demonstrating superior reproducibility and predictive accuracy compared to existing tools.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Medical Imaging Research</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15963v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15963v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15963v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15963v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15946v1"
                     data-domains="Cardiology,Diagnostic Imaging,Cardiovascular Medicine,Medical AI"
                     data-keywords="Echocardiography,3D Ultrasound,Deep Learning,Medical Imaging,2D Video Extraction,Cardiac Imaging,AI,Image Reconstruction"
                     data-authors="Milos Vukadinovic,Hirotaka Ieki,Yuki Sahasi,David Ouyang,Bryan He">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15946v1.html">Automated Interpretable 2D Video Extraction from 3D Echocardiography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Milos Vukadinovic, Hirotaka Ieki, Yuki Sahasi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an automated deep learning method to extract standard 2D echocardiography views from 3D cardiac ultrasound volumes. The system enables physicians to interpret complex 3D data in their conventional 2D format, benefiting from the speed and usability of 3D scanning while preserving diagnostic accuracy and spatial calibration. Validated by cardiologists and AI models, this approach aims to streamline cardiac imaging workflows.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Cardiovascular Medicine</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15946v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15946v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15946v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15946v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15943v1"
                     data-domains="Radiology,Diagnostic Imaging,Clinical Decision Support,Medical AI"
                     data-keywords="Medical Imaging,Visual Understanding,Multi-label Classification,Multi-granularity Learning,Contrastive Learning,Vision-Language Models,CLIP,Deep Learning"
                     data-authors="Zihan Li,Yiqing Wang,Sina Farsiu,Paul Kinahan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15943v1.html">Boosting Medical Visual Understanding From Multi-Granular Language Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihan Li, Yiqing Wang, Sina Farsiu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Multi-Granular Language Learning (MGLL), a novel contrastive learning framework designed to enhance visual understanding in complex medical imaging by addressing the limitations of existing methods like CLIP. MGLL specifically improves multi-label and cross-granularity alignment, integrating diverse textual descriptions and structured supervision to accurately interpret medical images with multiple diagnoses and varying levels of detail. Pretrained on large-scale multi-granular datasets, MGLL significantly outperforms state-of-the-art methods in downstream medical tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15943v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15943v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15943v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15943v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15932v1"
                     data-domains="Oncology,Radiation Oncology,Medical Physics,Computational Biology,Precision Medicine"
                     data-keywords="Mathematical modeling,Chemotherapy,Radiotherapy,Treatment optimization,Personalized medicine,Adaptive therapy,Model bias,Uncertainty quantification"
                     data-authors="Changin Oh,Kathleen P. Wilkie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15932v1.html">How Mathematical Forms of Chemotherapy and Radiotherapy Bias Model-Optimized Predictions: Implications for Model Selection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Changin Oh, Kathleen P. Wilkie
                </div>

                <div class="paper-summary">
                    This study comprehensively investigates how the choice of mathematical models for chemotherapy and radiotherapy significantly biases optimized treatment protocols, comparing three distinct models for each modality. It demonstrates that inherent model assumptions critically influence optimal dosing and sequencing, often leading to contradictory and non-generalizable predictions crucial for personalized and adaptive cancer therapies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15932v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15932v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15932v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15932v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15906v1"
                     data-domains="Drug Discovery,Biologics Development,Therapeutic Design,Immunology,Oncology,Infectious Diseases"
                     data-keywords="Generative AI,Drug Discovery,Neural Fields,Antibody Engineering,Peptide Design,Structure-Based Drug Design,Molecular Generation"
                     data-authors="Matthieu Kirchmeyer,Pedro O. Pinheiro,Emma Willett,Karolis Martinkus,Joseph Kleinhenz,Emily K. Makowski,Andrew M. Watkins,Vladimir Gligorijevic,Richard Bonneau,Saeed Saremi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15906v1.html">Unified all-atom molecule generation with neural fields</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Matthieu Kirchmeyer, Pedro O. Pinheiro, Emma Willett et al.
                </div>

                <div class="paper-summary">
                    This paper introduces FuncBind, a novel framework leveraging neural fields and score-based generative models adapted from computer vision, to unify all-atom molecule generation across diverse atomic systems. FuncBind overcomes modality-specific limitations, enabling a single model to generate small molecules, macrocyclic peptides, and antibody complementarity-determining region loops conditioned on target structures, and demonstrated successful *in vitro* generation of novel antibody binders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Biologics Development</span>
                    
                    <span class="domain-tag">Therapeutic Design</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15906v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15906v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15906v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15906v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15904v1"
                     data-domains="stat.ME"
                     data-keywords="stat.ME,econ.EM,math.ST,stat.ML"
                     data-authors="G√∂zde Sert,Abhishek Chakrabortty,Anirban Bhattacharya">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15904v1.html">Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> G√∂zde Sert, Abhishek Chakrabortty, Anirban Bhattacharya
                </div>

                <div class="paper-summary">
                    We propose a semiparametric Bayesian methodology for estimating the average treatment effect (ATE) within the potential outcomes framework using observational data with high-dimensional nuisance parameters. Our method introduces a Bayesian debiasing procedure that corrects for bias arising from nuis...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">stat.ME</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15904v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15904v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15904v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15904v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15902v1"
                     data-domains="Mental health,Clinical diagnostics,Caregiving,Home health,Telemedicine,Neuroscience"
                     data-keywords="EEG,emotion recognition,deep learning,CNN-Transformer,mental health,emotional monitoring,consumer-grade EEG,diagnostics"
                     data-authors="Roman Dolgopolyi,Antonis Chatzipanagiotou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15902v1.html">EEG Emotion Recognition Through Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Dolgopolyi, Antonis Chatzipanagiotou
                </div>

                <div class="paper-summary">
                    This paper presents an advanced CNN-Transformer deep learning model for EEG-based emotion recognition, classifying positive, neutral, and negative states with 91% testing accuracy. The model significantly reduces hardware requirements by effectively using only 5 EEG electrodes, enabling accessible and affordable at-home use for continuous emotional monitoring. This innovation holds promise for transforming mental health diagnostics and interventions, particularly in settings where traditional behavioral cues are difficult to interpret.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mental health</span>
                    
                    <span class="domain-tag">Clinical diagnostics</span>
                    
                    <span class="domain-tag">Caregiving</span>
                    
                    <span class="domain-tag">Home health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15902v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15902v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15902v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15902v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15896v1"
                     data-domains="Epidemiology,Health Outcomes Research,Comparative Effectiveness Research,Pharmacovigilance,Public Health,Clinical Research"
                     data-keywords="Causal Inference,Observational Studies,Covariate Adjustment,Outcome-Informed Design,Sample Splitting,Cross-Balancing,Efficiency,Multiply Robust"
                     data-authors="Ying Jin,Jos√© Zubizarreta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15896v1.html">Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ying Jin, Jos√© Zubizarreta
                </div>

                <div class="paper-summary">
                    This paper introduces cross-balancing, a novel method for causal inference in observational studies that strategically incorporates outcome data into the study design to construct or select balancing features. By employing sample splitting, it effectively separates errors in feature construction from errors in weight estimation, resulting in consistent, asymptotically normal, and efficient estimators for treatment effects. The method substantially improves both estimation and inference across scenarios, including high-dimensional variable selection and learned functions, while maintaining interpretability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Outcomes Research</span>
                    
                    <span class="domain-tag">Comparative Effectiveness Research</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15896v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15896v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15896v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15896v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15857v1"
                     data-domains="cs.HC"
                     data-keywords="cs.HC,cs.AI"
                     data-authors="Anthony Wise,Xinyi Zhou,Martin Reimann,Anind Dey,Leilani Battle">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15857v1.html">A Crowdsourced Study of ChatBot Influence in Value-Driven Decision Making Scenarios</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anthony Wise, Xinyi Zhou, Martin Reimann et al.
                </div>

                <div class="paper-summary">
                    Similar to social media bots that shape public opinion, healthcare and financial decisions, LLM-based ChatBots like ChatGPT can persuade users to alter their behavior. Unlike prior work that persuades via overt-partisan bias or misinformation, we test whether framing alone suffices. We conducted a c...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.HC</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15857v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15857v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15857v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15857v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15847v1"
                     data-domains="Intensive Care Medicine,Critical Care,Hospital Medicine,Clinical Informatics"
                     data-keywords="ICU mortality prediction,Multimodal learning,Clinical Transformers,Machine learning interpretability,Physiological time-series,Clinical notes,Ensemble models,MIMIC-III"
                     data-authors="Alexander Bakumenko,Janine Hoelscher,Hudson Smith">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15847v1.html">Transparent Early ICU Mortality Prediction with Clinical Transformer and Per-Case Modality Attribution</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alexander Bakumenko, Janine Hoelscher, Hudson Smith
                </div>

                <div class="paper-summary">
                    This paper presents a transparent and lightweight multimodal ensemble model for early in-hospital mortality prediction in Intensive Care Unit (ICU) patients, leveraging physiological time-series and unstructured clinical notes from the first 48 hours. By combining a bidirectional LSTM for vitals and a finetuned ClinicalModernBERT for notes with a logistic regression, the system significantly improves predictive performance (AUPRC 0.565, AUROC 0.891) on MIMIC-III while offering crucial per-case modality and feature-level interpretability, alongside robustness to missing data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Hospital Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15847v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15847v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15847v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15847v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15839v1"
                     data-domains="Infectious Disease Epidemiology,Public Health,Critical Care Medicine,Computational Biology"
                     data-keywords="Bayesian inference,Frequentist inference,Epidemic models,COVID-19,Mpox,Identifiability,Forecasting,Uncertainty quantification"
                     data-authors="Mohammed A. Y. Mohammed,Hamed Karami,Gerardo Chowell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15839v1.html">Comparing Bayesian and Frequentist Inference in Biological Models: A Comparative Analysis of Accuracy, Uncertainty, and Identifiability</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammed A. Y. Mohammed, Hamed Karami, Gerardo Chowell
                </div>

                <div class="paper-summary">
                    This paper comparatively analyzes Bayesian and Frequentist inference frameworks across three biological models (Lotka-Volterra, generalized logistic, and SEIUR epidemic) using four datasets to assess their accuracy, uncertainty quantification, and identifiability. It concludes that Frequentist methods perform best with rich, fully observed data, while Bayesian inference excels with sparse data and high latent-state uncertainty, offering critical guidance for model selection in biological and medical research.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15839v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15839v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15839v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15839v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15778v1"
                     data-domains="Clinical Informatics,Pediatric Medicine,Pharmacology,Natural Language Processing in Healthcare"
                     data-keywords="Clinical NLP,Large Language Models,Rule-based NLP,Electronic Health Records,Information Extraction,Polish EHR,Text Normalisation,Hybrid Approaches"
                     data-authors="Paulina Tworek,Mi≈Çosz Bargie≈Ç,Yousef Khan,Tomasz Pe≈Çech-Pilichowski,Marek Miko≈Çajczyk,Roman Lewandowski,Jose Sousa">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15778v1.html">Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paulina Tworek, Mi≈Çosz Bargie≈Ç, Yousef Khan et al.
                </div>

                <div class="paper-summary">
                    This study comparatively analyzes low-compute rule-based NLP methods and Large Language Models (LLMs) for extracting structured medical insights from Polish Electronic Health Records (EHRs). It finds that rule-based methods offer higher accuracy for demographic data like age and sex, while LLMs provide greater adaptability, scalability, and excel in drug name recognition, even considering translation-induced information loss. The paper advocates for hybrid NLP approaches to achieve reliable and resource-efficient clinical NLP.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Pediatric Medicine</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Natural Language Processing in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15778v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15778v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15778v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15778v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15771v1"
                     data-domains="Medical Imaging,Radiology,Diagnostics,Medical AI,Clinical Workflow Optimization"
                     data-keywords="Universal Segmentation,Ultrasound Imaging,SAM2,Parameter-Efficient Fine-Tuning,Knowledge Distillation,Medical Image Analysis,Deep Learning,Resource-Constrained Environments"
                     data-authors="Yue Li,Qing Xu,Yixuan Zhang,Xiangjian He,Qian Zhang,Yuan Yao,Fiseha B. Tesem,Xin Chen,Ruili Wang,Zhen Chen,Chang Wen Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15771v1.html">UniUltra: Interactive Parameter-Efficient SAM2 for Universal Ultrasound Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yue Li, Qing Xu, Yixuan Zhang et al.
                </div>

                <div class="paper-summary">
                    UniUltra addresses the degradation of SAM2's performance on ultrasound images and the challenges of deploying large models in clinical settings. It introduces a parameter-efficient Context-Edge Hybrid Adapter (CH-Adapter) for domain adaptation and a Deep-Supervised Knowledge Distillation (DSKD) technique for model compression, resulting in a lightweight, high-performing, and universal ultrasound segmentation model.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Clinical Workflow Optimization</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15771v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15771v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15771v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15771v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15640v1"
                     data-domains="Diagnostic Imaging,Radiology,Oncology,Hepatology,Cardiology,Gastroenterology"
                     data-keywords="Ultrasound Strain Elastography,Deep Learning,Unsupervised Learning,Strain Estimation,Tissue Mechanics,Medical Imaging,Residual-Aware,Encoder-Decoder"
                     data-authors="Shourov Joarder,Tushar Talukder Showrav,Md. Kamrul Hasan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15640v1.html">Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shourov Joarder, Tushar Talukder Showrav, Md. Kamrul Hasan
                </div>

                <div class="paper-summary">
                    MUSSE-Net is a novel multi-stage, residual-aware unsupervised deep learning framework designed for consistent and robust Ultrasound Strain Elastography (USE). It addresses critical challenges such as tissue decorrelation noise and inconsistent strain estimation by employing a multi-stream encoder-decoder network (USSE-Net) with attention mechanisms and a tailored consistency loss, followed by a secondary residual refinement stage, demonstrating superior performance across diverse datasets. The framework significantly enhances lesion contrast and suppresses noise, yielding clinically interpretable strain patterns.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15640v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15640v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15640v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15640v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15632v1"
                     data-domains="Cardiology,Telemedicine,Clinical Diagnostics,Public Health,Biomedical Engineering"
                     data-keywords="ECG analysis,Artificial intelligence,Cardiology,Dataset,Telehealth,Diagnostic criteria,Machine learning,Biomedical signal processing"
                     data-authors="Petrus E. O. G. B. Abreu,Gabriela M. M. Paix√£o,Jiawei Li,Paulo R. Gomes,Peter W. Macfarlane,Ana C. S. Oliveira,Vinicius T. Carvalho,Thomas B. Sch√∂n,Antonio Luiz P. Ribeiro,Ant√¥nio H. Ribeiro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15632v1.html">CODE-II: A large-scale dataset for artificial intelligence in ECG analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Petrus E. O. G. B. Abreu, Gabriela M. M. Paix√£o, Jiawei Li et al.
                </div>

                <div class="paper-summary">
                    CODE-II is a large-scale, real-world dataset comprising 2,735,269 12-lead ECGs from over 2 million adult patients, meticulously annotated with 66 clinically meaningful diagnostic classes validated by cardiologists, specifically designed to advance AI in ECG analysis. A neural network pre-trained on CODE-II demonstrated superior transfer performance on external benchmarks, outperforming models trained on other larger datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Clinical Diagnostics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15632v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15632v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15632v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15632v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15617v1"
                     data-domains="Musculoskeletal Imaging,Orthopedics,Sports Medicine,Rheumatology,Point-of-Care Diagnostics,Medical Physics"
                     data-keywords="ZTE imaging,low-field MRI,portable MRI,Halbach scanner,musculoskeletal imaging,hard tissue,T1 mapping,field inhomogeneity"
                     data-authors="Jose Borreguero,Luiz G. C. Santos,Lorena Vega Cid,Elisa Casta√±√≥n,Marina Fern√°ndez-Garc√≠a,Pablo Benlloch,Rub√©n Bosch,Jes√∫s Conejero,Pablo Garc√≠a-Crist√≥bal,Alba Gonz√°lez-Cebri√°n,Teresa Guallart-Naval,Eduardo Pall√°s,Laia Porcar,Lucas Swistunow,Jose Miguel Algar√≠n,Fernando Galve,Joseba Alonso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15617v1.html">Qualitative and quantitative hard-tissue MRI with portable Halbach scanners</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jose Borreguero, Luiz G. C. Santos, Lorena Vega Cid et al.
                </div>

                <div class="paper-summary">
                    This paper demonstrates the successful application of a comprehensive framework for artifact-free Zero Echo Time (ZTE) imaging on a portable, low-cost Halbach MRI scanner. It showcases the ability to perform in vivo qualitative imaging and quantitative T1 mapping of both soft and hard musculoskeletal tissues, previously challenging at low fields, within clinically viable acquisition times, thereby broadening the capabilities of portable MRI systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Musculoskeletal Imaging</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Point-of-Care Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15617v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15617v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15617v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15617v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.15603v1"
                     data-domains="Radiology,Diagnostic imaging,Surgical planning,Oncology (radiotherapy planning),Anatomical segmentation (e.g., abdominal organs),Quantitative image analysis"
                     data-keywords="Medical image segmentation,Decoupled prediction,Transformer networks,Deformable attention,Deep learning,Multi-class segmentation,Object queries,State-of-the-art"
                     data-authors="Bin Xie,Gady Agam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.15603v1.html">MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bin Xie, Gady Agam
                </div>

                <div class="paper-summary">
                    MaskMed proposes a novel approach to medical image segmentation by introducing a unified decoupled segmentation head that separates class-agnostic mask prediction from class label prediction using shared object queries. It also features a Full-Scale Aware Deformable Transformer module for memory-efficient and spatially aligned full-scale feature fusion. This method achieves state-of-the-art performance, significantly outperforming nnUNet on AMOS 2022 and BTCV datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Surgical planning</span>
                    
                    <span class="domain-tag">Oncology (radiotherapy planning)</span>
                    
                    <span class="domain-tag">Anatomical segmentation (e.g., abdominal organs)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.15603v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.15603v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.15603v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.15603v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-21 06:28:05</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>