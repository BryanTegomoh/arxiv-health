<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">152</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (8), Medical Imaging (8), Neurology (7)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (8)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (8)</option>
                        
                        <option value="Neurology">Neurology (7)</option>
                        
                        <option value="Oncology">Oncology (6)</option>
                        
                        <option value="Pathology">Pathology (4)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (4)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (4)</option>
                        
                        <option value="Public Health">Public Health (4)</option>
                        
                        <option value="Psychiatry">Psychiatry (4)</option>
                        
                        <option value="Computational Neuroscience">Computational Neuroscience (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.03693v1"
                     data-domains="Oncology,Pathology,Digital Pathology,Diagnostic Imaging"
                     data-keywords="Federated Learning,Colorectal Cancer,Histopathological Grading,Multi-Scale Deep Learning,Privacy-Preserving AI,Digital Pathology,Prognostic Factor,ResNetRS50"
                     data-authors="Md Ahasanul Arafath,Abhijit Kumar Ghosh,Md Rony Ahmed,Sabrin Afroz,Minhazul Hosen,Md Hasan Moon,Md Tanzim Reza,Md Ashad Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03693v1.html">Colorectal Cancer Histopathological Grading using Multi-Scale Federated Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md Ahasanul Arafath, Abhijit Kumar Ghosh, Md Rony Ahmed et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a privacy-preserving federated learning framework for colorectal cancer (CRC) histopathological grading, effectively addressing data sharing constraints and inter-observer variability. By integrating a dual-stream multi-scale ResNetRS50 architecture within a FedProx-stabilized federated learning system, the framework achieves superior performance (83.5% overall accuracy) compared to centralized models, particularly excelling in identifying aggressive Grade III tumors with high recall.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03693v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03693v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03693v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03693v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03677v1"
                     data-domains="Infectious Diseases,Clinical Pharmacology,Public Health,Microbiology,Critical Care Medicine"
                     data-keywords="antibiotic resistance,plasmid-mediated,mutation-induced,ODE models,dosing regimens,treatment outcomes,pharmacokinetics,antimicrobial resistance"
                     data-authors="Ailin Zhang,Shigui Ruan,Xi Huo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03677v1.html">Impact of Resistance Development Mechanisms on Antibiotic Treatment Outcomes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ailin Zhang, Shigui Ruan, Xi Huo
                </div>

                <div class="paper-summary">
                    This study employs periodic ordinary differential equation models to investigate how different antibiotic resistance mechanisms (plasmid-induced vs. mutation-induced) impact treatment outcomes and optimal dosing strategies. It reveals that fixed dosing is more effective against plasmid-mediated resistance, while mutation-driven resistance favors the selection of fully resistant strains upon treatment failure. The research also identifies superior dosing regimens, showing twice-daily regimens outperform once-daily for infection clearance, and a "catch-up" strategy is best for missed doses of short half-life antibiotics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Clinical Pharmacology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Microbiology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03677v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03677v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03677v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03677v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03675v1"
                     data-domains="Telemedicine,Electronic Health Records (EHR) management,Clinical Decision Support,Patient-Provider Communication,Medical Research,Mental Health Services,Health Information Exchange"
                     data-keywords="Side-channel attack,Large Language Models (LLMs),Privacy,Network surveillance,Metadata leakage,Packet analysis,Topic inference,Healthcare privacy"
                     data-authors="Geoff McDonald,Jonathan Bar Or">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03675v1.html">Whisper Leak: a side-channel attack on Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Geoff McDonald, Jonathan Bar Or
                </div>

                <div class="paper-summary">
                    This paper introduces Whisper Leak, a novel side-channel attack that infers user prompt topics from encrypted Large Language Model (LLM) traffic by analyzing packet size and timing patterns in streaming responses. Despite TLS encryption, these metadata patterns leak sufficient information, enabling near-perfect topic classification across 28 popular LLMs. The vulnerability poses significant privacy risks for users in sensitive domains like healthcare, as current mitigation strategies offer only partial protection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) management</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Patient-Provider Communication</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03671v1"
                     data-domains="Neurology,Neuroscience,Computational Neuroscience,Neuropsychiatry,Pathophysiology"
                     data-keywords="Chialvo neurons,Coupled oscillators,Basin geometry,Fractal basin boundaries,Final state sensitivity,Neuronal synchronization,Multistability,Chaotic dynamics"
                     data-authors="Bennett Lamb,Brandon B. Le">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03671v1.html">Final state sensitivity and fractal basin boundaries from coupled Chialvo neurons</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ nlin.CD</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bennett Lamb, Brandon B. Le
                </div>

                <div class="paper-summary">
                    This paper investigates the complex dynamics of two asymmetrically coupled Chialvo neurons, revealing that the system exhibits multistability with distinct chaotic and nonchaotic attractors despite individual non-chaotic behavior. A significant finding is the fractal nature of the basin boundaries, which leads to extreme final state sensitivity. The authors propose that this uncertainty in neural synchronization has crucial implications for understanding human behavior and neurological disease.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Neuropsychiatry</span>
                    
                    <span class="domain-tag">Pathophysiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03661v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG"
                     data-authors="Mahek Desai,Apoorva Rumale,Marjan Asadinia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03661v1.html">SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahek Desai, Apoorva Rumale, Marjan Asadinia
                </div>

                <div class="paper-summary">
                    The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty d...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03661v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03661v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03661v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03661v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03656v1"
                     data-domains="Medical Treatment"
                     data-keywords="Chinese NLP,Question Answering,Multi-Document QA,Dataset,Medical Treatment,Knowledge Extraction,Document Comprehension,Fine-grained Evaluation"
                     data-authors="Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03656v1.html">ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ChiMDQA, a novel Chinese Multi-Document Question Answering Dataset comprising 6,068 rigorously curated, high-quality QA pairs across six prevalent domains, including medical treatment. Designed with a fine-grained evaluation system and systematic construction, the dataset aims to support advanced NLP tasks like document comprehension and knowledge extraction, laying a crucial foundation for future Chinese QA research and practical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Treatment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03656v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03656v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03595v1"
                     data-domains="Clinical Decision Support Systems,Personalized Medicine,Medical Robotics,Treatment Optimization,Drug Discovery (e.g., optimizing experimental protocols)"
                     data-keywords="Reinforcement Learning,Q-learning,Tensor Decomposition,High-Dimensional Learning,Sample Efficiency,Exploration-Exploitation,Healthcare AI,Resource-Constrained Learning"
                     data-authors="Junyi Wu,Dan Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03595v1.html">Tensor-Efficient High-Dimensional Q-learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junyi Wu, Dan Li
                </div>

                <div class="paper-summary">
                    This paper introduces Tensor-Efficient Q-Learning (TEQL), an approach that enhances low-rank tensor decomposition to address the computational complexity and low sample efficiency inherent in high-dimensional reinforcement learning. TEQL integrates a novel exploration strategy combining approximation error with visit count-based Upper Confidence Bound (UCB) and a frequency-based regularization penalty. Empirical results demonstrate TEQL's superior sample efficiency and total rewards compared to conventional matrix-based and deep RL methods, making it well-suited for resource-constrained applications like healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Medical Robotics</span>
                    
                    <span class="domain-tag">Treatment Optimization</span>
                    
                    <span class="domain-tag">Drug Discovery (e.g., optimizing experimental protocols)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03595v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03595v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03595v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03595v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03488v1"
                     data-domains="Sleep Medicine,Clinical Neurophysiology,Neurology"
                     data-keywords="polysomnography,sleep staging,attention mechanisms,multimodal fusion,deep learning,zero-shot generalization,physiological signals,late fusion"
                     data-authors="Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03488v1.html">NAP: Attention-Based Late Fusion for Automatic Sleep Staging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvise Dei Rossi, Julia van der Meer, Markus H. Schmidt et al.
                </div>

                <div class="paper-summary">
                    NAP (Neural Aggregator of Predictions) introduces an attention-based late fusion model designed to address the heterogeneity of polysomnography (PSG) signals for automatic sleep staging. By combining predictions from frozen, pretrained single-channel models using a tri-axial attention mechanism, NAP consistently outperforms individual predictors and simple ensembles, achieving state-of-the-art zero-shot generalization across multiple diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03488v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03488v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03488v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03488v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03464v1"
                     data-domains="Oncology,Precision Medicine,Disease Diagnostics,Biomarker Research,Pharmacogenomics"
                     data-keywords="multiomics integration,interpretable AI,deep generative models,biomarker discovery,cancer subtyping,product of experts,sparse decoding,unsupervised learning"
                     data-authors="Mihriban Kocak Balik,Pekka Marttinen,Negar Safinianaini">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03464v1.html">POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mihriban Kocak Balik, Pekka Marttinen, Negar Safinianaini
                </div>

                <div class="paper-summary">
                    This paper introduces POEMS (Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding), an unsupervised probabilistic framework designed to integrate diverse molecular layers for disease understanding. POEMS overcomes the common tradeoff between predictive performance and interpretability in deep generative models by providing biomarker-based insights without sacrificing nonlinear expressiveness, demonstrating its efficacy in cancer subtyping.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Disease Diagnostics</span>
                    
                    <span class="domain-tag">Biomarker Research</span>
                    
                    <span class="domain-tag">Pharmacogenomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03464v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03464v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03464v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03464v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03416v1"
                     data-domains="Obstetrics,Perinatology,Fetal Medicine,Diagnostic Radiology,Prenatal Diagnosis"
                     data-keywords="3D Ultrasound,Embryo Alignment,Principal Component Analysis,Random Forest,Prenatal Growth Monitoring,First Trimester,Image Analysis,Medical Imaging"
                     data-authors="Nikolai Herrmann,Marcella C. Zijta,Stefan Klein,R√©gine P. M. Steegers-Theunissen,Rene M. H. Wijnen,Bernadette S. de Bakker,Melek Rousian,Wietske A. P. Bastiaansen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03416v1.html">Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nikolai Herrmann, Marcella C. Zijta, Stefan Klein et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a robust automated method for standardizing the 3D alignment of human embryos in first-trimester ultrasound images. The approach uses Principal Component Analysis (PCA) to derive candidate orientations, which are then evaluated by an ensemble of heuristic, atlas-based, and machine learning classifiers, achieving high accuracy on a large clinical cohort.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Obstetrics</span>
                    
                    <span class="domain-tag">Perinatology</span>
                    
                    <span class="domain-tag">Fetal Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Prenatal Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03416v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03416v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03416v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03416v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03376v1"
                     data-domains="Neuro-oncology,Diagnostic Radiology,Pathology (Molecular Diagnostics),Artificial Intelligence in Medicine"
                     data-keywords="IDH mutation,Brain Gliomas,Large Language Models,Computational Imaging,Zero-Shot Prediction,Multi-parametric MRI,Neuro-oncology,Non-invasive Diagnosis"
                     data-authors="Syed Muqeem Mahmood,Hassan Mohy-ud-Din">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03376v1.html">Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Syed Muqeem Mahmood, Hassan Mohy-ud-Din
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that integrates Large Language Models (LLMs) with computational image analysis to achieve non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. By extracting semantic attributes and quantitative features from multi-parametric MRI and tumor segmentations, serializing them into JSON, and querying advanced LLMs like GPT 4o and GPT 5 without fine-tuning, the method demonstrated high accuracy and balanced classification performance across diverse cohorts. The research highlights the potential for LLM-driven reasoning to revolutionize neuro-oncology diagnostics through precise, non-invasive tumor genotyping.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Pathology (Molecular Diagnostics)</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03376v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03376v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03376v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03376v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03365v1"
                     data-domains="eess.IV"
                     data-keywords="eess.IV,cs.CV,q-bio.QM"
                     data-authors="Gabriela Fernandes">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03365v1.html">Morpho-Genomic Deep Learning for Ovarian Cancer Subtype and Gene Mutation Prediction from Histopathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriela Fernandes
                </div>

                <div class="paper-summary">
                    Ovarian cancer remains one of the most lethal gynecological malignancies,
largely due to late diagnosis and extensive heterogeneity across subtypes.
Current diagnostic methods are limited in their ability to reveal underlying
genomic variations essential for precision oncology. This study introduces...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">eess.IV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03365v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03365v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03365v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03365v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03354v1"
                     data-domains="Oncology,Pharmacology,Genetics,Infectious Diseases,Personalized Medicine,Diagnostics,Structural Biology,Molecular Medicine"
                     data-keywords="Generative AI,Bioinformatics,Genomics,Proteomics,Drug Discovery,Structural Biology,Machine Learning,Systematic Review"
                     data-authors="Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03354v1.html">Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riasad Alvi, Sayeem Been Zaman, Wasimul Karim et al.
                </div>

                <div class="paper-summary">
                    This systematic review comprehensively analyzes the transformative impact of Generative Artificial Intelligence (GenAI) across various bioinformatics subfields, including genomics, proteomics, structural biology, and drug discovery. It evaluates GenAI models, applications, and methodological advances through six research questions, highlighting their superior performance over traditional methods, benefits of specialized architectures, and current limitations while proposing future research directions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Genetics</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03354v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03354v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03354v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03354v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03328v1"
                     data-domains="Radiology,Medical Imaging,Visual Question Answering (VQA),Clinical Decision Support"
                     data-keywords="Multimodal Large Language Models,MLLMs,Thinking Mode,Clinical Tasks,Medical VQA,Image Interpretation,Reasoning,Benchmarking"
                     data-authors="Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03328v1.html">Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jindong Hong, Tianjie Chen, Lingjie Luo et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates the impact of the newly introduced 'thinking mode' in Multimodal Large Language Models (MLLMs) on their performance and reliability in clinical tasks. Benchmarking two prominent MLLMs, Seed1.5-VL and Gemini-2.5-Flash, on visual medical tasks, the study found only marginal performance improvement from activating the thinking mode and suboptimal performance on complex tasks like open-ended VQA and medical image interpretation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Visual Question Answering (VQA)</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03328v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03328v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03328v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03328v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03287v1"
                     data-domains="Cardiovascular Surgery,Cardiology,Vascular Medicine,Radiology,Biomedical Engineering"
                     data-keywords="Aortic Dissection,Type B,Structural Stress,Biomechanics,Fluid-Structure Interaction,Aortic Growth,Risk Stratification,TEVAR"
                     data-authors="Yuhang Du,Yuxuan Wu,Hannah L. Cebull,Bangquan Liao,Rishika Agarwal,Alan Meraz,Hai Dong,Asanish Kalyanasundaram,John N. Oshinski,Rudolph L. Gleason Jr,John A. Elefteriades,Bradley G. Leshnower,Minliang Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03287v1.html">Structural Stress as a Predictor of the Rate and Spatial Location of Aortic Growth in Uncomplicated Type B Aortic Dissection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhang Du, Yuxuan Wu, Hannah L. Cebull et al.
                </div>

                <div class="paper-summary">
                    This study investigated biomechanical predictors of aortic expansion in uncomplicated Type B Aortic Dissection (TBAD) using reduced-order fluid-structure interaction (FSI) analysis. It found that structural stress is a significant predictor of both the rate and spatial location of aortic growth, outperforming traditional metrics like aortic diameter and other biomechanical factors like wall shear stress.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiovascular Surgery</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Vascular Medicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03287v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03287v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03287v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03287v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03263v1"
                     data-domains="Neurology,Epileptology,Clinical Neurophysiology,Biomedical Engineering"
                     data-keywords="Seizure prediction,Epilepsy,Electrophysiology,Fractional convolution,Time-frequency analysis,Subject-agnostic,Preictal biomarkers,Deep learning"
                     data-authors="Ruizhe Zheng,Lingyan Mao,Dingding Han,Tian Luo,Yi Wang,Jing Ding,Yuguo Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03263v1.html">FAPEX: Fractional Amplitude-Phase Expressor for Robust Cross-Subject Seizure Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruizhe Zheng, Lingyan Mao, Dingding Han et al.
                </div>

                <div class="paper-summary">
                    FAPEX introduces a novel architecture featuring a fractional neural frame operator (FrNFO) for adaptive time-frequency decomposition, addressing the challenge of robust subject-agnostic seizure prediction (SASP). By capturing a full range of electrophysiological dynamics and integrating structural state-space modeling, FAPEX achieves significant performance improvements (up to 15% sensitivity) and superior generalization across diverse species and recording modalities. This advancement offers a promising solution for discovering preictal biomarkers and facilitating clinical translation in epilepsy management.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Epileptology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03263v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03263v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03263v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03263v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03260v1"
                     data-domains="Diagnostic Radiology,Abdominal Imaging,Medical Imaging Analysis,Interventional Radiology (potential for guidance)"
                     data-keywords="Medical Image Segmentation,Deep Learning,U-Net,Mamba,State-Space Models,Heat Conduction Equation,Global Context Modeling,Multimodal Imaging"
                     data-authors="Rong Wu,Yim-Sang Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03260v1.html">Enhancing Medical Image Segmentation via Heat Conduction Equation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rong Wu, Yim-Sang Yu
                </div>

                <div class="paper-summary">
                    This research introduces a novel hybrid deep learning architecture, U-Mamba with Heat Conduction Equation, designed to enhance medical image segmentation. It addresses the common challenge of efficiently modeling global context and long-range dependencies in existing models by integrating Mamba-based state-space modules with Heat Conduction Operators (HCOs) that simulate frequency-domain thermal diffusion. Experimental results on multimodal abdominal CT and MRI datasets demonstrate the model's superior performance, effectiveness, and generalizability compared to strong baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Abdominal Imaging</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Interventional Radiology (potential for guidance)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03260v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03260v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03260v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03260v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03255v1"
                     data-domains="Cardiology,Diagnostic Imaging,General Ultrasound (various clinical domains)"
                     data-keywords="generative deep learning,ultrasound,video translation,color flow doppler,data augmentation,medical imaging,image synthesis,foundational AI"
                     data-authors="Nikolina Tomic Roshni Bhatnagar,Sarthak Jain,Connor Lau,Tien-Yu Liu,Laura Gambini,Rima Arnaout">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03255v1.html">Generative deep learning for foundational video translation in ultrasound</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nikolina Tomic Roshni Bhatnagar, Sarthak Jain, Connor Lau et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a generative deep learning method for foundational video translation in ultrasound, specifically converting Color Flow Doppler (CFD) videos to greyscale and vice-versa. The model, trained on over 50,000 videos, synthesizes realistic ultrasound footage that is quantitatively and qualitatively indistinguishable from real data in downstream deep learning tasks and by blinded clinical experts. Demonstrating foundational abilities, it effectively translates videos across various clinical domains despite being trained solely on cardiac ultrasound.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">General Ultrasound (various clinical domains)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03255v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03255v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03255v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03255v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03212v1"
                     data-domains="Obstetrics,Maternal-Fetal Medicine,Public Health,Medical Imaging,AI in Healthcare"
                     data-keywords="Cesarean section,Risk prediction,3D body scan,Transformer network,Explainable AI,Maternal health,Prenatal care,Machine learning"
                     data-authors="Ruting Cheng,Boyuan Feng,Yijiang Zheng,Chuhui Qiu,Aizierjiang Aiersilan,Joaquin A. Calderon,Wentao Zhao,Qing Pan,James K. Hahn">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03212v1.html">MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ruting Cheng, Boyuan Feng, Yijiang Zheng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MvBody, a novel multi-view-based Transformer network designed to predict Cesarean Section (CS) risk using self-reported medical data and 3D optical body scans acquired during late gestation. The model achieves an 84.62% accuracy and 0.724 AUC-ROC, demonstrating superior performance while providing explainable predictions for critical factors like maternal age, obstetric history, and specific body shape characteristics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Obstetrics</span>
                    
                    <span class="domain-tag">Maternal-Fetal Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03212v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03212v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03212v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03212v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03196v1"
                     data-domains="Diagnostic imaging,Clinical decision support systems,Predictive analytics in medicine,Personalized medicine,Medical record analysis,Patient phenotyping"
                     data-keywords="Multimodal learning,Copula modeling,Variational inference,Electronic Health Records (EHR),Gaussian Mixture Model,Data alignment,Missing data imputation,Joint distribution"
                     data-authors="Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03196v1.html">Cross-Modal Alignment via Variational Copula Modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Feng Wu, Tsai Hor Chan, Fuying Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel copula-driven multimodal learning framework designed to effectively align and fuse diverse data modalities, particularly in healthcare applications. By employing variational copula modeling to capture complex, higher-order interactions within a joint distribution and using Gaussian mixture models for marginal distributions, the method achieves superior performance in aggregating information and accurately generating representations for missing modalities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Clinical decision support systems</span>
                    
                    <span class="domain-tag">Predictive analytics in medicine</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                    <span class="domain-tag">Medical record analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03196v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03196v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03196v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03196v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03194v1"
                     data-domains="Oncology,Radiology,Nuclear Medicine,Medical Informatics,Artificial Intelligence in Medicine"
                     data-keywords="PET/CT,FDG-PET,Multi-cancer,Medical imaging,Radiology reports,Artificial intelligence,Radiomics,Dataset"
                     data-authors="Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03194v1.html">PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Le Xue, Gang Feng, Wenbo Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PETWB-REP, a novel, curated dataset comprising whole-body 18F-FDG PET/CT scans and corresponding radiology reports from 490 patients with various common malignancies. It addresses the scarcity of integrated functional and anatomical imaging datasets combined with detailed clinical reports for developing and validating artificial intelligence models in medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03194v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03194v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03194v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03194v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03163v1"
                     data-domains="General Surgery,Hepatic Surgery,Medical Imaging,Computer-Assisted Surgery,Interventional Radiology"
                     data-keywords="Liver landmark segmentation,Laparoscopic surgery,Foundation models,SAM2,Depth-guided,SRFT-GaLore,Medical imaging,Computer-assisted intervention"
                     data-authors="Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03163v1.html">Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a depth-guided liver landmark segmentation framework for laparoscopic surgery, integrating semantic RGB and geometric depth features using SAM2 and DA2 encoders. A novel low-rank gradient projection method, SRFT-GaLore, is proposed for efficient fine-tuning of SAM2's high-dimensional attention layers, leveraging Subsampled Randomized Fourier Transform. The method achieves significant performance improvements and strong cross-dataset generalization on both public L3D and a newly constructed Laparoscopic Liver Surgical Dataset (LLSD).
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Hepatic Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computer-Assisted Surgery</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03163v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03163v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03163v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03163v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03152v1"
                     data-domains="Digital Health,Clinical Decision Support,Medical Imaging,Patient Safety,Healthcare Policy"
                     data-keywords="LLM,Risk Assessment,Stakeholder Conflicts,AI Governance,Medical AI,Interpretability,Explanatory Policies,Transparency"
                     data-authors="Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03152v1.html">Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Srishti Yadav, Jasmina Gajcin, Erik Miehling et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a framework for stakeholder-grounded risk assessment of AI systems, leveraging Large Language Models (LLMs) as judges to predict and explain risks. It generates stakeholder-specific, interpretable policies highlighting agreements and disagreements on risks, demonstrated across domains including medical AI, and proposes an interactive visualization for conflict reasoning. The findings emphasize that stakeholder perspectives significantly influence risk perception and conflict patterns, advocating for transparent, human-centered AI governance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Healthcare Policy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03152v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03152v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03152v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03152v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03115v1"
                     data-domains="Radiation Oncology,Medical Physics,Radiotherapy Planning"
                     data-keywords="Proton therapy,Dose calculation,Stochastic Differential Equation (SDE),Monte Carlo,Geant4,Treatment planning,Medical physics,Radiation oncology"
                     data-authors="Christopher B. C. Dean,Maria L. P√©rez-Lara,Emma Horton,Matthew Southerby,Jere Koskela,Andreas E. Kyprianou">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03115v1.html">Fast SDE-based Monte Carlo dose calculation for proton therapy validated against Geant4</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christopher B. C. Dean, Maria L. P√©rez-Lara, Emma Horton et al.
                </div>

                <div class="paper-summary">
                    This paper validates a novel stochastic differential equation (SDE)-based model for proton beam energy deposition by comparing its predictions against Geant4 in simplified phantom scenarios. The SDE model demonstrated comparable accuracy to high-fidelity Monte Carlo simulations while achieving a significant fivefold computational speed-up, highlighting its potential for accelerating dose calculations and treatment planning in proton therapy.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiotherapy Planning</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03115v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03115v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03115v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03115v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03106v1"
                     data-domains="General healthcare,Clinical informatics,Medical AI safety,Digital health,Health technology assessment"
                     data-keywords="Large language models,LLMs,Oversight,Monitoring,Healthcare AI,Capability-based monitoring,Generalist AI,Machine learning"
                     data-authors="Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03106v1.html">Large language models require a new form of oversight: capability-based monitoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Katherine C. Kellogg, Bingyang Ye, Yifan Hu et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel framework called capability-based monitoring for large language models (LLMs) in healthcare, arguing that traditional task-based monitoring inherited from machine learning (ML) is insufficient for generalist LLMs. It suggests organizing oversight around shared model capabilities (e.g., summarization, reasoning) instead of individual downstream tasks, to enable scalable detection of systemic weaknesses, long-tail errors, and emergent behaviors across various healthcare applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General healthcare</span>
                    
                    <span class="domain-tag">Clinical informatics</span>
                    
                    <span class="domain-tag">Medical AI safety</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Health technology assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03106v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03106v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03106v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03106v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03099v1"
                     data-domains="orthodontics,dentistry,telemedicine,diagnostic imaging"
                     data-keywords="orthodontics,dental occlusion,3D Gaussian Splatting,novel view synthesis,sparse input,telemedicine,intra-oral photographs,point cloud reconstruction"
                     data-authors="Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03099v1.html">DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiyi Miao, Taoyu Wu, Tong Chen et al.
                </div>

                <div class="paper-summary">
                    DentalSplat addresses the critical need for multi-view dental occlusion visualization in orthodontics, particularly for telemedicine, by overcoming limitations of 3D Gaussian Splatting (3DGS) with sparse intra-oral photographs. The framework leverages a prior-guided dense stereo reconstruction, scale-adaptive pruning, and incorporates optical flow with gradient regularization for extremely sparse views, demonstrating superior novel view synthesis quality on extensive clinical datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">orthodontics</span>
                    
                    <span class="domain-tag">dentistry</span>
                    
                    <span class="domain-tag">telemedicine</span>
                    
                    <span class="domain-tag">diagnostic imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03099v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03099v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03099v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03099v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03089v1"
                     data-domains="Psychiatry,Neuropsychology,Clinical Psychology,Speech-Language Pathology,Biomarker Discovery"
                     data-keywords="Schizophrenia,Language disruption,Disorganized speech,Discourse coherence,Surprisal,Semantic coherence,Computational linguistics,Objective markers"
                     data-authors="Gowtham Premananth,Carol Espy-Wilson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03089v1.html">A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gowtham Premananth, Carol Espy-Wilson
                </div>

                <div class="paper-summary">
                    This study proposes a computational approach to objectively analyze language disruptions in schizophrenia by integrating two linguistic measures: surprisal and semantic coherence. It investigates how these measures differ between schizophrenia patients and healthy controls, and how they correlate with varying degrees of symptom severity. The ultimate goal is to establish these computational markers for enhanced diagnosis and symptom severity assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neuropsychology</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03089v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03089v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03089v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03089v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03084v1"
                     data-domains="Psychiatry,Speech-Language Pathology,Digital Health,Neuroscience (Cognitive/Motor Control)"
                     data-keywords="Schizophrenia,Biomarker,Articulatory speech features,Vocal tract coordination,Interpretability,AI in healthcare,Symptom severity,Psychiatric assessment"
                     data-authors="Gowtham Premananth,Carol Espy-Wilson">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03084v1.html">Quantifying Articulatory Coordination as a Biomarker for Schizophrenia</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-05</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.AS</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gowtham Premananth, Carol Espy-Wilson
                </div>

                <div class="paper-summary">
                    This paper introduces an interpretable AI framework that quantifies vocal tract coordination using articulatory speech features, specifically eigenspectra difference plots and a Weighted Sum with Exponential Decay (WSED) score. The WSED scores effectively distinguish complex from simpler coordination patterns and correlate significantly with both overall BPRS severity and the balance between positive and negative symptoms in schizophrenia, offering a transparent and severity-sensitive biomarker.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Neuroscience (Cognitive/Motor Control)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03084v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03084v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03084v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03084v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03070v1"
                     data-domains="Public Health,Epidemiology,Clinical Decision Support,Medical Informatics,Population Health Management"
                     data-keywords="Large Language Models,Probability Distributions,Observational Knowledge,Causal Hierarchy,Epidemiology,Health Statistics,AI Benchmarking,Probabilistic Reasoning"
                     data-authors="Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03070v1.html">Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Drago Plecko, Patrik Okanovic, Torsten Hoefler et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the first benchmark to evaluate Large Language Models' (LLMs) ability to internalize real-world probability distributions, specifically observational knowledge, across various domains including health. The study finds that LLMs perform poorly in this regard, indicating they do not naturally acquire or accurately represent such statistical understanding from their vast training data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03070v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03070v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03070v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03070v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03048v1"
                     data-domains="Systematic Reviews,Evidence-Based Medicine,Clinical Research,Pediatrics"
                     data-keywords="Risk of Bias,Clinical Trials,Large Language Models,Systematic Review,Retrieval-Augmented Generation,Pediatrics,Human-in-the-loop,Evidence-Based Medicine"
                     data-authors="Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03048v1.html">ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Anthony Hevia, Sanjana Chintalapati, Veronica Ka Wai Lai et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ROBOTO2, an open-source, web-based platform designed to streamline the labor-intensive Risk of Bias (ROB v2) assessment of clinical trials using LLM-assisted methods. It also presents a new dataset of 521 pediatric clinical trial reports, annotated via both manual and LLM-assisted approaches, which serves as a benchmark for evaluating LLM performance in this critical systematic review task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Systematic Reviews</span>
                    
                    <span class="domain-tag">Evidence-Based Medicine</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03048v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03048v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03048v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03048v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03041v1"
                     data-domains="q-bio.OT"
                     data-keywords="q-bio.OT"
                     data-authors="Aly A. Khan,Jason Perera,James Zou,Lo√Øc A. Royer,Alan R. Lowe,Ambrose Carr,Theofanis Karaletsos,Patricia Brennan,Roham Parsa,Marcus R. Clark,Joe DeRisi,Jay Shendure,Sandra L. Schmid,Scott E. Fraser,Andrea Califano,Shana O. Kelley">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03041v1.html">A Roadmap for Predictive Human Immunology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Aly A. Khan, Jason Perera, James Zou et al.
                </div>

                <div class="paper-summary">
                    For over a century, immunology has masterfully discovered and dissected the
components of our immune system, yet its collective behavior remains
fundamentally unpredictable. In this perspective, we argue that building on the
learnings of reductionist biology and systems immunology, the field is pois...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.OT</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03041v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03041v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03041v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03041v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.03034v1"
                     data-domains="Patient Experience Management,Clinical Informatics,Public Health Surveillance,Pharmacovigilance,Digital Health,Medical Education Feedback"
                     data-keywords="Aspect-based Sentiment Analysis,Low-resource NLP,Small Language Models,Domain Adaptation,Multitask Learning,Generative Models,Flexible Evaluation,Healthcare AI"
                     data-authors="Yan Cathy Hua,Paul Denny,J√∂rg Wicker,Katerina Ta≈°kova">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.03034v1.html">Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yan Cathy Hua, Paul Denny, J√∂rg Wicker et al.
                </div>

                <div class="paper-summary">
                    This paper addresses critical gaps in Aspect-based Sentiment Analysis (ABSA) for high-demand, low-resource domains like healthcare, focusing on data-efficient adaptation and improved evaluation. It introduces a novel flexible evaluation method (FTS-OBP) for generative models and demonstrates that small decoder-only language models (SLMs) can achieve state-of-the-art performance on ABSA tasks with significantly less data (200-1,000 examples) and computational resources via a multitask fine-tuning strategy, surpassing proprietary large models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Patient Experience Management</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.03034v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.03034v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.03034v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.03034v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02996v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Clinical Decision Support Systems"
                     data-keywords="Volumetric Vision-Language Pre-training,CT Scans,Medical Imaging,Contrastive Learning,Spatial Semantics,Radiological Ontologies,Report Generation,Abnormality Classification,Zero-shot Learning"
                     data-authors="Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02996v1.html">SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ailar Mahdizadeh, Puria Azadi Moghadam, Xiangteng He et al.
                </div>

                <div class="paper-summary">
                    SCALE-VLP introduces a novel soft-weighted contrastive vision-language pre-training framework specifically designed for volumetric medical data, like CT scans. By integrating volumetric spatial semantics and domain-aware, knowledge-infused semantics, it overcomes limitations of 2D-focused VLMs that often ignore crucial spatial coherence and structured dependencies. The framework demonstrates significant improvements across various tasks, achieving state-of-the-art performance in CT-report retrieval, abnormality classification, and report generation, while showcasing strong cross-task and zero-shot cross-domain generalizability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02996v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02996v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02996v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02996v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02944v1"
                     data-domains="Behavioral Health,Mental Health (Bipolar Disorder),Public Health (Physical Activity Promotion),Personalized Medicine,Digital Therapeutics"
                     data-keywords="Thompson Sampling,Micro-Randomized Trials,Nonstationary Bandits,Habituation,Recovery Dynamics,Adaptive Interventions,Statistical Power,Behavioral Health"
                     data-authors="Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02944v1.html">Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fengxu Li, Stephanie M. Carpenter, Matthew P. Buman et al.
                </div>

                <div class="paper-summary">
                    This paper introduces novel methods to optimize adaptive interventions in Micro-Randomized Trials (MRTs), addressing the challenge of interventions whose effectiveness changes over time due to habituation and recovery dynamics. It proposes ROGUE-TS, a Thompson Sampling algorithm for the ROGUE bandit framework, and a probability clipping procedure to balance personalized recommendations with the critical need for sufficient exploration to estimate population-level effects. Validated on MRT datasets for physical activity and bipolar disorder, the methods achieve lower regret and maintain high statistical power for detecting treatment effects.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Mental Health (Bipolar Disorder)</span>
                    
                    <span class="domain-tag">Public Health (Physical Activity Promotion)</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Digital Therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02944v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02944v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02944v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02944v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02932v1"
                     data-domains="Oncology,Immunology,Clinical Proteomics,Pathology,Biomarker Discovery"
                     data-keywords="Phospho-proteomics,Post-translational modifications,Low input proteomics,Formalin-fixed cells,Decrosslinking,Jurkat cells,T-cell stimulation,Mass spectrometry"
                     data-authors="Teresia Ndungu,Jana Zecha,Lisa Cazares,Sonja Hess">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02932v1.html">Phospho-Proteomics Method Optimization and Application to Stimulated Jurkat Cells</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Teresia Ndungu, Jana Zecha, Lisa Cazares et al.
                </div>

                <div class="paper-summary">
                    This study optimized phospho-proteomics methods for limited input and formalin-fixed cells, demonstrating that phospho-bulk titration improves phospho-peptide identification from low input. It established an efficient decrosslinking protocol for fixed samples and successfully applied these optimized methods to identify key phospho-sites in stimulated Jurkat cells relevant to T-cell activation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Clinical Proteomics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02932v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02932v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02932v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02932v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02928v1"
                     data-domains="Neuro-oncology,Radiology,Medical Imaging,Computational Neuroscience,Global Health"
                     data-keywords="Glioma Segmentation,Domain Adaptation,Transformer,Radiomics,Sub-Saharan Africa,MRI,Medical Image Analysis,Neuro-oncology"
                     data-authors="Ilerioluwakiiye Abolade,Aniekan Udo,Augustine Ojo,Abdulbasit Oyetunji,Hammed Ajigbotosho,Aondana Iorumbur,Confidence Raymond,Maruf Adewole">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02928v1.html">Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ilerioluwakiiye Abolade, Aniekan Udo, Augustine Ojo et al.
                </div>

                <div class="paper-summary">
                    This research addresses the critical challenge of glioma segmentation in Sub-Saharan Africa, where limited MRI infrastructure and diverse acquisition protocols lead to significant domain shift. The authors propose SegFormer3D-plus, a novel radiomics-guided transformer architecture designed for robust segmentation under such domain variability. Their method, which incorporates intensity harmonization, domain-aware sampling, and advanced encoder design, demonstrates improved tumor subregion delineation and boundary localization on heterogeneous African clinical scans, highlighting the efficacy of domain adaptation in resource-limited settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02928v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02928v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02928v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02928v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02826v2"
                     data-domains="Pathology,Histopathology,Dermatopathology,Oncology,Diagnostic Medicine"
                     data-keywords="Pathology Foundation Models,Whole Slide Imaging (WSI),Histopathology,Self-supervised Learning,Vision Transformer,DINOv2,Dermatopathology Diagnosis,Computational Pathology"
                     data-authors="Harshith Padigela,Shima Nofallah,Atchuth Naveen Chilaparasetti,Ryun Han,Andrew Walker,Judy Shen,Chintan Shah,Blake Martin,Aashish Sood,Elliot Miller,Ben Glass,Andy Beck,Harsha Pokkalla,Syed Ashar Javed">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02826v2.html">PLUTO-4: Frontier Pathology Foundation Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti et al.
                </div>

                <div class="paper-summary">
                    PLUTO-4 introduces next-generation pathology foundation models, extending the Pathology-Universal Transformer to frontier scale with two distinct Vision Transformer architectures: PLUTO-4S for efficient multi-scale deployment and PLUTO-4G for maximum representation capacity. These models achieve state-of-the-art performance across various histopathology tasks after self-supervised pretraining on an unprecedentedly large and diverse multi-institutional WSI corpus. The advancements underscore their potential to significantly impact translational research and diagnostic applications in real-world settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Dermatopathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02826v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02826v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02826v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02826v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02769v1"
                     data-domains="Drug Discovery,Medicinal Chemistry,Cheminformatics,Pharmaceutical Research and Development,Pharmacology"
                     data-keywords="Molecular Generation,Variational AutoEncoder,Transformers,SELFIES,Drug Discovery,Conditional Generation,Latent Space,Low-Rank Adapters"
                     data-authors="Bum Chul Kwon,Ben Shapira,Moshiko Raboh,Shreyans Sethi,Shruti Murarka,Joseph A Morrone,Jianying Hu,Parthasarathy Suryanarayanan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02769v1.html">STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bum Chul Kwon, Ben Shapira, Moshiko Raboh et al.
                </div>

                <div class="paper-summary">
                    STAR-VAE is a novel deep generative model leveraging Transformers and SELFIES representations to generate drug-like molecules. It enables scalable, controllable generation by incorporating a principled conditional latent-variable formulation and efficient LoRA-based finetuning, demonstrating competitive performance on molecular generation benchmarks and effective property-guided design. The model's success suggests that modernized Variational Autoencoders remain a competitive approach for de novo molecular generation when coupled with advanced techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Cheminformatics</span>
                    
                    <span class="domain-tag">Pharmaceutical Research and Development</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02766v2"
                     data-domains="Neurology,Gastroenterology,Endocrinology,Immunology,Psychiatry,Sleep Medicine,Metabolic Disorders,Neurogastroenterology"
                     data-keywords="gut microbiota,sleep,gut-microbiota-brain axis (GMBA),dysbiosis,neurotransmitters,probiotics,fecal microbiota transplantation (FMT),chrononutrition"
                     data-authors="Enso Onill Torres Alegre">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02766v2.html">Microbes in the Moonlight: How the Gut Microbiota Influences Sleep</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Enso Onill Torres Alegre
                </div>

                <div class="paper-summary">
                    This paper reviews the critical role of the gut microbiota in regulating sleep physiology via the gut-microbiota-brain axis (GMBA), detailing how microbial composition influences neural, endocrine, and immune pathways, as well as neurotransmitter production, circadian rhythms, and metabolic homeostasis. It highlights that gut dysbiosis contributes to sleep disorders and associated pathologies by altering key metabolic pathways, proposing microbiota-targeted therapies as promising interventions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Gastroenterology</span>
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02766v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02766v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02766v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02766v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02754v1"
                     data-domains="Clinical Informatics,Medical AI/Machine Learning,Population Health,Precision Medicine,Biostatistics,Health Data Science"
                     data-keywords="Distributed learning,Representation learning,EHR,Ising model,Privacy-preserving,Federated learning,Patient phenotyping,Patient clustering"
                     data-authors="Zebin Wang,Ziming Gan,Weijing Tang,Zongqi Xia,Tianrun Cai,Tianxi Cai,Junwei Lu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02754v1.html">DANIEL: A Distributed and Scalable Approach for Global Representation Learning with EHR Applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zebin Wang, Ziming Gan, Weijing Tang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DANIEL, a distributed and scalable framework that leverages a revisited Ising model to perform privacy-preserving representation learning from large-scale, high-dimensional binary medical data. It addresses challenges of data heterogeneity and sharing constraints in modern healthcare by optimizing a non-convex surrogate loss function via bi-factored gradient descent. Evaluated on multi-institutional EHR data from 58,248 patients, DANIEL demonstrates superior performance in global representation learning and critical downstream clinical tasks like patient phenotyping and clustering.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical AI/Machine Learning</span>
                    
                    <span class="domain-tag">Population Health</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02754v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02754v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02754v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02754v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02738v1"
                     data-domains="Radiology,Pathology,Clinical Informatics,Diagnostic AI,Precision Medicine,Electronic Health Records (EHR) Analysis"
                     data-keywords="machine learning,data quality,mislabeled data,model calibration,error detection,trust scores,robustness,medical AI"
                     data-authors="Ilies Chibane,Thomas George,Pierre Nodet,Vincent Lemaire">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02738v1.html">Calibration improves detection of mislabeled examples</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ilies Chibane, Thomas George, Pierre Nodet et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the crucial impact of calibrating base machine learning models on the effectiveness of mislabeled data detection. The authors demonstrate through empirical results that applying calibration methods significantly improves both the accuracy and robustness of identifying mislabeled instances, offering a practical and effective solution for enhancing data quality in real-world machine learning applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Diagnostic AI</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02738v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02738v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02738v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02738v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02735v1"
                     data-domains="Neurology,Neurodiagnostics,Brain-Computer Interface Research,Alzheimer's Disease Research,Computational Neuroscience"
                     data-keywords="EEG,P300,Brain-Computer Interface,eLORETA,Functional Connectivity,Regions of Interest,Alzheimer's Disease,Neurodegenerative Disease Diagnostics"
                     data-authors="Eva Guttmann-Flury,Jian Zhao,Mohamad Sawan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02735v1.html">Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that combines eLORETA source localization with cross-subject functional connectivity to overcome spatial specificity limitations in single-trial P300 classification for EEG-based Brain-Computer Interfaces (BCIs). The method reliably identifies stable, task-relevant regions of interest (ROIs) in deeper cortical-subcortical structures, such as the insula and parietal regions, crucial for Alzheimer's disease biomarkers, and demonstrates improved classification accuracy compared to whole-brain approaches.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurodiagnostics</span>
                    
                    <span class="domain-tag">Brain-Computer Interface Research</span>
                    
                    <span class="domain-tag">Alzheimer's Disease Research</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02735v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02735v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02735v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02735v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02722v1"
                     data-domains="Psychiatry,Cognitive Neuroscience,Computational Psychiatry,Neurology"
                     data-keywords="Schizophrenia,Neocortex,Sensory-to-Association Hierarchy,fMRI,Recurrent Neural Networks,Neural Timescale,Working Memory,Functional Differentiation,Computational Stability"
                     data-authors="Subati Abulikemu,Puria Radmard,Michail Mamalakis,John Suckling">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02722v1.html">Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Subati Abulikemu, Puria Radmard, Michail Mamalakis et al.
                </div>

                <div class="paper-summary">
                    This study investigated the sensory-to-association (AS) cortical hierarchy in schizophrenia patients compared to controls, revealing a compressed hierarchy and reduced functional differentiation in patients. Using fMRI, neural timescale modeling, and gradient-regularized recurrent neural networks (RNNs), the research demonstrated that this de-differentiation leads to flattened neural timescales and less stable neural computations, offering a mechanistic explanation for cognitive deficits in schizophrenia.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Computational Psychiatry</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02722v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02722v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02722v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02722v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02894v1"
                     data-domains="Remote Patient Monitoring,Elderly Care,Rehabilitation,Preventative Health,Telemedicine,Digital Therapeutics"
                     data-keywords="Data poisoning detection,Data sanitization,Wearable IoT,Human Activity Recognition (HAR),Large Language Models (LLMs),Zero-shot learning,Prompt engineering,Cybersecurity in healthcare"
                     data-authors="W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02894v1.html">Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> W. K. M Mithsara, Ning Yang, Ahmed Imteaj et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that employs Large Language Models (LLMs) to detect and sanitize data poisoning attacks in Human Activity Recognition (HAR) systems within wearable Internet of Things (IoT) ecosystems. By leveraging zero-shot, one-shot, and few-shot learning with specialized prompting strategies, the approach overcomes the limitations of conventional methods that require extensive labeled datasets. The framework provides a robust and adaptable defense mechanism, demonstrated through comprehensive evaluation of detection accuracy, sanitization quality, latency, and communication cost.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                    <span class="domain-tag">Elderly Care</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Preventative Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02894v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02894v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02894v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02894v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02893v1"
                     data-domains="Neuro-oncology,Radiology,Medical Imaging,Computational Neuroscience"
                     data-keywords="brain tumor segmentation,glioma,nnU-Net,medical imaging,MRI,data augmentation,Sub-Saharan Africa,Dice score"
                     data-authors="Chukwuemeka Arua Kalu,Adaobi Chiazor Emegoakor,Fortune Okafor,Augustine Okoh Uchenna,Chijioke Kelvin Ukpai,Godsent Erere Onyeugbo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02893v1.html">Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using a BraTS Sub-Saharan Africa (SSA) dataset</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chukwuemeka Arua Kalu, Adaobi Chiazor Emegoakor, Fortune Okafor et al.
                </div>

                <div class="paper-summary">
                    This study optimized the nnU-Net model for glioma segmentation using a unique BraTS Sub-Saharan Africa (SSA) dataset comprising 60 multimodal MRI cases. Surprisingly, training with the original 60 instances coupled with nnU-Net's robust online augmentations performed better than using an offline-augmented dataset of 360 cases, achieving a Dice score of 0.84 for whole tumor segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02893v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02893v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02893v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02893v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02587v1"
                     data-domains="Public Health,Pharmacology,Patient Education,Vaccinology,Infectious Diseases,Health Communication"
                     data-keywords="Machine Translation,Lexical Errors,English-Romanian,COVID-19,Patient Information,WHO,Google Translate,Error Analysis"
                     data-authors="Angela Stamatie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02587v1.html">The Analysis of Lexical Errors in Machine Translation from English into Romanian</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Angela Stamatie
                </div>

                <div class="paper-summary">
                    This research meticulously analyzes lexical errors encountered in Machine Translation (MT) from English into Romanian, specifically focusing on texts related to COVID-19 originating from critical health organizations like WHO, Gavi, and patient information leaflets. The study's primary objective is to enhance the quality of Google Translate by identifying and reducing these lexical errors, thereby improving the accuracy and fluency of automatically translated medical information.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Patient Education</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02587v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02587v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02587v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02587v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02576v1"
                     data-domains="Radiology,Orthopedics,Diagnostic Imaging,Surgical Planning,Medical Imaging"
                     data-keywords="medical image analysis,segmentation refinement,weak supervision,deep learning,CT scans,anatomical segmentation,resource-efficient,humerus"
                     data-authors="Alix de Langlais,Benjamin Billot,Th√©o Aguilar Vidal,Marc-Olivier Gauci,Herv√© Delingette">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02576v1.html">Resource-efficient Automatic Refinement of Segmentations via Weak Supervision from Light Feedback</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alix de Langlais, Benjamin Billot, Th√©o Aguilar Vidal et al.
                </div>

                <div class="paper-summary">
                    SCORE (Segmentation COrrection from Regional Evaluations) introduces a novel weakly supervised framework for refining anatomical segmentations, addressing the limitations of existing methods that require extensive user interaction or dense annotations. It leverages 'light feedback' in the form of region-wise quality scores and over/under-segmentation error labels to significantly improve initial automated predictions. Demonstrated on humerus CT scans, SCORE achieves performance comparable to fully supervised methods while drastically reducing supervision requirements and annotation time.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02576v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02576v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02576v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02576v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02565v1"
                     data-domains="Neurology,Neuroscience,Rehabilitation (Brain-Computer Interfaces),Neuroimaging diagnostics,Psychiatry (perceptual disorders)"
                     data-keywords="Brain decoding,fMRI,Visual reconstruction,Subject-agnostic,Ventral-dorsal streams,Contrastive learning,Neuroimaging,Deep learning"
                     data-authors="Jingyu Lu,Haonan Wang,Qixiang Zhang,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02565v1.html">A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain Visual Decoding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingyu Lu, Haonan Wang, Qixiang Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework designed for subject-agnostic brain visual decoding from fMRI data. VCFlow models the human visual system's ventral-dorsal architecture and employs a contrastive learning strategy to reconstruct continuous visual experiences from fMRI without subject-specific training. This approach offers a fast (10 seconds per video), clinically scalable solution, sacrificing only 7% accuracy on average compared to conventional, computationally intensive methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Rehabilitation (Brain-Computer Interfaces)</span>
                    
                    <span class="domain-tag">Neuroimaging diagnostics</span>
                    
                    <span class="domain-tag">Psychiatry (perceptual disorders)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02565v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02565v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02565v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02565v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.02564v1"
                     data-domains="Patient Safety and Monitoring,Hospital Security,Elderly Care,Clinical Operations Management,Psychiatric Care,Remote Patient Monitoring"
                     data-keywords="person re-identification,cross-view learning,video analysis,deep learning,computer vision,multi-temporal,ViT,surveillance"
                     data-authors="Md Rashidunnabi,Kailash A. Hambarde,Vasco Lopes,Joao C. Neves,Hugo Proenca">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.02564v1.html">Seeing Across Time and Views: Multi-Temporal Cross-View Learning for Robust Video Person Re-Identification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-04</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md Rashidunnabi, Kailash A. Hambarde, Vasco Lopes et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTF-CVReID, a novel and parameter-efficient framework for robust video-based person re-identification (ReID) across challenging cross-view domains like aerial-ground surveillance. By integrating seven specialized modules into a ViT-B/16 backbone, the framework effectively addresses extreme viewpoint shifts, scale disparities, and temporal inconsistencies while maintaining real-time performance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Patient Safety and Monitoring</span>
                    
                    <span class="domain-tag">Hospital Security</span>
                    
                    <span class="domain-tag">Elderly Care</span>
                    
                    <span class="domain-tag">Clinical Operations Management</span>
                    
                    <span class="domain-tag">Psychiatric Care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.02564v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.02564v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.02564v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.02564v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-06 06:27:54</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>