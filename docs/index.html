<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">153</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Neurology (9), Oncology (8), Diagnostic Imaging (8)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Neurology">Neurology (9)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (8)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Radiology">Radiology (7)</option>
                        
                        <option value="Pathology">Pathology (6)</option>
                        
                        <option value="Clinical Decision Support">Clinical Decision Support (5)</option>
                        
                        <option value="Interventional Radiology">Interventional Radiology (5)</option>
                        
                        <option value="Epidemiology">Epidemiology (4)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (4)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (4)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.21675v1"
                     data-domains="Epidemiology,Public Health,Health Economics,Social Medicine,Clinical Trials,Health Policy"
                     data-keywords="Causal Inference,Interference,Networked Systems,Evolution-Based Models,Difference-in-Differences,Spillover Effects,Randomization,Public Health"
                     data-authors="Sadegh Shirani,Mohsen Bayati">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21675v1.html">On Evolution-Based Models for Experimentation Under Interference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sadegh Shirani, Mohsen Bayati
                </div>

                <div class="paper-summary">
                    This paper proposes an evolution-based modeling approach to estimate population-level causal effects in networked systems where interference pathways are largely unobserved. It argues that precisely recovering the network structure is unnecessary; instead, characterizing how outcomes evolve across observation rounds in response to interventions, using low-dimensional recursive equations, suffices. This method offers a distributional counterpart to difference-in-differences, leveraging treatment randomization to implicitly sample hidden interference channels and learn about heterogeneous spillover effects.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Health Economics</span>
                    
                    <span class="domain-tag">Social Medicine</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21675v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21675v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21675v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21675v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21673v1"
                     data-domains="Neuro-oncology,Diagnostic Radiology,Medical Imaging,Neuropathology"
                     data-keywords="Glioma,Brain Tumor,Deep Learning,MRI Segmentation,Image Classification,Attention Mechanism,U-Net,DenseNet-VGG"
                     data-authors="Pandiyaraju V,Sreya Mynampati,Abishek Karthik,Poovarasan L,D. Saraswathi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21673v1.html">Revolutionizing Glioma Segmentation & Grading Using 3D MRI - Guided Hybrid Deep Learning Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Pandiyaraju V, Sreya Mynampati, Abishek Karthik et al.
                </div>

                <div class="paper-summary">
                    This research introduces a novel hybrid deep learning model that integrates U-Net for 3D MRI-based glioma segmentation with a DenseNet-VGG classification network, enhanced by multihead and spatial-channel attention. The framework achieved high performance, with a 98% Dice coefficient for tumor segmentation and 99% classification accuracy, demonstrating its potential for accurate and timely glioma diagnosis and grading.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Neuropathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21673v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21673v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21673v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21673v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21655v1"
                     data-domains="Developmental Biology,Oncology,Regenerative Medicine,Tissue Engineering,Biophysics,Wound Healing"
                     data-keywords="collective cell migration,epithelial dynamics,scale-free correlations,active matter,mechanobiology,tissue morphogenesis,vimentin,critical systems,wound healing,cancer"
                     data-authors="Guillaume Duprez,M√©lina Durande,Fran√ßois Graner,H√©l√®ne Delano√´-Ayari">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21655v1.html">Geometric Confinement Reveals Scale-Free Velocity Correlations in Epithelial Cell Monolayer</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guillaume Duprez, M√©lina Durande, Fran√ßois Graner et al.
                </div>

                <div class="paper-summary">
                    This paper investigates collective cell flows in MDCK epithelial monolayers under geometric confinement, revealing that spatial velocity correlations are scale-free, following a power law, which challenges the notion of a single intrinsic correlation length. The study demonstrates that the monolayer behaves as a critical-like system capable of long-range information transmission and stress propagation, and highlights how substrate properties and boundary conditions modulate flow organization and vimentin distribution.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Developmental Biology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Regenerative Medicine</span>
                    
                    <span class="domain-tag">Tissue Engineering</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21647v1"
                     data-domains="Diagnostic Imaging,Nephrology,Cardiology,Oncology,Neurology,Vascular Medicine,Interventional Radiology"
                     data-keywords="Ultrasound Localization Microscopy,3D ULM,Real-time imaging,Projection-based processing,Computational efficiency,Vascular imaging,GPU acceleration,Clinical translation"
                     data-authors="Jingke Zhang,Jingyi Yin,U-Wai Lok,Lijie Huang,Ryan M. DeRuiter,Tao Wu,Kaipeng Ji,Yanzhe Zhao,James D. Krier,Xiang-yang Zhu,Lilach O. Lerman,Chengwu Huang,Shigao Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21647v1.html">Fast 3D Ultrasound Localization Microscopy via Projection-based Processing Framework</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingke Zhang, Jingyi Yin, U-Wai Lok et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel projection-based processing framework for 3D Ultrasound Localization Microscopy (ULM) that dramatically reduces computational demands, enabling fast vascular reconstruction. By reformulating all pipeline steps into efficient 2D operations, the framework achieves near real-time processing speeds in an *in vivo* pig kidney model, maintaining image quality comparable to conventional 3D methods. This breakthrough offers the potential for real-time feedback during scanning, promising to improve diagnostic reliability and accelerate clinical workflows.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21647v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21647v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21647v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21647v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21600v1"
                     data-domains="Healthcare data management,Clinical research,Public health,Biomedical informatics,Medical AI development,Health policy"
                     data-keywords="watermarking,synthetic data,tabular data,discrete fourier transform,data provenance,generative AI,data security,healthcare data"
                     data-authors="Yizhou Zhao,Xiang Li,Peter Song,Qi Long,Weijie Su">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21600v1.html">TAB-DRW: A DFT-based Robust Watermark for Generative Tabular Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yizhou Zhao, Xiang Li, Peter Song et al.
                </div>

                <div class="paper-summary">
                    This paper introduces TAB-DRW, an efficient and robust post-editing watermarking scheme designed for generative tabular data, addressing critical concerns regarding data provenance and misuse in fields like healthcare. TAB-DRW embeds watermark signals in the frequency domain using Discrete Fourier Transform (DFT) after normalizing heterogeneous features, and employs a novel rank-based pseudorandom bit generation method for enhanced robustness and efficiency. Experiments demonstrate its strong detectability, robustness against post-processing attacks, high data fidelity, and full support for mixed-type features.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare data management</span>
                    
                    <span class="domain-tag">Clinical research</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                    <span class="domain-tag">Biomedical informatics</span>
                    
                    <span class="domain-tag">Medical AI development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21600v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21600v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21600v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21600v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21587v1"
                     data-domains="Epidemiology,Infectious Disease Modeling,Public Health,Biostatistics,Systems Biology (medical applications)"
                     data-keywords="ABC-SMC,Approximate Bayesian Computation,Likelihood-free Inference,Mechanistic Models,Dynamical Systems,PyMC,Epidemiology,Parameter Identifiability"
                     data-authors="Mario Castro">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21587v1.html">Approximate Bayesian Computation Made Easy: A Practical Guide to ABC-SMC for Dynamical Systems with \texttt{pymc}</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mario Castro
                </div>

                <div class="paper-summary">
                    This paper presents a practical, example-driven tutorial on Approximate Bayesian Computation with Sequential Monte Carlo (ABC-SMC), a likelihood-free method for parameter inference in complex mechanistic models with intractable likelihood functions. Leveraging Python and PyMC, it aims to demystify ABC-SMC for researchers, particularly in fields like epidemiology, by illustrating its implementation, diagnosis, and interpretation through diverse dynamical system examples, including hierarchical epidemic models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Systems Biology (medical applications)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21587v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21587v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21587v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21587v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21582v1"
                     data-domains="Oral Oncology,Oral and Maxillofacial Pathology,Dermatology (oral lesions),Diagnostic Imaging,Public Health (screening)"
                     data-keywords="Deep learning,Oral cancer,Multiclass classification,Data augmentation,Oversampling,Computer-aided diagnosis,Oral lesions,Early detection"
                     data-authors="Joy Naoum,Revana Salama,Ali Hamdi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21582v1.html">Deep Learning-Based Multiclass Classification of Oral Lesions with Stratified Augmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Joy Naoum, Revana Salama, Ali Hamdi
                </div>

                <div class="paper-summary">
                    This research introduces a deep learning-based multiclass classifier designed to differentiate between sixteen distinct types of oral lesions, aiming to improve early detection of oral cancer. By addressing challenges of limited and imbalanced datasets through stratified data splitting, advanced augmentation, and oversampling, the proposed model achieved superior performance metrics compared to existing methods, demonstrating the effectiveness of its data handling strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oral Oncology</span>
                    
                    <span class="domain-tag">Oral and Maxillofacial Pathology</span>
                    
                    <span class="domain-tag">Dermatology (oral lesions)</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Public Health (screening)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21582v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21582v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21582v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21582v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21575v1"
                     data-domains="Radiology,Orthopedics,Image-guided surgery,Interventional Radiology,Neurosurgery (potentially for spine or related imaging)"
                     data-keywords="Pelvic fluoroscopy,Landmark detection,2D/3D registration,U-Net,Pose estimation,Intra-operative imaging,Medical imaging,Deep learning"
                     data-authors="Chou Mo,Yehyun Suh,J. Ryan Martin,Daniel Moyer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21575v1.html">Enhanced Landmark Detection Model in Pelvic Fluoroscopy using 2D/3D Registration Loss</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chou Mo, Yehyun Suh, J. Ryan Martin et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel framework to enhance automated landmark detection in pelvic fluoroscopy, addressing the common limitation of models assuming a fixed Antero-Posterior view. It integrates a 2D/3D landmark registration loss into the training of a U-Net model to improve accuracy under variable patient or imaging unit orientations. The authors analyze the performance of this enhanced U-Net against baseline methods, particularly under realistic intra-operative conditions with varying patient pose.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Image-guided surgery</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Neurosurgery (potentially for spine or related imaging)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21575v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21575v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21575v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21575v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21563v1"
                     data-domains="stat.CO"
                     data-keywords="stat.CO,math.PR,stat.ML"
                     data-authors="Sam Power,Giorgos Vasdekis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21563v1.html">Some aspects of robustness in modern Markov Chain Monte Carlo</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ stat.CO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sam Power, Giorgos Vasdekis
                </div>

                <div class="paper-summary">
                    Markov Chain Monte Carlo (MCMC) is a flexible approach to approximate sampling from intractable probability distributions, with a rich theoretical foundation and comprising a wealth of exemplar algorithms. While the qualitative correctness of MCMC algorithms is often easy to ensure, their practical ...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">stat.CO</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21563v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21563v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21563v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21563v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21561v1"
                     data-domains="Clinical Risk Prediction,Predictive Analytics in Healthcare,Population Health Management,Chronic Disease Management,Medical Informatics,Personalized Medicine"
                     data-keywords="Machine Learning,Clinical Risk Prediction,Electronic Health Records (EHR),Time-Series Analysis,Multi-Scale Temporal Alignment,Deep Learning,Healthcare AI,Temporal Irregularity"
                     data-authors="Wei-Chen Chang,Lu Dai,Ting Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21561v1.html">Machine Learning Approaches to Clinical Risk Prediction: Multi-Scale Temporal Alignment in Electronic Health Records</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wei-Chen Chang, Lu Dai, Ting Xu
                </div>

                <div class="paper-summary">
                    This study introduces the Multi-Scale Temporal Alignment Network (MSTAN) to address challenges in clinical risk prediction from Electronic Health Records (EHR) due to temporal irregularity, varying sampling intervals, and multi-scale dynamic dependencies. The MSTAN effectively models long-term trends and short-term fluctuations by integrating a learnable temporal alignment mechanism and a multi-scale convolutional feature extraction structure. Experiments conducted on publicly available EHR datasets demonstrate that the proposed model significantly outperforms mainstream baselines across key performance metrics such as accuracy, recall, precision, and F1-Score.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Risk Prediction</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21561v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21561v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21561v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21561v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21530v1"
                     data-domains="Neurology,Geriatrics,Radiology,Predictive Medicine,Computational Neuroscience"
                     data-keywords="Alzheimer's Disease,MRI,Image Generation,Age-specific Prediction,Disease Progression,Cognitive Decline,Deep Learning,Structural Similarity"
                     data-authors="Xin Hong,Kaifeng Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21530v1.html">The Age-specific Alzheimer 's Disease Prediction with Characteristic Constraints in Nonuniform Time Span</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Hong, Kaifeng Huang
                </div>

                <div class="paper-summary">
                    This study introduces a novel methodology for age-specific Alzheimer's disease (AD) prediction by generating sequential MRI images, even from irregular time intervals. It leverages quantitative metrics and an age-scaling factor to maintain disease characteristics and predict advanced stages. The approach demonstrates improved synthesis accuracy and high structural similarity in generated images, crucial for timely identification and personalized treatment strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Predictive Medicine</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21530v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21530v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21530v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21530v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21519v1"
                     data-domains="Immunology,Rheumatology,Pathology,Laboratory Medicine"
                     data-keywords="Antinuclear Antibodies (ANA),Autoimmune Disorders,Multi-Instance Multi-Label (MIML) Learning,Deep Learning,Medical Image Analysis,Self-Paced Learning,Diagnostic Automation,Computer Vision"
                     data-authors="Yiyang Jiang,Guangwu Qian,Jiaxin Wu,Qi Huang,Qing Li,Yongkang Wu,Xiao-Yong Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21519v1.html">Self-Paced Learning for Images of Antinuclear Antibodies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yiyang Jiang, Guangwu Qian, Jiaxin Wu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel deep learning framework designed for automated Antinuclear Antibody (ANA) detection, specifically addressing the complex multi-instance, multi-label (MIML) challenges prevalent in clinical microscope images without requiring manual preprocessing. By integrating an instance sampler, a probabilistic pseudo-label dispatcher, and self-paced learning, the framework significantly enhances diagnostic accuracy and efficiency. The model achieves state-of-the-art results on an ANA dataset, showing substantial gains in F1-Macro and mAP, and demonstrates superior performance across public medical MIML benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Rheumatology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Laboratory Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21519v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21519v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21519v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21519v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21500v1"
                     data-domains="Cardiology,remote patient monitoring,continuous physiological monitoring,preventive medicine,non-invasive diagnostics,telemedicine"
                     data-keywords="Physiological signals,time misalignment,meta-learning,photoplethysmography (PPG),ballistocardiography (BCG),arterial blood pressure (ABP),signal transformation,Fourier phase shifts"
                     data-authors="Qian Hong,Cheng Bian,Xiao Zhou,Xiaoyu Li,Yelei Li,Zijing Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21500v1.html">Lost in Time? A Meta-Learning Framework for Time-Shift-Tolerant Physiological Signal Transformation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qian Hong, Cheng Bian, Xiao Zhou et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ShiftSyncNet, a meta-learning framework designed to overcome performance degradation caused by temporal misalignment in multimodal physiological signal transformation. By integrating a transformation network with a time-shift correction network that utilizes Fourier phase shifts, ShiftSyncNet automatically aligns supervision signals, significantly improving accuracy in translating non-invasive signals like PPG/BCG into clinical measurements such as ABP. It offers a robust solution for enhancing continuous, low-cost healthcare monitoring.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">remote patient monitoring</span>
                    
                    <span class="domain-tag">continuous physiological monitoring</span>
                    
                    <span class="domain-tag">preventive medicine</span>
                    
                    <span class="domain-tag">non-invasive diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21500v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21500v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21500v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21500v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21484v1"
                     data-domains="Neurology,Rehabilitation Medicine,Physical Therapy,Orthopedics,Biomedical Engineering"
                     data-keywords="Equinus foot,Orthosis,Electromyography (EMG),Neuromuscular rehabilitation,Dorsiflexion,Tibialis anterior,U-Net,Artificial Intelligence (AI)"
                     data-authors="Manuel Terradillos Perea,Olga Alonso Gonzalez,Cristina Soguero Ruiz,David Gutierrez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21484v1.html">A Dynamic Anti-Equinus Orthosis with Electromyography Sensor for Neuromuscular Rehabilitation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Manuel Terradillos Perea, Olga Alonso Gonzalez, Cristina Soguero Ruiz et al.
                </div>

                <div class="paper-summary">
                    This study introduces EquiSay, a dynamic anti-equinus orthosis incorporating an anterior elastic tension system and an electromyography (EMG) sensor for real-time tibialis anterior muscle activation monitoring. The system leverages a U-Net model for synthetic EMG signal generation and a predictive framework for automatic threshold calibration, demonstrating improved dorsiflexion, increased patient satisfaction, and providing valuable clinical insights for neuromuscular rehabilitation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21484v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21484v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21484v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21484v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21438v1"
                     data-domains="Pharmacology,Clinical Medicine,Systems Biology,Bioinformatics,Drug Discovery and Development,Personalized Medicine,Translational Research"
                     data-keywords="Drug Repurposing,Multi-agent Systems,Conversational AI,Knowledge Graph,Bioinformatics,Network Analysis,Personalized Medicine,Natural Language Processing"
                     data-authors="Simon S√ºwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21438v1.html">Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Simon S√ºwer, Kester Bagemihl, Sylvie Baier et al.
                </div>

                <div class="paper-summary">
                    ChatDRex is a novel conversational, multi-agent AI system designed to democratize network-based drug repurposing prediction by enabling non-expert researchers to control complex bioinformatic analyses using natural language. It integrates an extensive biomedical knowledge graph (NeDRex) with specialized bioinformatics agents for tasks ranging from data retrieval and algorithm execution to functional evaluation, literature mining, and scientific discussion, all while incorporating a reasoning module for user engagement and hallucination detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical Medicine</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21438v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21438v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21438v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21438v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21378v1"
                     data-domains="Diagnostic Imaging,Medical Records Analysis,Predictive Analytics,Disease Surveillance,Clinical Decision Support Systems"
                     data-keywords="Anomaly Detection,Contaminated Data,Machine Learning,Gaussian Mixture Model,Z-score,Data Cleansing,Healthcare AI,Robustness"
                     data-authors="Jungi Lee,Jungkwon Kim,Chi Zhang,Kwangsun Yoo,Seok-Joo Byun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21378v1.html">Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jungi Lee, Jungkwon Kim, Chi Zhang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Adaptive and Aggressive Rejection (AAR), a novel anomaly detection method designed to overcome the critical challenge of contaminated training data by dynamically excluding anomalies. AAR utilizes a modified z-score and Gaussian Mixture Model-based thresholds, integrating both hard and soft rejection strategies to effectively balance data preservation and anomaly removal. The method significantly enhances robustness and performance, outperforming state-of-the-art approaches, making it highly relevant for real-world applications, particularly in healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Records Analysis</span>
                    
                    <span class="domain-tag">Predictive Analytics</span>
                    
                    <span class="domain-tag">Disease Surveillance</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21378v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21378v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21378v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21378v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21363v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,cs.AI"
                     data-authors="Kevin Iselborn,David Dembinsky,Adriano Lucieri,Andreas Dengel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21363v1.html">The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kevin Iselborn, David Dembinsky, Adriano Lucieri et al.
                </div>

                <div class="paper-summary">
                    The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidel...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21363v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21363v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21363v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21363v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21344v1"
                     data-domains="Radiation oncology,Medical physics,Cancer treatment,Dosimetry"
                     data-keywords="Proton therapy,Stopping power,Prompt gamma timing,SER-PGT,Range monitoring,Adaptive therapy,Dosimetry,Particle therapy"
                     data-authors="Julius Werner,Francesco Pennazio,Piergiorgio Cerello,Elisa Fiorina,Simona Giordanengo,Felix Mas Milian,Alessio Mereghetti,Franco Mostardi,Marco Pullia,Sahar Ranjbar,Roberto Sacchi,Anna Vignati,Magdalena Rafecas,Veronica Ferrero">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21344v1.html">Stopping power monitoring during proton therapy by means of prompt gamma timing: first experimental results with a homogeneous phantom</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Julius Werner, Francesco Pennazio, Piergiorgio Cerello et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the first experimental results of Spatiotemporal Emission Reconstruction from Prompt-Gamma Timing (SER-PGT), a novel method designed to monitor stopping power and particle range during proton therapy. Using a sub-clinical proton beam on a homogeneous phantom, the technique demonstrated accurate stopping power estimation with an 8% average error and successfully identified range shifts, highlighting its potential to reduce treatment uncertainties and enable adaptive planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation oncology</span>
                    
                    <span class="domain-tag">Medical physics</span>
                    
                    <span class="domain-tag">Cancer treatment</span>
                    
                    <span class="domain-tag">Dosimetry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21344v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21344v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21344v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21344v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21339v1"
                     data-domains="Laparoscopic Surgery,Robot-assisted Surgery,Micro-surgery,Vascular Surgery"
                     data-keywords="Multimodal Large Language Models,Surgical Scene Understanding,Benchmark Dataset,Pixel-level Segmentation,Visual Question Answering,Micro-surgery,Robot-assisted Surgery,Laparoscopic Surgery"
                     data-authors="Tae-Min Choi,Tae Kyeong Jeong,Garam Kim,Jaemin Lee,Yeongyoon Koh,In Cheul Choi,Jae-Ho Chung,Jong Woong Park,Juyoun Park">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21339v1.html">SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tae-Min Choi, Tae Kyeong Jeong, Garam Kim et al.
                </div>

                <div class="paper-summary">
                    SurgMLLMBench is a novel unified multimodal benchmark dataset designed to advance surgical scene understanding using Multimodal Large Language Models (MLLMs). It overcomes limitations of existing datasets by integrating pixel-level instrument segmentation masks and structured VQA annotations across laparoscopic, robot-assisted, and micro-surgical domains under a consistent taxonomy, enabling richer visual-conversational interactions and comprehensive model evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Laparoscopic Surgery</span>
                    
                    <span class="domain-tag">Robot-assisted Surgery</span>
                    
                    <span class="domain-tag">Micro-surgery</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21339v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21339v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21339v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21339v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21223v1"
                     data-domains="Personalized Medicine,Diagnostics,Prognosis,Rare Disease Modeling,Clinical Decision Support,Drug Discovery (sparse data scenarios),Medical Imaging (uncertainty quantification)"
                     data-keywords="Variational Inference,Possibility Theory,Epistemic Uncertainty,Imprecise Probability,Bayesian Learning,Exponential Family,Machine Learning,Medical AI"
                     data-authors="Jasraj Singh,Shelvia Wongso,Jeremie Houssineau,Badr-Eddine Ch√©rief-Abdellatif">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21223v1.html">Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jasraj Singh, Shelvia Wongso, Jeremie Houssineau et al.
                </div>

                <div class="paper-summary">
                    This paper develops a principled formulation for possibilistic variational inference (VI), an adaptation of traditional VI to possibility theory, an imprecise probability framework. It addresses the challenges of extending VI concepts like entropy and divergence, which typically presuppose additivity, to model epistemic uncertainty directly, especially under sparse or imprecise information. The authors apply this new framework to exponential-family functions, highlighting its unique mathematical structures and parallels with probabilistic counterparts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Prognosis</span>
                    
                    <span class="domain-tag">Rare Disease Modeling</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21223v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21223v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21223v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21223v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21199v1"
                     data-domains="q-bio.PE"
                     data-keywords="q-bio.PE,math.DS"
                     data-authors="Alessia and√≤,Simone De Reggi,Francesca Scarabel,Rossana Vermiglio,Jianhong Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21199v1.html">Behavior-induced oscillations in epidemic outbreaks with distributed memory: beyond the linear chain trick using numerical methods</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alessia and√≤, Simone De Reggi, Francesca Scarabel et al.
                </div>

                <div class="paper-summary">
                    We considered a model for an infectious disease outbreak, when the depletion of susceptible individuals is negligible, and assumed that individuals adapt their behavior according to the information they receive about new cases. In line with the information index approach, we supposed that individual...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">q-bio.PE</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21199v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21199v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21199v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21199v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21120v1"
                     data-domains="pharmacology,drug discovery,toxicology,precision medicine,systems biology,computational biology"
                     data-keywords="molecular modeling,cellular responses,multi-modal learning,hierarchical representations,drug discovery,tree-structured vector quantization,biomedical modeling,gene expression"
                     data-authors="Mengran Li,Zelin Zang,Wenbin Xing,Junzhou Chen,Ronghui Zhang,Jiebo Luo,Stan Z. Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21120v1.html">Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mengran Li, Zelin Zang, Wenbin Xing et al.
                </div>

                <div class="paper-summary">
                    CHMR is a novel framework designed to enhance molecular property prediction by integrating chemical structures with cellular responses like morphology and gene expression. It addresses limitations in current cell-aware methods by robustly modeling multi-modal local-global dependencies and capturing latent biological hierarchies through a tree-structured vector quantization module. This approach significantly outperforms state-of-the-art baselines across various tasks, yielding more reliable and biologically grounded molecular representations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">pharmacology</span>
                    
                    <span class="domain-tag">drug discovery</span>
                    
                    <span class="domain-tag">toxicology</span>
                    
                    <span class="domain-tag">precision medicine</span>
                    
                    <span class="domain-tag">systems biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21120v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21120v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21120v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21120v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21114v1"
                     data-domains="Neurology,Diagnostic Radiology,Neuroimaging,Geriatric Medicine,Medical Artificial Intelligence"
                     data-keywords="Alzheimer's Disease,Early Prediction,Brain Atrophy,MRI,Generative Networks,Deep Learning,Temporal Modeling,Medical Imaging"
                     data-authors="Xin Honga,Jie Lin,Minghui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21114v1.html">Deformation-aware Temporal Generation for Early Prediction of Alzheimers Disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Honga, Jie Lin, Minghui Wang
                </div>

                <div class="paper-summary">
                    This paper introduces the Deformation-Aware Temporal Generative Network (DATGN) for the early prediction of Alzheimer's disease (AD) by automatically learning and generating future brain MRI images reflecting disease progression. DATGN addresses missing data in temporal MRI sequences and significantly improves AD classification accuracy when its generated synthetic data is used to augment training sets for existing classifiers. The network's qualitative outputs demonstrate consistency with characteristic brain atrophy in AD.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Geriatric Medicine</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21114v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21114v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21114v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21114v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21109v1"
                     data-domains="Public Health,Clinical Decision Support,Health Equity Research,Precision Medicine,Epidemiology,Medical Resource Allocation,Patient Risk Stratification"
                     data-keywords="Fair Clustering,Interpretable AI,Decision Trees,Algorithmic Fairness,Machine Learning,Sensitive Attributes,Healthcare Analytics"
                     data-authors="Mudi Jiang,Jiahui Zhou,Xinying Liu,Zengyou He,Zhikui Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21109v1.html">Interpretable Fair Clustering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mudi Jiang, Jiahui Zhou, Xinying Liu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an interpretable and fair clustering framework that integrates fairness constraints into the structure of decision trees. It aims to address the lack of interpretability in existing fair clustering methods, especially for high-stakes applications. The framework delivers competitive clustering performance, improved fairness, interpretability, and robust handling of multiple sensitive attributes, enabling more equitable and transparent data partitioning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Health Equity Research</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21109v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21109v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21109v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21109v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21075v1"
                     data-domains="Life Science Research,Medical Diagnostics,Pharmacology,Genomics,Systems Biology,Drug Discovery"
                     data-keywords="Large Language Models,Biomedical Knowledge,Fine-Tuning,Sparse Data,Overfitting,Text Embeddings,Gene Interaction,Single-Cell Perturbation"
                     data-authors="Zhenchao Tang,Fang Wang,Haohuai He,Jiale Zhou,Tianxu Lv,Jun Zhu,Shouzhi Chen,Minghao Yang,Yu Wang,Jiayang Wu,Yidong Song,Jianhua Yao">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21075v1.html">Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhenchao Tang, Fang Wang, Haohuai He et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Balanced Fine-Tuning (BFT), an efficient post-training method designed to align Large Language Models (LLMs) with specialized, often sparse, biomedical knowledge. BFT employs a novel two-layer weighting mechanism to stabilize gradients, prevent overfitting, and adaptively learn from hard samples without requiring external reward signals. It significantly outperforms standard Supervised Fine-Tuning (SFT) and specialized agents in various medical and biological reasoning tasks, enabling LLMs to acquire critical domain-specific knowledge.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Life Science Research</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Systems Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21075v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21075v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21075v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21075v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21057v1"
                     data-domains="Neurology,Neuroradiology,Geriatrics,Diagnostic Imaging,Computational Neuroscience"
                     data-keywords="Alzheimer's Disease,Image Generation,Long-Term Prediction,Normal Inverse Gamma Distribution,Temporal Parameter Estimation,Uncertainty Estimation,Uneven Time Series,Brain Imaging"
                     data-authors="Xin Hong,Xinze Sun,Yinhao Li,Yen-Wei Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21057v1.html">Long-Term Alzheimers Disease Prediction: A Novel Image Generation Method Using Temporal Parameter Estimation with Normal Inverse Gamma Distribution on Uneven Time Series</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xin Hong, Xinze Sun, Yinhao Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Temporal Parameter Estimation with Normal Inverse Gamma Distribution (T-NIG) model to address the challenge of long-term Alzheimer's Disease (AD) prediction using image generation, particularly when dealing with irregular time intervals in sequential brain imaging data. The T-NIG model effectively generates intermediate and future brain images by estimating temporal parameters and employing uncertainty estimation, demonstrating state-of-the-art performance in forecasting AD progression while preserving disease-related characteristics despite uneven data distribution.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21057v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21057v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21057v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21057v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21053v1"
                     data-domains="Disaster Medicine,Emergency Response,Public Health Surveillance,Remote Healthcare Logistics,Telemedicine (logistics)"
                     data-keywords="Referring Multi-Object Tracking,UAV,AerialMind,Computer Vision,Robotics,Natural Language Processing,Embodied Intelligence,Surveillance"
                     data-authors="Chenglizhao Chen,Shaofeng Liang,Runwei Guan,Xiaolou Sun,Haocheng Zhao,Haiyun Jiang,Tao Huang,Henghui Ding,Qing-Long Han">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21053v1.html">AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.RO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chenglizhao Chen, Shaofeng Liang, Runwei Guan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces AerialMind, the first large-scale benchmark dataset for Referring Multi-Object Tracking (RMOT) in Unmanned Aerial Vehicle (UAV) scenarios, addressing a critical gap where RMOT research has primarily focused on ground-level contexts. To facilitate this, the authors developed a semi-automated collaborative agent-based labeling assistant (COALA) framework and propose HawkEyeTrack (HETrack), a novel method designed to enhance vision-language representation learning for UAV perception, demonstrating the challenging nature of the dataset and the effectiveness of their approach.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Disaster Medicine</span>
                    
                    <span class="domain-tag">Emergency Response</span>
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                    <span class="domain-tag">Remote Healthcare Logistics</span>
                    
                    <span class="domain-tag">Telemedicine (logistics)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21053v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21053v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21053v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21053v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.21042v1"
                     data-domains="Pulmonology,Radiology,Oncology,Pathology,Medical Imaging"
                     data-keywords="lung nodules,CT scans,multi-agent system,AI in medicine,precision diagnosis,radiology,oncology,medical imaging"
                     data-authors="Cheng Yang,Hui Jin,Xinlei Yu,Zhipeng Wang,Yaoqun Liu,Fenglei Fan,Dajiang Lei,Gangyong Jia,Changmiao Wang,Ruiquan Ge">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.21042v1.html">LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cheng Yang, Hui Jin, Xinlei Yu et al.
                </div>

                <div class="paper-summary">
                    LungNoduleAgent is an innovative collaborative multi-agent system designed to enhance the precision diagnosis of lung nodules from CT scans, addressing the limitations of current multimodal large language models in morphological description and medical expertise integration. It streamlines the diagnostic process through a sequential pipeline of three specialized modules, significantly outperforming mainstream vision-language models, existing agent systems, and advanced expert models. The research highlights the critical importance of region-level semantic alignment and multi-agent collaboration for accurate nodule diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.21042v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.21042v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.21042v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.21042v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20983v1"
                     data-domains="Histopathology,Oncology (Lung Cancer),Medical Imaging Diagnostics,Pathology"
                     data-keywords="Federated Learning,Homomorphic Encryption,Vision Transformer,Privacy-Preserving AI,Medical Imaging,Histopathology,Gradient Reconstruction,CLS Token"
                     data-authors="Al Amin,Kamrul Hasan,Liang Hong,Sharif Ullah">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20983v1.html">Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Al Amin, Kamrul Hasan, Liang Hong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a privacy-preserving federated learning framework that combines Vision Transformers (ViT) with lightweight homomorphic encryption (HE) for secure medical AI. It addresses the vulnerability of conventional federated learning to gradient reconstruction attacks by encrypting compact ViT CLS tokens, significantly reducing communication overhead while maintaining high diagnostic accuracy for multi-institutional histopathology classification.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Oncology (Lung Cancer)</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnostics</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20983v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20983v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20983v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20983v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20956v1"
                     data-domains="Radiology,Oncology,Diagnostic Imaging"
                     data-keywords="Breast ultrasound,Radiology report generation,Vision-language model,Deep learning,BI-RADS,Medical imaging,Artificial intelligence"
                     data-authors="Rawa Mohammed,Mina Attin,Bryar Shareef">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20956v1.html">BUSTR: Breast Ultrasound Text Reporting with a Descriptor-Aware Vision-Language Model</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rawa Mohammed, Mina Attin, Bryar Shareef
                </div>

                <div class="paper-summary">
                    This paper introduces BUSTR, a novel multitask vision-language framework designed for automated breast ultrasound (BUS) report generation (RRG). BUSTR overcomes limitations of prior RRG methods, such as the scarcity of paired image-report datasets and large language model hallucinations, by generating reports from structured descriptors and achieving improved natural language generation and clinical efficacy metrics without requiring paired supervision.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20956v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20956v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20956v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20956v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20950v1"
                     data-domains="Neurology,Epileptology,Neurophysiology,Computational Neuroscience,Biomedical Engineering"
                     data-keywords="Epilepsy,Seizure suppression,Fractional dynamics,Intracranial EEG (iEEG),Dynamical networks,Brain states,Fractal analysis,Neuromodulation"
                     data-authors="Yaoyue Wang,Arian Ashourvan,Guilherme Ramos,Paul Bogdan,Emily Pereira">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20950v1.html">Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yaoyue Wang, Arian Ashourvan, Guilherme Ramos et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a state-of-the-art method that effectively suppresses epileptic seizure activity by stabilizing fractional dynamical networks modeled from intracranial EEG data. The approach successfully suppressed 34 out of 35 spontaneous seizure episodes, demonstrated a 49% average amplitude reduction in simulated controlled signals, and differentiated four distinct epileptic brain states based on fractal behavior and stability properties.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Epileptology</span>
                    
                    <span class="domain-tag">Neurophysiology</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20950v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20950v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20950v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20950v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20941v1"
                     data-domains="Drug Development,Clinical Trials,Biomarker Discovery,Personalized Medicine,Comparative Effectiveness Research"
                     data-keywords="two-sample test,quantum kernels,hybrid kernels,maximum mean discrepancy,small datasets,high-dimensional data,statistical power,clinical research"
                     data-authors="Yu Terada,Yugo Ogio,Ken Arai,Hiroyuki Tezuka,Yu Tanaka">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20941v1.html">Fusion of classical and quantum kernels enables accurate and robust two-sample tests</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-26</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ quant-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yu Terada, Yugo Ogio, Ken Arai et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MMD-FUSE, a novel kernel-based two-sample test that integrates quantum kernels and a hybrid classical-quantum kernel strategy. The approach aims to enhance the accuracy and robustness of statistical tests, particularly for small and high-dimensional datasets. By combining the inductive biases of classical kernels with the unique expressive power of quantum kernels, it offers a powerful and adaptive tool for discriminating between data distributions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Biomarker Discovery</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Comparative Effectiveness Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20941v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20941v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20941v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20941v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20926v1"
                     data-domains="Neuroradiology,Otolaryngology,Medical Imaging,Diagnostic Radiology,Neuro-oncology"
                     data-keywords="Deep Learning,MRI,Contrast Agent Reduction,Cerebellopontine Angle,Vestibular Schwannoma,Image Quality,Segmentation,Dose Reduction"
                     data-authors="Yunjie Chen,Rianne A. Weber,Olaf M. Neve,Stephan R. Romeijn,Erik F. Hensen,Jelmer M. Wolterink,Qian Tao,Marius Staring,Berit M. Verbist">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20926v1.html">A deep learning model to reduce agent dose for contrast-enhanced MRI of the cerebellopontine angle cistern</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yunjie Chen, Rianne A. Weber, Olaf M. Neve et al.
                </div>

                <div class="paper-summary">
                    This study developed and evaluated a deep learning (DL) model to restore standard-dose contrast-enhanced T1-weighted MRI (T1ce) of the cerebellopontine angle (CPA) cistern from simulated low-dose images. The DL model significantly improved image quality and segmentation performance, enabling lesion detection and diagnostic characterization with only 10-30% of the standard contrast agent dose.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Otolaryngology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20926v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20926v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20926v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20926v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20913v1"
                     data-domains="Critical Care Medicine,Sepsis Management,Intensive Care Unit (ICU),Clinical Decision Support"
                     data-keywords="Reinforcement Learning,Sepsis Treatment,Time-Step Size,Offline RL,Healthcare AI,Patient Dynamics,Policy Optimization,Critical Care"
                     data-authors="Yingchuan Sun,Shengpu Tang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20913v1.html">Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yingchuan Sun, Shengpu Tang
                </div>

                <div class="paper-summary">
                    This paper investigates the critical impact of time-step size on reinforcement learning (RL) models designed for sepsis treatment, challenging the conventional 4-hour data aggregation. Through controlled empirical experiments, it demonstrates that policies learned at finer time-step granularities (1h and 2h) consistently achieve superior and more stable performance, especially with a static behavior policy. The study advocates for a re-evaluation of time-step selection in offline RL for healthcare, moving beyond the established 4-hour setup to potentially develop more effective treatment strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Sepsis Management</span>
                    
                    <span class="domain-tag">Intensive Care Unit (ICU)</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20913v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20913v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20913v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20913v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20883v1"
                     data-domains="Oncology,Immunology,Metabolism,Pathology,Preventive Medicine,Precision Medicine"
                     data-keywords="Immunometabolism,Peto's Paradox,T-cell infiltration,Cancer prognosis,Metabolic gatekeeping,Tissue tropism,Cancer prevention,Combination therapy"
                     data-authors="Naomi Iris van den Berg,Matou≈° Elphick,Kevin Mulder,Omar Bouricha,Omid Sadeghi-Alavijeh,Xiao Fu,Samra Turajlic">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20883v1.html">Immunometabolic Gatekeeping: Reconciling Peto's & the T-cell Infiltration Prognostic Paradox</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Naomi Iris van den Berg, Matou≈° Elphick, Kevin Mulder et al.
                </div>

                <div class="paper-summary">
                    This paper proposes an "immunometabolic gatekeeping" framework, asserting that the inherent metabolic intensity and waste-handling capacity of healthy tissues are upstream determinants of anti-tumor immunity and cancer vulnerability. It posits that high-metabolism tissues with poor waste clearance foster immune-exhausting niches even before malignant transformation, thus reconciling several paradoxes in cancer biology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Metabolism</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20883v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20883v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20883v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20883v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20835v1"
                     data-domains="Neuroscience,Rehabilitation Medicine,Assistive Technology,Neurology,Neuroprosthetics"
                     data-keywords="Brain-Computer Interface (BCI),Non-invasive,Steady-State Visual Evoked Potentials (SSVEP),Mind-drawing,Single-channel EEG,Human-AI symbiosis,Stable Diffusion,Visual intent reconstruction"
                     data-authors="Gao Wang,Yingying Huang,Lars Muckli,Daniele Faccio">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20835v1.html">Symbiotic Brain-Machine Drawing via Visual Brain-Computer Interfaces</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gao Wang, Yingying Huang, Lars Muckli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel non-invasive Brain-Computer Interface (BCI) for 'mind-drawing' that reconstructs a subject's imagined shapes by iteratively analyzing Steady-State Visual Evoked Potentials (SSVEPs) from single-channel EEG. By adaptively presenting flicker-frequency encoded visual probes and leveraging symbiotic human-AI interaction, the system achieves a significant increase in BCI bit-rates, further enabling detailed visualization of reconstructed mental images using stable diffusion models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroprosthetics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20835v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20835v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20835v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20835v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20823v1"
                     data-domains="Radiology,Cardiology,Pulmonology,Interventional Radiology,Vascular Surgery,Thoracic Surgery,Medical Imaging Analysis"
                     data-keywords="Vascular tree analysis,Centerline detection,3D medical imaging,Recurrent neural networks,Transformer,Confluent trajectories,Non-maximum suppression,Clinical diagnosis"
                     data-authors="Roman Naeem,David Hagerman,Jennifer Alv√©n,Fredrik Kahl">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20823v1.html">RefTr: Recurrent Refinement of Confluent Trajectories for 3D Vascular Tree Centerline Graphs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Naeem, David Hagerman, Jennifer Alv√©n et al.
                </div>

                <div class="paper-summary">
                    RefTr is a novel 3D image-to-graph model that generates vascular tree centerlines using recurrent refinement of confluent trajectories, a method explicitly enforcing valid tree topology. This Producer-Refiner architecture, built on a Transformer decoder, achieves superior recall and comparable precision with significantly fewer parameters and faster inference, demonstrating its potential as a new state-of-the-art for critical clinical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Vascular Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20823v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20823v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20823v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20823v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20819v1"
                     data-domains="Epidemiology,Infectious Disease Modeling,Public Health Surveillance,Biostatistics"
                     data-keywords="Epidemic Forests,Transmission Trees,Statistical Comparison,PERMANOVA,Chi-square Test,Outbreak Analysis,Public Health,R package mixtree"
                     data-authors="Cyril Geismar,Peter J. White,Anne Cori,Thibaut Jombar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20819v1.html">A statistical framework for comparing epidemic forests</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cyril Geismar, Peter J. White, Anne Cori et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the first statistical framework to formally compare epidemic forests, which are collections of plausible transmission trees inferred from outbreak data. Addressing the lack of a robust method to assess differences between such forests, the authors propose using a chi-square test and permutational multivariate analysis of variance (PERMANOVA). Their assessment shows PERMANOVA consistently outperforms the chi-square test in sensitivity, while both achieve perfect specificity for larger forests, providing a robust tool for epidemic analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Infectious Disease Modeling</span>
                    
                    <span class="domain-tag">Public Health Surveillance</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20819v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20819v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20819v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20819v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20793v1"
                     data-domains="Oncology,Radiology,Diagnostic Imaging,Hepatology"
                     data-keywords="liver tumor,segmentation,dynamic MRI,multi-task learning,adversarial learning,deep learning,classification,regression"
                     data-authors="Xiaojiao Xiao,Qinmin Vivian Hu,Tae Hyun Kim,Guanghui Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20793v1.html">Adversarial Multi-Task Learning for Liver Tumor Segmentation, Dynamic Enhancement Regression, and Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaojiao Xiao, Qinmin Vivian Hu, Tae Hyun Kim et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTI-Net, a novel end-to-end adversarial multi-task learning framework designed to concurrently perform liver tumor segmentation, dynamic enhancement regression, and classification from MRI data. MTI-Net addresses prior limitations by effectively capturing inter-task relevance and extracting dynamic MRI information through components like Multi-domain Information Entropy Fusion and a task interaction module. Tested on a dataset of 238 subjects, the framework demonstrates high performance across all tasks, showing strong potential for clinical liver tumor assessment.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Hepatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20793v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20793v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20793v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20793v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20650v1"
                     data-domains="Radiology,Pathology,Medical Diagnostics,Medical Imaging Analysis,Clinical Decision Support"
                     data-keywords="Open-Vocabulary Object Detection,Medical Imaging,Real-Time Detection,Foundation Models,Contrastive Learning,Multi-modal Data,Deep Learning,Computer Vision"
                     data-authors="Tooba Tehreem Sheikh,Jean Lahoud,Rao Muhammad Anwer,Fahad Shahbaz Khan,Salman Khan,Hisham Cholakkal">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20650v1.html">MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer et al.
                </div>

                <div class="paper-summary">
                    MedROV is introduced as the first real-time open-vocabulary object detection (OVOD) model specifically for medical imaging, addressing the limitations of traditional closed-set detectors and data scarcity. It achieves this by curating a large multi-modality dataset (Omnis), employing a pseudo-labeling strategy, and integrating knowledge from a pre-trained foundation model, resulting in significant performance improvements and real-time operation at 70 FPS.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20650v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20650v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20601v1"
                     data-domains="Endocrinology,Diabetology,Digital Health,Predictive Analytics (Medicine),Precision Medicine"
                     data-keywords="Blood Glucose Forecasting,Deep Sequence Models,Driver-Blindness,Diabetes Management,Physiological Drivers,Autocorrelation,Causal Regularization,Personalized Medicine"
                     data-authors="Heman Shakeri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20601v1.html">The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to Autocorrelation in Blood Glucose Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Heman Shakeri
                </div>

                <div class="paper-summary">
                    This paper identifies and formalizes the "Driver-Blindness Phenomenon" in deep sequence models for blood glucose forecasting, where models consistently fail to leverage crucial physiological drivers like insulin, meals, and activity. It quantifies this failure using a metric $Œî_{	ext{drivers}}$ and attributes it to architectural biases, data fidelity gaps, and physiological heterogeneity, while synthesizing strategies to mitigate this issue.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Predictive Analytics (Medicine)</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20601v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20601v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20601v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20601v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20526v1"
                     data-domains="Pharmacy,Medical Education,Clinical Assessment,Digital Health,Pharmaceutical Sciences"
                     data-keywords="Large Language Models (LLMs),Pharmacist Licensure Exam,AI in Medical Education,Digital Health Assessment,ChatGPT-4o,DeepSeek-R1,Clinical Competency,Formative Evaluation"
                     data-authors="Xinran Wang,Boran Zhu,Shujuan Zhou,Ziwen Long,Dehua Zhou,Shu Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20526v1.html">Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinran Wang, Boran Zhu, Shujuan Zhou et al.
                </div>

                <div class="paper-summary">
                    This study evaluated the performance of two large language models, ChatGPT-4o and DeepSeek-R1, on real questions from the Chinese Pharmacist Licensing Examination. DeepSeek-R1 significantly outperformed ChatGPT-4o, achieving an impressive 90.0% overall accuracy compared to 76.1%, particularly excelling in foundational and clinical synthesis modules.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacy</span>
                    
                    <span class="domain-tag">Medical Education</span>
                    
                    <span class="domain-tag">Clinical Assessment</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Pharmaceutical Sciences</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20526v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20526v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20526v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20526v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20514v1"
                     data-domains="Interventional Radiology,Diagnostic Imaging,Minimally Invasive Surgery,Oncology (for biopsy procedures)"
                     data-keywords="Ultrasonic Needle Tracking,Photoacoustic Beacon,3D Guidance,Interventional Ultrasound,Core Needle Biopsy,Real-time Tracking,Time-of-flight,B-mode Imaging"
                     data-authors="Christian Baker,Weidong Liang,Richard Colchester,Peng Lei,Francois Joubert,Sebastien Ourselin,Simeon West,Adrien Desjardins,Athanasios Diamantopoulos,Wenfeng Xia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20514v1.html">Real-time 3D Ultrasonic Needle Tracking with a Photoacoustic Beacon</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christian Baker, Weidong Liang, Richard Colchester et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel interventional ultrasound system that enables real-time 3D tracking of a needle's tip during procedures, integrating this information with B-mode guidance. It addresses the critical issue of poor needle visibility and ambiguity regarding tip location, aiming to improve safety and reduce reliance on alternative, less desirable guidance methods like CT.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery</span>
                    
                    <span class="domain-tag">Oncology (for biopsy procedures)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20514v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20514v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20514v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20514v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20510v2"
                     data-domains="Oncology,Pharmacology,Medicinal Chemistry,Drug Development"
                     data-keywords="generative AI,drug discovery,molecule generation,fragmentation,Q-learning,agentic AI,drug lead optimization,cancer therapeutics"
                     data-authors="Yuto Suzuki,Paul Awolade,Daniel V. LaBarbera,Farnoush Banaei-Kashani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20510v2.html">FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuto Suzuki, Paul Awolade, Daniel V. LaBarbera et al.
                </div>

                <div class="paper-summary">
                    FRAGMENTA is an end-to-end generative AI framework designed to overcome challenges in drug lead optimization, particularly with limited training data, by integrating a novel fragmentation-based generative model with an agentic AI tuning system. It reframes fragmentation as a 'vocabulary selection' problem optimized via dynamic Q-learning, and employs conversational AI to learn from domain experts, automating objective refinement. In real-world cancer drug discovery, FRAGMENTA significantly outperformed baselines, with its autonomous Agent-Agent system surpassing traditional human-human tuning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20510v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20510v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20510v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20510v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20507v1"
                     data-domains="Neurology,Speech-Language Pathology,Cognitive Neuroscience,Neuropsychology"
                     data-keywords="Aphasia,Large Language Models (LLMs),Benchmark,Computational Linguistics,Neurological Disorders,Language Assessment,AI in Medicine,Speech-Language Pathology"
                     data-authors="Nathan Roll,Jill Kries,Flora Jin,Catherine Wang,Ann Marie Finley,Meghan Sumner,Cory Shain,Laura Gwilliams">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20507v1.html">The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB), designed to assess aphasia-like deficits in large language models (LLMs). The TAB comprises four subtests, providing a novel computational tool to study linguistic disorders. A key finding is the validation of an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Neuropsychology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20507v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20507v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20503v1"
                     data-domains="Medical Imaging,Computational Pathology,Drug Discovery and Design,Bioinformatics,Synthetic Data Generation for Healthcare,Medical Data Augmentation"
                     data-keywords="Generative Modeling,Manifold Learning,Continuum Percolation,Topological Data Analysis,Random Geometric Graphs,Mode Collapse,Hyper-Generalization,Medical Imaging"
                     data-authors="Rui Tong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20503v1.html">Generative Modeling with Manifold Percolation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Tong
                </div>

                <div class="paper-summary">
                    This paper redefines generative modeling as disentangling geometric support from probability distributions, proposing Continuum Percolation for robust geometric support analysis. It establishes a rigorous isomorphism between topological phase transitions in Random Geometric Graphs and high-dimensional data manifolds. The authors introduce a 'Percolation Shift' metric and a differentiable loss function based on this topological insight, which effectively prevents manifold shrinkage and drives generative models toward 'Hyper-Generalization' with enhanced fidelity and verified topological expansion.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Drug Discovery and Design</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Synthetic Data Generation for Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20503v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20503v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20503v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20503v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20501v1"
                     data-domains="Cerebrovascular Medicine,Interventional Radiology,Diagnostic Imaging,Neuroradiology,Neurology"
                     data-keywords="Digital Subtraction Angiography (DSA),Artery Segmentation,Physics-Informed Loss,Deep Learning,Cerebrovascular Diseases,Dislocation Theory,Boundary Coherence,Medical Imaging"
                     data-authors="Muhammad Irfan,Nasir Rahim,Khalid Mahmood Malik">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20501v1.html">A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Irfan, Nasir Rahim, Khalid Mahmood Malik
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Physics-Informed Loss (PIL) function for accurate cerebral artery segmentation in Digital Subtraction Angiography (DSA) sequences. Inspired by material physics' dislocation theory, PIL models boundary interactions as an elastic process, enforcing geometric consistency and smooth contour evolution. It consistently outperforms conventional loss functions across various deep learning architectures and benchmarks, significantly enhancing the precision and robustness of vascular segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cerebrovascular Medicine</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20501v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20501v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20501v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20501v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20490v1"
                     data-domains="Oncology,Precision Medicine,Clinical Decision Support,Pathology,Genomics"
                     data-keywords="Multimodal LLMs,Oncology,Molecular Tumor Boards,Clinical Decision-Making,AI Benchmarking,Precision Oncology,Agentic AI,Longitudinal Data"
                     data-authors="Kiril Vasilev,Alexandre Misrahi,Eeshaan Jain,Phil F Cheng,Petros Liakopoulos,Olivier Michielin,Michael Moor,Charlotte Bunne">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20490v1.html">MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MTBBench, a novel benchmark designed to simulate the complex, multimodal, and longitudinal decision-making processes of Molecular Tumor Boards (MTBs) in oncology. It reveals that current LLMs, despite their scale, consistently lack reliability, struggle with time-resolved data and conflicting evidence, but demonstrates that an agentic framework with foundation model-based tools can significantly enhance their multimodal and longitudinal reasoning capabilities.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20490v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20490v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.20472v1"
                     data-domains="Radiation Oncology,Medical Physics,Radiotherapy"
                     data-keywords="in vivo dosimetry,scintillator array,external beam radiotherapy,surface dosimetry,photon dosimetry,gamma analysis,Cherenkov imaging,conformal"
                     data-authors="Roman Vasyltsiv,Allison L. Matous,Natasha Mulenga,Megan A. Clark,Brian W. Pogue,David J. Gladstone,Lesley A. Jarvis,Petr Bruza">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.20472v1.html">Wide Area Surface Dosimetry with Conformal Scintillator Array for External Beam Radiotherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-25</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roman Vasyltsiv, Allison L. Matous, Natasha Mulenga et al.
                </div>

                <div class="paper-summary">
                    This paper presents a novel wide-area surface dosimetry system utilizing a conformable scintillator array combined with a stereovision and Cherenkov imaging system for external beam radiotherapy. The system demonstrated high dose linearity, minimal beam perturbation, robust angular and repetition rate stability, and excellent agreement with radiochromic film for field edge detection, addressing key limitations of current in vivo dosimetry techniques.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiotherapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.20472v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.20472v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.20472v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.20472v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-29 06:26:24</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>