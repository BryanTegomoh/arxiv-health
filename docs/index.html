<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">49</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">137</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (12), Diagnostic Imaging (12), Neurology (11)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (12)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (12)</option>
                        
                        <option value="Neurology">Neurology (11)</option>
                        
                        <option value="Oncology">Oncology (8)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (8)</option>
                        
                        <option value="Public Health">Public Health (6)</option>
                        
                        <option value="Infectious Diseases">Infectious Diseases (4)</option>
                        
                        <option value="Psychiatry">Psychiatry (4)</option>
                        
                        <option value="Pharmacology">Pharmacology (4)</option>
                        
                        <option value="Artificial Intelligence in Medicine">Artificial Intelligence In Medicine (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.05485v1"
                     data-domains="Clinical informatics,Diagnostic medicine,Health information management,Medical coding,Natural Language Processing in healthcare,Public health"
                     data-keywords="Narrative-based diagnosis,ICD-11,EHR,MIMIC,Likelihood re-ranking,PMI scoring,Clinical NLP,Diagnostic dataset"
                     data-authors="Yuexin Wu,Shiqi Wang,Vasile Rus">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05485v1.html">MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuexin Wu, Shiqi Wang, Vasile Rus
                </div>

                <div class="paper-summary">
                    This paper introduces MIMIC-SR-ICD11, a novel large English diagnostic dataset derived from EHR discharge notes and aligned with WHO ICD-11 terminology, aiming to capture rich narrative details for improved diagnosis. It also proposes LL-Rank, a likelihood-based re-ranking framework that consistently outperforms existing baselines by leveraging PMI-based scoring to enhance semantic compatibility and mitigate label frequency bias in narrative-based diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical informatics</span>
                    
                    <span class="domain-tag">Diagnostic medicine</span>
                    
                    <span class="domain-tag">Health information management</span>
                    
                    <span class="domain-tag">Medical coding</span>
                    
                    <span class="domain-tag">Natural Language Processing in healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05485v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05485v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05485v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05485v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05483v1"
                     data-domains="Drug Discovery,Biopharmaceutical Development,Protein Engineering,Structural Biology,Computational Biology,Pharmacogenomics"
                     data-keywords="Enzyme stability,DDG prediction,Graph Neural Networks (GNN),Transformers,Diffusive attention,Protein engineering,Drug design,Biophysics"
                     data-authors="Abigail Lin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05483v1.html">DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abigail Lin
                </div>

                <div class="paper-summary">
                    This paper introduces DGTN, a novel Graph-Enhanced Transformer that co-learns structural (GNN) and sequential (Transformer) protein information through a bidirectional diffusion mechanism to predict enzyme thermodynamic stability (DDG). DGTN addresses the limitations of independent processing by allowing GNN embeddings to guide transformer attention and transformer representations to refine GNN updates, achieving state-of-the-art performance on benchmark datasets. Rigorous mathematical analysis further demonstrates provably better approximation bounds and optimal structure-sequence coupling convergence.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Biopharmaceutical Development</span>
                    
                    <span class="domain-tag">Protein Engineering</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05483v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05483v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05483v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05483v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05477v1"
                     data-domains="Medical Imaging,Pathology (Histopathology),Oncology (Breast Cancer Detection),Gastroenterology (Endoscopy),Diagnostic Radiology"
                     data-keywords="Medical Image Segmentation,Kolmogorov-Arnold Networks (KAN),GroupKAN,Spline-based Mappings,Interpretability,Deep Learning,Lightweight Models,Computational Efficiency"
                     data-authors="Guojie Li,Anwar P. P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05477v1.html">GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guojie Li, Anwar P. P. Abdul Majeed, Muhammad Ateeq et al.
                </div>

                <div class="paper-summary">
                    GroupKAN introduces a novel, lightweight medical image segmentation network that enhances the scalability and efficiency of Kolmogorov-Arnold Networks (KANs) by overcoming the O(C^2) complexity of U-KAN. It achieves this through Grouped KAN Transform and Grouped KAN Activation modules, which enable multivariate spline mappings within channel groups. GroupKAN demonstrates superior accuracy and interpretability while significantly reducing model parameters on various medical benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology (Histopathology)</span>
                    
                    <span class="domain-tag">Oncology (Breast Cancer Detection)</span>
                    
                    <span class="domain-tag">Gastroenterology (Endoscopy)</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05477v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05477v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05477v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05477v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05292v1"
                     data-domains="Nutrition,Public Health,Chronic Disease Management,Preventive Medicine,Dietetics"
                     data-keywords="wearable sensors,IMU,Chinese cuisine,food intake detection,dietary monitoring,smartwatch,smart glasses,chronic disease prevention"
                     data-authors="Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05292v1.html">What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiaxi Yin, Pengcheng Wang, Han Ding et al.
                </div>

                <div class="paper-summary">
                    CuisineSense is a novel wearable-based system designed to accurately infer Chinese cuisine intake by integrating hand motions from a smartwatch and head dynamics from smart glasses. It employs a two-stage detection pipeline for eating state identification and fine-grained food classification, demonstrating high accuracy across 11 diverse Chinese food categories. This system offers an unobtrusive and practical solution for dietary monitoring, addressing limitations of existing methods concerning privacy and food diversity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nutrition</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Dietetics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05292v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05292v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05292v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05292v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05289v1"
                     data-domains="Clinical Informatics,Predictive Analytics in Healthcare,Medical AI Ethics,Patient Data Privacy,Health Data Science"
                     data-keywords="Membership Inference Attacks,Time Series Forecasting,Data Augmentation,Electronic Health Records,Privacy,ZOO-PCA,Clinical Informatics,Machine Learning"
                     data-authors="Marius Fracarolli,Michael Staniek,Stefan Riezler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05289v1.html">Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marius Fracarolli, Michael Staniek, Stefan Riezler
                </div>

                <div class="paper-summary">
                    This paper investigates using embedding-space data augmentation as a strategy to mitigate Membership Inference Attacks (MIA) on Time Series Forecasting (TSF) models trained with sensitive Electronic Health Records (EHR). It demonstrates that retraining models with strategically generated synthetic data, particularly through ZOO-PCA, substantially reduces the effectiveness of loss-based MIAs by lowering the attacker's true-positive to false-positive ratio, all without compromising predictive performance on test data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="domain-tag">Medical AI Ethics</span>
                    
                    <span class="domain-tag">Patient Data Privacy</span>
                    
                    <span class="domain-tag">Health Data Science</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05289v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05289v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05289v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05289v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05253v1"
                     data-domains="Surgical Oncology,Hepatobiliary Surgery,Medical Imaging,Radiology,Computer-Assisted Surgery"
                     data-keywords="Colorectal liver metastases,CRLM,Intraoperative ultrasound,iUS,3D U-Net,nnU-Net,Medical image segmentation,Surgical navigation,Deep learning"
                     data-authors="Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05253v1.html">Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tiziano Natali, Karin A. Olthof, Niels F. M. Kok et al.
                </div>

                <div class="paper-summary">
                    This paper presents an automated 3D U-Net model, trained via the nnU-Net framework, for real-time segmentation of colorectal liver metastases (CRLM) from intraoperative ultrasound (iUS) volumes. The model, particularly when trained on cropped regions around tumors, significantly outperforms a full-volume approach, achieving clinically acceptable accuracy (median DSC=0.74, HDist=17.1mm) approximately four times faster (~1 minute) than semi-automatic methods. This technology aims to enhance precision and efficiency in ultrasound-based surgical navigation for hepatic resections.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Surgical Oncology</span>
                    
                    <span class="domain-tag">Hepatobiliary Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Computer-Assisted Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05253v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05253v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05253v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05253v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05221v1"
                     data-domains="Neurology,Sleep Medicine,Movement Disorders,Geriatrics,Neurodegenerative Diseases"
                     data-keywords="Actigraphy,REM Sleep Behavior Disorder,Machine Learning,Prodromal Marker,Parkinson's Disease,Alpha-synucleinopathies,Wearable Devices,Generalizability"
                     data-authors="David Bertram,Anja Ophey,Sinah R√∂ttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,No √©mie Moreau,Michael Sommerauer,Katarzyna Bozek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05221v1.html">ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> David Bertram, Anja Ophey, Sinah R√∂ttgen et al.
                </div>

                <div class="paper-summary">
                    ActiTect is an open-source, automated machine learning pipeline designed for screening REM sleep behavior disorder (RBD) using standardized actigraphy data from wearable devices. The tool ensures generalizability through robust preprocessing and feature extraction from multi-device data, demonstrating strong discriminatory power (AUROC 0.95) and consistent generalization (AUROC 0.84-0.94) across internal and external cohorts. This advancement facilitates early, non-invasive detection of a major prodromal marker for alpha-synucleinopathies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                    <span class="domain-tag">Movement Disorders</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05221v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05221v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05221v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05221v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05183v1"
                     data-domains="Pathology,Oncology,Diagnostic Imaging,Computational Pathology,Precision Medicine"
                     data-keywords="Digital Pathology,Whole-Slide Images,Artificial Intelligence,Preprocessing,Open-Source Toolkit,Image Analysis,Stain Normalization,Tissue Detection"
                     data-authors="Gregory Verghese,Anthony Baptista,Chima Eke,Holly Rafique,Mengyuan Li,Fathima Mohamed,Ananya Bhalla,Lucy Ryan,Michael Pitcher,Enrico Parisini,Concetta Piazzese,Liz Ing-Simmons,Anita Grigoriadis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05183v1.html">PySlyde: A Lightweight, Open-Source Toolkit for Pathology Preprocessing</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gregory Verghese, Anthony Baptista, Chima Eke et al.
                </div>

                <div class="paper-summary">
                    PySlyde is an open-source Python toolkit designed to standardize and streamline the complex preprocessing of gigapixel whole-slide images (WSIs) for artificial intelligence (AI) in pathology. By unifying critical steps like tissue detection, tessellation, stain normalization, and annotation parsing, it addresses current fragmented workflows, accelerating the generation of reproducible, AI-ready datasets. This enables researchers to focus on developing advanced AI models for improved diagnosis and treatment planning in precision medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05183v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05183v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05183v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05183v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05170v1"
                     data-domains="Pathology,Histopathology,Oncology"
                     data-keywords="Nucleus Detection,Nucleus Classification,Histopathology,Self-supervised Learning,Deep Learning,Computational Pathology,Digital Pathology,Image Analysis"
                     data-authors="Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05170v1.html">MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zijiang Yang, Hanqing Chao, Bokai Zhao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MUSE (Multi-Scale Dense Self-Distillation), a novel self-supervised learning method for Nucleus Detection and Classification (NDC) in histopathology. MUSE addresses the reliance on labor-intensive annotations and leverages large-scale unlabeled data by employing a coordinate-guided local self-distillation mechanism (NuLo) that enables flexible cross-scale alignment. The resulting models demonstrate superior performance, outperforming state-of-the-art supervised baselines and generic pathology foundation models on multiple benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05170v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05170v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05170v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05170v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05169v1"
                     data-domains="Oncology,Nuclear Medicine,Radiology,Medical Imaging,Artificial Intelligence in Medicine,Endocrinology"
                     data-keywords="Neuroendocrine Tumors,PRRT,177Lu-DOTATOC,Progression-Free Survival,Deep Learning,Multimodal Fusion,SR-PET/CT,Biomarkers"
                     data-authors="Simon Baur,Tristan Ruhwedel,Ekin B√∂ke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05169v1.html">Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Simon Baur, Tristan Ruhwedel, Ekin B√∂ke et al.
                </div>

                <div class="paper-summary">
                    This study developed and evaluated unimodal and multimodal deep learning models for predicting progression-free survival (PFS) in 116 patients with metastatic neuroendocrine tumors (NETs) treated with 177Lu-DOTATOC PRRT. The research found that a multimodal fusion model, combining laboratory values, pre-therapeutic SR-PET, and CT imaging, significantly outperformed unimodal approaches, achieving an AUROC of 0.72 for classifying short vs. long PFS.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05169v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05169v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05169v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05169v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05150v1"
                     data-domains="Digital Pathology,Oncology,Molecular Diagnostics,Histopathology,Precision Medicine"
                     data-keywords="AI-based biomarkers,Digital Pathology,Foundation Models,H&E slides,Cell-level morphology,Self-supervised learning,Attention pooling,Molecular features"
                     data-authors="Jingsong Liu,Han Li,Nassir Navab,Peter J. Sch√ºffler">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05150v1.html">From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingsong Liu, Han Li, Nassir Navab et al.
                </div>

                <div class="paper-summary">
                    This paper introduces JWTH (Joint-Weighted Token Hierarchy), a novel pathology foundation model designed to bridge global patch-level and cellular-level representations for improved AI-based biomarker detection. By integrating self-supervised pretraining, cell-centric post-tuning, and attention pooling, JWTH achieves superior balanced accuracy and robustness compared to prior models across multiple biomarker tasks and cohorts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Molecular Diagnostics</span>
                    
                    <span class="domain-tag">Histopathology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05150v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05150v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05150v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05150v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05130v1"
                     data-domains="Vaccinology,Immunology,Infectious Diseases,Public Health,Computational Biology in Medicine"
                     data-keywords="RNA vaccination,Immunity waning,Mathematical model,SARS-CoV-2,Germinal centers,Protection time,Vaccine dosing,Immune variability"
                     data-authors="Juan Magalang,Tyll Krueger,Joerg Galle">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05130v1.html">Modelling variability of the immunity build-up and waning following RNA-based vaccination</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Juan Magalang, Tyll Krueger, Joerg Galle
                </div>

                <div class="paper-summary">
                    This paper introduces a mathematical model to explain the fast and variable waning immunity observed after RNA-based vaccination, particularly for SARS-CoV-2. It posits that an antibody-mediated negative feedback loop limits long-lasting immunity, and its computational simulations reveal that individual immune variability drives a broad distribution of protection times, while also suggesting an optimal 5-week interval for a second vaccine dose.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Immunology</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Computational Biology in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05130v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05130v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05130v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05130v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05106v1"
                     data-domains="Neurology,Ophthalmology,Geriatrics,Medical Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Alzheimer's disease,Optical Coherence Tomography,Deep learning,Early detection,Retina,UK Biobank,Neurodegeneration,Biomarker"
                     data-authors="Yasemin Turkan,F. Boray Tek,M. Serdar Nazlƒ±,√ñyk√º Eren">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05106v1.html">Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yasemin Turkan, F. Boray Tek, M. Serdar Nazlƒ± et al.
                </div>

                <div class="paper-summary">
                    This study pioneers the direct classification of raw retinal OCT B-scan images using deep learning for early Alzheimer's disease (AD) detection, a novel approach for AD prediction. Utilizing data from the UK Biobank, fine-tuned pretrained models like ResNet-34 achieved an AUC of 0.62 for detection within four years of imaging. Explainability analyses confirmed localized structural differences in the central macular subfield, establishing a baseline for this challenging task.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05106v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05106v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05106v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05106v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05089v1"
                     data-domains="physics.med-ph"
                     data-keywords="physics.med-ph,physics.bio-ph"
                     data-authors="Zhiquan Yu,Chenjia Zhao,Lingyun Xiong,Shanshan Su,Dawen Yu,Shilu Zhang,Yubin Ke,Hua Yang,Guo Zhang,Jiaming Sun,Nengqiang Guo,Yuanhao Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05089v1.html">A dispersal recolonisation 3D biofilm in vitro model based on co-assembled peptide amphiphiles and clinical wound fluid</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhiquan Yu, Chenjia Zhao, Lingyun Xiong et al.
                </div>

                <div class="paper-summary">
                    Chronic wound infections are sustained by dynamic 3D biofilm cycles involving
maturation, dispersal, and recolonisation, yet existing in vitro models fail to
reproduce these temporal and structural complexities. Here, we report a
strategy that co-assembles a designed protease-inhibitory peptide amph...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">physics.med-ph</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05089v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05089v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05089v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05089v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05059v1"
                     data-domains="Laparoscopic Surgery,General Surgery,Urology,Minimally Invasive Surgery"
                     data-keywords="Laparoscopic surgery,smoke removal,deep learning,physics-guided model,image enhancement,computer-assisted surgery,SurgiATM,surgical visualization"
                     data-authors="Mingyu Sheng,Jianan Fan,Dongnan Liu,Guoyan Zheng,Ron Kikinis,Weidong Cai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05059v1.html">SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingyu Sheng, Jianan Fan, Dongnan Liu et al.
                </div>

                <div class="paper-summary">
                    SurgiATM is a novel physics-guided, plug-and-play model designed to enhance deep learning-based smoke removal in laparoscopic surgery. It statistically bridges a physics-based atmospheric model with data-driven deep learning, improving the accuracy and stability of existing desmoking architectures without adding trainable weights or significant computational overhead. Extensive experiments demonstrate that SurgiATM consistently reduces restoration errors and enhances the generalizability of various desmoking methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Laparoscopic Surgery</span>
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Minimally Invasive Surgery</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05059v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05059v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05059v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05059v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.05044v1"
                     data-domains="Radiology,Diagnostic Imaging,Oncology (for lesion segmentation),Pulmonology (e.g., COVID-19 related lung imaging),Infectious Diseases"
                     data-keywords="Medical Referring Image Segmentation,MRIS,Autoregressive Models,Next-Token Prediction,Multimodal Learning,Deep Learning,Image Segmentation,Natural Language Processing"
                     data-authors="Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.05044v1.html">Medical Referring Image Segmentation via Next-Token Mask Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinyu Chen, Yiran Wang, Gaoyang Pang et al.
                </div>

                <div class="paper-summary">
                    NTP-MRISeg introduces a novel framework for Medical Referring Image Segmentation (MRIS) by reformulating it as an autoregressive next-token prediction task over a unified multimodal sequence of image, text, and mask representations. This approach significantly streamlines model design, enables end-to-end training leveraging pretrained tokenizers, and achieves new state-of-the-art performance on challenging medical datasets. The framework incorporates advanced strategies to address common issues like exposure bias, long-tail token distributions, and fine-grained edge prediction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (for lesion segmentation)</span>
                    
                    <span class="domain-tag">Pulmonology (e.g., COVID-19 related lung imaging)</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.05044v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.05044v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.05044v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.05044v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04998v1"
                     data-domains="Psychiatry,Addiction Medicine,Mental Health,Primary Care,Preventive Medicine"
                     data-keywords="Transformer,Deep learning,Electronic health records,Risk prediction,Alcohol use disorder,Substance use disorder,Positional embedding,Interpretability,Mental health"
                     data-authors="Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04998v1.html">BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel S. Lee, Mayra S. Haedo-Cruz, Chen Jiang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces BiPETE, a novel Transformer Encoder model designed for single-disease risk prediction from Electronic Health Records (EHRs). BiPETE uniquely integrates dual positional embeddings (rotary for relative timing and sinusoidal for visit order) to effectively model temporal dependencies in irregular EHR data. The model demonstrates significant performance improvements in predicting Alcohol and Substance Use Disorder (ASUD) risk, while offering interpretable insights into key clinical risk and protective factors.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Addiction Medicine</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Primary Care</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04998v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04998v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04998v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04998v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04984v1"
                     data-domains="Drug Discovery,Medicinal Chemistry,Pharmacology,Targeted Therapy,Oncology,Immunology,Infectious Diseases"
                     data-keywords="Peptide mimics,Peptidomimetics,Drug design,Diffusion model,Graph neural network,Protein binding,Small molecule generation,Structure-based drug design"
                     data-authors="Xinheng He,Yijia Zhang,Haowei Lin,Xingang Peng,Xiangzhe Kong,Mingyu Li,Jianzhu Ma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04984v1.html">Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinheng He, Yijia Zhang, Haowei Lin et al.
                </div>

                <div class="paper-summary">
                    Peptide2Mol presents an E(3)-equivariant graph neural network diffusion model designed to generate small molecules that function as peptide mimics for targeted protein binding. By referencing both endogenous peptide binders and their surrounding protein pocket environments, the model aims to improve upon AI-driven drug design by explicitly considering critical protein-peptide interactions. It achieves state-of-the-art generative performance and enables molecule optimization and peptidomimetic design through a partial diffusion process.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Targeted Therapy</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04984v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04984v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04984v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04984v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04983v1"
                     data-domains="Geriatrics,Neurology,Psychiatry,Digital Health,Remote Patient Monitoring"
                     data-keywords="Cognitive assessment,Wearable sensors,Mild cognitive impairment,Dementia,Artificial intelligence,Physiological data,Supervised learning,NIH Toolbox"
                     data-authors="Assma Habadi,Milos Zefran,Lijuan Yin,Woojin Song,Maria Caceres,Elise Hu,Naoko Muramatsu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04983v1.html">Predicting Cognitive Assessment Scores in Older Adults with Cognitive Impairment Using Wearable Sensors</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Assma Habadi, Milos Zefran, Lijuan Yin et al.
                </div>

                <div class="paper-summary">
                    This paper presents an AI-driven methodology to predict cognitive assessment scores in older adults with mild cognitive impairment or mild dementia using continuous physiological data from wearable sensors. By applying supervised learning to features extracted from blood volume pulse, skin conductance, temperature, and movement, the study successfully demonstrated accurate tracking of working memory, processing speed, and attention, significantly outperforming traditional predictors.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04983v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04983v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04983v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04983v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04971v1"
                     data-domains="Cardiology,Diabetology,Preventive Medicine,Public Health,Clinical Decision Support Systems"
                     data-keywords="Cardiovascular Disease,Diabetes,Risk Prediction,Machine Learning,Deep Learning,XGBoost,LSTM,BRFSS,PCA"
                     data-authors="Esha Chowdhury">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04971v1.html">Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Esha Chowdhury
                </div>

                <div class="paper-summary">
                    This study develops efficient machine learning (ML) and hybrid deep learning (DL) models to accurately predict cardiovascular disease (CVD) risk in diabetic patients using the BRFSS dataset. After rigorous preprocessing including PCA, both XGBoost (ML) and LSTM (DL) models achieved the highest accuracy of 0.9050, with some DL models demonstrating perfect recall. The research highlights the potential of these models to automate and enhance clinical decision-making, improving personalized risk management and preventive strategies for diabetic individuals.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Diabetology</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04971v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04971v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04971v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04971v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04963v1"
                     data-domains="Neurology,Neuroimaging,Radiology,Alzheimer's Disease (AD),Mild Cognitive Impairment (MCI)"
                     data-keywords="fMRI,dMRI,Modality Completion,Diffusion Models,Neurodegenerative Diseases,Image Synthesis,Deep Learning,Neuroimaging"
                     data-authors="Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04963v1.html">Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiongri Shen, Jiaqi Wang, Yi Zhong et al.
                </div>

                <div class="paper-summary">
                    This paper introduces PDS, a novel pattern-aware dual-modal 3D diffusion framework with tissue and microstructure refinement for synthesizing fMRI and dMRI data. PDS addresses limitations of previous generative models by effectively handling signal differences and integrating disease-related neuroanatomical patterns. The method achieves state-of-the-art synthesis quality and demonstrates strong diagnostic performance in classifying neurodegenerative diseases using the generated data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Alzheimer's Disease (AD)</span>
                    
                    <span class="domain-tag">Mild Cognitive Impairment (MCI)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04963v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04963v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04963v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04963v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04957v1"
                     data-domains="Clinical trials,personalized medicine,public health epidemiology,diagnostic imaging,bioinformatics,pharmacogenomics,disease prediction"
                     data-keywords="Split-sample inference,predictive modeling,Central Limit Theorem,statistical dependence,reproducibility,machine learning,heterogeneous treatment effects,model comparison"
                     data-authors="Bruno Fava">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04957v1.html">Training and Testing with Multiple Splits: A Central Limit Theorem for Split-Sample Estimators</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ econ.EM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bruno Fava
                </div>

                <div class="paper-summary">
                    This paper addresses the challenges of split-sample inference in predictive modeling, particularly the issues of data underutilization and variability across different data splits. It introduces a novel inference approach based on averaging across multiple splits, backed by a new Central Limit Theorem that accounts for statistical dependence arising from observation reuse. The method improves reproducibility, utilizes more data, and demonstrates increased statistical power, especially for complex comparisons like evaluating two models.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical trials</span>
                    
                    <span class="domain-tag">personalized medicine</span>
                    
                    <span class="domain-tag">public health epidemiology</span>
                    
                    <span class="domain-tag">diagnostic imaging</span>
                    
                    <span class="domain-tag">bioinformatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04957v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04957v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04957v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04957v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04948v1"
                     data-domains="Dentistry,Oral and Maxillofacial Radiology,Medical Informatics,Computational Medicine"
                     data-keywords="multimodal dataset,oro-dental,dentistry,AI in healthcare,vision-language models,dental diagnostics,radiographs,intraoral images"
                     data-authors="Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04948v1.html">A benchmark multimodal oro-dental dataset for large vision-language models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Haoxin Lv, Ijazul Haq, Jin Du et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, comprehensive multimodal oro-dental dataset derived from 8775 dental checkups, integrating intraoral images, radiographs, and detailed textual records. The dataset was utilized to fine-tune state-of-the-art large vision-language models (Qwen-VL 3B/7B), which subsequently achieved substantial performance gains in oro-dental anomaly classification and diagnostic report generation compared to baseline models and GPT-4o.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Oral and Maxillofacial Radiology</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04948v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04948v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04948v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04948v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04892v1"
                     data-domains="Pathology,Oncology,Histology,Diagnostic Imaging,Computational Pathology"
                     data-keywords="Nuclei segmentation,Self-supervised learning,Histology image analysis,Digital pathology,Cancer diagnosis,Deep learning,Medical image processing,Explainable AI"
                     data-authors="Vasileios Magoulianitis,Catherine A. Alexander,Jiaxin Yang,C. -C. Jay Kuo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04892v1.html">LG-NuSegHop: A Local-to-Global Self-Supervised Pipeline For Nuclei Instance Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-07</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vasileios Magoulianitis, Catherine A. Alexander, Jiaxin Yang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces LG-NuSegHop, a novel local-to-global self-supervised pipeline designed for nuclei instance segmentation in histology images, a critical task for disease diagnosis. It addresses the challenges of high nuclei variability and the prohibitive cost of manual data annotation by operating entirely without manually labeled training data or domain adaptation. The pipeline achieves strong generalization and competitive performance against supervised methods while being fully transparent.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04892v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04892v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04892v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04892v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04872v1"
                     data-domains="Otolaryngology,Diagnostic Imaging,Artificial Intelligence in Medicine"
                     data-keywords="Vision Transformers,Swin Transformers,Otoscopy,Ear Diseases,Diagnostic Accuracy,Data Leakage,Machine Learning,Medical Imaging"
                     data-authors="James Ndubuisi,Fernando Auat,Marta Vallejo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04872v1.html">Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> James Ndubuisi, Fernando Auat, Marta Vallejo
                </div>

                <div class="paper-summary">
                    This study evaluated Vision Transformers (Swin v1/v2) against ResNet for diagnosing ear diseases from otoscopic videos, initially reporting exceptionally high accuracies (up to 100%). However, a critical data leakage issue was subsequently identified in the preprocessing pipeline, leading to a significant drop in corrected model performance (82-83% accuracy) across all models, underscoring the paramount importance of rigorous data handling in medical AI development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Otolaryngology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04872v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04872v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04872v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04872v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04871v1"
                     data-domains="Neurology,Neuroscience,Neuroimaging,Radiology,Neurodegenerative Disorders"
                     data-keywords="Diffusion-weighted MRI,DW-MRI,harmonization,scanner bias,Clinical-ComBAT,neurodegenerative diseases,white matter,normative modeling,multi-site data"
                     data-authors="Gabriel Girard,Manon Edde,F√©lix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Bor√©,Maxime Descoteaux,Pierre-Marc Jodoin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04871v1.html">Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Gabriel Girard, Manon Edde, F√©lix Dumais et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Clinical-ComBAT, a novel harmonization method for diffusion-weighted magnetic resonance imaging (DW-MRI) data, specifically designed to address scanner-specific biases in real-world clinical applications. It overcomes the limitations of existing methods like ComBAT by enabling independent, non-linear harmonization of sites, making multi-site data more reliable for assessing neurodegenerative diseases and white matter properties. The method demonstrates improved alignment of diffusion metrics and enhanced applicability for normative modeling on simulated and real data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neurodegenerative Disorders</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04871v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04871v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04871v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04871v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04854v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Development,Structural Biology,Pharmaceutical Research"
                     data-keywords="molecular docking,drug discovery,SE(3) diffusion,deep learning,fragment-based,pose prediction,generative models,protein-ligand binding"
                     data-authors="Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04854v1.html">SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alvaro Prat, Leo Zhang, Charlotte M. Deane et al.
                </div>

                <div class="paper-summary">
                    SigmaDock introduces a novel SE(3) Riemannian diffusion model for molecular docking that decomposes ligands into rigid-body fragments and learns to reassemble them within a protein binding pocket. This fragment-based approach achieves state-of-the-art performance, with over 79.9% Top-1 success rates on the PoseBusters set, significantly outperforming other deep learning methods. Crucially, SigmaDock is the first deep learning model to surpass classical physics-based docking methods, marking a significant leap in the reliability and feasibility of AI for molecular modeling.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04854v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04854v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04854v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04854v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04789v1"
                     data-domains="Neurology,Neuroscience,Medical Imaging,Computational Medicine,Precision Medicine"
                     data-keywords="Parkinson's Disease,Neural ODE,Longitudinal Forecasting,MRI,Heterogeneity,Digital Twin,Disease Progression,Machine Learning"
                     data-authors="Xiaoda Wang,Yuji Zhao,Kaiqiao Han,Xiao Luo,Sanne van Rooij,Jennifer Stevens,Lifang He,Liang Zhan,Yizhou Sun,Wei Wang,Carl Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04789v1.html">Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoda Wang, Yuji Zhao, Kaiqiao Han et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CNODE (Conditional Neural ODE), a novel framework designed to forecast the continuous and individualized progression of Parkinson's disease (PD). It addresses the limitations of existing methods, such as recurrent neural networks and transformers, which struggle with irregular/sparse MRI data and the inherent patient heterogeneity in PD progression. CNODE leverages neural ordinary differential equations to model brain morphological changes as continuous temporal processes, enhancing individualized forecasting by learning patient-specific initial times and progression speeds.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04789v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04789v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04789v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04789v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04655v1"
                     data-domains="Diagnostic Imaging,Computational Pathology,Medical AI Development,Clinical Decision Support Systems,Radiology"
                     data-keywords="MLLMs,Benchmark Bias,Visual Understanding,Diagnostic AI,Test-set Stress-Test,Iterative Bias Pruning,Robustness,Medical Imaging AI"
                     data-authors="Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04655v1.html">Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ellis Brown, Jihan Yang, Shusheng Yang et al.
                </div>

                <div class="paper-summary">
                    This research reveals that Multimodal Large Language Models (MLLMs) can exploit non-visual shortcuts, linguistic priors, and superficial patterns to achieve high performance on benchmarks, even those meant to require strong visual understanding. The paper introduces a diagnostic framework, comprising a "Test-set Stress-Test" (TsT) and "Iterative Bias Pruning" (IBP), to systematically identify and mitigate these biases, creating more robust and truly vision-centric benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Medical AI Development</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04637v1"
                     data-domains="neurodevelopmental disorders,psychiatric disorders,cancer,aging"
                     data-keywords="risk gene discovery,allele frequency,genetic variants,missing middle,variant annotation,joint modeling,phenotype refinement,network inference"
                     data-authors="Madison Caballero,Behrang Mahjani">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04637v1.html">Advancing Risk Gene Discovery Across the Allele Frequency Spectrum</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.GN</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Madison Caballero, Behrang Mahjani
                </div>

                <div class="paper-summary">
                    This review addresses the slowdown in genetic risk factor discovery, focusing on the 'missing middle' of variants with intermediate allele frequency and effect size, which are overlooked by current methods optimized for rare or common variants. It proposes and organizes strategies, including innovations in variant annotation, joint modeling, phenotype refinement, and network-based inference, to extend gene discovery into this critical, under-explored spectrum. The paper aims to provide a conceptual framework for comprehensive risk gene identification across various diseases.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">neurodevelopmental disorders</span>
                    
                    <span class="domain-tag">psychiatric disorders</span>
                    
                    <span class="domain-tag">cancer</span>
                    
                    <span class="domain-tag">aging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04637v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04637v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04637v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04637v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04729v1"
                     data-domains="Radiology,Breast Imaging,Medical Artificial Intelligence,Diagnostic Imaging"
                     data-keywords="Synthetic data,Anomaly detection,Shape artifacts,Medical imaging,Mammography,Deep learning,Image quality,AI explainability"
                     data-authors="Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04729v1.html">Knowledge-based anomaly detection for identifying network-induced shape artifacts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rucha Deshpande, Tahsin Rahman, Miguel Lago et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel knowledge-based anomaly detection method to identify network-induced shape artifacts in synthetic medical images, crucial for ensuring data quality in AI model training. It utilizes a two-stage framework involving a specialized feature extractor analyzing angle gradients along anatomical boundaries and an isolation forest anomaly detector. The method demonstrates high effectiveness and agreement with human experts on synthetic mammography datasets, advancing the responsible use of synthetic data in medical AI.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Breast Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04729v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04729v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04729v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04729v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04619v1"
                     data-domains="Neurology,Neurodegeneration,Geriatric Medicine,Biomarker Research,Computational Neuroscience"
                     data-keywords="Alzheimer's disease,causal discovery,pseudotime,latent variable model,dynamic interactions,biomarkers,NfL,GFAP,disease progression,computational biology"
                     data-authors="Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04619v1.html">Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ stat.AP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Natalia Glazman, Jyoti Mangal, Pedro Borges et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the limitations of static causal discovery methods in analyzing dynamic diseases like Alzheimer's (AD) by proposing a latent pseudotime model. This model infers a data-driven disease trajectory, enabling the discovery of evolving causal relationships between AD markers. The pseudotime significantly outperforms chronological age in predicting AD diagnosis and benefits from integrating background knowledge to reveal dynamic interactions among novel and established biomarkers.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurodegeneration</span>
                    
                    <span class="domain-tag">Geriatric Medicine</span>
                    
                    <span class="domain-tag">Biomarker Research</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04574v1"
                     data-domains="Infectious Disease Epidemiology,Public Health,Mathematical Epidemiology,Virology"
                     data-keywords="Reproduction numbers,R0,Rt,COVID-19,Serial interval,Presymptomatic transmission,Lotka-Euler equation,Gaussian distribution"
                     data-authors="Derek Marsh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04574v1.html">Reproduction Numbers R_0, R_t for COVID-19 Infections with Gaussian Distribution of Generation Times, and of Serial Intervals including Presymptomatic Transmission</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Derek Marsh
                </div>

                <div class="paper-summary">
                    This paper addresses a critical inconsistency in calculating COVID-19 reproduction numbers (R0, Rt) when accounting for presymptomatic transmission. It highlights that common applications of the Lotka-Euler equation with Gaussian-distributed serial intervals extending to negative infinity can underestimate R values compared to the renewal equation. The work proposes and formulates a corrected Lotka-Euler equation that incorporates an explicit lower cut-off for these serial interval distributions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Mathematical Epidemiology</span>
                    
                    <span class="domain-tag">Virology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04726v1"
                     data-domains="Ophthalmology,Glaucoma Research,Biomechanics,Neuro-ophthalmology"
                     data-keywords="Glaucoma,Lamina Cribrosa,Intraocular Pressure,Poroelasticity,Anisotropy,Biomechanics,Retinal Ganglion Cells,Ischemia"
                     data-authors="Riccardo Cavuoto,Sofia Damian,Luca Deseri,Massimiliano Fraldi,Alon Harris,Brent Siesky,Alice Verticchio,Giovanna Guidoboni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04726v1.html">Stresses and fluid flow in lamina cribrosa through anisotropic poroelasticty</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.flu-dyn</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riccardo Cavuoto, Sofia Damian, Luca Deseri et al.
                </div>

                <div class="paper-summary">
                    This study presents a transversely isotropic poroelastic model of the Lamina Cribrosa (LC), based on Reissner-Mindlin plate theory, to explore the mechanical correlations between intraocular pressure (IOP) variations and glaucoma. The model demonstrates that increasing IOP leads to peak strains and stresses in the peripheral LC, a known site of glaucomatous damage, and predicts a reduction in fluid content that could contribute to ischemia.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Glaucoma Research</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                    <span class="domain-tag">Neuro-ophthalmology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04726v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04726v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04726v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04726v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04557v1"
                     data-domains="Clinical Decision Support,Electronic Health Records (EHR) Analysis,Disease Progression Modeling,Personalized Medicine,Healthcare Analytics,Patient Risk Stratification"
                     data-keywords="Graph Transformers,Relational Deep Learning,Temporal Graphs,Multi-Task Learning,Latent Bottleneck,Cross-Attention,Healthcare AI,Patient Journeys"
                     data-authors="Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04557v1.html">Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Divyansha Lachi, Mahmoud Mohammadi, Joe Meyer et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Relational Graph Perceiver (RGP), a novel graph transformer architecture designed to overcome limitations of existing models by integrating both long-range temporal and structural dependencies in relational data. RGP achieves this through a temporal subgraph sampler and a cross-attention-based latent bottleneck that unifies diverse entity signals, enabling state-of-the-art performance on complex multi-task prediction problems across domains like healthcare. It provides a general and scalable solution for relational deep learning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Analysis</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Healthcare Analytics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04557v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04557v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04557v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04557v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04556v1"
                     data-domains="Environmental Health,Public Health,Disaster Preparedness,Epidemiology (indirectly, for flood-related disease surveillance)"
                     data-keywords="Urban flooding,Stormwater management,Sensor placement,Sparse sensing,Data-driven,EPA-SWMM,Peak flowrate,Flood prediction,Artificial Intelligence"
                     data-authors="Zihang Ding,Kun Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04556v1.html">Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zihang Ding, Kun Zhang
                </div>

                <div class="paper-summary">
                    This study presents a Data-Driven Sparse Sensing (DSS) framework, integrated with the EPA-SWMM model, to optimize sensor placement and accurately reconstruct peak flowrates in urban stormwater systems using minimal resources. Applied to a real-world catchment, the framework demonstrated that only three optimally placed sensors among 77 nodes could achieve high-accuracy flowrate reconstruction (NSE 0.92-0.95) and good robustness to measurement uncertainty, addressing a critical challenge in flood monitoring under practical constraints.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Disaster Preparedness</span>
                    
                    <span class="domain-tag">Epidemiology (indirectly, for flood-related disease surveillance)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04556v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04556v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04556v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04556v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04525v1"
                     data-domains="General Surgery,Laparoscopic Surgery,Surgical Training,Medical Imaging,AI in Healthcare"
                     data-keywords="Laparoscopic Cholecystectomy,Surgical Complexity,Parkland Grading Scale,Deep Learning,Weak Supervision,Temporal Localization,Surgical Video Analysis,Artificial Intelligence in Surgery"
                     data-authors="Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04525v1.html">Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios Anastasiou, Santiago Barbarisi, Lucy Culshaw et al.
                </div>

                <div class="paper-summary">
                    This paper introduces STC-Net, a novel deep learning framework for automated surgical complexity estimation in Laparoscopic Cholecystectomy (LC) using the Parkland Grading Scale (PGS). Operating directly on full surgical videos with weak temporal supervision, STC-Net jointly performs temporal localization and grading, achieving 62.11% accuracy and 61.42% F1-score, significantly outperforming non-localized baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">General Surgery</span>
                    
                    <span class="domain-tag">Laparoscopic Surgery</span>
                    
                    <span class="domain-tag">Surgical Training</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">AI in Healthcare</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04525v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04525v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04525v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04525v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04506v1"
                     data-domains="Radiology,Diagnostic Imaging,Clinical Decision Support,Medical Informatics,Pulmonology"
                     data-keywords="radiology reports,clinical uncertainty,explicit uncertainty,implicit uncertainty,large language models,diagnostic pathways,medical NLP,image classification"
                     data-authors="Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04506v1.html">Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paloma Rabaey, Jong Hak Moon, Jung-Oh Lee et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, two-part framework to systematically model both explicit and implicit clinical uncertainty found in radiology reports. It quantifies explicit uncertainty by assigning probability values to findings based on an expert-validated, LLM-based ranking of hedging phrases, and models implicit uncertainty by expanding reports with characteristic sub-findings derived from expert-defined diagnostic pathways. The culmination is Lunguage++, an uncertainty-aware benchmark for enhanced automated analysis and research into diagnostic uncertainty.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04506v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04506v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04506v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04506v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04476v1"
                     data-domains="Psychiatry,Mental Health,Clinical Psychology"
                     data-keywords="Depression detection,PHQ-8,Time series analysis,Natural language processing,Deep learning,Uncertainty estimation,Clinical decision support,Probabilistic modeling"
                     data-authors="Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04476v1.html">Probabilistic Textual Time Series Depression Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fabian Schmidt, Seyedehmoniba Ravan, Vladimir Vlassov
                </div>

                <div class="paper-summary">
                    This paper introduces PTTSD (Probabilistic Textual Time Series Depression Detection), a novel framework for predicting PHQ-8 depression severity scores from utterance-level clinical interviews. PTTSD uniquely models uncertainty over time, achieving state-of-the-art performance among text-only systems on E-DAIC and DAIC-WOZ datasets while providing well-calibrated prediction intervals essential for clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Clinical Psychology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04476v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04476v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04476v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04476v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04458v1"
                     data-domains="Oncology,Neurology,Medical Imaging,Biostatistics,Diagnostic Imaging"
                     data-keywords="PET imaging,Preprocessing,Statistical modeling,TRAECR,Alzheimer's disease,Cancer,Image harmonization,Image registration"
                     data-authors="Akhil Ambekar,Robert Zielinski,Ani Eloyan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04458v1.html">TRAECR: A Tool for Preprocessing Positron Emission Tomography Imaging for Statistical Modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Akhil Ambekar, Robert Zielinski, Ani Eloyan
                </div>

                <div class="paper-summary">
                    This paper introduces TRAECR, a novel preprocessing and visualization tool designed to prepare Positron Emission Tomography (PET) imaging data for statistical analysis. TRAECR aims to facilitate the development of advanced statistical models by providing statisticians with essential tools for data harmonization and registration, addressing critical research questions in diseases like cancer and Alzheimer's disease.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04458v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04458v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04458v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04458v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04334v1"
                     data-domains="Radiology,Oncology,Urology,Diagnostic Imaging"
                     data-keywords="Automated Segmentation,3D Segmentation,Kidney Tumors,Computed Tomography,Submanifold Sparse Convolutional Networks,Voxel Sparsification,Renal Cancer,Medical Imaging"
                     data-authors="Sa√∫l Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04334v1.html">Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sa√∫l Alonso-Monsalve, Leigh H. Whitehead, Adam Aurisano et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel two-stage methodology utilizing voxel sparsification and submanifold sparse convolutional networks for automated 3D segmentation of kidneys and kidney tumors in Computed Tomography (CT) scans. The method achieves state-of-the-art accuracy, competitive with challenge winners, yielding high Dice similarity coefficients. Crucially, it significantly reduces computational resource requirements, demonstrating up to a 60% reduction in inference time and 75% reduction in VRAM usage compared to equivalent dense architectures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04334v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04334v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04334v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04334v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04333v1"
                     data-domains="Intensive Care,Critical Care Medicine,Longitudinal Patient Monitoring,Clinical Decision Support Systems"
                     data-keywords="Dynamic Bayesian Networks,Missing Data Imputation,Full Bayesian Inference,Gibbs Sampling,Intensive Care,Temporal Modeling,Uncertainty Quantification,Clinical Decision Support"
                     data-authors="Federico Pirola,Fabio Stella,Marco Grzegorczyk">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04333v1.html">LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Federico Pirola, Fabio Stella, Marco Grzegorczyk
                </div>

                <div class="paper-summary">
                    The paper introduces LUME-DBN, a novel Gibbs sampling-based method for full Bayesian learning of Dynamic Bayesian Networks (DBNs) from incomplete longitudinal patient data, specifically addressing the gap in existing approaches that fail to account for the temporal nature of missing values. This approach treats missing data as unknown Gaussian parameters, enabling principled imputation and uncertainty estimation, and demonstrates superior reconstruction accuracy and convergence compared to standard model-agnostic techniques like MICE on real-world intensive care data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Longitudinal Patient Monitoring</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04328v1"
                     data-domains="Pharmacology,Clinical Informatics,Medical AI,Patient Safety,Clinical Pharmacy,Drug Discovery"
                     data-keywords="Medication Safety,Large Language Models,Clinical Decision Support,Drug Interactions,Contraindications,Benchmark,Simulated Consultation,Healthcare AI"
                     data-authors="Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04328v1.html">RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiahao Zhao, Luxin Xu, Minghuan Tan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces RxSafeBench, a novel benchmark framework designed to evaluate the medication safety capabilities of Large Language Models (LLMs) in simulated clinical consultations. It addresses the scarcity of real-world data by generating realistic patient dialogues with embedded medication risks, backed by a comprehensive RxRisk DB. The study reveals that current LLMs struggle significantly with integrating contraindication and drug interaction knowledge, especially when risks are implicitly presented, highlighting critical areas for improving AI-driven clinical decision support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Clinical Pharmacy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04328v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04328v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04328v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04328v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04276v1"
                     data-domains="Infectious Diseases,Epidemiology,Public Health,Medical Entomology,Virology"
                     data-keywords="Dengue,Vector competence,Aedes mosquito,Predator-prey model,Disease persistence,Transmission dynamics,Innate immunity,Vector control"
                     data-authors="Piyumi Chathurangika,Tharushika Peiris,Lakmini S. Premadasa,S. S. N. Perera,Kushani De Silva">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04276v1.html">Vector Traits Shape Disease Persistence: A Predator Prey Approach to Dengue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Piyumi Chathurangika, Tharushika Peiris, Lakmini S. Premadasa et al.
                </div>

                <div class="paper-summary">
                    This study employs a predator-prey mathematical framework to model Aedes mosquito-dengue virus interactions, identifying vector competence (vc) as a critical driver of disease persistence. It demonstrates that while endemic conditions are globally stable, the vector's innate immune system is overwhelmed by high vc in tropical/subtropical environments, revealing an evolutionary trade-off that limits immune enhancement and drives transmission instability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Medical Entomology</span>
                    
                    <span class="domain-tag">Virology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04276v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04276v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04276v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04276v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04255v1"
                     data-domains="Medical Imaging,Radiology,Orthopedics,Dentistry,Computer-Aided Diagnosis,Surgical Planning"
                     data-keywords="Medical Imaging,Anatomical Landmark Detection,Foundation Models,Human-Centric AI,Pose Estimation,Deep Learning,State-of-the-Art,Few-Shot Learning"
                     data-authors="Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04255v1.html">MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Marawan Elbatel, Anbang Wang, Keyuan Liu et al.
                </div>

                <div class="paper-summary">
                    This paper re-examines the adaptation of human-centric foundation models for anatomical landmark detection in medical imaging, challenging the traditional reliance on domain-specific models. By adapting Sapiens, a human pose estimation model, through multi-dataset pretraining, the proposed MedSapiens model establishes a new state of the art, demonstrating that these models provide strong and underexploited priors for medical landmark localization.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Computer-Aided Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04255v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04255v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04255v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04255v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04720v1"
                     data-domains="Neurology,Radiology,Diagnostic Imaging,Rare Disease Medicine"
                     data-keywords="Retrieval-Augmented Generation,Rare Diseases,Medical Imaging,Brain MRI,Diagnostic Reasoning,AI Agents,Interpretability,Large Language Models"
                     data-authors="Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04720v1.html">Learning to reason about rare diseases through retrieval-augmented agents</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ha Young Kim, Jun Li, Ana Beatriz Solana et al.
                </div>

                <div class="paper-summary">
                    RADAR (Retrieval Augmented Diagnostic Reasoning Agents) is an agentic AI system designed to improve rare disease detection in brain MRI, specifically addressing the challenges of data scarcity. It enhances diagnostic decision-making by enabling AI agents to access and retrieve clinically relevant evidence from external medical knowledge sources like case reports and literature. This model-agnostic system achieved up to a 10.2% performance gain on 280 distinct rare diseases in the NOVA dataset, particularly benefiting open-source language models, while also providing interpretable, literature-grounded explanations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Rare Disease Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04720v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04720v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04720v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04720v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04718v1"
                     data-domains="Neurology,Psychiatry,Neuroimaging,Diagnostic Imaging,Computational Neuroscience"
                     data-keywords="fMRI,Brain Disorder Classification,Multi-frequency Analysis,Adaptive Frequency Decomposition,Functional Connectivity,Graph Neural Networks,Alzheimer's Disease,Autism Spectrum Disorder"
                     data-authors="Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04718v1.html">Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yue Xun, Jiaxing Xu, Wenbo Gao et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Ada-FCN, an Adaptive Frequency-Coupled Network, designed to improve fMRI-based brain disorder classification by explicitly addressing the multi-frequency nature of neuronal oscillations. It adaptively learns task-relevant frequency sub-bands for each brain region and constructs a unified functional connectivity network that captures both intra- and nuanced cross-band interactions, leading to superior diagnostic performance on ADNI and ABIDE datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04718v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04718v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04718v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04718v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04190v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Image Analysis,Digital Pathology (potential)"
                     data-keywords="Covariance descriptors,Riemannian deep learning,Medical image classification,SPDNet,General Vision Encoders,DINOv2,MedSAM,Second-order statistics,MedMNSIT"
                     data-authors="Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04190v1.html">Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Josef Mayr, Anna Reithmeir, Maxime Di Folco et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the effectiveness of covariance descriptors, particularly when derived from features of pre-trained General Vision Encoders (GVEs) like DINOv2 and MedSAM, for medical image classification. It demonstrates that these GVE-based descriptors, especially in conjunction with the SPDNet architecture, consistently outperform handcrafted features and achieve superior performance compared to state-of-the-art methods on the MedMNSIT benchmark. The findings highlight a promising paradigm for enhancing medical image analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                    <span class="domain-tag">Digital Pathology (potential)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04190v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04190v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04190v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04190v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.04174v1"
                     data-domains="Neurology,Neurodegenerative Diseases,Molecular Medicine,Pharmacology"
                     data-keywords="Huntington's disease,protein aggregation,polyglutamine,neuronal death,hydrogen bonding,covalent bonding,transglutaminase,therapeutic targets"
                     data-authors="Guylaine Hoffner,Philippe Djian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.04174v1.html">Protein aggregation in Huntington's disease</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-06</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guylaine Hoffner, Philippe Djian
                </div>

                <div class="paper-summary">
                    This paper investigates protein aggregation mechanisms in Huntington's disease (HD), where an expanded polyglutamine (polyQ) tract in huntingtin causes a toxic gain of function leading to neuronal death. It outlines two proposed aggregation mechanisms ‚Äì hydrogen bonding (polar-zipper) and transglutaminase-catalyzed covalent cross-linking ‚Äì noting that while cell culture models show aggregates primarily stabilized by hydrogen bonds, the nature of these bonds in the brains of HD patients remains unknown and is critical for informing therapeutic strategies.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                    <span class="domain-tag">Molecular Medicine</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.04174v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.04174v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2511.04174v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.04174v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-10 06:28:48</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>