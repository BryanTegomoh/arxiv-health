<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Health AI Hub</h1>
            <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">16</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">16</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">66</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (5), Pharmacology (3), Pathology (3)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (5)</option>
                        
                        <option value="Pharmacology">Pharmacology (3)</option>
                        
                        <option value="Clinical Informatics">Clinical Informatics (3)</option>
                        
                        <option value="Pathology">Pathology (3)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (2)</option>
                        
                        <option value="Radiology">Radiology (2)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (2)</option>
                        
                        <option value="Public Health">Public Health (2)</option>
                        
                        <option value="Pharmacovigilance">Pharmacovigilance (2)</option>
                        
                        <option value="Computational Chemistry">Computational Chemistry (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2510.20792v1"
                     data-domains="Drug Discovery,Computational Chemistry,Bioinformatics,Pharmacology,Medicinal Chemistry,AI in Healthcare"
                     data-keywords="backdoor attack,latent diffusion models,text-guided graph generation,drug discovery,molecular design,AI security,data poisoning,subgraph generation"
                     data-authors="Liang Ye,Shengqin Chen,Jiazhu Dai">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20792v1.html">BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Liang Ye, Shengqin Chen, Jiazhu Dai
                </div>

                <div class="paper-summary">
                    This paper introduces BadGraph, a novel backdoor attack method targeting latent diffusion models used for text-guided graph generation. By poisoning training data with textual triggers, BadGraph covertly implants vulnerabilities that compel the model to generate attacker-specified subgraphs during inference when triggers are present, while maintaining normal performance on clean inputs. The research demonstrates high attack success rates with low poisoning rates, highlighting significant security risks for applications like drug discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Chemistry</span>
                    
                    <span class="domain-tag">Bioinformatics</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20792v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20792v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20792v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20792v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20788v1"
                     data-domains="Structural Biology,Computational Biology,Pharmacology,Drug Discovery,Oncology,Infectious Diseases"
                     data-keywords="Protein-nucleic acid flexibility,B-factor prediction,Persistent Sheaf Laplacian,Multiscale analysis,Algebraic topology,Biomolecular dynamics,Drug design,Gaussian Network Model"
                     data-authors="Nicole Hayes,Ekaterina Merkurjev,Guo-Wei Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20788v1.html">Predicting Protein-Nucleic Acid Flexibility Using Persistent Sheaf Laplacians</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ q-bio.BM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nicole Hayes, Ekaterina Merkurjev, Guo-Wei Wei
                </div>

                <div class="paper-summary">
                    This paper introduces the Persistent Sheaf Laplacian (PSL) framework for accurately predicting atomic B-factors, which characterize the flexibility of protein-nucleic acid complexes. Integrating multiscale analysis, algebraic topology, and sheaf theory, PSL significantly outperforms traditional and existing multiscale models in capturing complex biomolecular interactions. The method achieved up to a 21% improvement in Pearson correlation coefficient for B-factor prediction, highlighting its robustness and potential for broader applications in structural biology and drug design.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20788v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20788v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20788v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20788v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20764v1"
                     data-domains="Neurosurgery,Orthopedics,Biomedical Engineering,Traumatology"
                     data-keywords="Acoustic Emission,bone failure,skull fracture,neurosurgery,predictive analytics,microcrack coalescence,quasi-brittle materials,material mechanics"
                     data-authors="Andrew P. Bunger,Yunxing Lu,Ayyaz Mustafa,Michael M. McDowell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20764v1.html">Acoustic Emission Cascade Predicting Progression to Failure of Rock and Bone</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Andrew P. Bunger, Yunxing Lu, Ayyaz Mustafa et al.
                </div>

                <div class="paper-summary">
                    This paper identifies an "Acoustic Emission (AE) cascade" as a reliable predictor of impending failure in quasi-brittle materials like rock and bone. By monitoring the inverse AE energy rate, the study demonstrates that this cascade provides a crucial warning period before material fracture, with significant implications for preventing patient injury in medical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurosurgery</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                    <span class="domain-tag">Traumatology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20764v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20764v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20764v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20764v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20754v1"
                     data-domains="Pathology,Oncology,Histology,Digital Pathology,Diagnostic Medicine"
                     data-keywords="Deep Learning,Histopathology,Image Segmentation,Semantic Segmentation,Attention Mechanisms,Convolutional Neural Networks,Vision Transformers,Computer-Aided Diagnosis"
                     data-authors="Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20754v1.html">ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nima Torbati, Anastasia Meshcheryakova, Ramona Woitek et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ACS-SegNet, a novel attention-based deep learning model designed for precise semantic tissue segmentation in histopathological images. By integrating convolutional neural networks (CNNs) and vision transformers (ViTs) with attention-driven feature fusion within a dual-encoder architecture, the model achieved superior performance. Evaluated on two public datasets (GCPS and PUMA), ACS-SegNet outperformed state-of-the-art benchmarks, offering a significant advancement for automated image analysis in computer-aided diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20754v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20754v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20754v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20754v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20743v1"
                     data-domains="telemedicine,mental health support,patient education,clinical decision support (patient-facing),elderly care,rehabilitation"
                     data-keywords="multimodal LLM,empathic prompting,non-verbal cues,facial expression recognition,human-AI interaction,affective computing,healthcare AI,conversational AI"
                     data-authors="Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20743v1.html">Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Lorenzo Stacchio, Andrea Ubaldi, Alessandro Galdelli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces "Empathic Prompting," a novel framework that enhances multimodal human-AI interaction by integrating implicit non-verbal emotional cues into Large Language Model (LLM) conversations. The system uses a facial expression recognition service to capture user emotions and embeds this affective information as contextual signals during LLM prompting, aiming for more fluid and contextually aligned dialogues without explicit user control. A preliminary evaluation (N=5) demonstrated consistent integration of non-verbal input into coherent LLM outputs and improved conversational fluidity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">telemedicine</span>
                    
                    <span class="domain-tag">mental health support</span>
                    
                    <span class="domain-tag">patient education</span>
                    
                    <span class="domain-tag">clinical decision support (patient-facing)</span>
                    
                    <span class="domain-tag">elderly care</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20743v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20743v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20743v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20743v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20727v1"
                     data-domains="Oncology,Pharmacology,Clinical Informatics,Pharmacovigilance,Toxicology"
                     data-keywords="Fluoropyrimidine,Toxicity,Natural Language Processing,Large Language Models,Clinical Notes,Oncology,Pharmacovigilance,Deep Learning"
                     data-authors="Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20727v1.html">Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xizhi Wu, Madeline S. Kreider, Philip E. Empey et al.
                </div>

                <div class="paper-summary">
                    This research developed and evaluated various Natural Language Processing (NLP) methods to automatically extract fluoropyrimidine treatment and associated toxicity information from unstructured clinical notes. The study found that Large Language Model (LLM)-based approaches, particularly with error-analysis prompting, significantly outperformed traditional machine learning, deep learning, and rule-based methods, achieving perfect F1 scores for both treatment and toxicity extraction.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20727v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20727v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20727v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20727v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20714v1"
                     data-domains="hospital medicine,patient safety,nursing informatics,clinical decision support,preventive medicine,quality improvement"
                     data-keywords="fall risk prediction,Johns Hopkins Fall Risk Assessment Tool,EHR,constrained score optimization,machine learning,patient safety,inpatient care,AUC-ROC"
                     data-authors="Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20714v1.html">Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fardin Ganjkhanloo, Emmett Springer, Erik H. Hoyer et al.
                </div>

                <div class="paper-summary">
                    This study optimized the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) by integrating additional Electronic Health Record (EHR) variables using a data-driven Constrained Score Optimization (CSO) modeling approach. Analyzing over 54,000 inpatient admissions, the CSO model significantly improved fall risk prediction (AUC-ROC 0.91) compared to the standard JHFRAT (AUC-ROC 0.86). This robust methodology offers a stronger foundation for health systems to enhance inpatient fall prevention protocols and improve patient safety.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">hospital medicine</span>
                    
                    <span class="domain-tag">patient safety</span>
                    
                    <span class="domain-tag">nursing informatics</span>
                    
                    <span class="domain-tag">clinical decision support</span>
                    
                    <span class="domain-tag">preventive medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20714v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20714v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20714v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20714v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20696v1"
                     data-domains="Radiology,Pathology,Dermatology,Ophthalmology,Diagnostic Imaging,Oncology (for image interpretation),Medical Robotics (for visual perception)"
                     data-keywords="multimodal large language models,visual reasoning,visual hallucinations,agent-based architecture,medical imaging,diagnostic AI,chain-of-thought,AI reliability"
                     data-authors="Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20696v1.html">Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jing Bi, Guangyu Sun, Ali Vosoughi et al.
                </div>

                <div class="paper-summary">
                    Multimodal large language models (MLLMs) struggle with visual hallucinations and an over-reliance on textual priors when performing complex visual reasoning tasks. This paper addresses these issues by systematically diagnosing existing MLLMs and proposing an agent-based architecture that combines LLM reasoning with lightweight visual modules for iterative refinement. The new system achieves significant performance gains on benchmarks, matching or surpassing much larger models, highlighting the need for integrating specialized visual tools.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20696v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20696v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20696v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20696v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20671v1"
                     data-domains="Addiction Medicine,Psychiatry,Healthcare Management,Public Health,Clinical Informatics"
                     data-keywords="Addiction Care,Locus of Care,Graph Neural Networks,Class Imbalance,Structured Learning,Resource Allocation,Clinical Decision Support,F1 Score"
                     data-authors="Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20671v1.html">GRACE: GRaph-based Addiction Care prEdiction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Subham Kumar, Prakrithi Shivaprakash, Koustav Rudra et al.
                </div>

                <div class="paper-summary">
                    This paper introduces GRACE, a novel graph neural network (GNN) framework designed to automate the critical clinical decision of determining the appropriate locus of care for addiction patients. By formalizing this as a structured learning problem and employing a novel unbiased meta-graph approach, GRACE effectively addresses severe class imbalances in addiction datasets, demonstrating significant improvements in prediction accuracy for minority classes.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Addiction Medicine</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Healthcare Management</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20671v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20671v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20671v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20671v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20651v1"
                     data-domains="Critical Care,Cardiology,Emergency Medicine,Patient Monitoring,Chronic Disease Management,Telemedicine"
                     data-keywords="extreme event prediction,time series forecasting,knowledge distillation,mixture of experts,data imbalance,healthcare,acute medical episodes,physiological monitoring"
                     data-authors="Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20651v1.html">xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Quan Li, Wenchao Yu, Suhang Wang et al.
                </div>

                <div class="paper-summary">
                    The xTime framework addresses the critical challenge of accurately forecasting extreme events in time series, which existing models often fail at due to data imbalance and neglect of intermediate event information. It leverages hierarchical knowledge distillation to transfer learning from common events and a mixture of experts (MoE) for dynamic prediction fusion, achieving significant improvements in forecasting accuracy for rare, high-impact events.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Critical Care</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Patient Monitoring</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20651v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20651v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20651v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20651v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20639v1"
                     data-domains="Radiology,Medical Imaging,Diagnostic Imaging,Artificial Intelligence in Medicine"
                     data-keywords="3D medical imaging,vision-language modeling,CT scans,volumetric tokens,report generation,text-to-CT synthesis,deep learning,radiology AI"
                     data-authors="Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20639v1.html">Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ibrahim Ethem Hamamci, Sezgin Er, Suprosanna Shit et al.
                </div>

                <div class="paper-summary">
                    BTB3D (Better Tokens for Better 3D) introduces a novel causal convolutional encoder-decoder that unifies 2D/3D training to generate compact, frequency-aware volumetric tokens from high-resolution medical images. This approach significantly improves state-of-the-art performance in both automated report generation and text-to-CT synthesis by addressing the limitations of slice-wise tokenization and vision-language misalignment. The paper demonstrates that precise three-dimensional tokenization is crucial for scalable vision-language modeling in 3D medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20639v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20639v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20639v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20639v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20634v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,cs.AI"
                     data-authors="Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20634v1.html">Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zhenhuan Zhou, Jingbo Zhu, Yuchen Zhang et al.
                </div>

                <div class="paper-summary">
                    Efficient analysis and processing of dental images are crucial for dentists
to achieve accurate diagnosis and optimal treatment planning. However, dental
imaging inherently poses several challenges, such as low contrast, metallic
artifacts, and variations in projection angles. Combined with the subj...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20634v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20634v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20634v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20634v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20629v1"
                     data-domains="Oncology,Cancer Prognosis,Health Disparities Research,Clinical Informatics,Public Health"
                     data-keywords="Fairness-Aware Survival Modeling (FASM),Algorithmic Bias,Health Equity,Survival Analysis,Breast Cancer Prognosis,Cross-Group Ranking,Machine Learning in Healthcare,Clinical Decision-Making"
                     data-authors="Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20629v1.html">Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mingxuan Liu, Yilin Ning, Haoyuan Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Fairness-Aware Survival Modeling (FASM), an approach designed to mitigate algorithmic bias in survival prediction by addressing both intra-group and cross-group risk ranking disparities over time. Applied to SEER breast cancer prognosis data, FASM significantly enhances fairness without compromising discrimination performance, maintaining stable improvements over a 10-year horizon, particularly in the mid-term.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cancer Prognosis</span>
                    
                    <span class="domain-tag">Health Disparities Research</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20629v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20629v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20629v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20629v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20611v1"
                     data-domains="Oncology,Diagnostic Imaging (Computer-aided diagnosis),Pathology,Women's Health"
                     data-keywords="Breast cancer detection,Machine learning,Explainable AI (XAI),Particle Swarm Optimization (PSO),Feature selection,Computer-aided diagnosis,Early detection,Clinical interpretability"
                     data-authors="Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20611v1.html">PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mirza Raquib, Niloy Das, Farida Siddiqi Prity et al.
                </div>

                <div class="paper-summary">
                    This research proposes PSO-XAI, an integrated framework leveraging customized Particle Swarm Optimization (PSO) for intelligent feature selection, coupled with Explainable AI (XAI) methods, to improve breast cancer detection. Evaluated across 29 diverse machine learning models, the framework achieved a superior performance of 99.1% across all metrics while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The study highlights the potential of combining swarm intelligence with XAI for robust and clinically meaningful breast cancer diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging (Computer-aided diagnosis)</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Women's Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20611v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20611v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20611v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20611v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20543v1"
                     data-domains="Clinical Decision Support,Electronic Health Record (EHR) Analysis,Medical Research Synthesis,Pharmacovigilance,Diagnostic Assistance,Medical Education AI"
                     data-keywords="language models,syntactic analysis,semantic plausibility,center-embedded sentences,comprehension,AI reliability,natural language processing,diagnostic tools"
                     data-authors="Sangmitra Madhusudan,Kaige Chen,Ali Emami">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20543v1.html">The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sangmitra Madhusudan, Kaige Chen, Ali Emami
                </div>

                <div class="paper-summary">
                    This research introduces CenterBench, a novel dataset designed to meticulously evaluate when large language models (LLMs) abandon deep syntactic parsing for superficial semantic pattern matching. By testing models on center-embedded sentences with both plausible and implausible semantics across varying complexity levels, the study quantifies performance gaps, revealing that models increasingly rely on semantic shortcuts as linguistic complexity grows. The framework provides a critical tool to distinguish genuine structural understanding from associative reasoning in AI systems.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Electronic Health Record (EHR) Analysis</span>
                    
                    <span class="domain-tag">Medical Research Synthesis</span>
                    
                    <span class="domain-tag">Pharmacovigilance</span>
                    
                    <span class="domain-tag">Diagnostic Assistance</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20543v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20543v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20543v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20543v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2510.20500v1"
                     data-domains="Infectious disease epidemiology,Public health genomics,Antimicrobial resistance,Vaccine development,Evolutionary medicine"
                     data-keywords="Fitness inference,Population genetics,In silico simulation,Natural selection,Mutation,Recombination,Whole-genome sequencing,Time-stratified data,Pathogen evolution"
                     data-authors="Hong-Li Zeng,Yu-Han Huang,John Barton,Erik Aurell">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2510.20500v1.html">Fitness inference tested by in silico population genetics</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-10-23</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hong-Li Zeng, Yu-Han Huang, John Barton et al.
                </div>

                <div class="paper-summary">
                    This research investigates the feasibility of inferring fitness parameters and the order of genotype fitness from population-wide, whole-genome, time-stratified genomic data. Using *in silico* simulations of populations evolving under natural selection, mutation, and recombination, the study successfully delineates specific parameter ranges where such inference is possible and where it is not. The work provides a crucial framework for assessing when fitness inference is robustly feasible from genomic surveillance data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious disease epidemiology</span>
                    
                    <span class="domain-tag">Public health genomics</span>
                    
                    <span class="domain-tag">Antimicrobial resistance</span>
                    
                    <span class="domain-tag">Vaccine development</span>
                    
                    <span class="domain-tag">Evolutionary medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2510.20500v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2510.20500v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="http://arxiv.org/pdf/2510.20500v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2510.20500v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-10-24 20:22:36</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>