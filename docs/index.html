<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">47</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">168</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (9), Radiology (9), Diagnostic Imaging (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (9)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (9)</option>
                        
                        <option value="Radiology">Radiology (9)</option>
                        
                        <option value="Personalized Medicine">Personalized Medicine (6)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (5)</option>
                        
                        <option value="Drug Discovery">Drug Discovery (5)</option>
                        
                        <option value="Pharmacology">Pharmacology (4)</option>
                        
                        <option value="Precision Medicine">Precision Medicine (3)</option>
                        
                        <option value="Epidemiology">Epidemiology (3)</option>
                        
                        <option value="Pathology">Pathology (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.10619v1"
                     data-domains="Clinical Trials,Drug Discovery & Development,Biomedical Research Funding,Personalized Medicine (treatment optimization)"
                     data-keywords="Multi-armed bandits,Improving bandits,Clinical trials,Algorithm design,Approximation guarantees,Sample complexity,Concavity,Statistical learning"
                     data-authors="Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10619v1.html">Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Avrim Blum, Marten Garicano, Kavya Ravichandran et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the Improving Multi-Armed Bandits (IMAB) problem, relevant to scenarios like clinical trials, where rewards increase monotonically with diminishing returns, and prior algorithms had pessimistic worst-case guarantees. The authors propose two new parameterized families of bandit algorithms that achieve stronger, data-dependent guarantees by learning near-optimal algorithms from offline data. The first family yields optimal dependence on the number of arms under specific concavity conditions, while the second provides robust performance, guaranteeing best-arm identification on well-behaved instances and gracefully degrading on poorly-behaved ones without requiring explicit assumption verification.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Drug Discovery & Development</span>
                    
                    <span class="domain-tag">Biomedical Research Funding</span>
                    
                    <span class="domain-tag">Personalized Medicine (treatment optimization)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10619v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10619v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10619v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10619v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10591v1"
                     data-domains="Dermatology,Wound Management,Telemedicine,Nursing,General Practice,Remote Patient Monitoring"
                     data-keywords="Wound Care,Visual Question Answering,Natural Language Generation,AI in Healthcare,Mined Prompting,Metadata-Guided Generation,Telemedicine,Clinical Decision Support"
                     data-authors="Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10591v1.html">Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bavana Durgapraveen, Sornaraj Sivasankaran, Abhinand Balachandran et al.
                </div>

                <div class="paper-summary">
                    This paper presents two complementary AI approaches for the MEDIQA-WV 2025 shared task, focusing on generating free-text responses to wound care queries paired with images. The first method, mined prompting, enhances response relevance by leveraging few-shot examples from similar training data. The second, metadata-guided generation, refines clinical precision by incorporating dynamically predicted metadata attributes, collectively offering promising directions for efficient and reliable wound care support.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Wound Management</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                    <span class="domain-tag">Nursing</span>
                    
                    <span class="domain-tag">General Practice</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10591v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10591v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10591v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10591v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10590v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Development,Oncology"
                     data-keywords="Bayesian Optimization,Drug Discovery,Molecular Design,Epistemic Neural Networks,Binding Affinity,Foundation Models,Pretraining,EGFR Inhibitors"
                     data-authors="Miles Wang-Henderson,Ben Kaufman,Edward Williams,Ryan Pederson,Matteo Rossi,Owen Howell,Carl Underkoffler,Narbe Mardirossian,John Parkhill">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10590v1.html">Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Miles Wang-Henderson, Ben Kaufman, Edward Williams et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel approach for scalable Batch Bayesian Optimization (BO) of molecular designs, a critical bottleneck in drug development. It achieves this by leveraging Epistemic Neural Networks (ENNs) to construct scalable probabilistic surrogates for binding affinity, integrating representations from large structure-informed models. A key innovation involves pretraining ENN prior networks on synthetic data, leading to significantly faster discovery of potent molecular inhibitors, demonstrating up to a 10x acceleration.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10590v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10590v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10590v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10590v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10583v1"
                     data-domains="Clinical Documentation,Patient Safety,Clinical Informatics,Healthcare Operations"
                     data-keywords="Medical Order Extraction,MedGemma,Prompting Strategies,One-Shot Prompting,ReAct Framework,Agentic Workflow,Clinical NLP,Large Language Models (LLMs),Information Extraction"
                     data-authors="Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10583v1.html">Evaluating Prompting Strategies with MedGemma for Medical Order Extraction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Abhinand Balachandran, Bavana Durgapraveen, Gowsikkan Sikkan Sudhagar et al.
                </div>

                <div class="paper-summary">
                    This paper evaluates the performance of MedGemma, a domain-specific large language model, for the critical task of medical order extraction from doctor-patient conversations. The study systematically compares three prompting strategies‚Äîone-Shot, ReAct, and a multi-step agentic workflow‚Äîand surprisingly finds that the simpler one-Shot method achieved the highest performance on manually annotated transcripts, suggesting complex reasoning can introduce noise in certain data contexts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Documentation</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Healthcare Operations</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10583v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10583v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10583v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10583v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10573v1"
                     data-domains="Mental Health,Behavioral Health,Psychiatry,Substance Use Disorders,Depression Treatment,Digital Therapeutics"
                     data-keywords="Reinforcement Learning,Responsible AI,Affective Computing,Behavioral Health,Constrained Markov Decision Process,Digital Therapeutics,Emotional Intelligence,Personalization"
                     data-authors="Garapati Keerthana,Manik Gupta">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10573v1.html">Towards Emotionally Intelligent and Responsible Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Garapati Keerthana, Manik Gupta
                </div>

                <div class="paper-summary">
                    This paper proposes a Responsible Reinforcement Learning (RRL) framework to address the limitations of existing personalized decision systems in healthcare and behavioral support, which often overlook users' emotional context and ethical constraints. The RRL framework formulates personalization as a Constrained Markov Decision Process (CMDP), optimizing engagement and adherence while ensuring emotional alignment and ethical safety. It achieves this through a multi-objective reward function and an emotion-informed state representation, aiming to provide emotionally intelligent and trustworthy interventions in sensitive domains like mental illness and substance use disorders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Substance Use Disorders</span>
                    
                    <span class="domain-tag">Depression Treatment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10573v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10573v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10573v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10573v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10572v1"
                     data-domains="Intensive Care Units (ICU),Oncology Treatment Planning,Public Health Interventions,Chronic Disease Management,Organ Transplantation,Emergency Medical Services"
                     data-keywords="contextual bandits,individualized allocation,delayed feedback,bi-level optimization,neural networks,fairness,healthcare,temporal dynamics"
                     data-authors="Mohammadsina Almasi,Hadis Anahideh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10572v1.html">Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammadsina Almasi, Hadis Anahideh
                </div>

                <div class="paper-summary">
                    This paper introduces a novel bi-level contextual bandit framework designed for individualized resource allocation, specifically addressing challenges like delayed feedback, hidden heterogeneity, and ethical constraints in high-stakes domains like healthcare. The framework optimizes subgroup-level budget allocations at a meta-level for fairness and operational constraints, while a base-level uses a neural network with delay kernels to identify the most responsive individuals. Validated on real-world datasets, the approach demonstrates higher cumulative outcomes, better adaptation to delay structures, and equitable resource distribution.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Intensive Care Units (ICU)</span>
                    
                    <span class="domain-tag">Oncology Treatment Planning</span>
                    
                    <span class="domain-tag">Public Health Interventions</span>
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Organ Transplantation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10572v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10572v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10572v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10572v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10484v1"
                     data-domains="Endocrinology,Radiology,Diagnostic Imaging,Preventive Medicine,Metabolic Disease"
                     data-keywords="Pancreas Surface Lobularity,Type 2 Diabetes Mellitus,CT Biomarker,Opportunistic Screening,Deep Learning,Pancreas Segmentation,Computer Vision,Early Detection"
                     data-authors="Tejas Sudharshan Mathai,Anisa V. Prasad,Xinya Wang,Praveen T. S. Balamuralikrishna,Yan Zhuang,Abhinav Suri,Jianfei Liu,Perry J. Pickhardt,Ronald M. Summers">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10484v1.html">Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic Screening of Type 2 Diabetes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tejas Sudharshan Mathai, Anisa V. Prasad, Xinya Wang et al.
                </div>

                <div class="paper-summary">
                    This pilot study introduces a fully automated deep learning-based approach for opportunistic screening of Type 2 Diabetes Mellitus (T2DM) using CT imaging biomarkers, specifically pancreatic surface lobularity (PSL). It found that diabetic patients exhibit significantly higher PSL compared to non-diabetic individuals, and a multivariate model incorporating these CT biomarkers achieved high accuracy in T2DM prediction. The findings suggest PSL is a useful biomarker for early T2DM detection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Endocrinology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Metabolic Disease</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10484v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10484v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10484v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10484v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10432v1"
                     data-domains="Oncology,Pathology,Computational Pathology,Urology"
                     data-keywords="Digital pathology,Semantic segmentation,Whole slide imaging,Multiple-instance learning,Prostate cancer,Copy number variation,Cancer relapse,Gleason score"
                     data-authors="Willem Bonnaff√©,Yang Hu,Andrea Chatrian,Mengran Fan,Stefano Malacrino,Sandy Figiel,CRUK ICGC Prostate Group,Srinivasa R. Rao,Richard Colling,Richard J. Bryant,Freddie C. Hamdy,Dan J. Woodcock,Ian G. Mills,Clare Verrill,Jens Rittscher">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10432v1.html">Histology-informed tiling of whole tissue sections improves the interpretability and predictability of cancer relapse and genetic alterations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Willem Bonnaff√©, Yang Hu, Andrea Chatrian et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Histology-informed Tiling (HIT), a novel digital pathology method that utilizes semantic segmentation to extract biologically meaningful gland structures from whole slide images (WSIs), rather than relying on arbitrary grid-based tiling. HIT significantly improved the accuracy and interpretability of multiple-instance learning (MIL) models, enabling more precise detection of genetic alterations and the identification of gland clusters strongly associated with cancer relapse, oncogenic mutations, and high Gleason scores in prostate cancer.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                    <span class="domain-tag">Urology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10432v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10432v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10432v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10432v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10412v1"
                     data-domains="Obstetrics,Fetal Medicine,Diagnostic Imaging,Perinatology,Radiology"
                     data-keywords="Fetal ultrasound,3D ultrasound,Facial planes,Deep learning,Standardization,Prenatal diagnosis,Image processing,Anatomical landmarks"
                     data-authors="Alomar Antonia,Rubio Ricardo,Albaiges Gerard,Salort-Benejam Laura,Caminal Julia,Prat Maria,Rueda Carolina,Cortes Berta,Piella Gemma,Sukno Federico">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10412v1.html">3DFETUS: Standardizing Fetal Facial Planes in 3D Ultrasound</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alomar Antonia, Rubio Ricardo, Albaiges Gerard et al.
                </div>

                <div class="paper-summary">
                    This paper introduces 3DFETUS, a deep learning model, and GT++, an algorithm, aimed at standardizing the acquisition and localization of fetal facial planes in 3D ultrasound. By automating this challenging process, the methods reduce operator dependency and improve accuracy, addressing inconsistencies and potential diagnostic bias in prenatal examinations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Obstetrics</span>
                    
                    <span class="domain-tag">Fetal Medicine</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Perinatology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10412v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10412v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10412v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10412v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10383v1"
                     data-domains="Precision Medicine,Dynamic Treatment Regimens,Critical Care Management,Anesthesia Control,Disease Progression Modeling,Drug Dosing Optimization,Surgical Robotics,Rehabilitation Robotics"
                     data-keywords="Reinforcement Learning,Offline RL,Continuous-Time Control,Hamilton-Jacobi-Bellman,Operator Theory,Reproducing Kernel Hilbert Space,Diffusion Processes,Finite-Sample Guarantees"
                     data-authors="Nicolas Hoischen,Petar Bevanda,Max Beier,Stefan Sosnowski,Boris Houska,Sandra Hirche">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10383v1.html">Operator Models for Continuous-Time Offline Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ML</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nicolas Hoischen, Petar Bevanda, Max Beier et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the critical challenge of approximation errors in continuous-time offline reinforcement learning, a necessity for high-stakes fields like healthcare where direct interaction is infeasible. It proposes an operator-theoretic algorithm grounded in the Hamilton-Jacobi-Bellman equation, representing the world model using the infinitesimal generator of controlled diffusion processes learned in a Reproducing Kernel Hilbert Space. The research establishes global convergence of the value function and provides finite-sample guarantees, highlighting the promise of this operator-based approach for continuous-time optimal control.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Dynamic Treatment Regimens</span>
                    
                    <span class="domain-tag">Critical Care Management</span>
                    
                    <span class="domain-tag">Anesthesia Control</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10383v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10383v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10383v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10383v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10367v1"
                     data-domains="Dermatology,Medical Imaging,Digital Health,Telemedicine"
                     data-keywords="dermatology,AI classification,mobile health,skin lesions,image acquisition,dataset diversity,quality control,smartphone application"
                     data-authors="Thales Bezerra,Emanoel Thyago,Kelvin Cunha,Rodrigo Abreu,F√°bio Papais,Francisco Mauro,Nat√°lia Lopes,√ârico Medeiros,J√©ssica Guido,Shirley Cruz,Paulo Borba,Tsang Ing Ren">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10367v1.html">DermAI: Clinical dermatology acquisition through quality-driven image collection for AI classification in mobile</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Thales Bezerra, Emanoel Thyago, Kelvin Cunha et al.
                </div>

                <div class="paper-summary">
                    DermAI is a novel smartphone-based application designed for real-time capture, annotation, and classification of skin lesions, addressing critical limitations in AI-based dermatology such as biased datasets and variable image quality. Preliminary experiments demonstrated that models fine-tuned with DermAI's diverse, quality-controlled local data significantly outperformed those trained solely on public datasets, highlighting the necessity of standardized, diverse data collection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10367v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10367v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10367v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10367v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10320v1"
                     data-domains="Personalized Medicine,Precision Medicine,Drug Efficacy Studies,Treatment Planning,Clinical Decision Support,Epidemiology,Pharmacogenomics"
                     data-keywords="Individual Treatment Effect (ITE),Multi-Prototype Alignment,Confounding Bias,Observational Data,Local Structure,Heterogeneity,Causal Inference,Personalized Medicine"
                     data-authors="Fuyuan Cao,Jiaxuan Zhang,Xiaoli Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10320v1.html">PITE: Multi-Prototype Alignment for Individual Treatment Effect Estimation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Fuyuan Cao, Jiaxuan Zhang, Xiaoli Li
                </div>

                <div class="paper-summary">
                    PITE addresses the critical challenge of estimating Individual Treatment Effects (ITE) from observational data by introducing a novel multi-prototype alignment method. It overcomes limitations of existing approaches by effectively capturing local data structures and individual heterogeneity through prototype-based clustering and cross-group alignment. This leads to significantly more accurate and robust ITE estimation, outperforming state-of-the-art methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                    <span class="domain-tag">Drug Efficacy Studies</span>
                    
                    <span class="domain-tag">Treatment Planning</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10320v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10320v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10320v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10320v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10286v1"
                     data-domains="Pathology,Oncology,Diagnostic Imaging,Digital Pathology,Molecular Pathology"
                     data-keywords="computational pathology,vision foundation models,histopathology,whole-slide images,data diversity,deep learning,AI in medicine,digital pathology"
                     data-authors="Christoph Bosch,John K. L. Wong,Martin Paulikat,Myroslav Zapukhlyak,Bharti Arora,Manasi Aichm√ºller-Ratnaparkhe,Jens Baumann,Shivani Karn,Rutuja Kamble,Swapnil Karnik,Bhushan Khedkar,Serey Vathana Chhut,Witali Aswolinskiy,Christian Aichm√ºller">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10286v1.html">Diversity Over Scale: Whole-Slide Image Variety Enables H&E Foundation Model Training with Fewer Patches</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.TO</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christoph Bosch, John K. L. Wong, Martin Paulikat et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Athena, a histopathology foundation model trained on significantly fewer tissue patches (115 million) compared to other state-of-the-art models, by prioritizing data diversity over sheer scale. Athena achieved competitive performance on multiple downstream tasks, suggesting that the diversity of whole-slide images, rather than just the quantity of patches, is the primary driver for effective learning in computational pathology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Molecular Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10286v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10286v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10286v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10286v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10244v1"
                     data-domains="Drug Discovery,Infectious Diseases (e.g., HIV/AIDS),Toxicology,Pharmacology,Biotechnology,Computational Biology,Antimicrobial Research"
                     data-keywords="Peptide classification,Explainable AI,Protein Language Models,Graph Attention Networks,Drug Discovery,Peptide Toxicity,HIV Inhibition,3D Structural Features,Bioinformatics,Interpretability"
                     data-authors="Vincent Schilling,Akshat Dubey,Georges Hattab">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10244v1.html">PepTriX: A Framework for Explainable Peptide Analysis through Protein Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vincent Schilling, Akshat Dubey, Georges Hattab
                </div>

                <div class="paper-summary">
                    PepTriX is a novel framework designed for explainable peptide analysis, integrating 1D sequence embeddings and 3D structural features through a graph attention network enhanced with contrastive training and cross-modal co-attention. This framework addresses the limitations of traditional handcrafted encodings and computationally costly, uninterpretable protein language models (PLMs) in peptide classification tasks. PepTriX demonstrates robust predictive performance across various tasks while providing interpretable insights into the biological motifs driving its predictions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Infectious Diseases (e.g., HIV/AIDS)</span>
                    
                    <span class="domain-tag">Toxicology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Biotechnology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10244v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10244v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10244v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10244v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10173v1"
                     data-domains="Orthodontics,Dentistry,Radiology,Medical Imaging Analysis"
                     data-keywords="Cephalometric Landmark Detection,Deep Learning,Convolutional Neural Networks,Residual Networks,Attention Mechanisms,Orthodontics,Medical Imaging,X-ray Analysis"
                     data-authors="Ahmed Jaheen,Islam Hassan,Mohanad Abouserie,Abdelaty Rehab,Adham Elasfar,Knzy Elmasry,Mostafa El-Dawlatly,Seif Eldawlatly">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10173v1.html">CephRes-MHNet: A Multi-Head Residual Network for Accurate and Robust Cephalometric Landmark Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ahmed Jaheen, Islam Hassan, Mohanad Abouserie et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CephRes-MHNet, a multi-head residual convolutional network designed for accurate and robust cephalometric landmark detection from 2D lateral skull X-rays. It achieves state-of-the-art performance with a Mean Radial Error of 1.23 mm and a Success Detection Rate @ 2.0 mm of 85.5%, outperforming previous models like AFPF-Net with significantly fewer parameters, thus offering an efficient and practical solution for orthodontic diagnosis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Orthodontics</span>
                    
                    <span class="domain-tag">Dentistry</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10173v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10173v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10173v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10173v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10165v1"
                     data-domains="Drug Discovery,Structural Biology,Pharmacology,Biophysics,Protein Engineering"
                     data-keywords="Protein conformational ensembles,Generative models,Energy Preference Optimization (EPO),Stochastic Differential Equations (SDE),Molecular Dynamics (MD),Drug discovery,Structural biology,Machine learning"
                     data-authors="Yuancheng Sun,Yuxuan Ren,Zhaoming Chen,Xu Han,Kang Liu,Qiwei Ye">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10165v1.html">EPO: Diverse and Realistic Protein Ensemble Generation via Energy Preference Optimization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuancheng Sun, Yuxuan Ren, Zhaoming Chen et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Energy Preference Optimization (EPO), an online refinement algorithm designed to generate diverse and physically realistic protein conformational ensembles. EPO transforms pretrained protein ensemble generators into energy-aware samplers by integrating stochastic differential equation sampling with a novel list-wise preference optimization strategy, efficiently overcoming the high computational cost and energy-barrier trapping issues prevalent in traditional molecular dynamics (MD) simulations. The method achieves state-of-the-art results across multiple benchmarks, demonstrating that energy-only preference signals can effectively steer generative models towards thermodynamically consistent ensembles, thus offering a powerful alternative to long MD simulations.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Biophysics</span>
                    
                    <span class="domain-tag">Protein Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10165v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10165v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10165v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10165v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10116v1"
                     data-domains="Oncology,Radiotherapy,Neuro-oncology,Photodynamic Therapy,Nanomedicine,Medical Physics"
                     data-keywords="X-ray-induced Photodynamic Therapy,FRET,Lanthanide Nanoparticles,AGuIX,Rose Bengal,Glioblastoma,Singlet Oxygen,Cancer Targeting,Nanomedicine"
                     data-authors="Batoul Dhaini,Jo√´l Daouk,Herv√© Schohn,Philippe Arnoux,Val√©rie Jouan-Hureaux,Albert Moussaron,Agn√®s Hagege,Mathilde Achard,Samir Acherar,Tayssir Hamieh,C√©line Frochot">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10116v1.html">Lanthanides-Based Nanoparticles Conjugated with Rose Bengal for FRET-Mediated X-Ray-Induced PDT</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Batoul Dhaini, Jo√´l Daouk, Herv√© Schohn et al.
                </div>

                <div class="paper-summary">
                    This paper presents the development of lanthanide-based AGuIX nanoparticles conjugated with Rose Bengal (AGuIX Ln@RB) for F{√∂}rster Resonance Energy Transfer (FRET)-mediated X-ray-induced photodynamic therapy (X-PDT) against cancer. The research optimized FRET efficiency, demonstrated X-ray-induced singlet oxygen production, achieved significant glioblastoma cell death in vitro, and showed successful conjugation of a cancer-targeting peptide, addressing the critical challenge of treating deep-seated tumors with PDT.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiotherapy</span>
                    
                    <span class="domain-tag">Neuro-oncology</span>
                    
                    <span class="domain-tag">Photodynamic Therapy</span>
                    
                    <span class="domain-tag">Nanomedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10116v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10116v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10116v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10116v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10065v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Informatics,Artificial Intelligence in Medicine"
                     data-keywords="Radiology Workflow,Medical Report Generation,Hierarchical Reinforcement Learning,Diagnostic Coherence,Clinical Consistency,Critical-Aware Policy,Chest X-ray,Carotid Ultrasound"
                     data-authors="Bodong Du,Honglong Yang,Xiaomeng Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10065v1.html">Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Bodong Du, Honglong Yang, Xiaomeng Li
                </div>

                <div class="paper-summary">
                    This paper introduces RadFlow, a novel hierarchical reinforcement fine-tuning framework that mimics radiologists' structured workflow for medical report generation. By incorporating a clinically grounded reward hierarchy and a critical-aware policy optimization, RadFlow addresses inconsistencies in existing flat-sequence models, generating reports that are both linguistically consistent and clinically aligned. Experiments on chest X-ray and carotid ultrasound datasets demonstrate RadFlow's superior performance in improving diagnostic coherence and overall report quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10065v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10065v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10065v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10065v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10060v1"
                     data-domains="Emergency Medicine,Medical Training and Simulation,Clinical Skill Assessment,Patient Safety,Cardiopulmonary Resuscitation (CPR)"
                     data-keywords="Medical Action Evaluation,Multivariate Gaussian,Representation Learning,Skeletal Motion Analysis,CPR Evaluation,Medical Vision,Spatiotemporal Modeling,Deep Learning"
                     data-authors="Luming Yang,Haoxian Liu,Siqing Li,Alper Yilmaz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10060v1.html">Multivariate Gaussian Representation Learning for Medical Action Evaluation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Luming Yang, Haoxian Liu, Siqing Li et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenges of fine-grained medical action evaluation, particularly for rapid actions, by introducing CPREval-6k, a new multi-view, multi-label benchmark dataset of 6,372 expert-annotated videos. Alongside the dataset, they propose GaussMedAct, a multivariate Gaussian encoding framework that leverages adaptive 3D Gaussians as tokens to learn robust spatiotemporal representations, achieving superior accuracy and efficiency compared to baselines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Medical Training and Simulation</span>
                    
                    <span class="domain-tag">Clinical Skill Assessment</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Cardiopulmonary Resuscitation (CPR)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10060v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10060v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10060v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10060v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10032v1"
                     data-domains="Nephrology,Transplant Medicine,Medical Ethics,Health Informatics,Bioethics"
                     data-keywords="AI alignment,moral preferences,temporal instability,kidney allocation,human-AI interaction,preference elicitation,healthcare AI,decision support"
                     data-authors="Vijay Keswani,Cyrus Cousins,Breanna Nguyen,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10032v1.html">Moral Change or Noise? On Problems of Aligning AI With Temporally Unstable Human Feedback</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.HC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vijay Keswani, Cyrus Cousins, Breanna Nguyen et al.
                </div>

                <div class="paper-summary">
                    This research investigates the critical challenge of aligning AI with human moral preferences in high-stakes domains, noting that such preferences are often dynamic rather than static. Grounded in kidney allocation, the study reveals significant temporal instability in participants' responses and decision-making models, leading to decreased predictive performance of AI systems over time. The findings highlight the urgent need for AI alignment methods to account for evolving human preferences to ensure trustworthiness and prevent harm.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nephrology</span>
                    
                    <span class="domain-tag">Transplant Medicine</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Bioethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10032v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10032v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10032v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10032v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10023v1"
                     data-domains="Ophthalmology,Neonatology,Pediatric Ophthalmology,Medical Imaging"
                     data-keywords="Retinopathy of Prematurity,ROP,Deep Learning,Convolutional Neural Networks,CNN,Automated Diagnosis,Medical Imaging,Computational Efficiency"
                     data-authors="Farzan Saeedi,Sanaz Keshvari,Nasser Shoeibi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10023v1.html">Efficient Automated Diagnosis of Retinopathy of Prematurity by Customize CNN Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Farzan Saeedi, Sanaz Keshvari, Nasser Shoeibi
                </div>

                <div class="paper-summary">
                    This paper presents a deep learning approach for the efficient and precise diagnosis of Retinopathy of Prematurity (ROP) using customized Convolutional Neural Network (CNN) models. The study demonstrates that these tailored CNNs achieve superior accuracy and F1-scores compared to pre-trained models, further enhancing performance with a voting system, while also reducing computational burden. The developed models are highlighted for their deployability as valuable diagnostic aids in clinical settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Neonatology</span>
                    
                    <span class="domain-tag">Pediatric Ophthalmology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10023v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10023v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10023v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10023v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10014v1"
                     data-domains="Scientific Research,Drug Discovery,Clinical Research,Medical Informatics,Personalized Medicine,Public Health"
                     data-keywords="Graph-based RAG,Large Language Models,Biomedical Literature,Knowledge Graph,Entity Linking,Computational Efficiency,Drug Discovery,Healthcare AI"
                     data-authors="Guofeng Meng,Li Shen,Qiuyan Zhong,Wei Wang,Haizhou Zhang,Xiaozhen Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10014v1.html">fastbmRAG: A Fast Graph-Based RAG Framework for Efficient Processing of Large-Scale Biomedical Literature</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.QM</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guofeng Meng, Li Shen, Qiuyan Zhong et al.
                </div>

                <div class="paper-summary">
                    fastbmRAG is a novel, fast graph-based Retrieval-Augmented Generation (RAG) framework designed for efficient processing of large-scale biomedical literature. It addresses the computational intensity of existing graph-RAGs by employing a two-stage knowledge graph construction process that leverages paper structure and vector-based entity linking. The framework demonstrates over 10x speed improvement while maintaining superior coverage and accuracy for understanding, summarizing, and querying medical texts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Scientific Research</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Clinical Research</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10014v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10014v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10014v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10014v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.10013v1"
                     data-domains="Diagnostic Medical Imaging,Traditional Chinese Medicine (specifically tongue diagnosis),General internal medicine (for systemic disease indicators),Dermatology (potential for skin conditions),Oncology (for specific visual markers)"
                     data-keywords="medical imaging,deep learning,self-supervised learning,graph neural networks,diagnostic AI,tongue diagnosis,clinical priors,label imbalance"
                     data-authors="Shufeng Kong,Zijie Wang,Nuan Cui,Hao Tang,Yihan Meng,Yuanyuan Wei,Feifan Chen,Yingheng Wang,Zhuo Cai,Yaonan Wang,Yulong Zhang,Yuzheng Li,Zibin Zheng,Caihua Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.10013v1.html">MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shufeng Kong, Zijie Wang, Nuan Cui et al.
                </div>

                <div class="paper-summary">
                    MIRNet introduces a novel framework for automated interpretation of diagnostic medical images, integrating self-supervised pre-training with constrained graph-based reasoning. It addresses critical challenges like annotation scarcity, label imbalance, and the need for clinical plausibility, achieving state-of-the-art performance in tongue image diagnosis while demonstrating broad generalizability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Medical Imaging</span>
                    
                    <span class="domain-tag">Traditional Chinese Medicine (specifically tongue diagnosis)</span>
                    
                    <span class="domain-tag">General internal medicine (for systemic disease indicators)</span>
                    
                    <span class="domain-tag">Dermatology (potential for skin conditions)</span>
                    
                    <span class="domain-tag">Oncology (for specific visual markers)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.10013v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.10013v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.10013v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.10013v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09970v1"
                     data-domains="Clinical Decision Support,Electronic Health Records (EHR) Analysis,Predictive Analytics in Healthcare,Personalized Medicine,Population Health Management,Genomics and Proteomics Data Analysis"
                     data-keywords="Tabular Data,Multitask Learning,Transformers,MultiTab-Net,Masked Attention,Healthcare AI,Scalable AI,Clinical Prediction"
                     data-authors="Dimitrios Sinodinos,Jack Yi Wei,Narges Armanfard">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09970v1.html">MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dimitrios Sinodinos, Jack Yi Wei, Narges Armanfard
                </div>

                <div class="paper-summary">
                    MultiTab introduces MultiTab-Net, the first multitask transformer architecture specifically designed for large tabular data, employing a novel multitask masked-attention mechanism. This approach dynamically models complex feature interactions while mitigating task competition, demonstrating superior multitask generalization compared to existing MTL and single-task models across diverse domains and task types.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR) Analysis</span>
                    
                    <span class="domain-tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Population Health Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09970v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09970v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09970v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09970v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09949v1"
                     data-domains="Neurology,Neuroimaging,Computational Neuroscience,Diagnostic Imaging,Neurodegenerative Diseases"
                     data-keywords="Dynamic Brain Connectivity,Functional Connectivity,Network Topology,Persistent Homology,Wasserstein Distance,Alzheimer's Disease,Convolutional Neural Networks,Transfer Learning"
                     data-authors="Peilin He,Tananun Songdechakraiwut">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09949v1.html">Imaging the Topology of Dynamic Brain Connectivity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ q-bio.NC</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Peilin He, Tananun Songdechakraiwut
                </div>

                <div class="paper-summary">
                    This paper introduces a novel framework that transforms dynamic functional brain connectivity into a 'topological image' representation by encoding evolving network topology using persistent graph homology. This approach enables the use of convolutional neural networks and transfer learning for non-Euclidean brain data, achieving clinically meaningful accuracy in early Alzheimer's detection despite limited and imbalanced datasets. It establishes a principled foundation for imaging dynamic brain topology.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neuroimaging</span>
                    
                    <span class="domain-tag">Computational Neuroscience</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09949v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09949v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09949v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09949v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09947v1"
                     data-domains="Neurology,Clinical Neurophysiology,Cognitive Neuroscience,Psychiatry,Sleep Medicine"
                     data-keywords="EEG,Large Language Models (LLMs),Automated Analysis,Brain Activity,Clinical Diagnostics,Cognitive Research,Multi-task Learning,Neuroinformatics"
                     data-authors="Sha Zhao,Mingyi Peng,Haiteng Jiang,Tao Li,Shijian Li,Gang Pan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09947v1.html">EEGAgent: A Unified Framework for Automated EEG Analysis Using Large Language Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sha Zhao, Mingyi Peng, Haiteng Jiang et al.
                </div>

                <div class="paper-summary">
                    EEGAgent introduces a unified framework leveraging Large Language Models (LLMs) to automate multi-task EEG analysis, addressing the limitations of existing task-specific models. By scheduling specialized EEG tools, it performs functions like basic information perception, spatiotemporal exploration, event detection, user interaction, and report generation, demonstrating flexible and interpretable analysis with significant potential for clinical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Clinical Neurophysiology</span>
                    
                    <span class="domain-tag">Cognitive Neuroscience</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Sleep Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09947v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09947v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09947v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09947v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09914v1"
                     data-domains="Public Health,Healthcare Policy,Addiction Medicine,Health Law,Medical Ethics,Epidemiology"
                     data-keywords="opioid crisis,public health,AI,Large Language Models (LLMs),multimodal analysis,document analysis,UCSF-JHU Opioid Industry Documents Archive,benchmarking"
                     data-authors="Xuan Shen,Brian Wingenroth,Zichao Wang,Jason Kuen,Wanrong Zhu,Ruiyi Zhang,Yiwei Wang,Lichun Ma,Anqi Liu,Hongfu Liu,Tong Sun,Kevin S. Hawkins,Kate Tasker,G. Caleb Alexander,Jiuxiang Gu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09914v1.html">OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Documents Archive</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xuan Shen, Brian Wingenroth, Zichao Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces OIDA-QA, a novel multimodal benchmark and an AI assistant designed to systematically analyze the complex, vast UCSF-JHU Opioid Industry Documents Archive (OIDA). By extracting rich multimodal information and leveraging domain-specific multimodal Large Language Models, the work significantly improves information extraction and question-answering from these critical documents. Preliminary results demonstrate enhanced performance in uncovering the systemic failures that contributed to the opioid crisis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Healthcare Policy</span>
                    
                    <span class="domain-tag">Addiction Medicine</span>
                    
                    <span class="domain-tag">Health Law</span>
                    
                    <span class="domain-tag">Medical Ethics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09914v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09914v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09914v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09914v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09895v1"
                     data-domains="Cardiology,Electrophysiology,Artificial Intelligence in Medicine,Medical Diagnostics"
                     data-keywords="ECG generation,Diffusion models,Physiological simulation,Clinical knowledge,Large Language Models (LLMs),Cardiovascular disease,Data augmentation,AI in medicine"
                     data-authors="Xiaoda Wang,Kaiqiao Han,Yuhao Xu,Xiao Luo,Yizhou Sun,Wei Wang,Carl Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09895v1.html">Simulator and Experience Enhanced Diffusion Model for Comprehensive ECG Generation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xiaoda Wang, Kaiqiao Han, Yuhao Xu et al.
                </div>

                <div class="paper-summary">
                    SE-Diff is a novel diffusion model designed for comprehensive ECG generation, aiming to overcome the scarcity of large, well-annotated ECG datasets. It uniquely integrates a lightweight ODE-based physiological simulator for anatomically plausible waveforms and an LLM-powered strategy for real-world clinical knowledge, demonstrating improved signal fidelity and semantic alignment in generated ECGs, which also benefits downstream classification tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Electrophysiology</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Medical Diagnostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09895v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09895v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09895v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09895v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09894v1"
                     data-domains="Emergency Medicine,Paramedicine,Prehospital Care,Critical Care Transport"
                     data-keywords="EgoEMS,Emergency Medical Services,AI Cognitive Assistants,Multimodal Dataset,Egocentric Vision,Action Recognition,Action Quality Estimation,Healthcare AI"
                     data-authors="Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09894v1.html">EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Keshara Weerasinghe, Xueren Ge, Tessa Heick et al.
                </div>

                <div class="paper-summary">
                    This paper introduces EgoEMS, the first high-fidelity, multimodal egocentric dataset designed to facilitate the development of AI cognitive assistants for Emergency Medical Services (EMS). Capturing over 20 hours of realistic simulated emergency scenarios performed by EMS professionals, EgoEMS provides rich annotations and benchmarks crucial for real-time keystep recognition and action quality estimation in high-stakes environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Paramedicine</span>
                    
                    <span class="domain-tag">Prehospital Care</span>
                    
                    <span class="domain-tag">Critical Care Transport</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09894v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09894v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09894v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09894v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09893v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical Artificial Intelligence"
                     data-keywords="Medical Image Captioning,Swin Transformer,BART,Regional Attention,Radiology,Deep Learning,Interpretability,Diagnostic Imaging"
                     data-authors="Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09893v1.html">Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zubia Naz, Farhan Asghar, Muhammad Ishfaq Hussain et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a Swin-BART encoder-decoder system with a novel lightweight regional attention module for automated medical image captioning. The system amplifies diagnostically salient image regions before cross-attention, achieving state-of-the-art semantic fidelity on the ROCO dataset. It generates accurate, clinically phrased captions with transparent regional attributions, intended for safe research use with human oversight.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical Artificial Intelligence</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09893v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09893v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09893v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09893v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09853v1"
                     data-domains="Oncology,Cancer Research,Digital Pathology,Computational Genomics,Precision Medicine,Prognostics"
                     data-keywords="Continual Learning,Multimodal Learning,Survival Analysis,Cancer Prognosis,Whole Slide Images,Genomics,Catastrophic Forgetting,Mixture of Experts"
                     data-authors="Dianzhi Yu,Conghao Xiong,Yankai Chen,Wenqian Cui,Xinni Zhang,Yifei Zhang,Hao Chen,Joseph J. Y. Sung,Irwin King">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09853v1.html">ConSurv: Multimodal Continual Learning for Survival Analysis</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-13</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Dianzhi Yu, Conghao Xiong, Yankai Chen et al.
                </div>

                <div class="paper-summary">
                    ConSurv addresses the critical limitations of static models and unimodal continual learning in cancer survival prediction by introducing the first multimodal continual learning (MMCL) method. It effectively mitigates catastrophic forgetting and leverages complex inter-modal interactions between gigapixel whole slide images and genomics, demonstrating superior performance on a newly proposed benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cancer Research</span>
                    
                    <span class="domain-tag">Digital Pathology</span>
                    
                    <span class="domain-tag">Computational Genomics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09853v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09853v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09853v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09853v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09814v1"
                     data-domains="Oncology (combination therapies),Cardiology (polypharmacy for chronic heart conditions),Endocrinology (managing multiple comorbidities like diabetes and hypertension),Psychiatry (combination pharmacotherapies),Critical Care (multi-drug regimens),Pharmacogenomics (predicting drug-drug interactions)"
                     data-keywords="Causal Inference,Multiple Treatments,Treatment Effects,Deep Learning,Task Embeddings,Representation Learning,Balancing Scores,Healthcare Analytics"
                     data-authors="Yuki Murakami,Takumi Hattori,Kohsuke Kubota">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09814v1.html">Multiple Treatments Causal Effects Estimation with Task Embeddings and Balanced Representation Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuki Murakami, Takumi Hattori, Kohsuke Kubota
                </div>

                <div class="paper-summary">
                    This paper proposes a novel deep learning framework to estimate causal effects, including single treatment and interaction effects, when multiple treatments are applied simultaneously. Addressing limitations of prior methods such as lack of parameter sharing and inaccurate latent variable estimation, the framework combines a task embedding network for efficient parameter sharing with a balanced representation learning network to mitigate selection bias and avoid model misspecification. Simulation studies confirm its superiority over existing baselines, highlighting its practical utility for applications in fields like healthcare and marketing.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology (combination therapies)</span>
                    
                    <span class="domain-tag">Cardiology (polypharmacy for chronic heart conditions)</span>
                    
                    <span class="domain-tag">Endocrinology (managing multiple comorbidities like diabetes and hypertension)</span>
                    
                    <span class="domain-tag">Psychiatry (combination pharmacotherapies)</span>
                    
                    <span class="domain-tag">Critical Care (multi-drug regimens)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09814v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09814v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09814v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09814v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09808v1"
                     data-domains="Drug Discovery,Pharmaceutical Research,Medicinal Chemistry,Early-Stage Clinical Development,Toxicology Screening"
                     data-keywords="Best Arm Identification,Feasibility Constraints,Drug Discovery,Sample Complexity,Asymptotic Optimality,Fixed Confidence Setting,Machine Learning,Experimental Design"
                     data-authors="Ting Cai,Kirthevasan Kandasamy">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09808v1.html">Constrained Best Arm Identification with Tests for Feasibility</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ting Cai, Kirthevasan Kandasamy
                </div>

                <div class="paper-summary">
                    This paper addresses Best Arm Identification (BAI) problems with feasibility constraints, where performance and constraint measurements can be conducted independently, as seen in drug discovery. The authors propose an efficient algorithm for the fixed confidence setting that intelligently allocates resources to test for an arm's performance or its specific feasibility constraints. The algorithm is shown to be asymptotically optimal in its sample complexity and empirically outperforms existing methods on both synthetic and real-world datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Pharmaceutical Research</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Early-Stage Clinical Development</span>
                    
                    <span class="domain-tag">Toxicology Screening</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09808v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09808v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09808v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09808v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09773v1"
                     data-domains="Sleep medicine,Neurology,Diagnostic electrophysiology,Public health"
                     data-keywords="Sleep stage classification,EEG,EOG,Polysomnography,Transformers,Graph Convolutional Network,Multimodal fusion,Interpretability"
                     data-authors="Mahdi Samaee,Mehran Yazdi,Daniel Massicotte">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09773v1.html">NeuroLingua: A Language-Inspired Hierarchical Framework for Multimodal Sleep Stage Classification Using EEG and EOG</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mahdi Samaee, Mehran Yazdi, Daniel Massicotte
                </div>

                <div class="paper-summary">
                    NeuroLingua introduces a novel language-inspired hierarchical framework for automated sleep stage classification, addressing current limitations in expressive temporal hierarchies, multimodal EEG and EOG fusion, and deep learning model interpretability. By conceptualizing sleep as a structured physiological language and employing dual-level Transformers with Graph Convolutional Network-based fusion, it achieves state-of-the-art results on benchmark datasets. This framework not only improves classification accuracy but also enhances the detection of clinically relevant sleep microevents, paving the way for more transparent and clinically meaningful applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Sleep medicine</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Diagnostic electrophysiology</span>
                    
                    <span class="domain-tag">Public health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09773v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09773v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09773v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09773v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09759v1"
                     data-domains="Oncology,Personalized Medicine,Clinical Trials,Drug Discovery and Development,Epidemiology"
                     data-keywords="Optimal Transport,Distributional Treatment Effect,Cross-site Heterogeneity,Causal Inference,Effect Modification,Counterfactual Synthesis,Patient-Derived Xenograft,Precision Medicine"
                     data-authors="Borna Bateni,Yubai Yuan,Qi Xu,Annie Qu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09759v1.html">Distributional Treatment Effect Estimation across Heterogeneous Sites via Optimal Transport</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ stat.ME</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Borna Bateni, Yubai Yuan, Qi Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Optimal Transport-based framework to synthesize counterfactual treatment group data for a target site, overcoming challenges of cross-site heterogeneity in treatment effects. By leveraging full treatment and control data from a source site alongside control data from the target, the method learns a push-forward transformation to generate a synthetic target treatment distribution. This approach robustly recovers the full distributional properties of treatment effects, departing from conventional average treatment effect estimation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Drug Discovery and Development</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09742v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical AI"
                     data-keywords="Foundation Models,Medical Imaging,Chest X-ray,Radiology,Classification,Segmentation,Deep Learning,Pre-training"
                     data-authors="Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09742v1.html">Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Frank Li, Theo Dapamede, Mohammadreza Chavoshi et al.
                </div>

                <div class="paper-summary">
                    This paper comparatively evaluates eight medical and general-domain Foundation Models (FMs) for chest X-ray analysis, revealing that domain-specific pre-training yields superior initial feature quality. However, the study highlights that FM utility is highly task-dependent, excelling in global classification but critically failing in localizing subtle pathologies like pneumothorax without extensive fine-tuning, where traditional supervised models remain highly competitive.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09742v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09742v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09742v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09742v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09702v1"
                     data-domains="Laryngology,Otolaryngology,Speech-Language Pathology,Voice Disorders,Medical Imaging"
                     data-keywords="Phonotrauma,Vocal Folds,Severity Classification,Ordinal Regression,Soft Labels,Medical Imaging,Machine Learning,Laryngology"
                     data-authors="Katie Matton,Purvaja Balaji,Hamzeh Ghasemzadeh,Jameson C. Cooper,Daryush D. Mehta,Jarrad H. Van Stan,Robert E. Hillman,Rosalind Picard,John Guttag,S. Mazdak Abulnaga">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09702v1.html">Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Katie Matton, Purvaja Balaji, Hamzeh Ghasemzadeh et al.
                </div>

                <div class="paper-summary">
                    This paper presents the first automated method for classifying phonotrauma severity from vocal fold images, addressing the current reliance on subjective and costly clinical judgment. It introduces a novel soft ordinal regression framework that modifies loss functions to accommodate soft labels reflecting annotator rating distributions, achieving predictive performance comparable to clinical experts with well-calibrated uncertainty estimates.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Laryngology</span>
                    
                    <span class="domain-tag">Otolaryngology</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Voice Disorders</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09702v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09702v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09702v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09702v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09652v1"
                     data-domains="Personalized Medicine,Critical Care Management,Drug Dosing Optimization,Treatment Protocol Design,Disease Management,Medical Robotics (e.g., surgery with safety constraints)"
                     data-keywords="Reinforcement Learning,Risk Sensitivity,Quantile Optimization,Markov Decision Processes,Optimistic Learning,Regret Bound,Healthcare AI,Clinical Decision Support"
                     data-authors="Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09652v1.html">Optimistic Reinforcement Learning with Quantile Objectives</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Alipour-Vaezi, Huaiyang Zhong, Kwok-Leung Tsui et al.
                </div>

                <div class="paper-summary">
                    This paper introduces UCB-QRL, an optimistic Reinforcement Learning algorithm designed to optimize the $\tau$-quantile of cumulative reward in finite-horizon Markov Decision Processes (MDPs). Addressing the classical RL's lack of risk sensitivity, UCB-QRL iteratively estimates transition probabilities and optimizes the quantile value function within a confidence ball. The algorithm provides a high-probability regret bound, making it suitable for risk-averse applications like healthcare and finance.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Critical Care Management</span>
                    
                    <span class="domain-tag">Drug Dosing Optimization</span>
                    
                    <span class="domain-tag">Treatment Protocol Design</span>
                    
                    <span class="domain-tag">Disease Management</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09652v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09652v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09652v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09652v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09540v2"
                     data-domains="Diagnostic Imaging,Medical AI,Radiology,Pathology,Biomedical Informatics,Computer-Aided Diagnosis"
                     data-keywords="vMFCoOp,Prompt Learning,Biomedical VLMs,Hyperspherical Manifold,von Mises-Fisher Distribution,Few-Shot Learning,Semantic Alignment,Medical Imaging"
                     data-authors="Minye Shao,Sihan Guo,Xinrun Li,Xingyu Miao,Haoran Duan,Yang Long">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09540v2.html">vMFCoOp: Towards Equilibrium on a Unified Hyperspherical Manifold for Prompting Biomedical VLMs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Minye Shao, Sihan Guo, Xinrun Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces vMFCoOp, a novel framework designed to enhance prompt learning for biomedical Vision-Language Models (VLMs) by addressing semantic misalignment and scalability issues between LLMs and CLIP variants. It achieves robust biomedical prompting and superior few-shot classification by inversely estimating von Mises-Fisher (vMF) distributions on a shared Hyperspherical Manifold, leveraging Unified Semantic Anchors for alignment. vMFCoOp consistently outperforms state-of-the-art methods across diverse medical datasets, modalities, and anatomical regions, demonstrating significant improvements in accuracy, generalization, and clinical applicability.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09540v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09540v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09540v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09540v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09529v1"
                     data-domains="Pharmacology,Medicinal Chemistry,Drug Development,Structural Biology,Computational Biology"
                     data-keywords="Ligand design,Drug discovery,Generative AI,Diffusion models,Protein-ligand interaction,SMILES,Computational chemistry,Molecular generation"
                     data-authors="Samyak Sanghvi,Nishant Ranjan,Tarak Karmakar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09529v1.html">SiDGen: Structure-informed Diffusion for Generative modeling of Ligands for Proteins</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Samyak Sanghvi, Nishant Ranjan, Tarak Karmakar
                </div>

                <div class="paper-summary">
                    SiDGen is a novel protein-conditioned diffusion framework designed to overcome bottlenecks in computational drug discovery by generating chemically valid and protein-pocket compatible ligands. It integrates masked SMILES generation with lightweight structural features, offering two conditioning modes and employing efficiency enhancements like coarse-stride folding and optimized training. The framework achieves scalable, high-throughput molecular design, demonstrating high validity, uniqueness, and novelty in generated ligands, along with competitive docking performance and good molecular properties.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Drug Development</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09529v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09529v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09529v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09529v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09497v1"
                     data-domains="Rehabilitation Medicine,Assistive Technology,Robotics in Healthcare,Geriatric Care,Physical Therapy"
                     data-keywords="Physical AI,Embodied Intelligence,Rehabilitation Robotics,Assistive Technology,Sensorimotor Learning,Adaptive Systems,Human-Robot Interaction"
                     data-authors="Vahid Salehi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09497v1.html">Fundamentals of Physical AI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Vahid Salehi
                </div>

                <div class="paper-summary">
                    This paper introduces the fundamental principles of Physical Artificial Intelligence (Physical AI), proposing a theoretical framework that views intelligence as an emergent phenomenon derived from the real-world interaction of a system's body, environment, and experience. It outlines six interconnected principles‚Äîembodiment, sensory perception, motor action, learning, autonomy, and context sensitivity‚Äîwhich form a closed control loop enabling systems to generate meaning from physical experience rather than static data. This paradigm shifts the understanding of intelligence to an embodied process, illustrated by an adaptive rehabilitation robot.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation Medicine</span>
                    
                    <span class="domain-tag">Assistive Technology</span>
                    
                    <span class="domain-tag">Robotics in Healthcare</span>
                    
                    <span class="domain-tag">Geriatric Care</span>
                    
                    <span class="domain-tag">Physical Therapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09497v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09497v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09497v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09497v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09468v1"
                     data-domains="Radiation oncology,Medical physics,Nuclear medicine,Cancer therapy,Diagnostic imaging"
                     data-keywords="Proton therapy,Beta-plus emitters,Nuclear reactions,Cross section,In-beam PET,Radioisotopes,Range verification,Medical physics"
                     data-authors="Izabela Skwira-Chalot,Przemys≈Çaw Sekowski,Agata Taranienko,Adam Spyra,Tomasz Matulewicz,Jan Swako≈Ñ,Joanna Matulewicz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09468v1.html">$Œ≤^+$ radioactive nuclei created during proton therapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ nucl-ex</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Izabela Skwira-Chalot, Przemys≈Çaw Sekowski, Agata Taranienko et al.
                </div>

                <div class="paper-summary">
                    This research paper investigates the nuclear reactions occurring during proton therapy, specifically focusing on the production of short-lived $Œ≤^+$ emitting radioisotopes like $^{11}$C, $^{13}$N, and $^{15}$O. The authors measured the cross sections for the creation of these isotopes using various target materials relevant to biological tissues (C, BN, SiO$_2$). Their experimental results, obtained with proton beams below 58 MeV, precisely follow previously established excitation functions with high accuracy (a few percent uncertainty), contributing crucial data for in-beam Positron Emission Tomography (PET) applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation oncology</span>
                    
                    <span class="domain-tag">Medical physics</span>
                    
                    <span class="domain-tag">Nuclear medicine</span>
                    
                    <span class="domain-tag">Cancer therapy</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09468v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09468v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09468v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09468v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09605v1"
                     data-domains="Diagnostic Imaging,Oncology,Radiology,Medical AI,Computational Pathology"
                     data-keywords="3D Medical Image Classification,Omnidirectional Slicing,Graph Neural Networks,Vision Foundation Models,Tomography,Tumor Characterization,Spatial Coherence,Automated Diagnosis"
                     data-authors="Johannes Kiechle,Stefan M. Fischer,Daniel M. Lang,Cosmin I. Bercea,Matthew J. Nyflot,Lina Felsner,Julia A. Schnabel,Jan C. Peeken">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09605v1.html">TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Johannes Kiechle, Stefan M. Fischer, Daniel M. Lang et al.
                </div>

                <div class="paper-summary">
                    TomoGraphView introduces a novel framework for 3D medical image classification that addresses the limitations of conventional slice-based methods by integrating omnidirectional volume slicing with spherical graph-based feature aggregation. This approach leverages powerful 2D vision foundation models for feature extraction, aiming to more comprehensively capture complex spatial relationships and preserve volumetric coherence in medical tomography data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09605v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09605v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09605v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09605v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09443v1"
                     data-domains="Pulmonology,Interventional Radiology,Thoracic Surgery,Medical Imaging,Oncology"
                     data-keywords="Bronchoscopy,Navigation,Pose Optimization,2D-3D Registration,Vision-Based,Deep Learning,Synthetic Data,Medical Robotics"
                     data-authors="Hongchao Shu,Roger D. Soberanis-Mukul,Jiru Xu,Hao Ding,Morgan Ringel,Mali Shen,Saif Iftekar Sayed,Hedyeh Rafii-Tari,Mathias Unberath">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09443v1.html">BronchOpt : Vision-Based Pose Optimization with Fine-Tuned Foundation Models for Accurate Bronchoscopy Navigation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Hongchao Shu, Roger D. Soberanis-Mukul, Jiru Xu et al.
                </div>

                <div class="paper-summary">
                    This paper introduces BronchOpt, a vision-based pose optimization framework designed for accurate intra-operative bronchoscope tip localization, addressing challenges like respiratory motion and anatomical variability. It employs a fine-tuned, domain-invariant encoder and differentiable rendering for frame-wise 2D-3D registration between real endoscopic views and pre-operative CT scans. The framework, trained on a novel synthetic benchmark dataset, achieves precise localization (2.65 mm, 0.19 rad error on synthetic data) and demonstrates strong cross-domain generalization to real patient data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pulmonology</span>
                    
                    <span class="domain-tag">Interventional Radiology</span>
                    
                    <span class="domain-tag">Thoracic Surgery</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09443v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09443v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09443v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09443v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09404v1"
                     data-domains="Healthcare monitoring,Biomedical informatics,Digital health,Patient data privacy,Personalized medicine"
                     data-keywords="Spatio-temporal graphs,Graph unlearning,Machine unlearning,Privacy regulations,Healthcare monitoring,GDPR,CallosumNet,Deep learning"
                     data-authors="Qiming Guo,Wenbo Sun,Wenlu Wang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09404v1.html">Spatio-Temporal Graph Unlearning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qiming Guo, Wenbo Sun, Wenlu Wang
                </div>

                <div class="paper-summary">
                    This paper introduces CallosumNet, a novel spatio-temporal graph unlearning framework designed to efficiently remove specific data from complex dynamic models while complying with stringent privacy regulations like GDPR. Inspired by the brain's corpus callosum, CallosumNet uses a divide-and-conquer approach with Enhanced Subgraph Construction and Global Ganglion Bridging to achieve complete data unlearning with minimal accuracy loss, significantly outperforming existing methods.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Healthcare monitoring</span>
                    
                    <span class="domain-tag">Biomedical informatics</span>
                    
                    <span class="domain-tag">Digital health</span>
                    
                    <span class="domain-tag">Patient data privacy</span>
                    
                    <span class="domain-tag">Personalized medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09404v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09404v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09404v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09404v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09383v1"
                     data-domains="Nuclear Medicine,Medical Imaging,Oncology,Radiology"
                     data-keywords="PET imaging,Sinogram interpolation,Limited angle PET,Diffusion models,Generative models,Machine learning,Undersampling,Medical imaging"
                     data-authors="R√ºveyda Yilmaz,Julian Thull,Johannes Stegmaier,Volkmar Schulz">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09383v1.html">Diffusion-based Sinogram Interpolation for Limited Angle PET</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> R√ºveyda Yilmaz, Julian Thull, Johannes Stegmaier et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel approach to address the challenge of undersampled sinograms in PET imaging arising from unconstrained and limited-angle detector geometries. By treating missing lines-of-responses as a learnable prior, the authors explore the use of conditional diffusion models to interpolate sparsely sampled sinograms. This method aims to enable the development of more cost-efficient and patient-friendly PET scanner designs without compromising image quality.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Nuclear Medicine</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09383v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09383v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09383v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09383v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.09376v1"
                     data-domains="Diagnostic Support,Prognostic Prediction,Personalized Medicine,Treatment Outcome Prediction,Risk Stratification,Drug Discovery"
                     data-keywords="SHAP,Interpretability,Decision Trees,Machine Learning,Game Theory,Boolean Logic,GPU Acceleration,Feature Importance,Clinical Prediction Models"
                     data-authors="Alexander Nadel,Ron Wettenstein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.09376v1.html">From Decision Trees to Boolean Logic: A Fast and Unified SHAP Algorithm</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-12</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Alexander Nadel, Ron Wettenstein
                </div>

                <div class="paper-summary">
                    WOODELF is a novel SHAP algorithm that unifies decision trees, game theory, and Boolean logic to significantly accelerate the computation of feature contributions for machine learning models. It constructs a pseudo-Boolean formula for each prediction instance, enabling linear-time Background SHAP calculation and demonstrating up to 165x speedups on GPUs over existing methods, making large-scale model interpretability practical. This design also allows for the computation of other game-theoretic values like interaction effects.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Support</span>
                    
                    <span class="domain-tag">Prognostic Prediction</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Treatment Outcome Prediction</span>
                    
                    <span class="domain-tag">Risk Stratification</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.09376v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.09376v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.09376v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.09376v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-16 06:25:36</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>