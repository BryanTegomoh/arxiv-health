<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">50</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">50</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">153</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Radiology (9), Public Health (9), Oncology (9)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Radiology">Radiology (9)</option>
                        
                        <option value="Public Health">Public Health (9)</option>
                        
                        <option value="Oncology">Oncology (9)</option>
                        
                        <option value="Diagnostic Imaging">Diagnostic Imaging (8)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (6)</option>
                        
                        <option value="Pathology">Pathology (5)</option>
                        
                        <option value="Neurology">Neurology (5)</option>
                        
                        <option value="Geriatrics">Geriatrics (4)</option>
                        
                        <option value="Medical Physics">Medical Physics (4)</option>
                        
                        <option value="Orthopedics">Orthopedics (3)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2511.17485v1"
                     data-domains="Radiology,Orthopedics,Geriatrics,Preventive Medicine,Biomechanics"
                     data-keywords="Spine Aging,MRI,Deep Learning,Spine Age Gap,Biomarker,Degenerative Spine Conditions,Computer Vision,UMAP"
                     data-authors="Roozbeh Bazargani,Saqib Abdullah Basar,Daniel Daly-Grafstein,Rodrigo Solis Pompa,Soojin Lee,Saurabh Garg,Yuntong Ma,John A. Carrino,Siavash Khallaghi,Sam Hashemi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17485v1.html">An Artificial Intelligence Framework for Measuring Human Spine Aging Using MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roozbeh Bazargani, Saqib Abdullah Basar, Daniel Daly-Grafstein et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel computer-vision-based deep learning framework to estimate human spine age using over 18,000 MRI series, specifically curating data for age-related degeneration via UMAP and HDBSCAN. The model's clinical utility is demonstrated by the Spine Age Gap (SAG), the difference between actual and predicted age, which shows significant associations with common degenerative spine conditions and lifestyle factors. This positions SAG as a potentially valuable biomarker for overall spine health.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17485v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17485v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17485v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17485v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17446v1"
                     data-domains="Public Health,Infectious Disease Epidemiology,Biodefense and Biosecurity,Environmental Health Monitoring,Clinical Microbiology (Diagnostics)"
                     data-keywords="MALDI-MS,Aerosol Mass Spectrometry,Pathogen Identification,Transformer Networks,Singular Value Decomposition,Real-time Monitoring,Biodefense,Environmental Surveillance"
                     data-authors="Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17446v1.html">Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Kyle M. Regan, Michael McLoughlin, Wayne A. Bryden et al.
                </div>

                <div class="paper-summary">
                    This paper introduces the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer), a data-driven framework designed to enable real-time, autonomous pathogen identification from noisy, single-shot aerosol mass spectrometry data. By leveraging a transformer architecture with a novel SVD-enhanced dictionary encoder, the MS-DGFormer overcomes traditional MALDI-MS limitations, facilitating rapid environmental monitoring and response to biological threats in field conditions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Biodefense and Biosecurity</span>
                    
                    <span class="domain-tag">Environmental Health Monitoring</span>
                    
                    <span class="domain-tag">Clinical Microbiology (Diagnostics)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17446v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17446v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17446v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17446v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17421v1"
                     data-domains="Radiology,Dermatology,Medical Imaging Diagnostics,Artificial Intelligence in Medicine"
                     data-keywords="Shortcut learning,Knowledge distillation,Medical image analysis,Bias mitigation,Deep learning robustness,Intermediate layers,Clinical relevance,Out-of-distribution"
                     data-authors="Christopher Boland,Sotirios Tsaftaris,Sonia Dahdouh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17421v1.html">Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Christopher Boland, Sotirios Tsaftaris, Sonia Dahdouh
                </div>

                <div class="paper-summary">
                    This paper addresses the critical issue of shortcut learning in deep learning models for medical image analysis, where models may use irrelevant features leading to poor robustness and potential harm. The authors propose a novel knowledge distillation framework that leverages a specialist teacher network (fine-tuned on a small, task-relevant dataset) to mitigate shortcut learning in a student network trained on a large, biased dataset. Their approach, which targets intermediate network layers, consistently outperforms traditional bias mitigation methods and achieves performance comparable to models trained on bias-free data, even on out-of-distribution datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Medical Imaging Diagnostics</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17421v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17421v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17421v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17421v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17392v1"
                     data-domains="Neuroimaging (Brain MRI),Abdominal Imaging (Liver CT, Abdomen MR-CT),Oncology (implied by liver CT for tumor tracking),Radiology,Radiation Oncology"
                     data-keywords="Deformable Image Registration,Reinforcement Learning,Policy Optimization,Latent Representation,Medical Image Analysis,Dice Score,Label Efficiency,Spatially Coherent"
                     data-authors="Runxun Zhang,Yizhou Liu,Li Dongrui,Bo XU,Jingwei Wei">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17392v1.html">MorphSeek: Fine-grained Latent Representation-Level Policy Optimization for Deformable Image Registration</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Runxun Zhang, Yizhou Liu, Li Dongrui et al.
                </div>

                <div class="paper-summary">
                    MorphSeek proposes a novel fine-grained latent representation-level policy optimization paradigm for Deformable Image Registration (DIR), addressing the challenges of high-dimensional deformation spaces and scarce voxel-level supervision. It reformulates DIR as a spatially continuous optimization in the latent feature space, leveraging a stochastic Gaussian policy head and Group Relative Policy Optimization for efficient exploration and label-efficient training. The framework consistently improves registration accuracy (Dice scores) over baselines across multiple 3D medical imaging benchmarks while maintaining high efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroimaging (Brain MRI)</span>
                    
                    <span class="domain-tag">Abdominal Imaging (Liver CT, Abdomen MR-CT)</span>
                    
                    <span class="domain-tag">Oncology (implied by liver CT for tumor tracking)</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17392v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17392v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17392v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17392v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17355v1"
                     data-domains="Oncology,Pathology,Diagnostic Imaging,Computational Pathology"
                     data-keywords="tumor cell classification,radiomics,H&E images,Attention-Mamba,multimodal framework,image segmentation,deep learning,computational pathology"
                     data-authors="Taixi Chen,Jingyun Chen,Nancy Guo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17355v1.html">UAM: A Unified Attention-Mamba Backbone of Multimodal Framework for Tumor Cell Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Taixi Chen, Jingyun Chen, Nancy Guo
                </div>

                <div class="paper-summary">
                    This paper introduces UAM, a novel Unified Attention-Mamba backbone designed for cell-level tumor classification using radiomics features from H&E images, addressing the gap in dedicated backbones for radiomics data. The multimodal UAM framework flexibly combines Attention and Mamba architectures, achieving state-of-the-art performance in both cell classification and image segmentation. It significantly improves cell classification accuracy from 74% to 78% and tumor segmentation precision from 75% to 80% on public benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Computational Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17355v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17355v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17355v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17355v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17300v1"
                     data-domains="Pharmaceutical Research and Development,Drug Discovery,Computational Chemistry,Pharmacoinformatics,Medicinal Chemistry,Biomedical Data Science"
                     data-keywords="Optical Chemical Structure Recognition (OCSR),Stereochemistry,SMILES Pretraining,Multi-Granularity Learning,Reinforcement Learning (RL),Drug Discovery,Chemical Informatics,Deep Learning"
                     data-authors="Wenrui Zhang,Xinggang Wang,Bin Feng,Wenyu Liu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17300v1.html">MolSight: Optical Chemical Structure Recognition with SMILES Pretraining, Multi-Granularity Learning and Reinforcement Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Wenrui Zhang, Xinggang Wang, Bin Feng et al.
                </div>

                <div class="paper-summary">
                    MolSight introduces a novel, three-stage learning framework for Optical Chemical Structure Recognition (OCSR), specifically addressing the critical challenge of accurately recognizing subtle stereochemical information. By integrating SMILES pretraining, multi-granularity fine-tuning with auxiliary tasks, and reinforcement learning optimization, the system achieves state-of-the-art performance in converting chemical structure images into machine-readable representations. This advancement significantly enhances capabilities crucial for large-scale chemical data mining and drug discovery pipelines.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceutical Research and Development</span>
                    
                    <span class="domain-tag">Drug Discovery</span>
                    
                    <span class="domain-tag">Computational Chemistry</span>
                    
                    <span class="domain-tag">Pharmacoinformatics</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17300v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17300v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17300v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17300v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17265v1"
                     data-domains="Medical Imaging Analysis,Robotic Surgery,Real-time Patient Monitoring,Point-of-Care Diagnostics,Personalized Medicine"
                     data-keywords="Digital In-memory Computing,Stochastic Computing,Artificial Intelligence,Energy Efficiency,Matrix Multiplication,Edge AI,Bent-Pyramid Format,Healthcare AI"
                     data-authors="Shady Agwa,Yikang Shen,Shiwei Wang,Themis Prodromakis">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17265v1.html">DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ cs.AR</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Shady Agwa, Yikang Shen, Shiwei Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces DISCA, a novel digital in-memory stochastic computing architecture designed to address the energy efficiency challenges of large-scale AI models, particularly for data-intensive matrix multiplication tasks at the edge. Utilizing a compressed Bent-Pyramid data format, DISCA demonstrates significant energy efficiency gains, achieving 3.59 TOPS/W per bit at 500 MHz, making it highly promising for AI applications in various domains, including healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging Analysis</span>
                    
                    <span class="domain-tag">Robotic Surgery</span>
                    
                    <span class="domain-tag">Real-time Patient Monitoring</span>
                    
                    <span class="domain-tag">Point-of-Care Diagnostics</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17265v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17265v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17265v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17265v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17249v1"
                     data-domains="Pharmaceutical R&D,Medicinal Chemistry,Computational Drug Design,Structural Biology,Pharmacology"
                     data-keywords="molecular generation,conformational ensemble,flow matching,drug discovery,de novo design,3D molecular structures,ligand design,protein-conditioned generation"
                     data-authors="Riccardo Tedoldi,Ola Engkvist,Patrick Bryant,Hossein Azizpour,Jon Paul Janet,Alessandro Tibo">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17249v1.html">FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Riccardo Tedoldi, Ola Engkvist, Patrick Bryant et al.
                </div>

                <div class="paper-summary">
                    FlexiFlow introduces a novel architecture extending flow-matching models to enable the joint sampling of molecules with multiple low-energy conformations, addressing the limitation of existing models that generate only single conformations. This approach achieves state-of-the-art results in molecular generation tasks, effectively capturing conformational diversity, and demonstrates successful transfer to protein-conditioned ligand generation, crucial for advanced drug discovery.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pharmaceutical R&D</span>
                    
                    <span class="domain-tag">Medicinal Chemistry</span>
                    
                    <span class="domain-tag">Computational Drug Design</span>
                    
                    <span class="domain-tag">Structural Biology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17249v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17249v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17249v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17249v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17217v1"
                     data-domains="Radiology,Pathology,Ophthalmology,Microscopy,Ultrasound,Diagnostic Imaging"
                     data-keywords="Image Super-resolution,Domain Adaptation,Realistic SR,Medical Imaging,Low-rank Adaptation,Frequency Domain,Deep Learning"
                     data-authors="Chaowei Fang,Bolin Fu,De Cheng,Lechao Cheng,Guanbin Li">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17217v1.html">Dual-domain Adaptation Networks for Realistic Image Super-resolution</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.85</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Chaowei Fang, Bolin Fu, De Cheng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces Dual-domain Adaptation Networks (DAN), a novel approach for realistic image super-resolution that efficiently adapts pre-trained models from synthetic to real-world datasets. DAN employs both spatial-domain parameter adaptation, including low-rank adaptation (LoRA), and a unique frequency-domain branch to recover high-frequency details. Experimental evaluations demonstrate the superiority of DAN over existing state-of-the-art models on public realistic SR benchmarks, offering significant implications for applications like medical imaging.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Microscopy</span>
                    
                    <span class="domain-tag">Ultrasound</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17217v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17217v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17217v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17217v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17209v1"
                     data-domains="Radiology,Diagnostic Imaging,Medical AI,Computational Medicine"
                     data-keywords="Volumetric CT,Foundation Model,Vision Transformer,Self-Supervised Learning,Vision-Language Pretraining,Radiology,Medical Imaging,3D Attention"
                     data-authors="Cris Claessens,Christiaan Viviers,Giacomo D'Amicantonio,Egor Bondarev,Fons van der Sommen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17209v1.html">Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Cris Claessens, Christiaan Viviers, Giacomo D'Amicantonio et al.
                </div>

                <div class="paper-summary">
                    SPECTRE introduces a novel, fully transformer-based foundation model for volumetric computed tomography (CT), specifically designed to overcome challenges like extreme token scaling and geometric anisotropy. It utilizes a hybrid architecture of local and global transformers combined with DINO-style self-distillation and SigLIP-based vision-language pretraining on open CT datasets. This approach yields general-purpose, clinically meaningful CT representations that consistently outperform prior foundation models in zero-shot and fine-tuned settings.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Medical AI</span>
                    
                    <span class="domain-tag">Computational Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17209v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17209v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17209v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17209v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17201v1"
                     data-domains="Medical Imaging,Diagnostic Imaging,Image-Guided Surgery (implied)"
                     data-keywords="Medical Image Segmentation,Continual Learning,Catastrophic Forgetting,Segment Anything Model (SAM),Alignment Layer,Foundation Models,Privacy-Preserving AI,State-of-the-Art"
                     data-authors="Jiayi Wang,Wei Dai,Haoyu Wang,Sihan Yang,Haixia Bi,Jian Sun">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17201v1.html">Continual Alignment for SAM: Rethinking Foundation Models for Medical Image Segmentation in Continual Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jiayi Wang, Wei Dai, Haoyu Wang et al.
                </div>

                <div class="paper-summary">
                    This paper introduces CA-SAM, a continual learning strategy built upon the Segment Anything Model (SAM) and a novel lightweight Alignment Layer, to address the challenges of medical image segmentation under privacy-constrained, continual learning scenarios. CA-SAM effectively mitigates catastrophic forgetting and leverages SAM's zero-shot priors, demonstrating state-of-the-art performance across nine medical segmentation datasets while significantly improving computational efficiency.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Image-Guided Surgery (implied)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17201v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17201v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17201v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17201v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17176v1"
                     data-domains="Public Health,Emergency Medicine,Environmental Health,Disaster Preparedness,Epidemiology,Climate Change Health"
                     data-keywords="AI weather prediction,Extreme events,Uncertainty quantification,Ensemble forecasting,Heatwave,Floods,Public health,Early warning systems"
                     data-authors="Rodrigo Almeida,Noelia Otero,Miguel-√Ångel Fern√°ndez-Torres,Jackie Ma">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17176v1.html">On the Predictive Skill of Artificial Intelligence-based Weather Models for Extreme Events using Uncertainty Quantification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ physics.ao-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rodrigo Almeida, Noelia Otero, Miguel-√Ångel Fern√°ndez-Torres et al.
                </div>

                <div class="paper-summary">
                    This study investigates how state-of-the-art deterministic AI-based weather models can be extended towards probabilistic forecasting of extreme events through initial-condition perturbations. By generating 50-member ensembles for major 2022 events (Pakistan floods, China heatwave), the research demonstrates that flow-dependent perturbations significantly enhance ensemble spread realism and probabilistic skill, narrowing but not fully closing the performance gap with traditional numerical weather prediction ensembles.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Emergency Medicine</span>
                    
                    <span class="domain-tag">Environmental Health</span>
                    
                    <span class="domain-tag">Disaster Preparedness</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17176v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17176v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17176v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17176v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17158v1"
                     data-domains="Oncology,Diagnostic Radiology,Medical Imaging,Pathology,Computational Biology"
                     data-keywords="Breast Cancer,Neoadjuvant Chemotherapy,Pathological Complete Response,MRI,BI-RADS,Machine Learning,Tumor-Infiltrating Lymphocytes,Prognostic Biomarkers"
                     data-authors="Caroline Malhaire,Fatine Selhane,Marie-Judith Saint-Martin,Vincent Cockenpot,Pia Akl,Enora Laas,Audrey Bellesoeur,Catherine Ala Eddine,Melodie Bereby-Kahane,Julie Manceau,Delphine Sebbag-Sfez,Jean-Yves Pierga,Fabien Reyal,Anne Vincent-Salomon,Herve Brisse,Frederique Frouin">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17158v1.html">Exploring the added value of pretherapeutic MR descriptors in predicting breast cancer pathologic complete response to neoadjuvant chemotherapy</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Caroline Malhaire, Fatine Selhane, Marie-Judith Saint-Martin et al.
                </div>

                <div class="paper-summary">
                    This study evaluated pretreatment MRI descriptors in predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC) in breast cancer (BC) patients. It found that specific MRI features, particularly unifocality and non-spiculated margins, were independently associated with pCR and significantly enhanced the performance of machine learning models when combined with clinicobiological variables.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Computational Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17158v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17158v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17158v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17158v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17155v1"
                     data-domains="radiology,cardiology,obstetrics and gynecology,emergency medicine,point-of-care ultrasound"
                     data-keywords="ultrasound imaging,domain adaptation,image style transfer,unpaired image translation,cross-device diagnosis,class-aware prompting,black-box inference,medical AI"
                     data-authors="Nhat-Tuong Do-Tran,Ngoc-Hoang-Lam Le,Ching-Chun Huang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17155v1.html">UI-Styler: Ultrasound Image Style Transfer with Class-Aware Prompts for Cross-Device Diagnosis Using a Frozen Black-Box Inference Network</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nhat-Tuong Do-Tran, Ngoc-Hoang-Lam Le, Ching-Chun Huang
                </div>

                <div class="paper-summary">
                    This paper introduces UI-Styler, a novel ultrasound image style transfer framework designed to address domain shifts caused by variations in acquisition devices. By leveraging a pattern-matching mechanism and a class-aware prompting strategy guided by pseudo labels, UI-Styler effectively aligns statistical distributions and enforces accurate semantic content alignment, enabling robust cross-device diagnosis using pre-trained black-box inference models. The method achieves state-of-the-art performance in distribution distance and improves downstream tasks like classification and segmentation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">radiology</span>
                    
                    <span class="domain-tag">cardiology</span>
                    
                    <span class="domain-tag">obstetrics and gynecology</span>
                    
                    <span class="domain-tag">emergency medicine</span>
                    
                    <span class="domain-tag">point-of-care ultrasound</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17155v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17155v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17155v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17155v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17146v1"
                     data-domains="Neuroradiology,Neurology,Medical Imaging,Diagnostic Imaging"
                     data-keywords="Cerebral lesions,Medical image segmentation,Instance-wise loss,CC-DiceCE,Deep learning,Recall,False positives,nnU-Net,Neuroimaging"
                     data-authors="Luc Bouteille,Alexander Jaus,Jens Kleesiek,Rainer Stiefelhagen,Lukas Heine">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17146v1.html">Learning to Look Closer: A New Instance-Wise Loss for Small Cerebral Lesion Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Luc Bouteille, Alexander Jaus, Jens Kleesiek et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the challenge of under-segmentation of small cerebral lesions by traditional loss functions in medical image analysis. It introduces CC-DiceCE, a novel instance-wise loss function designed to improve detection on a per-lesion basis. The study demonstrates that CC-DiceCE significantly increases lesion detection (recall) with minimal impact on segmentation quality, outperforming existing methods like blob loss, albeit with a slight increase in false positives.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17146v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17146v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17146v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17146v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17094v1"
                     data-domains="Patient Monitoring,Elderly Care,Surgical Assistance,Rehabilitation,Telemedicine,Clinical Surveillance"
                     data-keywords="Video Anomaly Detection,Sparse Reasoning,Large Pre-trained Models,Biological-Inspired AI,CLIP,Vision-Language Models,Real-time Monitoring,Computational Efficiency"
                     data-authors="He Huang,Zixuan Hu,Dongxiao Li,Yao Xiao,Ling-Yu Duan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17094v1.html">Sparse Reasoning is Enough: Biological-Inspired Framework for Video Anomaly Detection with Large Pre-trained Models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.75</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> He Huang, Zixuan Hu, Dongxiao Li et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ReCoVAD, a biologically-inspired framework for training-free video anomaly detection (VAD) that leverages large pre-trained models with sparse reasoning. By mimicking the human nervous system's dual pathways, ReCoVAD selectively processes frames, significantly reducing computational load and latency. It achieves state-of-the-art performance while processing a fraction of the frames compared to existing dense inference methods, demonstrating the sufficiency of sparse reasoning for effective large-model-based VAD.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Patient Monitoring</span>
                    
                    <span class="domain-tag">Elderly Care</span>
                    
                    <span class="domain-tag">Surgical Assistance</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17094v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17094v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17094v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17094v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17068v1"
                     data-domains="Neuroradiology,Diagnostic Imaging,Neurology,Medical Physics"
                     data-keywords="MRI reconstruction,CT synthesis,sparse data,diffusion models,retrieval-augmented generation,brain imaging,medical imaging,cross-modal reconstruction"
                     data-authors="Junming Liu,Yifei Sun,Weihua Cheng,Yujin Kang,Yirong Chen,Ding Wang,Guosun Zeng">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17068v1.html">ReBrain: Brain MRI Reconstruction from Sparse CT Slice via Retrieval-Augmented Diffusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Junming Liu, Yifei Sun, Weihua Cheng et al.
                </div>

                <div class="paper-summary">
                    This paper introduces ReBrain, a novel retrieval-augmented diffusion framework designed to reconstruct full brain MRI volumes from highly sparse CT slices. It addresses the critical challenge of synthesizing diagnostic-quality MRI when direct MRI scanning is unfeasible, achieving state-of-the-art performance in cross-modal reconstruction under sparse conditions by combining 2D diffusion generation with structural guidance from retrieved similar slices.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17068v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17068v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17068v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17068v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17056v1"
                     data-domains="Clinical Informatics,Medical Data Science,Decision Support Systems,Health Information Technology,Precision Medicine"
                     data-keywords="EHRs,Information Extraction,Bayesian Networks,Neural Text Classifiers,Multi-modal Data,Clinical Decision Support,Data Fusion,Medical Informatics"
                     data-authors="Paloma Rabaey,Adrick Tench,Stefan Heytens,Thomas Demeester">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17056v1.html">Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Paloma Rabaey, Adrick Tench, Stefan Heytens et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a multi-modal information extraction method for Electronic Health Records (EHRs), integrating structured tabular data with unstructured clinical notes. It leverages expert-informed Bayesian networks for tabular features and neural text classifiers for text, fusing their predictions using virtual evidence augmented with a novel consistency node. The approach aims to create large, structured datasets for transparent clinical decision support systems, demonstrating improved prediction calibration and robustness to missing information and contradictions on a simulated benchmark.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Medical Data Science</span>
                    
                    <span class="domain-tag">Decision Support Systems</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17056v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17056v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17056v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17056v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17052v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Jingyun Chen,Linghan Cai,Zhikang Wang,Yi Huang,Songhan Jiang,Shenjin Huang,Hongpeng Wang,Yongbing Zhang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17052v1.html">PathAgent: Toward Interpretable Analysis of Whole-slide Pathology Images via Large Language Model-based Agentic Reasoning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Jingyun Chen, Linghan Cai, Zhikang Wang et al.
                </div>

                <div class="paper-summary">
                    Analyzing whole-slide images (WSIs) requires an iterative, evidence-driven reasoning process that parallels how pathologists dynamically zoom, refocus, and self-correct while collecting the evidence. However, existing computational pipelines often lack this explicit reasoning trajectory, resulting i...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17052v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17052v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17052v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17052v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.17043v1"
                     data-domains="Radiology,Diagnostic Imaging,Artificial Intelligence in Medicine,Medical Informatics"
                     data-keywords="Chest X-ray,Thoracic Diagnosis,Medical Imaging,Foundational Model,Deep Learning,Radiologist Workload,PACS,Binary Classification"
                     data-authors="Rama Krishna Boya,Mohan Kireeti Magalanadu,Azaruddin Palavalli,Rupa Ganesh Tekuri,Amrit Pattanayak,Prasanthi Enuga,Vignesh Esakki Muthu,Vivek Aditya Boya">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.17043v1.html">MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rama Krishna Boya, Mohan Kireeti Magalanadu, Azaruddin Palavalli et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal or Abnormal categories to address increasing radiologist workload. The fine-tuned MedImageInsight achieved superior performance with an ROC-AUC of 0.888 and better calibration compared to transfer learning approaches, demonstrating its effectiveness in reducing training requirements while maintaining diagnostic reliability comparable to established models like CheXNet.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.17043v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.17043v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.17043v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.17043v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16982v1"
                     data-domains="Radiology,Pathology,Dermatology,Ophthalmology,Oncology"
                     data-keywords="Deep Learning,Ensemble Learning,Diversity Optimization,Image Classification,Synergistic Diversity,Medical Imaging AI,Convolutional Neural Networks,Diagnostic Accuracy"
                     data-authors="Sai Nath Chowdary Medikonduru,Hongpeng Jin,Yanzhao Wu">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16982v1.html">A Diversity-optimized Deep Ensemble Approach for Accurate Plant Leaf Disease Detection</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Sai Nath Chowdary Medikonduru, Hongpeng Jin, Yanzhao Wu
                </div>

                <div class="paper-summary">
                    This paper introduces the Synergistic Diversity (SQ) framework, a novel metric for optimizing deep neural network ensembles to enhance prediction accuracy, specifically for plant leaf disease detection. It addresses the limitations of existing ensemble diversity metrics that often fail to select optimal ensemble teams, demonstrating that SQ consistently aligns with and improves ensemble accuracy. The research paves the way for more reliable and efficient image-based disease detection by improving ensemble selection.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Dermatology</span>
                    
                    <span class="domain-tag">Ophthalmology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16982v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16982v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16982v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16982v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16933v1"
                     data-domains="cs.LG"
                     data-keywords="cs.LG,q-bio.QM"
                     data-authors="Angelina Yan,Matt L. Sampson,Peter Melchior">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16933v1.html">A novel approach to classification of ECG arrhythmia types with latent ODEs</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-21</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Angelina Yan, Matt L. Sampson, Peter Melchior
                </div>

                <div class="paper-summary">
                    12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, mak...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.LG</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16933v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16933v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16933v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16933v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16858v1"
                     data-domains="Digital Health,Medical Devices,Health Informatics,Clinical Decision Support Systems,Biomedical Engineering,Pharmaceutical Research (software tools)"
                     data-keywords="Automated Program Repair,Large Language Models,Test Overfitting,Software Reliability,Code Generation,SWE-bench,Hidden Tests,AI in Software Engineering"
                     data-authors="Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16858v1.html">Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.SE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Toufique Ahmed, Jatin Ganhotra, Avraham Shinnar et al.
                </div>

                <div class="paper-summary">
                    This paper investigates the persistent problem of test overfitting in Automated Program Repair (APR), specifically examining its prevalence when Large Language Models (LLMs) are used to generate code fixes. The study experimentally assesses if LLM-based repairs pass known tests but fail on hidden, hold-out tests, utilizing repository-level SWE-bench tasks to determine how significant this issue remains today. It highlights the risk that an automated 'fix' might be brittle, ultimately being 'worse than the disease' by introducing subtle, undetected failures.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Digital Health</span>
                    
                    <span class="domain-tag">Medical Devices</span>
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Clinical Decision Support Systems</span>
                    
                    <span class="domain-tag">Biomedical Engineering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16858v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16858v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16858v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16858v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16856v1"
                     data-domains="Neurology,Neurodegeneration,Speech-Language Pathology,Diagnostic Medicine,Telemedicine"
                     data-keywords="Parkinson's Disease,Vocal Biomarkers,Deep Neural Network,Machine Learning,Early Detection,Hypophonia,Dysarthria,MFCCs"
                     data-authors="Katia Pires Nascimento do Sacramento,Elliot Q. C. Garcia,Nic√©ias Silva Vilela,Vinicius P. Sacramento,Tiago A. E. Ferreira">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16856v1.html">The use of vocal biomarkers in the detection of Parkinson's disease: a robust statistical performance comparison of classic machine learning models</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Katia Pires Nascimento do Sacramento, Elliot Q. C. Garcia, Nic√©ias Silva Vilela et al.
                </div>

                <div class="paper-summary">
                    This cross-sectional study demonstrates the superior performance of Deep Neural Networks (DNNs) over traditional Machine Learning (ML) models in detecting Parkinson's disease (PD) using vocal biomarkers. Achieving high accuracies of up to 98.65%, the research highlights the potential of DNNs to provide an accurate, reliable, non-invasive, and cost-effective method for early diagnosis of neurodegenerative disorders.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurodegeneration</span>
                    
                    <span class="domain-tag">Speech-Language Pathology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Telemedicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16856v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16856v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16856v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16856v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16854v1"
                     data-domains="Radiology,Neuroradiology,Oncology,Cardiology,Orthopedics,Neurology,Medical Physics,Biomedical Engineering"
                     data-keywords="MRI,Super-Resolution,Deep Learning,Computational Imaging,Inverse Problem,Medical Imaging,Diagnostic Imaging,Image Reconstruction"
                     data-authors="Mohammad Khateri,Serge Vasylechko,Morteza Ghahremani,Liam Timms,Deniz Kocanaogullari,Simon K. Warfield,Camilo Jaimes,Davood Karimi,Alejandra Sierra,Jussi Tohka,Sila Kurugol,Onur Afacan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16854v1.html">MRI Super-Resolution with Deep Learning: A Comprehensive Survey</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani et al.
                </div>

                <div class="paper-summary">
                    This paper provides a comprehensive survey of deep learning-based super-resolution (SR) techniques applied to Magnetic Resonance Imaging (MRI). It systematically reviews recent advancements, proposing a taxonomy for these methods while examining their theoretical foundations, architectural designs, and learning strategies to overcome the technical and cost constraints of acquiring high-resolution MRI. The ultimate goal is to improve diagnostic accuracy and efficiency without requiring additional hardware.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Neuroradiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Orthopedics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16854v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16854v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16854v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16854v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16845v1"
                     data-domains="Medical imaging,Medical diagnosis,Clinical decision support"
                     data-keywords="Conformal Prediction,Ordinal Classification,Uncertainty Quantification,Minimum-Length Prediction Sets,Model-Agnostic,Sliding-Window Algorithm,Predictive Efficiency,Medical Diagnosis"
                     data-authors="Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16845v1.html">Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zijian Zhang, Xinyu Chen, Yuanjie Shi et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel, model-agnostic conformal prediction method for ordinal classification that generates provably minimum-length prediction sets at the instance level. By formulating the problem as a minimum-length covering problem and employing a linear-time sliding-window algorithm, the method significantly improves predictive efficiency, demonstrating an average 15% reduction in prediction set size while maintaining statistically valid coverage guarantees. This advancement is particularly crucial for high-stakes applications such as medical diagnosis and imaging, where reliable uncertainty quantification is essential.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical imaging</span>
                    
                    <span class="domain-tag">Medical diagnosis</span>
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16845v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16845v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16845v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16845v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16839v1"
                     data-domains="Cardiology,Internal Medicine,Hospital Medicine,Clinical Informatics,Public Health"
                     data-keywords="Heart Failure,Clinical Prediction,Electronic Health Records,Sequence Modeling,Transformers,Mamba,Llama,Machine Learning,Ablation Study,Mortality Prediction"
                     data-authors="Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sj√∂land">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16839v1.html">Analysis of heart failure patient trajectories using sequence modeling</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Falk Dippela, Yinan Yu, Annika Rosengren et al.
                </div>

                <div class="paper-summary">
                    This paper conducts a systematic empirical analysis of six advanced sequence models (Transformers, Transformers++, Mambas) for three one-year clinical prediction tasks in a large heart failure cohort using electronic health records (EHRs). It demonstrates that Llama-based Transformer++ and Mamba architectures achieve superior predictive discrimination, calibration, and efficiency, outperforming other Transformers even with smaller configurations or less training data.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Hospital Medicine</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16839v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16839v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16839v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16839v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16832v1"
                     data-domains="Public Health,Vaccinology,Epidemiology,Health Communication,Behavioral Health,Preventive Medicine"
                     data-keywords="vaccine discourse,social media,COVID-19,sentiment analysis,vaccine hesitancy,X (Twitter),public health communication,computational social science"
                     data-authors="Nikesh Gyawali,Doina Caragea,Cornelia Caragea,Saif M. Mohammad">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16832v1.html">The Shifting Landscape of Vaccine Discourse: Insights From a Decade of Pre- to Post-COVID-19 Vaccine Posts on Social Media</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.SI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nikesh Gyawali, Doina Caragea, Cornelia Caragea et al.
                </div>

                <div class="paper-summary">
                    This paper analyzes 18.7 million English-language X (formerly Twitter) posts from 2013-2022 to understand the evolving vaccine discourse from pre- to post-COVID-19 periods. It reveals complex shifts in user sentiment and language, showing an initial decrease in negative emotion words and a rise in trust and warmth-related language early in the pandemic. However, this was followed by a significant increase in negative sentiment towards the end of the studied period, indicating growing vaccine hesitancy and skepticism.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Vaccinology</span>
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Health Communication</span>
                    
                    <span class="domain-tag">Behavioral Health</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16832v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16832v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16832v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16832v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16823v1"
                     data-domains="Biosecurity,Public Health,Infectious Disease Epidemiology,Bioethics,Disaster Preparedness"
                     data-keywords="AI Safety,Biosecurity,LLMs,Risk Assessment,Threat Evaluation,Monte Carlo,AI Governance,Public Health"
                     data-authors="Joseph Kim,Saahith Potluri">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16823v1.html">Monte Carlo Expected Threat (MOCET) Scoring</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Joseph Kim, Saahith Potluri
                </div>

                <div class="paper-summary">
                    This paper introduces Monte Carlo Expected Threat (MOCET) Scoring, a novel metric designed to quantify real-world risks associated with advanced AI models, particularly ASL-3+ LLMs in biosecurity. MOCET aims to provide an interpretable, automatable, and open-ended framework to inform AI safety cases and keep pace with rapid AI advancements, addressing limitations of existing evaluation benchmarks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biosecurity</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Disease Epidemiology</span>
                    
                    <span class="domain-tag">Bioethics</span>
                    
                    <span class="domain-tag">Disaster Preparedness</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16823v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16823v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16823v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16823v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16802v1"
                     data-domains="Epidemiology,Public Health,Infectious Diseases,Vector Control,Mathematical Biology"
                     data-keywords="Mosquito-borne diseases,Epidemic modeling,Protective behavior,Information dynamics,Reproduction number,Geometric Singular Perturbation Theory,Vector-borne diseases,Public health"
                     data-authors="Simone De Reggi,Andrea Pugliese,Mattia Sensi,Cinzia Soresina">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16802v1.html">A model for mosquito-borne epidemic outbreaks with information-dependent protective behaviour</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Simone De Reggi, Andrea Pugliese, Mattia Sensi et al.
                </div>

                <div class="paper-summary">
                    This paper develops a mathematical model for mosquito-borne epidemic outbreaks that incorporates human protective behavior influenced by information on disease prevalence. It demonstrates that such information-dependent behavior can have complex and sometimes counterintuitive effects, potentially either containing an outbreak or, paradoxically, prolonging its duration and even inducing recurrent epidemic waves.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Epidemiology</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Vector Control</span>
                    
                    <span class="domain-tag">Mathematical Biology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16802v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16802v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16802v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16802v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16795v1"
                     data-domains="Pathology (e.g., whole slide image analysis for cancer detection),Radiology (e.g., lesion detection in image series, mammography),Ophthalmology (e.g., retinal disease screening),Dermatology (e.g., multi-view skin lesion classification)"
                     data-keywords="Multiple Instance Learning (MIL),Vector Symbolic Architectures (VSA),Medical Imaging,Deep Learning,Machine Learning,Interpretability,Diagnostic AI,Pathology"
                     data-authors="Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16795v1.html">A Vector Symbolic Approach to Multiple Instance Learning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ehsan Ahmed Dhrubo, Mohammad Mahmudul Alam, Edward Raff et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Multiple Instance Learning (MIL) framework using Vector Symbolic Architectures (VSAs) to strictly enforce the "iff" logical constraint often violated by deep learning MIL models. By encoding the MIL assumption through high-dimensional vector operations and employing a VSA-driven MaxNetwork classifier, the method achieves state-of-the-art results on standard and medical imaging datasets while providing a principled and interpretable alternative.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology (e.g., whole slide image analysis for cancer detection)</span>
                    
                    <span class="domain-tag">Radiology (e.g., lesion detection in image series, mammography)</span>
                    
                    <span class="domain-tag">Ophthalmology (e.g., retinal disease screening)</span>
                    
                    <span class="domain-tag">Dermatology (e.g., multi-view skin lesion classification)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16795v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16795v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16795v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16795v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16775v1"
                     data-domains="Radiation Oncology,Cardiology,Medical Physics,Radiotherapy"
                     data-keywords="Stereotactic Arrhythmia Radiotherapy,STAR,Ventricular Tachycardia,Cardiorespiratory Motion,Deformable Image Registration,4DCT,Principal Component Filtering,Motion Management"
                     data-authors="Yuhao Wang,Yao Hao,Hongyu An,H Michael Gach,Clifford Robinson,Phillip S Cuculich,Deshan Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16775v1.html">A Respiratory Motion Analysis for Guiding Stereotactic Arrhythmia Radiotherapy Motion Management</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuhao Wang, Yao Hao, Hongyu An et al.
                </div>

                <div class="paper-summary">
                    This paper introduces gCGF, a novel groupwise deformable image registration algorithm incorporating principal component filtering and spatial smoothing, designed to accurately quantify cardiac respiratory motion in r4DCTs for Stereotactic Arrhythmia Radiotherapy (STAR) patients. It effectively removes cardiac motion artifacts to isolate respiratory motion, demonstrating high precision on digital phantoms and providing detailed heart and VT target motion magnitudes in 20 STAR patients. The findings offer crucial insights for improving motion management in STAR.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Radiation Oncology</span>
                    
                    <span class="domain-tag">Cardiology</span>
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Radiotherapy</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16775v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16775v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16775v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16775v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16635v1"
                     data-domains="Oncology,Pathology,Genomics,Prognostics,Precision Medicine"
                     data-keywords="Survival analysis,Multi-agent system,Chain-of-Thought (CoT),Multimodal prediction,Whole Slide Imaging (WSI),Gene expression,Cancer prognosis,Explainable AI,Precision oncology,Case-based reasoning"
                     data-authors="Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16635v1.html">SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guolin Huang, Wenting Chen, Jiaqi Yang et al.
                </div>

                <div class="paper-summary">
                    SurvAgent is a pioneering hierarchical Chain-of-Thought (CoT)-enhanced multi-agent system designed for explainable and multimodal survival prediction in cancer. It constructs a rich case bank with detailed CoT reasoning from both whole slide images (WSI) and gene expression data, then employs a dichotomy-based multi-expert agent for progressive inference, demonstrating superior performance over existing methods on TCGA cohorts.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Genomics</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16635v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16635v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16635v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16635v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16633v1"
                     data-domains="Medical Physics,Diagnostic Imaging,Oncology (e.g., tumor characterization),Breast Imaging,Hepatology (e.g., liver fibrosis staging),Biomedical Engineering"
                     data-keywords="Quantitative Ultrasound Tomography,Ray-Born Inversion,Hessian-free,Sound Speed Reconstruction,Medical Imaging,Single Scattering,In-vitro,In-vivo"
                     data-authors="Ashkan Javaherian">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16633v1.html">The First In Vitro and In Vivo Validation of the Hessian-Free Ray-Born Inversion for Quantitative Ultrasound Tomography</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ physics.med-ph</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Ashkan Javaherian
                </div>

                <div class="paper-summary">
                    This study presents the first experimental validation of a Hessian-free ray-Born inversion technique for quantitatively reconstructing sound speed from transmission ultrasound data. The method, which combines single-scattering theory with high-frequency approximations and a unique Green's function approach, demonstrated strong potential as a computationally efficient and accurate tool suitable for clinical translation, as validated using both in-vitro and in-vivo datasets. It offers an advanced solution for quantitative ultrasound tomography.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Physics</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Oncology (e.g., tumor characterization)</span>
                    
                    <span class="domain-tag">Breast Imaging</span>
                    
                    <span class="domain-tag">Hepatology (e.g., liver fibrosis staging)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16633v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16633v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16633v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16633v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16625v1"
                     data-domains="Clinical Decision Support,Diagnostic Medicine,Medical Natural Language Processing,Biomedical Question Answering"
                     data-keywords="Bayesian uncertainty,clinical decision support,transformer models,overconfidence,Monte Carlo dropout,medical AI,calibration,diagnostic errors"
                     data-authors="Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16625v1.html">MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Elias Hossain, Md Mehedi Hasan Nipu, Maleeha Sheikh et al.
                </div>

                <div class="paper-summary">
                    MedBayes-Lite is a novel, lightweight Bayesian enhancement designed for existing transformer-based clinical language models to produce reliable, uncertainty-aware predictions. It integrates Bayesian Embedding Calibration, Uncertainty-Weighted Attention, and Confidence-Guided Decision Shaping to significantly improve calibration and trustworthiness in clinical decision support. The framework achieves this without requiring retraining or substantial architectural changes, adding minimal parameter overhead.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                    <span class="domain-tag">Medical Natural Language Processing</span>
                    
                    <span class="domain-tag">Biomedical Question Answering</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16625v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16625v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16625v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16625v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16596v1"
                     data-domains="Diagnostic imaging,Oncology,Surgery,Internal medicine,Rehabilitation"
                     data-keywords="Artificial palpation,Tactile sensing,Representation learning,Self-supervised learning,Medical imaging,Change detection,Soft robotics,Diagnostic tools"
                     data-authors="Zohar Rimon,Elisei Shafer,Tal Tepper,Efrat Shimron,Aviv Tamar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16596v1.html">Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zohar Rimon, Elisei Shafer, Tal Tepper et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a proof-of-concept for artificial palpation using a self-supervised learning approach, specifically an encoder-decoder framework, to learn a rich representation from tactile measurements on soft bodies. This learned representation is demonstrated to be effective for downstream tasks such as tactile imaging and detecting internal changes, validated through both simulation and real-world robotic palpation with MRI ground truth.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Surgery</span>
                    
                    <span class="domain-tag">Internal medicine</span>
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16596v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16596v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16596v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16596v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16574v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV"
                     data-authors="Nirjhor Datta,Md. Golam Rabiul Alam">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16574v1.html">Erase to Retain: Low Rank Adaptation Guided Selective Unlearning in Medical Segmentation Networks</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Nirjhor Datta, Md. Golam Rabiul Alam
                </div>

                <div class="paper-summary">
                    The ability to selectively remove knowledge from medical segmentation networks is increasingly important for privacy compliance, ethical deployment, and continual dataset revision. We introduce Erase to Retain, a controllable unlearning framework for medical image segmentation that achieves targeted...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16574v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16574v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16574v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16574v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16571v1"
                     data-domains="Rare Disease Diagnostics,Patient Risk Stratification,Adverse Event Prediction,Medical Imaging Analysis (tabular features),Precision Medicine,Epidemiology (rare outcome prediction)"
                     data-keywords="Data Augmentation,Tabular Data,Class Imbalance,Diffusion Models,Latent Space,Gradient-Boosted Trees,Oversampling,Healthcare AI,Privacy-Preserving"
                     data-authors="Md. Tawfique Ihsan,Md. Rakibul Hasan Rafi,Ahmed Shoyeb Raihan,Imtiaz Ahmed,Abdullahil Azeem">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16571v1.html">Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Md. Tawfique Ihsan, Md. Rakibul Hasan Rafi, Ahmed Shoyeb Raihan et al.
                </div>

                <div class="paper-summary">
                    This paper introduces novel latent-space, tree-driven diffusion methods (PCAForest, EmbedForest, AttentionForest) for minority oversampling in tabular data, addressing challenges of severe class imbalance, tabular heterogeneity, and privacy concerns. These models leverage conditional flow matching with gradient-boosted trees in compact latent spaces, demonstrating an efficient and privacy-aware approach to high-fidelity data augmentation. AttentionForest achieves superior minority recall, while PCAForest and EmbedForest offer favorable accuracy-efficiency trade-offs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rare Disease Diagnostics</span>
                    
                    <span class="domain-tag">Patient Risk Stratification</span>
                    
                    <span class="domain-tag">Adverse Event Prediction</span>
                    
                    <span class="domain-tag">Medical Imaging Analysis (tabular features)</span>
                    
                    <span class="domain-tag">Precision Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16571v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16571v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16571v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16571v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16566v1"
                     data-domains="Pediatrics,Public Health,Nutrition,Global Health,Diagnostic Imaging (AI-assisted)"
                     data-keywords="Child Malnutrition,AI Screening,Computer Vision,Graph Attention Network,Anthropometry,Low-Resource Settings,Global Health,Early Intervention"
                     data-authors="Misaal Khan,Mayank Vatsa,Kuldeep Singh,Richa Singh">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16566v1.html">NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Misaal Khan, Mayank Vatsa, Kuldeep Singh et al.
                </div>

                <div class="paper-summary">
                    NutriScreener is a novel retrieval-augmented, multi-pose graph attention network designed for scalable and accurate detection of child malnutrition and anthropometric prediction from images. It integrates CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to address issues of generalizability and class imbalance in pediatric settings. Clinical studies and extensive testing confirm its high accuracy and efficiency, making it suitable for deployment in low-resource environments.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pediatrics</span>
                    
                    <span class="domain-tag">Public Health</span>
                    
                    <span class="domain-tag">Nutrition</span>
                    
                    <span class="domain-tag">Global Health</span>
                    
                    <span class="domain-tag">Diagnostic Imaging (AI-assisted)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16566v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16566v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16566v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16566v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16551v1"
                     data-domains="Oncology,Rare Diseases,Clinical Trial Design,Biostatistics"
                     data-keywords="Generative AI,Synthetic Data,Clinical Trials,Survival Analysis,Variational Autoencoder (VAE),Time-to-Event Outcomes,Censoring,Oncology"
                     data-authors="Perrine Chassat,Van Tuan Nguyen,Lucas Ducrot,Emilie Lanoy,Agathe Guilloux">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16551v1.html">Toward Valid Generative Clinical Trial Data with Survival Endpoints</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Perrine Chassat, Van Tuan Nguyen, Lucas Ducrot et al.
                </div>

                <div class="paper-summary">
                    This paper introduces a novel Variational Autoencoder (VAE) for generating synthetic clinical trial data, specifically addressing the complex challenge of time-to-event outcomes with censoring. The VAE jointly models mixed-type covariates and survival data without assuming independent censoring, outperforming GAN baselines in fidelity, utility, and privacy for data sharing and control-arm augmentation scenarios.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Rare Diseases</span>
                    
                    <span class="domain-tag">Clinical Trial Design</span>
                    
                    <span class="domain-tag">Biostatistics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16551v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16551v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16551v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16551v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16549v1"
                     data-domains="Medical diagnosis,Clinical decision support,Health equity,Diagnostic imaging,Precision medicine"
                     data-keywords="deep learning,fairness,bias mitigation,Singular Value Decomposition (SVD),low rank factorization (LRF),medical diagnosis,resource-constrained,group disparities"
                     data-authors="Yuanbo Guo,Jun Xia,Yiyu Shi">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16549v1.html">FairLRF: Achieving Fairness through Sparse Low Rank Factorization</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yuanbo Guo, Jun Xia, Yiyu Shi
                </div>

                <div class="paper-summary">
                    FairLRF proposes a novel fairness-oriented low rank factorization (LRF) framework that leverages Singular Value Decomposition (SVD) to enhance deep learning model fairness, particularly for sensitive applications like medical diagnosis. By identifying and selectively removing bias-inducing elements from SVD's unitary matrices, FairLRF effectively reduces group disparities, outperforming existing LRF and state-of-the-art fairness methods without significant accuracy drops or high computational costs.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical diagnosis</span>
                    
                    <span class="domain-tag">Clinical decision support</span>
                    
                    <span class="domain-tag">Health equity</span>
                    
                    <span class="domain-tag">Diagnostic imaging</span>
                    
                    <span class="domain-tag">Precision medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16549v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16549v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16549v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16549v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16548v1"
                     data-domains="Biomedical Informatics,Clinical Informatics,Health Information Technology,Medical Research,Natural Language Processing in Medicine,Public Health"
                     data-keywords="Medical ontology,ontology extension,large language models (LLMs),zero-shot learning,clinical notes,entity extraction,hierarchical relationships,protected health information (PHI)"
                     data-authors="Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16548v1.html">Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Guanchen Wu, Yuzhang Xie, Huanwei Wu et al.
                </div>

                <div class="paper-summary">
                    CLOZE is a novel zero-shot framework that leverages large language models (LLMs) to automatically extract medical entities and hierarchical relationships from unstructured clinical notes. It aims to extend existing medical ontologies by integrating new disease-related concepts, demonstrating an accurate, scalable, and privacy-preserving solution crucial for biomedical research and clinical applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Biomedical Informatics</span>
                    
                    <span class="domain-tag">Clinical Informatics</span>
                    
                    <span class="domain-tag">Health Information Technology</span>
                    
                    <span class="domain-tag">Medical Research</span>
                    
                    <span class="domain-tag">Natural Language Processing in Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16548v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16548v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16548v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16548v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16544v2"
                     data-domains="Clinical Documentation,Telehealth,Medical Informatics,Patient Safety,Healthcare Technology Assessment"
                     data-keywords="ASR,Word Error Rate,Clinical Impact,LLM-as-a-Judge,Patient Safety,Clinical Dialogue,Medical Informatics,Speech Recognition,Evaluation Metrics"
                     data-authors="Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16544v2.html">WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Zachary Ellis, Jared Joselowitz, Yash Deo et al.
                </div>

                <div class="paper-summary">
                    This paper challenges the conventional reliance on Word Error Rate (WER) for evaluating Automatic Speech Recognition (ASR) in clinical dialogue, demonstrating its poor correlation with the actual clinical impact of transcription errors. To address this, the authors introduce and validate an LLM-as-a-Judge framework, optimized using GEPA through DSPy, which accurately replicates expert clinical assessment of ASR error severity, providing a scalable method for safety-focused evaluation.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Clinical Documentation</span>
                    
                    <span class="domain-tag">Telehealth</span>
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Patient Safety</span>
                    
                    <span class="domain-tag">Healthcare Technology Assessment</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16544v2.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16544v2" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16544v2" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16544v2" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16498v1"
                     data-domains="Oncology,Radiology,Medical Imaging,Breast Cancer Diagnosis"
                     data-keywords="DCE-MRI,Breast Cancer,Tumor Segmentation,Deep Learning,Acquisition Time,FiLM Layers,Model Generalization,Medical Imaging"
                     data-authors="Rui Wang,Yuexi Du,John Lewin,R. Todd Constable,Nicha C. Dvornek">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16498v1.html">Acquisition Time-Informed Breast Tumor Segmentation from Dynamic Contrast-Enhanced MRI</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.98</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rui Wang, Yuexi Du, John Lewin et al.
                </div>

                <div class="paper-summary">
                    This paper proposes a novel breast tumor segmentation method for Dynamic Contrast-Enhanced MRI (DCE-MRI) that addresses the challenge of image variability by incorporating image acquisition time. By leveraging Feature-wise linear modulation (FiLM) layers, the model's features are dynamically adjusted based on the specific acquisition sequence, leading to improved tumor segmentation performance and enhanced model generalization across diverse datasets.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Breast Cancer Diagnosis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16498v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16498v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16498v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16498v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16471v1"
                     data-domains="Neurology,Neurodegenerative Diseases,Clinical Trials,Medical Imaging,Neuroscience,Geriatrics"
                     data-keywords="Corpus Callosum,Morphometry,Segmentation,Neurological Diseases,Huntington's Disease,Biomarker,Automated Analysis,Neuroimaging"
                     data-authors="Clemens Pollak,Kersten Diers,Santiago Estrada,David K√ºgler,Martin Reuter">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16471v1.html">FastSurfer-CC: A robust, accurate, and comprehensive framework for corpus callosum morphometry</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Clemens Pollak, Kersten Diers, Santiago Estrada et al.
                </div>

                <div class="paper-summary">
                    FastSurfer-CC is a novel, automated framework designed for comprehensive morphometric analysis of the corpus callosum (CC), addressing the lack of publicly available, integrated tools. It provides a robust pipeline for segmentation, head position standardization, and extraction of multiple shape metrics, demonstrating superior performance over existing methods. The tool successfully reveals previously undetected statistically significant differences in corpus callosum morphology between Huntington's disease patients and healthy controls.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Neurology</span>
                    
                    <span class="domain-tag">Neurodegenerative Diseases</span>
                    
                    <span class="domain-tag">Clinical Trials</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Neuroscience</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16471v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16471v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16471v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16471v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16427v1"
                     data-domains="Oncology,Intensive Care Medicine,Pharmacology,Personalized Medicine,Clinical Decision Support,Electronic Health Records"
                     data-keywords="Generative Modeling,Clinical Time Series,Stochastic Differential Equations,Variational Inference,Irregular Sampling,Individual Treatment Effect,Pharmacokinetics-Pharmacodynamics,Intensive Care Unit"
                     data-authors="Muhammad Aslanimoghanloo,Ahmed ElGazzar,Marcel van Gerven">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16427v1.html">Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Muhammad Aslanimoghanloo, Ahmed ElGazzar, Marcel van Gerven
                </div>

                <div class="paper-summary">
                    This paper introduces a generative modeling framework based on latent neural stochastic differential equations (SDEs) to overcome challenges in clinical time series data, such as irregular sampling, complex latent physiology, and inherent uncertainties. The framework effectively models non-linear interactions and stochasticity, demonstrating superior accuracy and uncertainty estimation compared to baseline models in individual treatment effect estimation and physiological forecasting tasks.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Intensive Care Medicine</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Personalized Medicine</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16427v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16427v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16427v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16427v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16398v1"
                     data-domains="Chronic Disease Management,Mental Health,Psychiatry,Internal Medicine,Preventive Medicine,Geriatrics,Digital Health,Public Health"
                     data-keywords="Chronic Disease Management,Depression,Multi-Task Learning,Wearable Sensors,Double Heterogeneity,Comorbidity Assessment,Digital Health,Integrated Healthcare"
                     data-authors="Yidong Chai,Haoxin Liu,Jiaheng Xie,Chaopeng Wang,Xiao Fang">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16398v1.html">Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Yidong Chai, Haoxin Liu, Jiaheng Xie et al.
                </div>

                <div class="paper-summary">
                    This paper introduces an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method for the joint assessment of comorbid physical chronic diseases and depression using wearable sensor data. It effectively addresses the challenge of "double heterogeneity" (variations in disease manifestation and patient patterns) in multi-disease assessment, significantly outperforming existing baselines and providing a robust computational solution for integrated physical and mental healthcare.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Chronic Disease Management</span>
                    
                    <span class="domain-tag">Mental Health</span>
                    
                    <span class="domain-tag">Psychiatry</span>
                    
                    <span class="domain-tag">Internal Medicine</span>
                    
                    <span class="domain-tag">Preventive Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16398v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16398v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16398v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16398v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16346v1"
                     data-domains="Rehabilitation,Geriatrics,Sports Medicine,Telehealth,Remote Patient Monitoring,Fall Prevention,Biomechanics,Orthopedics"
                     data-keywords="Motion capture,Capacitive sensing,Smart textiles,Wearable technology,Deep learning,Human pose estimation,Rehabilitation,Telehealth,Embedded systems,Privacy-preserving"
                     data-authors="Deniz Kasap,Taraneh Aminosharieh Najafi,J√©r√¥me Paul R√©my Thevenot,Jonathan Dan,Stefano Albini,David Atienza">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16346v1.html">VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ eess.SP</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Deniz Kasap, Taraneh Aminosharieh Najafi, J√©r√¥me Paul R√©my Thevenot et al.
                </div>

                <div class="paper-summary">
                    VersaPants introduces the first loose-fitting, textile-based capacitive sensing system for comfortable, privacy-preserving lower-body motion capture, leveraging the open-hardware VersaSens platform. It employs a lightweight Transformer-based deep learning model to accurately reconstruct hip, knee, and ankle joint angles from integrated textile sensors. This innovation delivers real-time inference on edge devices like smartwatches, offering a scalable and embedded solution for fitness, healthcare, and wellbeing applications.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Rehabilitation</span>
                    
                    <span class="domain-tag">Geriatrics</span>
                    
                    <span class="domain-tag">Sports Medicine</span>
                    
                    <span class="domain-tag">Telehealth</span>
                    
                    <span class="domain-tag">Remote Patient Monitoring</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16346v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16346v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16346v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16346v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16333v1"
                     data-domains="Medical Imaging,Diagnostics,Oncology (tumor simulation),Disease Progression Modeling,Electronic Health Records (EHR),Robotic Surgery,Surgical Planning"
                     data-keywords="World Models,Clinical Prediction,Counterfactuals,Planning,Healthcare AI,Temporal Reasoning,Causal Inference,Decision Support"
                     data-authors="Mohammad Areeb Qazi,Maryam Nadeem,Mohammad Yaqub">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16333v1.html">Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.LG</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Mohammad Areeb Qazi, Maryam Nadeem, Mohammad Yaqub
                </div>

                <div class="paper-summary">
                    This paper reviews World Models as an advanced AI paradigm for healthcare, advocating their superiority over traditional generative AI due to their ability to learn multimodal, temporally coherent, and action-conditioned representations that reflect the physical and causal structure of clinical care. It surveys their application across medical imaging, disease progression modeling, and robotic surgery, highlighting their potential for predictive dynamics, counterfactual evaluation, and planning.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Diagnostics</span>
                    
                    <span class="domain-tag">Oncology (tumor simulation)</span>
                    
                    <span class="domain-tag">Disease Progression Modeling</span>
                    
                    <span class="domain-tag">Electronic Health Records (EHR)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16333v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16333v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16333v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16333v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2511.16292v1"
                     data-domains="Health Informatics,Medical Decision Support Systems,Healthcare Administration,Clinical Pathways Management,Insurance Claims Processing"
                     data-keywords="Distributed Agents,Data Locality,Privacy Preservation,Healthcare Interoperability,Multi-agent Systems,Pseudonymization,Natural Language Processing,Secure Communication"
                     data-authors="Daniel Vaughan,Kate≈ôina Vaughan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2511.16292v1.html">Distributed Agent Reasoning Across Independent Systems With Strict Data Locality</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-11-20</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.AI</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Daniel Vaughan, Kate≈ôina Vaughan
                </div>

                <div class="paper-summary">
                    This paper presents a proof-of-concept demonstrating secure, distributed agent communication across independent systems in healthcare using only natural-language messages and strict data locality. It showcases how organizations like a Clinic, Insurer, and Specialist Network can cooperatively facilitate decision support without sharing identifiers, structured schemas, or centralizing sensitive patient data, primarily utilizing pseudonymized tokens and local data processing.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Health Informatics</span>
                    
                    <span class="domain-tag">Medical Decision Support Systems</span>
                    
                    <span class="domain-tag">Healthcare Administration</span>
                    
                    <span class="domain-tag">Clinical Pathways Management</span>
                    
                    <span class="domain-tag">Insurance Claims Processing</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2511.16292v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2511.16292v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2511.16292v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2511.16292v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-11-24 06:29:17</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>