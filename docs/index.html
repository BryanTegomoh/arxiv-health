<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Health AI Hub</title>
    <meta name="description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta name="keywords" content="medical AI, health AI, arXiv, research papers, machine learning, healthcare">
    <meta name="author" content="Health AI Hub">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Health AI Hub">
    <meta property="og:description" content="AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily">
    <meta property="og:url" content="https://arxiv-health.org">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ArXiv_Health">

    <link rel="icon" type="image/svg+xml" href="favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-top">
                <div class="header-title">
                    <h1><a href="index.html" class="home-link">Health AI Hub</a></h1>
                    <p class="tagline">AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                </div>
                <a href="index.html" class="home-btn">üè† Home</a>
            </div>

            <!-- Weekly Activity Hero Section -->
            <div class="weekly-hero">
                <h2>This Week's Activity</h2>
                <div class="hero-stats">
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">10</div>
                        <div class="hero-stat-label">New Papers</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">10</div>
                        <div class="hero-stat-label">Total Curated</div>
                    </div>
                    <div class="hero-stat-item">
                        <div class="hero-stat-number">37</div>
                        <div class="hero-stat-label">Medical Domains</div>
                    </div>
                </div>
                
                <div class="hottest-domains">
                    <strong>Hottest domains this week:</strong> Oncology (3), Medical Imaging (2), Radiology (2)
                </div>
                
            </div>
        </div>
    </header>

    <nav class="container">
        <div class="nav-tools">
            <div class="search-box">
                <input type="text" id="search" placeholder="üîç Search papers by title, author, keywords, or domain...">
            </div>
            <div class="filters">
                <div class="filter-group">
                    <label>Sort by:</label>
                    <select id="sort-select">
                        <option value="date">Newest First</option>
                        <option value="relevance">Relevance Score</option>
                        <option value="citations">Most Cited</option>
                        <option value="title">Title A-Z</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Domain:</label>
                    <select id="domain-filter">
                        <option value="">All Domains</option>
                        
                        <option value="Oncology">Oncology (3)</option>
                        
                        <option value="Medical Imaging">Medical Imaging (2)</option>
                        
                        <option value="Radiology">Radiology (2)</option>
                        
                        <option value="Pathology">Pathology (2)</option>
                        
                        <option value="Public Health (indirect)">Public Health (Indirect) (1)</option>
                        
                        <option value="Nutrition (indirect)">Nutrition (Indirect) (1)</option>
                        
                        <option value="Food Safety (indirect)">Food Safety (Indirect) (1)</option>
                        
                        <option value="Agricultural AI (direct relevance to domain, not human health)">Agricultural Ai (Direct Relevance To Domain, Not Human Health) (1)</option>
                        
                        <option value="cs.CV">Cs.cv (1)</option>
                        
                        <option value="Veterinary Medicine">Veterinary Medicine (1)</option>
                        
                    </select>
                </div>
                <div class="filter-group">
                    <label>Author:</label>
                    <input type="text" id="author-filter" placeholder="Filter by author">
                </div>
            </div>
        </div>
    </nav>

    <main class="container">
        <div class="papers-grid" id="papers-container">
            
            <article class="paper-card"
                     data-arxiv-id="2512.17864v1"
                     data-domains="Public Health (indirect),Nutrition (indirect),Food Safety (indirect),Agricultural AI (direct relevance to domain, not human health)"
                     data-keywords="Plant disease detection,Convolutional Neural Network (CNN),Attention Mechanism,CBAM,Explainable AI (XAI),Grad-CAM,Smart farming,Agricultural AI"
                     data-authors="Balram Singh,Ram Prakash Sharma,Somnath Dey">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17864v1.html">Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.70</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Balram Singh, Ram Prakash Sharma, Somnath Dey
                </div>

                <div class="paper-summary">
                    This study introduces CBAM-VGG16, an interpretable attention-guided Convolutional Neural Network, for highly accurate plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model achieves enhanced feature extraction, disease localization, and robust generalization across five diverse plant disease datasets, demonstrating superior performance (up to 98.87% accuracy) compared to existing techniques. The approach also emphasizes explainability through various visualization methods, advancing transparent AI in agricultural diagnostics.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Public Health (indirect)</span>
                    
                    <span class="domain-tag">Nutrition (indirect)</span>
                    
                    <span class="domain-tag">Food Safety (indirect)</span>
                    
                    <span class="domain-tag">Agricultural AI (direct relevance to domain, not human health)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17864v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17864v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17864v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17864v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17847v1"
                     data-domains="Veterinary Medicine,Animal Welfare Science,Livestock Health Management,Biomechanics,Preventive Medicine (Veterinary)"
                     data-keywords="Kinematics,Gait analysis,Dairy cows,Lameness detection,Machine learning,Gradient Boosting Machine,Automated monitoring,Animal welfare"
                     data-authors="Celia Julliot,Gabriel M. Dallago,Amir Nejati,Abdoulaye B. Diallo,Elsa Vasseur">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17847v1.html">The use of kinematics to quantify gait attributes and predict gait scores in dairy cows</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.80</span>
                        
                        <span class="category">üìÇ q-bio.OT</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Celia Julliot, Gabriel M. Dallago, Amir Nejati et al.
                </div>

                <div class="paper-summary">
                    This study investigated the use of kinematic data and machine learning to predict gait scores in non-clinically lame dairy cows, aiming for early detection of walking pattern abnormalities. By quantifying specific gait attributes from 3D marker data, a Gradient Boosting Machine (GBM) model was developed, achieving an overall accuracy and F1 score of 0.65 in predicting categorized gait scores on a test set. The research contributes to developing automated monitoring systems for enhancing dairy cow welfare and longevity.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Veterinary Medicine</span>
                    
                    <span class="domain-tag">Animal Welfare Science</span>
                    
                    <span class="domain-tag">Livestock Health Management</span>
                    
                    <span class="domain-tag">Biomechanics</span>
                    
                    <span class="domain-tag">Preventive Medicine (Veterinary)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17847v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17847v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17847v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17847v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17838v1"
                     data-domains="Medical Imaging,Radiology,Diagnostic Medicine"
                     data-keywords="Medical Imaging,Autonomous Agents,LLMs,Benchmarks,Deep Learning,Domain-Specific AI,Computational Medicine,AI in Healthcare"
                     data-authors="Roshan Kenia,Xiaoman Zhang,Pranav Rajpurkar">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17838v1.html">ReX-MLE: The Autonomous Agent Benchmark for Medical Imaging Challenges</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Roshan Kenia, Xiaoman Zhang, Pranav Rajpurkar
                </div>

                <div class="paper-summary">
                    This paper introduces ReX-MLE, a novel benchmark comprising 20 medical imaging challenges, designed to rigorously evaluate autonomous LLM-based agents on end-to-end workflows under realistic constraints. The study reveals a severe performance gap, with state-of-the-art agents consistently ranking in the 0th percentile compared to human experts due to profound domain-knowledge and engineering limitations. ReX-MLE thus exposes critical bottlenecks for developing truly domain-aware autonomous AI systems in medicine.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Diagnostic Medicine</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17838v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17838v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17838v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17838v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17825v1"
                     data-domains="Infectious Diseases,Clinical Microbiology,Pharmacology,Critical Care Medicine,Antibiotic Stewardship"
                     data-keywords="Biofilm,Antibiotic Resistance,Horizontal Gene Transfer,Optimal Control,Mathematical Modeling,Dosing Strategies,Bacterial Eradication,Pontryagin's Maximum Principle"
                     data-authors="Rehan Akber,Adnan Khan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17825v1.html">Mathematical Modeling of Biofilm Eradication Using Optimal Control</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ q-bio.PE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rehan Akber, Adnan Khan
                </div>

                <div class="paper-summary">
                    This paper develops a 1-D mathematical model to analyze antibiotic resistance transfer and eradication in bacterial biofilms containing susceptible, persistor, and resistant strains via horizontal gene transfer. It evaluates various antibiotic dosing strategies, demonstrating that while continuous or periodic dosing often fail or require high concentrations, optimal control methods yield efficient, low-total-dose, tapered antibiotic schedules capable of ensuring bacterial elimination.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Infectious Diseases</span>
                    
                    <span class="domain-tag">Clinical Microbiology</span>
                    
                    <span class="domain-tag">Pharmacology</span>
                    
                    <span class="domain-tag">Critical Care Medicine</span>
                    
                    <span class="domain-tag">Antibiotic Stewardship</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17825v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17825v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17825v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17825v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17815v1"
                     data-domains="drug discovery,immunology,biopharmaceutical development,protein engineering,infectious disease therapeutics"
                     data-keywords="antibody design,affinity optimization,inverse folding,protein language models,therapeutic antibodies,computational biology,drug discovery,ESM-IF"
                     data-authors="Xinyan Zhao,Yi-Ching Tang,Rivaaj Monsia,Victor J. Cantu,Ashwin Kumar Ramesh,Xiaozhong Liu,Zhiqiang An,Xiaoqian Jiang,Yejin Kim">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17815v1.html">Structure-Aware Antibody Design with Affinity-Optimized Inverse Folding</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.95</span>
                        
                        <span class="category">üìÇ cs.CE</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Xinyan Zhao, Yi-Ching Tang, Rivaaj Monsia et al.
                </div>

                <div class="paper-summary">
                    This paper introduces SimBinder-IF, a novel computational method that transforms the inverse folding model ESM-IF into an efficient high-affinity antibody sequence generator. By selectively training ESM-IF's decoder with preference optimization to favor experimentally stronger binders, SimBinder-IF significantly improves the correlation between generated antibody sequences and measured binding affinities. The approach offers a faster and more cost-effective alternative to traditional laboratory affinity maturation, critical for antibody therapeutic development.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">drug discovery</span>
                    
                    <span class="domain-tag">immunology</span>
                    
                    <span class="domain-tag">biopharmaceutical development</span>
                    
                    <span class="domain-tag">protein engineering</span>
                    
                    <span class="domain-tag">infectious disease therapeutics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17815v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17815v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17815v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17815v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17774v1"
                     data-domains="Diagnostic Radiology,Oncology,Radiotherapy Planning,Surgical Planning,Medical Image Analysis"
                     data-keywords="3D Medical Image Segmentation,ConvNeXt,Deep Learning,Representation Learning,Pretraining,CT Imaging,MR Imaging,Global Response Normalization"
                     data-authors="Saikat Roy,Yannick Kirchhoff,Constantin Ulrich,Maximillian Rokuss,Tassilo Wald,Fabian Isensee,Klaus Maier-Hein">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17774v1.html">MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Saikat Roy, Yannick Kirchhoff, Constantin Ulrich et al.
                </div>

                <div class="paper-summary">
                    This paper introduces MedNeXt-v2, a compound-scaled 3D ConvNeXt architecture, specifically designed to address the suboptimality of existing backbones in large-scale supervised representation learning for 3D medical image segmentation. By leveraging an improved micro-architecture and data scaling, MedNeXt-v2 achieves state-of-the-art performance across multiple CT and MR benchmarks, demonstrating the critical importance of effective backbone design beyond just dataset size.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Diagnostic Radiology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiotherapy Planning</span>
                    
                    <span class="domain-tag">Surgical Planning</span>
                    
                    <span class="domain-tag">Medical Image Analysis</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17774v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17774v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17774v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17774v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17769v1"
                     data-domains="Medical Informatics,Healthcare Systems,Patient Care,Clinical Decision Support,Pharmacovigilance (implied)"
                     data-keywords="Medical Entity Recognition,Bangla NLP,Low-resource Language,Multi-BERT Ensemble,Transformer Models,Healthcare AI,Natural Language Processing,Annotated Dataset"
                     data-authors="Tanjim Taharat Aurpa,Farzana Akter,Md. Mehedi Hasan,Shakil Ahmed,Shifat Ara Rafiq,Fatema Khan">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17769v1.html">Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CL</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Tanjim Taharat Aurpa, Farzana Akter, Md. Mehedi Hasan et al.
                </div>

                <div class="paper-summary">
                    This paper addresses the significant gap in Medical Entity Recognition (MedER) for low-resource languages by developing a novel approach for Bangla. The researchers propose a Multi-BERT Ensemble model, which, alongside a newly developed high-quality Bangla medical dataset, achieved an impressive 89.58% accuracy, outperforming existing transformer models and marking a substantial 11.80% improvement over a single BERT model.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Medical Informatics</span>
                    
                    <span class="domain-tag">Healthcare Systems</span>
                    
                    <span class="domain-tag">Patient Care</span>
                    
                    <span class="domain-tag">Clinical Decision Support</span>
                    
                    <span class="domain-tag">Pharmacovigilance (implied)</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17769v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17769v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17769v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17769v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17759v1"
                     data-domains="Oncology,Radiology,Medical Imaging,Pathology"
                     data-keywords="Breast Cancer,Neoadjuvant Chemotherapy,MRI,Image Registration,Radiomics,Machine Learning,PCR Prediction,RFS Prediction"
                     data-authors="Rahul Ravi,Ruizhe Li,Tarek Abdelfatah,Stephen Chan,Xin Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17759v1.html">Breast Cancer Neoadjuvant Chemotherapy Treatment Response Prediction Using Aligned Longitudinal MRI and Clinical Data</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ eess.IV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Rahul Ravi, Ruizhe Li, Tarek Abdelfatah et al.
                </div>

                <div class="paper-summary">
                    This study developed machine learning models to predict pathologic complete response (PCR) and 5-year relapse-free survival (RFS) in breast cancer patients undergoing neoadjuvant chemotherapy (NACT), utilizing longitudinal contrast-enhanced MRI and clinical data. The research demonstrated that an image registration-based approach significantly enhanced feature extraction from MRI, and that radiomic features, particularly with logistic regression, outperformed deep learning-based features for these prognostic predictions.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Radiology</span>
                    
                    <span class="domain-tag">Medical Imaging</span>
                    
                    <span class="domain-tag">Pathology</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17759v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17759v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17759v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17759v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17726v1"
                     data-domains="Pathology,Oncology,Histology,Diagnostic Imaging,Prognostics"
                     data-keywords="computational pathology,whole-slide images (WSI),multiple instance learning (MIL),Mamba,long-range context,spatial context,AI in medicine,diagnostic classification"
                     data-authors="Qian Zeng,Yihui Wang,Shu Yang,Yingxue Xu,Fengtao Zhou,Jiabo Ma,Dejia Cai,Zhengyu Zhang,Lijuan Qu,Yu Wang,Li Liang,Hao Chen">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17726v1.html">MambaMIL+: Modeling Long-Term Contextual Patterns for Gigapixel Whole Slide Image</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 1.00</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Qian Zeng, Yihui Wang, Shu Yang et al.
                </div>

                <div class="paper-summary">
                    MambaMIL+ introduces a novel Multiple Instance Learning (MIL) framework leveraging Mamba's long-sequence modeling capabilities, specifically designed to address the challenges of gigapixel whole-slide images (WSIs) in computational pathology. By integrating explicit spatial context modeling and dynamic contextual memory, it overcomes limitations of existing methods, including Mamba's memory decay and limited spatial understanding. The framework consistently achieves state-of-the-art performance across 20 benchmarks spanning diagnostic classification, molecular prediction, and survival analysis.
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">Pathology</span>
                    
                    <span class="domain-tag">Oncology</span>
                    
                    <span class="domain-tag">Histology</span>
                    
                    <span class="domain-tag">Diagnostic Imaging</span>
                    
                    <span class="domain-tag">Prognostics</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17726v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17726v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17726v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17726v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
            <article class="paper-card"
                     data-arxiv-id="2512.17655v1"
                     data-domains="cs.CV"
                     data-keywords="cs.CV,q-bio.NC"
                     data-authors="Evangelos Sariyanidi,Gokul Nair,Lisa Yankowitz,Casey J. Zampella,Mohan Kashyap Pargi,Aashvi Manakiwala,Maya McNealis,John D. Herrington,Jeffrey Cohn,Robert T. Schultz,Birkan Tunc">

                <div class="paper-header">
                    <h2 class="paper-title">
                        <a href="papers/2512.17655v1.html">Bitbox: Behavioral Imaging Toolbox for Computational Analysis of Behavior from Videos</a>
                    </h2>
                    <div class="paper-meta">
                        <span class="date">üìÖ 2025-12-19</span>
                        <span class="relevance">‚≠ê 0.90</span>
                        
                        <span class="category">üìÇ cs.CV</span>
                    </div>
                </div>

                <div class="paper-authors">
                    <strong>Authors:</strong> Evangelos Sariyanidi, Gokul Nair, Lisa Yankowitz et al.
                </div>

                <div class="paper-summary">
                    Computational measurement of human behavior from video has recently become feasible due to major advances in AI. These advances now enable granular and precise quantification of facial expression, head movement, body action, and other behavioral modalities and are increasingly used in psychology, ps...
                </div>

                <div class="paper-domains">
                    
                    <span class="domain-tag">cs.CV</span>
                    
                </div>

                <div class="paper-links">
                    <a href="papers/2512.17655v1.html" class="btn btn-primary">Read Full Summary</a>
                    <a href="http://arxiv.org/abs/2512.17655v1" target="_blank" class="btn btn-secondary">arXiv</a>
                    <a href="https://arxiv.org/pdf/2512.17655v1" target="_blank" class="btn btn-secondary">PDF</a>
                    <button class="export-btn" data-paper-id="2512.17655v1" title="Export Citation">
                        üìö Cite
                    </button>
                </div>
            </article>
            
        </div>
    </main>

    <footer class="container">
        <div class="footer-content">
            <div class="footer-section">
                <h3>Health AI Hub</h3>
                <p>AI-powered medical research discovery | Latest health AI papers from arXiv, curated daily</p>
                <p>Curated by <a href="mailto:bryan@arxiv-health.org">Bryan Tegomoh</a></p>
                <p>Powered by Gemini AI | Updated Daily</p>
            </div>
            <div class="footer-section">
                <h3>About</h3>
                <p><a href="about.html">Methodology</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health" target="_blank">Open Source</a></p>
                <p><a href="https://github.com/BryanTegomoh/arxiv-health/discussions" target="_blank">Discussions</a></p>
            </div>
            <div class="footer-section">
                <h3>Connect</h3>
                <p><a href="https://twitter.com/ArXiv_Health" target="_blank">Twitter/X</a></p>
                <p><a href="https://bryantegomoh.substack.com" target="_blank">Newsletter</a></p>
                <p><a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
            </div>
        </div>
        <div class="footer-bottom">
            <p>¬© 2025 Health AI Hub | Last updated: 2025-12-22 06:16:30</p>
        </div>
    </footer>

    <!-- Export Modal -->
    <div id="export-modal" class="modal">
        <div class="modal-content">
            <span class="modal-close">&times;</span>
            <h2>Export Citation</h2>
            <div class="export-options">
                <button class="export-format" data-format="bibtex">BibTeX</button>
                <button class="export-format" data-format="ris">RIS (EndNote/Mendeley)</button>
                <button class="export-format" data-format="plain">Plain Text</button>
            </div>
            <textarea id="citation-output" readonly></textarea>
            <button id="copy-citation" class="btn btn-primary">Copy to Clipboard</button>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>