[
  {
    "id": "2601.16073v1",
    "title": "DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models",
    "authors": [
      "Hanwen Zhang",
      "Qiaojin Shen",
      "Yuxi Liu",
      "Yuesheng Zhu",
      "Guibo Luo"
    ],
    "summary": "This paper introduces DSFedMed, a novel dual-scale federated framework designed to efficiently deploy powerful Foundation Models (FMs) for medical image segmentation in resource-constrained federated settings. It achieves this by employing mutual knowledge distillation between a centralized foundation model and lightweight client models, significantly reducing computational and communication overhead while enhancing segmentation accuracy. The framework leverages generated medical images and a learnability-guided sample selection strategy to facilitate effective knowledge transfer.",
    "keywords": [
      "Federated Learning",
      "Foundation Models",
      "Medical Image Segmentation",
      "Knowledge Distillation",
      "Dual-Scale",
      "Computational Efficiency",
      "Mutual Distillation",
      "Lightweight Models"
    ],
    "domains": [
      "Medical Imaging",
      "Radiology",
      "Image Analysis",
      "Diagnostic Imaging"
    ],
    "url": "papers/2601.16073v1.html"
  },
  {
    "id": "2601.16064v1",
    "title": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation",
    "authors": [
      "Shams Nafisa Ali",
      "Taufiq Hasan"
    ],
    "summary": "This paper introduces Phi-SegNet, a novel CNN-based architecture designed to enhance medical image segmentation by explicitly integrating phase-aware information at both architectural and optimization levels. By leveraging frequency-domain representations, Phi-SegNet addresses the crucial challenge of generalization across diverse imaging modalities and anatomical structures. The model consistently achieves state-of-the-art performance and exhibits robust cross-dataset generalization, underscoring the potential of spectral priors for fine-grained object localization in medical imaging.",
    "keywords": [
      "Medical Image Segmentation",
      "Deep Learning",
      "Phase-Aware",
      "Frequency Domain",
      "Generalization",
      "CNN",
      "Spectral Priors",
      "Fine-Grained Localization"
    ],
    "domains": [
      "X-ray imaging",
      "Ultrasound (US) imaging",
      "Histopathology",
      "Magnetic Resonance Imaging (MRI)",
      "Colonoscopy"
    ],
    "url": "papers/2601.16064v1.html"
  },
  {
    "id": "2601.16060v1",
    "title": "ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation",
    "authors": [
      "Yuan Lin",
      "Murong Xu",
      "Marc H\u00f6lle",
      "Chinmay Prabhakar",
      "Andreas Maier",
      "Vasileios Belagiannis",
      "Bjoern Menze",
      "Suprosanna Shit"
    ],
    "summary": "ProGiDiff introduces a novel framework that adapts pre-trained text-to-image diffusion models for medical image segmentation using a ControlNet-style conditioning mechanism. This approach enables multi-class segmentation via natural language prompts and demonstrates strong performance on CT images, with robust few-shot cross-modality transferability to MR images. It addresses critical limitations of current methods by allowing multiple proposals and human interaction.",
    "keywords": [
      "medical image segmentation",
      "diffusion models",
      "ControlNet",
      "prompt-guided",
      "multi-class segmentation",
      "cross-modality",
      "CT imaging",
      "MR imaging"
    ],
    "domains": [
      "Radiology",
      "Diagnostic Imaging",
      "Anatomy",
      "Oncology"
    ],
    "url": "papers/2601.16060v1.html"
  },
  {
    "id": "2601.15481v1",
    "title": "Early predicting of hospital admission using machine learning algorithms: Priority queues approach",
    "authors": [
      "Jakub Antczak",
      "James Montgomery",
      "Ma\u0142gorzata O'Reilly",
      "Zbigniew Palmowski",
      "Richard Turner"
    ],
    "summary": "This study evaluates and compares SARIMAX, XGBoost, and LSTM machine learning models for forecasting daily Emergency Department (ED) admissions over a seven-day horizon, using five years of data from an Australian hospital. It uniquely decomposes demand by ward category and clinical complexity, addressing COVID-19 data anomalies with counterfactual values. The models consistently outperform a seasonal naive baseline, with XGBoost being most accurate for total admissions and SARIMAX for major complexity cases, though all models struggle with sudden patient surges.",
    "keywords": [
      "Emergency Department",
      "Forecasting",
      "Machine Learning",
      "XGBoost",
      "SARIMAX",
      "LSTM",
      "Hospital Admission",
      "Resource Allocation"
    ],
    "domains": [
      "Emergency Medicine",
      "Hospital Management",
      "Healthcare Operations",
      "Public Health Informatics"
    ],
    "url": "papers/2601.15481v1.html"
  },
  {
    "id": "2601.15457v1",
    "title": "Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering",
    "authors": [
      "Anuj Maharjan",
      "Umesh Yadav"
    ],
    "summary": "This paper empirically evaluates Retrieval-Augmented Generation (RAG) architectures to mitigate Large Language Model (LLM) hallucinations when answering questions from public health policy documents, specifically CDC guidance. It demonstrates that Advanced RAG, employing a two-stage retrieval mechanism with cross-encoder re-ranking, significantly improves output faithfulness (0.797) compared to Basic RAG (0.621) and Vanilla LLMs (0.347), which is crucial for high-stakes information integrity.",
    "keywords": [
      "RAG",
      "LLM",
      "Public Health Policy",
      "CDC",
      "Hallucination",
      "Faithfulness",
      "Retrieval-Augmented Generation",
      "Cross-Encoder Re-ranking"
    ],
    "domains": [
      "Public Health",
      "Health Policy",
      "Health Informatics",
      "Regulatory Affairs"
    ],
    "url": "papers/2601.15457v1.html"
  },
  {
    "id": "2601.15442v1",
    "title": "A tensor network formalism for neuro-symbolic AI",
    "authors": [
      "Alex Goessmann",
      "Janina Sch\u00fctte",
      "Maximilian Fr\u00f6hlich",
      "Martin Eigel"
    ],
    "summary": "The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basi...",
    "keywords": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "math.NA",
      "stat.ML"
    ],
    "domains": [
      "cs.AI"
    ],
    "url": "papers/2601.15442v1.html"
  },
  {
    "id": "2601.15416v1",
    "title": "DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction",
    "authors": [
      "Cuong Tran Van",
      "Trong-Thang Pham",
      "Ngoc-Son Nguyen",
      "Duy Minh Ho Nguyen",
      "Ngan Le"
    ],
    "summary": "DuFal introduces a novel dual-path framework for high-fidelity sparse-view Cone-Beam Computed Tomography (CBCT) reconstruction, specifically addressing the challenge of recovering fine-grained anatomical details (high-frequency components) often lost in undersampled data. By integrating frequency-domain and spatial-domain processing through a High-Local Factorized Fourier Neural Operator and efficient feature fusion, DuFal significantly outperforms existing state-of-the-art methods. This leads to superior preservation of high-frequency anatomical features, especially in extremely sparse-view settings, as demonstrated on LUNA16 and ToothFairy datasets.",
    "keywords": [
      "CBCT reconstruction",
      "sparse-view",
      "deep learning",
      "Fourier Neural Operator",
      "high-frequency features",
      "medical imaging",
      "low-dose CT",
      "anatomical details"
    ],
    "domains": [
      "Radiology",
      "Oncology (specifically lung nodule screening/diagnosis)",
      "Dentistry (orthodontics, implant planning, endodontics)",
      "Diagnostic Imaging"
    ],
    "url": "papers/2601.15416v1.html"
  },
  {
    "id": "2601.15408v1",
    "title": "CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation",
    "authors": [
      "Pablo Messina",
      "Andr\u00e9s Villa",
      "Juan Le\u00f3n Alc\u00e1zar",
      "Karen S\u00e1nchez",
      "Carlos Hinojosa",
      "Denis Parra",
      "\u00c1lvaro Soto",
      "Bernard Ghanem"
    ],
    "summary": "CURE addresses the critical issues of inaccurate visual grounding and factual inconsistencies in AI-generated radiology reports by introducing an error-aware curriculum learning framework. It fine-tunes a multimodal instructional model across multiple tasks, dynamically emphasizing challenging samples to significantly improve grounding accuracy, overall report quality, and substantially reduce hallucinations, all without requiring additional data.",
    "keywords": [
      "radiology report generation",
      "visual grounding",
      "curriculum learning",
      "multimodal AI",
      "hallucination reduction",
      "medical imaging",
      "vision-language models",
      "anatomy grounding"
    ],
    "domains": [
      "Radiology",
      "Medical Imaging",
      "Clinical Diagnosis",
      "Artificial Intelligence in Medicine"
    ],
    "url": "papers/2601.15408v1.html"
  },
  {
    "id": "2601.15392v1",
    "title": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation",
    "authors": [
      "Francesca Pia Panaccione",
      "Carlo Sgaravatti",
      "Pietro Pinoli"
    ],
    "summary": "GeMM-GAN is a novel multimodal Generative Adversarial Network designed to synthesize realistic and biologically coherent gene expression profiles. It addresses the challenges of privacy regulations and high costs associated with real gene expression data by conditioning its generation on readily available histopathology images and clinical metadata. The framework demonstrates superior performance, generating functionally meaningful profiles that improve downstream disease type prediction by over 11% compared to current state-of-the-art generative models.",
    "keywords": [
      "Generative Adversarial Network",
      "Gene Expression",
      "Histopathology Images",
      "Clinical Metadata",
      "Multimodal Learning",
      "Transformer Encoder",
      "Cross Attention",
      "Synthetic Data"
    ],
    "domains": [
      "Oncology",
      "Pathology",
      "Genomics",
      "Precision Medicine",
      "Biomedical Research",
      "Bioinformatics"
    ],
    "url": "papers/2601.15392v1.html"
  }
]