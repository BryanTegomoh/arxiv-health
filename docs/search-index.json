[
  {
    "id": "2512.23686v1",
    "title": "PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech",
    "authors": [
      "Deepak Babu Piskala"
    ],
    "summary": "This paper introduces ProfASR-Bench, a novel evaluation benchmark designed to assess Automatic Speech Recognition (ASR) performance in high-stakes professional environments, specifically addressing challenges in fields like medicine, finance, legal, and technology. The research reveals a significant \"context-utilization gap\" (CUG), indicating that current advanced ASR systems, even when provided with explicit contextual prompts, largely fail to leverage this information to improve accuracy, particularly for critical entity recognition.",
    "keywords": [
      "Automatic Speech Recognition (ASR)",
      "Context-Conditioned ASR",
      "Medical Transcription",
      "Professional Speech",
      "Benchmarking",
      "Word Error Rate (WER)",
      "Entity Recognition",
      "Context-Utilization Gap (CUG)",
      "High-Stakes Applications",
      "AI in Healthcare"
    ],
    "domains": [
      "Clinical Documentation",
      "Medical Diagnostics",
      "Pharmacology",
      "Surgical Reporting",
      "Telemedicine",
      "Medical Legal Compliance"
    ],
    "url": "papers/2512.23686v1.html"
  },
  {
    "id": "2512.23671v1",
    "title": "Calibrated Multi-Level Quantile Forecasting",
    "authors": [
      "Tiffany Ding",
      "Isaac Gibbs",
      "Ryan J. Tibshirani"
    ],
    "summary": "This paper introduces Multi-Level Quantile Tracker (MultiQT), an online method designed to guarantee calibrated quantile forecasts simultaneously across multiple levels. MultiQT wraps existing forecasters to produce corrected, ordered forecasts that maintain calibration even under adversarial distribution shifts, while also offering a no-regret guarantee against quantile loss. The method significantly improves calibration in real-world applications like epidemic forecasting.",
    "keywords": [
      "Quantile forecasting",
      "Calibration",
      "Online learning",
      "Epidemic forecasting",
      "Multi-level",
      "No-regret",
      "Uncertainty quantification",
      "Machine learning"
    ],
    "domains": [
      "Epidemiology",
      "Public Health",
      "Infectious Disease Modeling",
      "Emergency Preparedness",
      "Healthcare Operations"
    ],
    "url": "papers/2512.23671v1.html"
  },
  {
    "id": "2512.23637v1",
    "title": "A Dataset and Benchmark for Consumer Healthcare Question Summarization",
    "authors": [
      "Abhishek Basu",
      "Deepak Gupta",
      "Dina Demner-Fushman",
      "Shweta Yadav"
    ],
    "summary": "This paper introduces CHQ-Sum, a novel dataset comprising 1507 domain-expert annotated consumer health questions and their corresponding summaries, to address the challenge of overly descriptive language in consumer health queries. The dataset aims to facilitate the development of efficient summarization systems for consumer healthcare questions, thereby improving natural language understanding in this domain. The authors benchmarked the CHQ-Sum dataset on multiple state-of-the-art summarization models to demonstrate its utility.",
    "keywords": [
      "Consumer Healthcare",
      "Question Summarization",
      "Natural Language Understanding",
      "Medical NLP",
      "Dataset",
      "Community Question Answering",
      "Benchmark",
      "Domain-Expert Annotation"
    ],
    "domains": [
      "Consumer Health Informatics",
      "Medical Natural Language Processing",
      "Digital Health",
      "Telemedicine",
      "Patient Engagement"
    ],
    "url": "papers/2512.23637v1.html"
  }
]