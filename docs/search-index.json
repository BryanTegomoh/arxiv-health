[
  {
    "id": "2601.16073v1",
    "title": "DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models",
    "authors": [
      "Hanwen Zhang",
      "Qiaojin Shen",
      "Yuxi Liu",
      "Yuesheng Zhu",
      "Guibo Luo"
    ],
    "summary": "DSFedMed tackles the challenge of deploying computationally intensive Foundation Models (FMs) in federated medical image segmentation by proposing a dual-scale framework. It leverages mutual knowledge distillation between a centralized FM and lightweight client models, supported by synthetic medical images and a learnability-guided sample selection strategy. This approach significantly boosts efficiency and performance, achieving a 2% Dice score improvement and a 90% reduction in communication costs and inference time.",
    "keywords": [
      "Federated Learning",
      "Foundation Models",
      "Medical Image Segmentation",
      "Knowledge Distillation",
      "Dual-Scale",
      "Synthetic Data",
      "Efficiency",
      "Privacy",
      "Deep Learning"
    ],
    "domains": [
      "Radiology",
      "Pathology",
      "Medical Imaging",
      "Diagnostic Imaging"
    ],
    "url": "papers/2601.16073v1.html"
  },
  {
    "id": "2601.16064v1",
    "title": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation",
    "authors": [
      "Shams Nafisa Ali",
      "Taufiq Hasan"
    ],
    "summary": "Phi-SegNet is a novel CNN-based architecture that enhances medical image segmentation by integrating phase-aware frequency-domain information at both architectural and optimization levels, addressing limitations in robust generalization. It leverages specialized modules and a phase-aware loss to improve structural and boundary precision. Evaluated across five diverse medical imaging modalities, Phi-SegNet achieved state-of-the-art performance and demonstrated robust cross-dataset generalization, highlighting the potential of spectral priors for fine-grained object localization.",
    "keywords": [
      "medical image segmentation",
      "deep learning",
      "frequency domain",
      "phase-aware",
      "CNN",
      "generalization",
      "state-of-the-art",
      "multi-modal"
    ],
    "domains": [
      "X-ray",
      "Ultrasound (US)",
      "Histopathology",
      "Magnetic Resonance Imaging (MRI)",
      "Colonoscopy"
    ],
    "url": "papers/2601.16064v1.html"
  },
  {
    "id": "2601.16060v1",
    "title": "ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation",
    "authors": [
      "Yuan Lin",
      "Murong Xu",
      "Marc H\u00f6lle",
      "Chinmay Prabhakar",
      "Andreas Maier",
      "Vasileios Belagiannis",
      "Bjoern Menze",
      "Suprosanna Shit"
    ],
    "summary": "This paper introduces ProGiDiff, a novel prompt-guided, diffusion-based framework designed for medical image segmentation that leverages pre-trained image generation models. It overcomes limitations of existing methods by enabling multi-class segmentation, natural language prompt conditioning, and efficient cross-modality adaptation with few-shot learning. The system demonstrates strong performance on CT organ segmentation and transferability to MR images, facilitating an expert-in-the-loop workflow.",
    "keywords": [
      "Medical Image Segmentation",
      "Diffusion Models",
      "Prompt-Guided",
      "ControlNet",
      "Multi-class Segmentation",
      "Cross-modality Adaptation",
      "Few-shot Learning",
      "Organ Segmentation"
    ],
    "domains": [
      "Radiology",
      "Diagnostic Imaging",
      "Oncology (for tumor segmentation not explicitly mentioned but implied by organ segmentation)",
      "Surgery (for pre-operative planning)",
      "Anatomy"
    ],
    "url": "papers/2601.16060v1.html"
  }
]