<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="UKAST is a novel U-Net-like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders for medical im">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.04084v1" target="_blank">2511.04084v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nishchal Sapkota, Haoyan Shi, Yejia Zhang, Xianshi Ma, Bofang Zheng, Danny Z. Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.04084v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.04084v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">UKAST is a novel U-Net-like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders for medical image segmentation. This approach addresses the limitations of standard CNNs and Transformers by achieving state-of-the-art performance on four diverse medical benchmarks, particularly excelling in data-scarce environments. By leveraging Group Rational KANs, UKAST offers a more expressive, data-efficient, and computationally optimized framework, significantly advancing medical image analysis.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate medical image segmentation is fundamental for precise disease diagnosis, surgical planning, and personalized treatment strategies. This work's enhanced accuracy and data efficiency are crucial for clinical applications, especially in contexts with rare diseases or limited patient data.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is medical image segmentation, which is a crucial component in healthcare for automating and assisting radiologists and clinicians in identifying anatomical structures, pathologies, and abnormalities from medical scans (e.g., MRI, CT). This improves diagnostic accuracy, enables precise surgical planning, and facilitates monitoring disease progression. The proposed UKAST architecture aims to make these AI models more data-efficient, which is highly beneficial given the challenges of obtaining large, expertly annotated medical datasets.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Medical image segmentation is critical for accurate diagnostics and treatment planning, but faces challenges from complex anatomical structures and limited annotated training data.</li>
                    
                    <li>Existing deep learning methods have drawbacks: CNNs excel at local features but struggle with long-range dependencies, while Transformers capture global context but are data-hungry and computationally expensive.</li>
                    
                    <li>The proposed UKAST architecture is a U-Net like network that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into its Swin Transformer encoders.</li>
                    
                    <li>It specifically leverages Group Rational KANs (GR-KANs) from the Kolmogorov-Arnold Transformer (KAT) to overcome inefficiencies of vanilla spline-based KANs.</li>
                    
                    <li>GR-KANs yield a more expressive and data-efficient framework with reduced FLOPs and only a very small increase in parameter count compared to SwinUNETR.</li>
                    
                    <li>UKAST achieves state-of-the-art performance on four diverse 2D and 3D medical image segmentation benchmarks, consistently surpassing both CNN- and Transformer-based baselines.</li>
                    
                    <li>Notably, it attains superior accuracy in data-scarce settings, effectively alleviating the data-hungry limitations typically associated with standard Vision Transformers.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves developing UKAST, a U-Net-like architecture that incorporates Swin Transformer encoders. A key innovation is the integration of rational-function based Kolmogorov-Arnold Networks (KANs), specifically Group Rational KANs (GR-KANs) derived from the Kolmogorov-Arnold Transformer (KAT), into the Transformer blocks. This modification aims to enhance expressiveness and data efficiency compared to traditional linear layers or MLPs. The architecture was rigorously evaluated on four diverse 2D and 3D medical image segmentation benchmarks, comparing its performance against established CNN- and Transformer-based baselines.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>UKAST demonstrates state-of-the-art performance across four diverse 2D and 3D medical image segmentation benchmarks, consistently outperforming both CNN and Transformer baselines. A significant discovery is its superior accuracy in data-scarce settings, which effectively mitigates the data-hungry nature of conventional Vision Transformers. The integration of GR-KANs proves highly effective, yielding a more expressive and data-efficient framework with reduced computational FLOPs and a minimal increase in parameter count.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to significantly enhance the accuracy and reliability of medical image segmentation, leading to more precise diagnoses, improved surgical planning, and better treatment outcomes for patients. Its data-efficient nature is particularly impactful for rare diseases, specialized imaging tasks, or resource-limited settings where large annotated datasets are scarce, enabling the deployment of advanced AI models in scenarios previously constrained by data limitations.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any inherent limitations of the proposed UKAST model itself. However, it implicitly addresses and aims to overcome the limitations of prior CNN architectures (struggling with long-range dependencies) and standard Transformer architectures (being data-hungry and computationally expensive).</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly outlining specific future research directions, the paper concludes by highlighting the "potential of KAN-enhanced Transformers to advance data-efficient medical image segmentation," suggesting broader exploration and application of this architectural paradigm across various medical imaging tasks and modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Diagnostics</span>
                    
                    <span class="tag">Surgery</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Swin Transformer</span>
                    
                    <span class="tag tag-keyword">Kolmogorov-Arnold Networks (KANs)</span>
                    
                    <span class="tag tag-keyword">U-Net</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Data Efficiency</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Artificial Intelligence</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>