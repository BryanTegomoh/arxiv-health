<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection - Health AI Hub</title>
    <meta name="description" content="This paper introduces MedSapiens, a novel adaptation of the human-centric foundation model Sapiens, for anatomical landmark detection in medical imaging. By lev">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.04255v1" target="_blank">2511.04255v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Marawan Elbatel, Anbang Wang, Keyuan Liu, Kaouther Mouheb, Enrique Almar-Munoz, Lizhuo Lin, Yanqi Yang, Karim Lekadir, Xiaomeng Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.04255v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.04255v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MedSapiens, a novel adaptation of the human-centric foundation model Sapiens, for anatomical landmark detection in medical imaging. By leveraging multi-dataset pretraining, MedSapiens establishes a new state of the art, demonstrating that models inherently optimized for spatial pose localization provide strong, previously untapped priors for medical landmark tasks. The model achieves significant performance improvements over existing generalist and specialist methods, even in limited-data settings.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and efficient anatomical landmark detection is crucial for precise diagnosis, surgical planning, quantitative analysis, and monitoring disease progression in various medical applications. MedSapiens offers a significantly improved and robust method for this fundamental task, potentially leading to more reliable clinical workflows and objective insights derived from medical images.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to significantly improve the accuracy and efficiency of detecting anatomical landmarks in medical images. This can aid clinicians in tasks such as automated measurement for diagnosis, surgical planning, monitoring disease progression, and ensuring precision in various medical interventions where exact anatomical localization is critical.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Revisits and adapts human-centric foundation models, specifically Sapiens (designed for human pose estimation), for anatomical landmark detection in medical imaging.</li>
                    
                    <li>Employs multi-dataset pretraining to adapt the Sapiens model, creating the proposed MedSapiens architecture.</li>
                    
                    <li>Establishes a new state of the art across multiple medical imaging datasets for anatomical landmark detection.</li>
                    
                    <li>Demonstrates that human-centric foundation models offer strong inherent priors and capabilities for anatomical spatial localization in medical contexts.</li>
                    
                    <li>Achieves significant performance improvements: up to 5.26% over generalist models and up to 21.81% over specialist models in average Success Detection Rate (SDR).</li>
                    
                    <li>Shows robust adaptability and strong performance in limited-data (few-shot) settings, improving 2.69% over existing few-shot state-of-the-art models in SDR.</li>
                    
                    <li>Code and model weights are publicly available for reproducibility and further research.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves adapting Sapiens, a pre-trained human-centric foundation model originally designed for human pose estimation, to the task of anatomical landmark detection in medical imaging. This adaptation is achieved through multi-dataset pretraining. The resulting model, MedSapiens, leverages the inherent spatial localization capabilities of the human-centric model and is then benchmarked against existing generalist and specialist state-of-the-art models, as well as evaluated in limited-data settings.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedSapiens establishes a new state of the art in anatomical landmark detection across multiple medical datasets. It achieves significant performance gains, including up to 5.26% improvement over generalist models and up to 21.81% improvement over specialist models in the average Success Detection Rate (SDR). Crucially, the study finds that human-centric foundation models provide strong, largely untapped priors for anatomical landmark detection. Furthermore, MedSapiens demonstrates robust adaptability and strong performance in limited-data settings, improving 2.69% over the few-shot state of the art in SDR.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced accuracy and efficiency of MedSapiens for anatomical landmark detection can significantly improve diagnostic precision, refine surgical planning by providing more accurate reference points, and streamline quantitative analysis in medical research and clinical practice. Its strong performance with limited data could also reduce the annotation burden, accelerating the development and deployment of AI tools in niche medical applications where extensive datasets are unavailable.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Orthopedics</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Surgical Planning</span>
                    
                    <span class="tag">Anatomy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Anatomical landmark detection</span>
                    
                    <span class="tag tag-keyword">Foundation models</span>
                    
                    <span class="tag tag-keyword">Human-centric models</span>
                    
                    <span class="tag tag-keyword">Pose estimation</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">State-of-the-art</span>
                    
                    <span class="tag tag-keyword">Few-shot learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>