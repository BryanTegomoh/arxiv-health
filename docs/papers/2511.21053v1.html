<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios - Health AI Hub</title>
    <meta name="description" content="This paper introduces AerialMind, the first large-scale benchmark dataset for Referring Multi-Object Tracking (RMOT) in Unmanned Aerial Vehicle (UAV) scenarios,">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.21053v1" target="_blank">2511.21053v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-26
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chenglizhao Chen, Shaofeng Liang, Runwei Guan, Xiaolou Sun, Haocheng Zhao, Haiyun Jiang, Tao Huang, Henghui Ding, Qing-Long Han
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.RO, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.85 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.21053v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.21053v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces AerialMind, the first large-scale benchmark dataset for Referring Multi-Object Tracking (RMOT) in Unmanned Aerial Vehicle (UAV) scenarios, addressing the current limitation of RMOT research primarily being confined to ground-level environments. It proposes an innovative semi-automated annotation framework called COALA to efficiently build the dataset and a novel method, HawkEyeTrack (HETrack), to enhance vision-language representation learning for improved perception in UAV contexts. The research aims to bridge a critical gap, enabling intelligent aerial systems to perform precise object detection and tracking using natural language instructions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>While not directly a medical paper, this research is crucial for advancing autonomous UAV capabilities, which have significant indirect implications for health and medicine. It lays the groundwork for intelligent aerial systems that can perform precise tasks using natural language, directly applicable to remote medical assistance, emergency response, and logistics in hard-to-reach or hazardous environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>AI-powered UAVs capable of precise object tracking via natural language commands can be applied to health for: search and rescue operations (locating missing persons or injured individuals), remote assessment of health crises (e.g., in inaccessible areas), targeted delivery of medical supplies or vaccines, and surveillance for epidemiological control or biosecurity threats. For example, a medical AI could direct a UAV to 'track the person in the red shirt near the accident site' or 'monitor the crowd movement in zone B for signs of distress', significantly enhancing situational awareness and response efficiency in health-related emergencies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Identified a significant research gap: RMOT has largely been confined to ground-level scenarios, limiting the capture of broad scene contexts and comprehensive tracking/path planning capabilities.</li>
                    
                    <li>Introduced AerialMind, the pioneering large-scale benchmark dataset for Referring Multi-Object Tracking (RMOT) specifically designed for UAV scenarios.</li>
                    
                    <li>Emphasized the growing demand for intelligent aerial systems capable of natural language interaction, driven by UAVs' advantages in wide-area surveillance and their role in Embodied Intelligence.</li>
                    
                    <li>Developed COALA (semi-automated collaborative agent-based labeling assistant), an innovative framework that significantly reduces labor costs while maintaining high annotation quality for dataset construction.</li>
                    
                    <li>Proposed HawkEyeTrack (HETrack), a novel methodology that collaboratively enhances vision-language representation learning to improve perception and tracking performance in complex UAV scenarios.</li>
                    
                    <li>Experimental validation confirmed that the AerialMind dataset presents challenging conditions inherent to UAV perspectives (e.g., varying scales, complex backgrounds, object occlusion).</li>
                    
                    <li>Comprehensive experiments demonstrated the effectiveness of the proposed HawkEyeTrack (HETrack) method in enhancing RMOT capabilities within the challenging UAV environment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involved three main components: (1) **Dataset Construction**: Creating AerialMind, the first large-scale RMOT benchmark for UAVs, facilitated by the novel COALA (Collaborative Agent-based Labeling Assistant) framework for semi-automated, cost-effective, and high-quality annotation. (2) **Model Development**: Proposing HawkEyeTrack (HETrack), a method designed to collaboratively enhance vision-language representation learning for improved perception in UAV scenarios. (3) **Evaluation**: Conducting comprehensive experiments to validate the challenging nature of the AerialMind dataset and demonstrate the effectiveness of the HETrack method.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study successfully established AerialMind as the first large-scale and challenging RMOT benchmark for UAV scenarios. It demonstrated that the COALA framework is an effective solution for efficient and high-quality dataset annotation. Furthermore, the proposed HawkEyeTrack (HETrack) method proved effective in collaboratively enhancing vision-language representation learning, leading to improved perception and tracking performance for multi-objects in complex UAV environments, bridging the research gap in aerial RMOT.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research enables the development of highly intelligent and autonomous UAVs capable of understanding and executing complex tasks through natural language. In a clinical context, this translates to faster and more accurate search and rescue operations in disaster-stricken or remote areas, automated and precise delivery of critical medical supplies (e.g., vaccines, blood products) to inaccessible locations, and enhanced remote monitoring capabilities for public health emergencies (e.g., tracking crowd movement, identifying hazardous areas). It could significantly augment the capabilities of emergency medical services and disaster relief efforts by providing superior situational awareness and operational efficiency.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the *gap* in existing RMOT research (confined to ground-level scenarios) rather than explicit limitations of their own work. However, the mention of the 'challenging nature of our dataset' implies inherent complexities in UAV scenarios (e.g., variable object scales, occlusions, complex backgrounds from an aerial perspective) that even advanced methods like HETrack must contend with, indicating that further research is needed to fully master these challenges.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated in the abstract, the introduction of a novel benchmark dataset like AerialMind strongly implies an encouragement for future research. This includes developing more advanced RMOT models tailored for UAVs, exploring more complex natural language instructions, integrating these capabilities with real-world UAV platforms for specific applications, and further enhancing robustness against various environmental challenges inherent in aerial scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Disaster Response</span>
                    
                    <span class="tag">Public Health (surveillance, logistics)</span>
                    
                    <span class="tag">Remote Healthcare</span>
                    
                    <span class="tag">Medical Supply Chain Management</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Referring Multi-Object Tracking (RMOT)</span>
                    
                    <span class="tag tag-keyword">UAVs</span>
                    
                    <span class="tag tag-keyword">Natural Language Interaction</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Robotics</span>
                    
                    <span class="tag tag-keyword">Benchmark Dataset</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Aerial Surveillance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Referring Multi-Object Tracking (RMOT) aims to achieve precise object detection and tracking through natural language instructions, representing a fundamental capability for intelligent robotic systems. However, current RMOT research remains mostly confined to ground-level scenarios, which constrains their ability to capture broad-scale scene contexts and perform comprehensive tracking and path planning. In contrast, Unmanned Aerial Vehicles (UAVs) leverage their expansive aerial perspectives and superior maneuverability to enable wide-area surveillance. Moreover, UAVs have emerged as critical platforms for Embodied Intelligence, which has given rise to an unprecedented demand for intelligent aerial systems capable of natural language interaction. To this end, we introduce AerialMind, the first large-scale RMOT benchmark in UAV scenarios, which aims to bridge this research gap. To facilitate its construction, we develop an innovative semi-automated collaborative agent-based labeling assistant (COALA) framework that significantly reduces labor costs while maintaining annotation quality. Furthermore, we propose HawkEyeTrack (HETrack), a novel method that collaboratively enhances vision-language representation learning and improves the perception of UAV scenarios. Comprehensive experiments validated the challenging nature of our dataset and the effectiveness of our method.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>AAAI 2026</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>