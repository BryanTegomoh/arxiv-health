<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Faithful Summarization of Consumer Health Queries: A Cross-Lingual Framework with LLMs - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel cross-lingual framework combining TextRank-based sentence extraction and medical named entity recognition (NER) with large languag">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Faithful Summarization of Consumer Health Queries: A Cross-Lingual Framework with LLMs</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.10768v1" target="_blank">2511.10768v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-13
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Ajwad Abrar, Nafisa Tabassum Oeshy, Prianka Maheru, Farzana Tabassum, Tareque Mohmud Chowdhury
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.10768v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.10768v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel cross-lingual framework combining TextRank-based sentence extraction and medical named entity recognition (NER) with large language models (LLMs) to generate faithful summaries of consumer health questions (CHQs). The approach specifically fine-tunes LLaMA-2-7B on English (MeQSum) and Bangla (BanglaCHQ-Summ) datasets, achieving consistent improvements across quality and faithfulness metrics. This framework significantly outperforms zero-shot baselines and prior systems, demonstrating enhanced reliability for LLM deployment in healthcare by ensuring critical medical information is preserved.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Unfaithful summaries of consumer health questions can lead to miscommunication and potentially life-threatening medical errors by misrepresenting critical patient information. This research directly enhances patient safety and quality of care by developing a robust method to ensure medical summaries are accurate and reliable, facilitating clearer and safer communication in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using Large Language Models (LLMs) for faithful summarization of consumer health queries. This aims to improve communication between patients and healthcare providers, reduce the risk of misinformation, and enhance patient understanding by providing accurate and concise summaries of their health concerns. It also utilizes medical named entity recognition as part of the framework.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of unfaithful medical summaries, which can misrepresent medical details and pose serious risks in healthcare communication.</li>
                    
                    <li>Proposes a hybrid framework that integrates TextRank for sentence extraction and medical Named Entity Recognition (NER) to identify crucial information, used in conjunction with Large Language Models (LLMs).</li>
                    
                    <li>The LLaMA-2-7B model was fine-tuned on two distinct datasets: MeQSum (English) and BanglaCHQ-Summ (Bangla), showcasing its cross-lingual applicability.</li>
                    
                    <li>Achieved consistent improvements in both summary quality (evaluated by ROUGE, BERTScore, readability) and faithfulness (evaluated by SummaC, AlignScore) metrics.</li>
                    
                    <li>Outperformed both zero-shot LLM baselines and prior state-of-the-art summarization systems in the experimental evaluations.</li>
                    
                    <li>Human evaluation corroborated the objective metrics, revealing that over 80% of the generated summaries accurately preserved critical medical information.</li>
                    
                    <li>Emphasizes faithfulness as an essential dimension for developing reliable medical summarization tools, thereby enabling safer and more trustworthy deployment of LLMs in clinical contexts.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed a hybrid framework combining TextRank-based sentence extraction and medical Named Entity Recognition (NER) with Large Language Models (LLMs). Specifically, the LLaMA-2-7B model was fine-tuned on two distinct datasets: MeQSum (English) and BanglaCHQ-Summ (Bangla). Performance was comprehensively evaluated using both intrinsic quality metrics (ROUGE, BERTScore, readability) and faithfulness metrics (SummaC, AlignScore), complemented by human evaluation to assess the preservation of critical medical information.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed framework consistently demonstrated significant improvements across both summary quality and faithfulness metrics, outperforming zero-shot LLM baselines and prior systems. A critical finding from human evaluation was that over 80% of the generated summaries faithfully preserved essential medical information, confirming the method's effectiveness in producing reliable and risk-mitigating medical text summaries.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework offers a practical solution for generating highly faithful and accurate summaries of patient-generated health queries, which can substantially improve the efficiency and safety of communication between patients and healthcare professionals. Its successful deployment could lead to reduced diagnostic errors, enhanced clinical decision-making, and improved patient outcomes by ensuring that critical medical information is accurately conveyed and understood.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework or the experimental setup.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state specific future research directions beyond the general implication of enabling 'safer deployment of LLMs in healthcare contexts'.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">general medicine</span>
                    
                    <span class="tag">patient communication</span>
                    
                    <span class="tag">health informatics</span>
                    
                    <span class="tag">medical natural language processing</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">consumer health queries</span>
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">faithful summarization</span>
                    
                    <span class="tag tag-keyword">medical named entity recognition</span>
                    
                    <span class="tag tag-keyword">cross-lingual</span>
                    
                    <span class="tag tag-keyword">healthcare communication</span>
                    
                    <span class="tag tag-keyword">TextRank</span>
                    
                    <span class="tag tag-keyword">LLaMA-2</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Summarizing consumer health questions (CHQs) can ease communication in healthcare, but unfaithful summaries that misrepresent medical details pose serious risks. We propose a framework that combines TextRank-based sentence extraction and medical named entity recognition with large language models (LLMs) to enhance faithfulness in medical text summarization. In our experiments, we fine-tuned the LLaMA-2-7B model on the MeQSum (English) and BanglaCHQ-Summ (Bangla) datasets, achieving consistent improvements across quality (ROUGE, BERTScore, readability) and faithfulness (SummaC, AlignScore) metrics, and outperforming zero-shot baselines and prior systems. Human evaluation further shows that over 80\% of generated summaries preserve critical medical information. These results highlight faithfulness as an essential dimension for reliable medical summarization and demonstrate the potential of our approach for safer deployment of LLMs in healthcare contexts.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted at the 5th Muslims in Machine Learning (MusIML) Workshop, co-located with NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>