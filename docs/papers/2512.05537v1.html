<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches - Health AI Hub</title>
    <meta name="description" content="This paper evaluates large language models (LLMs) against supervised methods for fine-grained, lesion-level identification of incidentalomas requiring follow-up">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05537v1" target="_blank">2512.05537v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Namu Park, Farzad Ahmed, Zhaoyi Sun, Kevin Lybarger, Ethan Breinhorst, Julie Hu, Ozlem Uzuner, Martin Gunn, Meliha Yetisgen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05537v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05537v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper evaluates large language models (LLMs) against supervised methods for fine-grained, lesion-level identification of incidentalomas requiring follow-up directly from radiology reports. The study demonstrates that generative LLMs, especially an anatomy-informed GPT-OSS-20b model with structured lesion tagging, significantly outperform traditional supervised baselines and achieve performance comparable to human experts, paving the way for reliable automated incidental finding surveillance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Automated and accurate identification of incidentalomas from radiology reports is critical for preventing missed diagnoses, ensuring timely follow-up for potentially serious conditions, and improving patient outcomes while simultaneously alleviating the manual workload on radiologists.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automated detection and classification of incidental findings (incidentalomas) within radiology reports. Specifically, it aims to identify those incidentalomas that require further medical follow-up, thereby assisting radiologists in prioritizing cases, reducing diagnostic errors, and streamlining patient care pathways.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study addresses limitations of document-level classification by focusing on fine-grained, lesion-level detection of incidentalomas requiring follow-up.</li>
                    
                    <li>It compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b).</li>
                    
                    <li>A novel inference strategy was introduced using lesion-tagged inputs and anatomy-aware prompting to ground LLM reasoning on a dataset of 400 annotated radiology reports (1,623 lesion findings).</li>
                    
                    <li>The anatomy-informed GPT-OSS-20b model achieved the highest incidentaloma-positive macro-F1 score of 0.79, significantly surpassing all supervised baselines (maximum macro-F1: 0.70).</li>
                    
                    <li>This LLM performance closely matched the human inter-annotator agreement of 0.76, indicating expert-level capability.</li>
                    
                    <li>Explicit anatomical grounding yielded statistically significant performance gains (p < 0.05) across GPT-based models, highlighting the importance of context.</li>
                    
                    <li>A majority-vote ensemble of the top systems further improved the macro-F1 to 0.90, demonstrating enhanced robustness and accuracy.</li>
                    
                    <li>Error analysis confirmed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The research utilized a comparative experimental design, evaluating three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). A dataset of 400 annotated radiology reports containing 1,623 verified lesion findings was employed. A novel inference strategy incorporated lesion-tagged inputs and anatomy-aware prompting to enhance LLM reasoning and grounding. Model performance was quantitatively assessed using class-specific F1-scores, and statistical significance was determined for observed performance gains.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Generative LLMs, particularly the anatomy-informed GPT-OSS-20b, achieved superior performance in lesion-level incidentaloma detection (macro-F1 of 0.79) compared to all supervised baselines (maximum macro-F1 of 0.70). This performance was comparable to human inter-annotator agreement (0.76). Explicit anatomical grounding statistically significantly improved GPT-based models' performance (p < 0.05), and an ensemble method further boosted the macro-F1 to 0.90. Error analysis confirmed the LLMs' enhanced contextual reasoning in differentiating actionable from benign findings.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This approach offers a reliable and interpretable pathway for automating incidental finding surveillance, directly integrable into radiology workflows. It promises to enhance patient safety by reducing missed follow-up recommendations, streamline clinical processes, and decrease the significant manual burden on radiologists, thereby allowing them to focus on more complex diagnostic tasks.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any specific limitations or caveats of the study, such as dataset size generalizability across institutions or specific types of incidentalomas.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. However, the successful ensemble approach and the focus on interpretability suggest potential for further work in explainable AI for clinical decision support and validation on larger, more diverse real-world datasets.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Preventive Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">incidentalomas</span>
                    
                    <span class="tag tag-keyword">radiology reports</span>
                    
                    <span class="tag tag-keyword">large language models (LLMs)</span>
                    
                    <span class="tag tag-keyword">natural language processing (NLP)</span>
                    
                    <span class="tag tag-keyword">automated surveillance</span>
                    
                    <span class="tag tag-keyword">follow-up recommendations</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">contextual reasoning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.
  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.
  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.
  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>