<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep learning EPI-TIRF cross-modality enables background subtraction and axial super-resolution for widefield fluorescence microscopy - Health AI Hub</title>
    <meta name="description" content="This paper introduces ET2dNet, a deep learning-based EPI-TIRF cross-modality network that significantly enhances wide-field fluorescence microscopy by achieving">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Deep learning EPI-TIRF cross-modality enables background subtraction and axial super-resolution for widefield fluorescence microscopy</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.06853v1" target="_blank">2511.06853v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Qiushi Li, Celi Lou, Yanfang Cheng, Bilang Gong, Xinlin Chen, Hao Chen, Baowan Li, Jieli Wang, Yulin Wang, Sipeng Yang, Yunqing Tang, Luru Dai
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> physics.optics, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.06853v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.06853v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ET2dNet, a deep learning-based EPI-TIRF cross-modality network that significantly enhances wide-field fluorescence microscopy by achieving TIRF-comparable background subtraction and axial super-resolution from a single image without hardware modifications. Utilizing a physics-informed hybrid architecture, ET2dNet exhibits exceptional generalization and can be adapted with few-shot learning. The framework is further extended to ET3dNet for artifact-reduced 3D volumetric reconstruction, making axial super-resolution imaging more accessible for live cell studies and clinical histopathology.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>By enabling high-quality, axially super-resolved images with reduced background noise from standard wide-field microscopes, this technology significantly improves the clarity and precision of cellular and tissue imaging, which is critical for accurate diagnosis, disease research, and drug discovery without incurring high hardware costs.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI (deep learning networks ET2dNet and ET3dNet) is applied to enhance fluorescence microscopy images of biological samples (cells and tissues). It performs background subtraction, axial super-resolution, and artifact-reduced 3D volumetric reconstruction. This directly supports health and medical applications by improving the quality and accessibility of imaging data used in clinical histopathology for disease diagnosis and in live cell studies for understanding biological processes and disease progression. By reducing hardware requirements, it makes advanced imaging more widely deployable in research and potentially clinical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Developed ET2dNet, a deep learning network for EPI-TIRF cross-modality, achieving TIRF-comparable background subtraction and axial super-resolution from a single wide-field image.</li>
                    
                    <li>The method eliminates the need for hardware modifications, making axial super-resolution more accessible and cost-effective.</li>
                    
                    <li>Employs a physics-informed hybrid architecture, combining supervised learning with registered EPI-TIRF image pairs and self-supervised physical modeling via convolution with the point spread function (PSF).</li>
                    
                    <li>Demonstrates exceptional generalization across various microscope objectives and enables few-shot adaptation to new imaging setups.</li>
                    
                    <li>Maintains compatibility with existing deconvolution techniques, allowing for concurrent lateral resolution improvement.</li>
                    
                    <li>Extended to ET3dNet via knowledge distillation, enabling artifact-reduced 3D volumetric reconstruction and effective removal of out-of-focus background signals, even when the input image stack lacks the background source.</li>
                    
                    <li>Rigorous validation on cellular and tissue samples confirms ET2dNet's superiority in background suppression and axial resolution enhancement.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The core methodology involves training a deep learning model, ET2dNet, with a physics-informed hybrid architecture. This architecture integrates supervised learning using registered EPI-TIRF image pairs for ground truth and self-supervised learning through convolution with the point spread function (PSF) to model physical processes. ET2dNet processes a single wide-field image to produce an axially super-resolved, background-subtracted output. For 3D volumetric reconstruction, ET3dNet is developed as an extension using knowledge distillation from ET2dNet.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>ET2dNet successfully provides TIRF-comparable background subtraction and axial super-resolution from a single wide-field image without hardware changes. It exhibits robust generalization capabilities and adapts efficiently to new setups with minimal training. The framework is compatible with lateral deconvolution for overall resolution improvement. Furthermore, ET3dNet effectively reconstructs artifact-reduced 3D volumes and removes out-of-focus background even when the input stack doesn't contain the background source.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology offers an easy-to-deploy, cost-effective solution for enhancing imaging capabilities in clinical settings, particularly in histopathology for clearer tissue analysis and in live cell studies for dynamic cellular processes. By making axial super-resolution widely accessible without expensive hardware upgrades, it can accelerate research, improve diagnostic accuracy, and provide deeper insights into disease mechanisms.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly mention any limitations of the developed framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper highlights the great potential for the framework's application in live cell studies and clinical histopathology, suggesting these as key areas for further deployment and investigation of its utility and benefits in real-world biological and medical scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Live cell studies</span>
                    
                    <span class="tag">Clinical histopathology</span>
                    
                    <span class="tag">Cellular biology</span>
                    
                    <span class="tag">Tissue analysis</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Fluorescence microscopy</span>
                    
                    <span class="tag tag-keyword">Axial super-resolution</span>
                    
                    <span class="tag tag-keyword">Background subtraction</span>
                    
                    <span class="tag tag-keyword">EPI-TIRF</span>
                    
                    <span class="tag tag-keyword">ET2dNet</span>
                    
                    <span class="tag tag-keyword">ET3dNet</span>
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The resolving ability of wide-field fluorescence microscopy is fundamentally
limited by out-of-focus background owing to its low axial resolution,
particularly for densely labeled biological samples. To address this, we
developed ET2dNet, a deep learning-based EPI-TIRF cross-modality network that
achieves TIRF-comparable background subtraction and axial super-resolution from
a single wide-field image without requiring hardware modifications. The model
employs a physics-informed hybrid architecture, synergizing supervised learning
with registered EPI-TIRF image pairs and self-supervised physical modeling via
convolution with the point spread function. This framework ensures exceptional
generalization across microscope objectives, enabling few-shot adaptation to
new imaging setups. Rigorous validation on cellular and tissue samples confirms
ET2dNet's superiority in background suppression and axial resolution
enhancement, while maintaining compatibility with deconvolution techniques for
lateral resolution improvement. Furthermore, by extending this paradigm through
knowledge distillation, we developed ET3dNet, a dedicated three-dimensional
reconstruction network that produces artifact-reduced volumetric results.
ET3dNet effectively removes out-of-focus background signals even when the input
image stack lacks the source of background. This framework makes axial
super-resolution imaging more accessible by providing an easy-to-deploy
algorithm that avoids additional hardware costs and complexity, showing great
potential for live cell studies and clinical histopathology.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>