<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Knowledge Immunization Framework (KIF), a representation-aware unlearning method for Large Language Models (LLMs) that achieves true k">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.10566v1" target="_blank">2601.10566v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-15
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Syed Naveed Mahmood, Md. Rezaur Rahman Bhuiyan, Tasfia Zaman, Jareen Tasneem Khondaker, Md. Sameer Sakib, Nazia Tasnim, Farig Sadeque
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.85 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.10566v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.10566v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Knowledge Immunization Framework (KIF), a representation-aware unlearning method for Large Language Models (LLMs) that achieves true knowledge erasure by targeting internal activation signatures, rather than merely suppressing surface outputs. KIF successfully breaks the long-standing stability-erasure tradeoff, demonstrating near-oracle erasure while preserving model utility at oracle levels across various LLM architectures.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for the deployment of safe and compliant AI in healthcare by ensuring that sensitive patient data, outdated medical guidelines, or biased information can be genuinely and permanently removed from medical LLMs, adhering to privacy regulations like HIPAA and GDPR.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The Knowledge Immunization Framework (KIF) developed in this paper would be critical for large language models (LLMs) used in various medical and health applications. For instance, in clinical decision support systems, medical chatbots, drug discovery platforms, or tools processing electronic health records, KIF could enable these LLMs to:
1.  **Protect patient privacy:** By effectively and permanently erasing specific patient data or identifying information used during training, ensuring compliance with regulations like GDPR.
2.  **Ensure safety and ethics:** By removing biased, harmful, or outdated medical information that could lead to incorrect diagnoses or treatments.
3.  **Maintain data integrity:** By allowing models to 'forget' erroneous or retracted medical facts and adapt to new guidelines.
4.  **Enhance biosecurity:** By enabling the targeted erasure of knowledge that, if retained, could be misused to generate harmful biological agents or information.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** Current LLM unlearning techniques often only suppress problematic or sensitive information, allowing latent knowledge and capabilities to persist, which fails to meet stringent compliance and safety requirements.</li>
                    
                    <li>**Solution Proposed:** The Knowledge Immunization Framework (KIF) employs a 'representation-aware' approach, focusing on eradicating internal 'activation signatures' associated with specific knowledge rather than just external behavioral refusals.</li>
                    
                    <li>**Methodology:** KIF combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, which enables durable unlearning without requiring computationally intensive full model retraining.</li>
                    
                    <li>**Performance Metrics:** The framework achieves near-oracle erasure (FQ ‚âà 0.99 vs. 1.00) and preserves general model utility at oracle levels (MU = 0.62), indicating it effectively resolves the stability-erasure tradeoff prevalent in prior unlearning methods.</li>
                    
                    <li>**Evaluation Scope:** KIF was evaluated on both standard foundation models (Llama, Mistral) and reasoning-prior models (Qwen, DeepSeek), across parameter scales ranging from 3B to 14B.</li>
                    
                    <li>**Key Findings on Model Types:** Standard models demonstrated scale-independent true erasure with minimal utility drift (<3%), whereas reasoning-prior models exhibited fundamental architectural divergence in their unlearning behavior, suggesting varied mechanisms of knowledge encoding.</li>
                    
                    <li>**Evaluation Protocol:** The paper introduces a comprehensive dual-metric evaluation protocol that assesses both surface-level leakage (behavioral output) and latent trace persistence (internal representations), enabling a systematic diagnosis of forgetting mechanisms.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The Knowledge Immunization Framework (KIF) is a representation-aware architecture. It operates by identifying and dynamically suppressing subject-specific internal activation signatures within LLMs. This is coupled with parameter-efficient adaptation techniques to maintain overall model utility. A novel dual-metric evaluation protocol (combining surface-level leakage and latent trace persistence) is used to rigorously assess the degree of true erasure versus mere obfuscation, tested across diverse LLM families (Llama, Mistral, Qwen, DeepSeek) and scales (3B to 14B parameters).</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>KIF achieves groundbreaking near-oracle knowledge erasure (FQ ‚âà 0.99) while sustaining oracle-level utility (MU = 0.62), thereby fundamentally overcoming the long-standing stability-erasure tradeoff in LLM unlearning. Standard models exhibit consistent, scale-independent true erasure, whereas reasoning-prior models show distinct, architecture-dependent unlearning characteristics, highlighting differences in how knowledge is embedded.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology offers a robust mechanism for purging sensitive patient health information (PHI) or outdated/misleading medical knowledge from AI models used in clinical settings, thereby enhancing patient privacy, reducing risks of AI-generated misinformation, and facilitating regulatory compliance (e.g., HIPAA, GDPR, EU AI Act). It enables the development of safer, more ethical, and up-to-date medical AI tools for tasks like clinical decision support, medical information retrieval, and personalized treatment planning.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While achieving near-oracle performance, the abstract implies that perfect 'oracle' erasure is a theoretical upper bound. The divergence in unlearning behavior observed between standard and reasoning-prior models suggests that KIF's application or tuning might require model-specific considerations. The computational overhead of identifying and suppressing specific activation signatures for complex knowledge in very large models, though parameter-efficient compared to full retraining, is not fully detailed.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research should focus on further understanding and addressing the architectural divergence in unlearning behavior observed across different LLM families. Investigating the generalizability of KIF to more complex and multifaceted knowledge types, and potentially exploring its application to other forms of AI models beyond LLMs, particularly those used for image or tabular data in medicine, would be valuable. Further optimization of the activation signature identification and suppression process for extremely large models is also implied.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Bioethics (AI)</span>
                    
                    <span class="tag">Regulatory Compliance (Healthcare AI)</span>
                    
                    <span class="tag">Personalized Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLM Unlearning</span>
                    
                    <span class="tag tag-keyword">Knowledge Erasure</span>
                    
                    <span class="tag tag-keyword">Activation Signatures</span>
                    
                    <span class="tag tag-keyword">GDPR Compliance</span>
                    
                    <span class="tag tag-keyword">Patient Data Privacy</span>
                    
                    <span class="tag tag-keyword">AI Safety</span>
                    
                    <span class="tag tag-keyword">Representation-Aware</span>
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>16 pages, 4 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>