<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement - Health AI Hub</title>
    <meta name="description" content="This paper introduces SMILE, an anatomy-aware diffusion model designed for contrast enhancement in medical images without introducing common artifacts like orga">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.07251v1" target="_blank">2512.07251v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-08
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Junqi Liu, Zejun Wu, Pedro R. A. S. Bassi, Xinze Zhou, Wenxuan Li, Ibrahim E. Hamamci, Sezgin Er, Tianyu Lin, Yi Luo, Szymon P≈Çotka, Bjoern Menze, Daguang Xu, Kai Ding, Kang Wang, Yang Yang, Yucheng Tang, Alan L. Yuille, Zongwei Zhou
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.07251v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.07251v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SMILE, an anatomy-aware diffusion model designed for contrast enhancement in medical images without introducing common artifacts like organ distortion or false findings. SMILE selectively enhances clinically relevant regions by learning organ shapes and contrast dynamics, demonstrating superior image quality and significant improvements in cancer detection, particularly from non-contrast CT scans.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work is highly relevant for medical imaging and diagnostics as it addresses critical limitations of current image enhancement techniques that can compromise diagnostic accuracy. By providing anatomically accurate and diagnostically meaningful enhanced images, SMILE directly supports better clinical decision-making and potentially improves the early detection of diseases like cancer.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is an 'anatomy-aware diffusion model' (SMILE) that enhances medical images (specifically CT scans, multi-phase and non-contrast) by learning organ shapes and contrast dynamics. This enhancement aims to improve the visual quality of medical images, aid clinical decision-making, prevent false findings, and significantly boost the detection accuracy of conditions like cancer from non-contrast scans.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>SMILE is an anatomy-aware diffusion model that learns true organ boundaries and contrast uptake patterns, enhancing only clinically relevant regions.</li>
                    
                    <li>It prevents common issues in existing enhancement models such as organ distortion, creation of false findings, and missing small tumors due to a lack of anatomical understanding.</li>
                    
                    <li>The model incorporates structure-aware supervision, ensuring adherence to actual anatomical contours and contrast dynamics.</li>
                    
                    <li>SMILE features registration-free learning, allowing it to process unaligned multi-phase CT scans directly without preprocessing alignment.</li>
                    
                    <li>It provides unified inference, ensuring fast and consistent enhancement across all contrast phases of a scan.</li>
                    
                    <li>Evaluated on six external datasets, SMILE achieved significant improvements in image quality metrics: 14.2% higher SSIM, 20.6% higher PSNR, and 50% better FID compared to existing methods.</li>
                    
                    <li>Clinically, it produced anatomically accurate and diagnostically meaningful images, raising the F1 score for cancer detection from non-contrast CT scans by up to 10%.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SMILE is an anatomy-aware diffusion model that learns from medical images by modeling organ shapes and their contrast uptake characteristics. Its methodology is built upon three key ideas: (1) structure-aware supervision, which guides the model to respect true organ boundaries and contrast patterns; (2) registration-free learning, enabling direct processing of unaligned multi-phase CT scans; and (3) unified inference, which ensures fast and consistent enhancement across different contrast phases.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SMILE consistently outperforms existing methods in objective image quality metrics (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID). It successfully generates anatomically accurate and diagnostically meaningful enhanced images. Critically, SMILE improves cancer detection from non-contrast CT by increasing the F1 score by up to 10%, demonstrating its clinical utility in improving diagnostic accuracy without over-editing or introducing artifacts.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SMILE has the potential to significantly enhance diagnostic confidence and accuracy in radiology by providing clearer, anatomically faithful images that highlight clinically relevant features. Its ability to improve cancer detection from non-contrast CT could lead to earlier diagnoses, potentially reducing the need for contrast agents in some cases and streamlining workflows by offering consistent enhancement across multi-phase studies.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the SMILE model. However, potential general limitations for such models might include performance variability across different patient populations, scanner types, or specific pathologies not covered in the six external datasets used for evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. However, potential avenues could include extending SMILE to other imaging modalities (e.g., MRI), evaluating its impact in prospective clinical trials, or exploring its application in automated disease grading or treatment response assessment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">contrast enhancement</span>
                    
                    <span class="tag tag-keyword">diffusion models</span>
                    
                    <span class="tag tag-keyword">anatomy-aware AI</span>
                    
                    <span class="tag tag-keyword">CT scans</span>
                    
                    <span class="tag tag-keyword">cancer detection</span>
                    
                    <span class="tag tag-keyword">image quality</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Image enhancement improves visual quality and helps reveal details that are hard to see in the original image. In medical imaging, it can support clinical decision-making, but current models often over-edit. This can distort organs, create false findings, and miss small tumors because these models do not understand anatomy or contrast dynamics. We propose SMILE, an anatomy-aware diffusion model that learns how organs are shaped and how they take up contrast. It enhances only clinically relevant regions while leaving all other areas unchanged. SMILE introduces three key ideas: (1) structure-aware supervision that follows true organ boundaries and contrast patterns; (2) registration-free learning that works directly with unaligned multi-phase CT scans; (3) unified inference that provides fast and consistent enhancement across all contrast phases. Across six external datasets, SMILE outperforms existing methods in image quality (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID) and in clinical usefulness by producing anatomically accurate and diagnostically meaningful images. SMILE also improves cancer detection from non-contrast CT, raising the F1 score by up to 10 percent.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>