<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GRASP: Guided Residual Adapters with Sample-wise Partitioning - Health AI Hub</title>
    <meta name="description" content="This paper introduces GRASP, a novel method addressing mode collapse in text-to-image diffusion models when generating images for rare medical pathologies, a pr">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>GRASP: Guided Residual Adapters with Sample-wise Partitioning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.01675v1" target="_blank">2512.01675v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-01
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Felix N√ºtzel, Mischa Dombrowski, Bernhard Kainz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.01675v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.01675v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces GRASP, a novel method addressing mode collapse in text-to-image diffusion models when generating images for rare medical pathologies, a prevalent issue in long-tail datasets. GRASP mitigates gradient conflicts between frequent and rare classes by partitioning samples into clusters and injecting cluster-specific residual adapters, leading to significantly improved generation quality and diversity for rare conditions and enhanced downstream classification performance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging by enabling the robust generation of high-fidelity synthetic data for rare diseases and pathologies. This capability directly addresses critical data scarcity challenges, which can help overcome dataset imbalances and bias in training AI models for medical diagnosis and research.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI method (GRASP) to improve the quality and diversity of synthetic medical images, especially for rare diseases or conditions. This is crucial for medical AI applications, as it can augment scarce datasets, enhance the training of diagnostic AI models (e.g., for identifying rare pathologies from chest X-rays), and potentially lead to more accurate and robust AI-assisted diagnosis in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Identifies gradient conflicts between frequent (head) and rare (tail) classes as the root cause of mode collapse in diffusion models applied to long-tail medical imaging.</li>
                    
                    <li>Proposes GRASP, which utilizes external priors to statically partition samples into clusters, thereby minimizing intra-group gradient clashes during training.</li>
                    
                    <li>GRASP fine-tunes pre-trained diffusion models by injecting cluster-specific residual adapters into transformer feedforward layers, a design choice that bypasses learned gating for improved stability and efficiency.</li>
                    
                    <li>Achieves superior FID (Fr√©chet Inception Distance) and diversity metrics, especially for rare classes, on the long-tail MIMIC-CXR-LT dataset.</li>
                    
                    <li>Demonstrates considerable improvement in downstream classification performance for tail labels on the NIH-CXR-LT dataset, highlighting the utility of GRASP-generated synthetic data.</li>
                    
                    <li>Outperforms existing baselines, including vanilla fine-tuning and Mixture of Experts variants, showcasing its effectiveness in handling long-tail data distributions.</li>
                    
                    <li>The method is lightweight, scalable, and readily integrates into existing diffusion pipelines, with confirmed general applicability through evaluation on ImageNet-LT.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>GRASP operates by first using external priors to statically partition medical imaging samples into distinct clusters, carefully designed to minimize gradient conflicts within each cluster. Subsequently, it fine-tunes pre-trained text-to-image diffusion models by injecting cluster-specific residual adapters into the transformer feedforward layers. This injection method bypasses learned gating mechanisms, which contributes to the stability and efficiency of adapting the model to generate high-quality images across the entire long-tail distribution.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>GRASP yielded superior FID and diversity metrics on the MIMIC-CXR-LT dataset, particularly for rare medical conditions, significantly outperforming baseline methods. Furthermore, the synthetic data generated by GRASP led to substantial improvements in downstream classification performance for underrepresented (tail) labels on the NIH-CXR-LT dataset, confirming the practical utility of its generated outputs. The method's broad applicability was also validated on the general ImageNet-LT dataset.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The ability of GRASP to generate high-quality and diverse synthetic images for rare medical conditions holds significant clinical impact. It can mitigate the data scarcity problem for uncommon pathologies, allowing for the training of more robust, accurate, and less biased AI diagnostic tools. This could lead to earlier and more reliable detection of rare diseases, improving patient outcomes and assisting clinicians in complex diagnostic scenarios where real-world data is extremely limited.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the GRASP method.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Diagnostics</span>
                    
                    <span class="tag">AI in Healthcare</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Diffusion Models</span>
                    
                    <span class="tag tag-keyword">Long-tail Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Data Augmentation</span>
                    
                    <span class="tag tag-keyword">Residual Adapters</span>
                    
                    <span class="tag tag-keyword">Mode Collapse</span>
                    
                    <span class="tag tag-keyword">Rare Pathologies</span>
                    
                    <span class="tag tag-keyword">Generative AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Recent advances in text-to-image diffusion models enable high-fidelity generation across diverse prompts. However, these models falter in long-tail settings, such as medical imaging, where rare pathologies comprise a small fraction of data. This results in mode collapse: tail-class outputs lack quality and diversity, undermining the goal of synthetic data augmentation for underrepresented conditions. We pinpoint gradient conflicts between frequent head and rare tail classes as the primary culprit, a factor unaddressed by existing sampling or conditioning methods that mainly steer inference without altering the learned distribution. To resolve this, we propose GRASP: Guided Residual Adapters with Sample-wise Partitioning. GRASP uses external priors to statically partition samples into clusters that minimize intra-group gradient clashes. It then fine-tunes pre-trained models by injecting cluster-specific residual adapters into transformer feedforward layers, bypassing learned gating for stability and efficiency. On the long-tail MIMIC-CXR-LT dataset, GRASP yields superior FID and diversity metrics, especially for rare classes, outperforming baselines like vanilla fine-tuning and Mixture of Experts variants. Downstream classification on NIH-CXR-LT improves considerably for tail labels. Generalization to ImageNet-LT confirms broad applicability. Our method is lightweight, scalable, and readily integrates with diffusion pipelines.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>10 pages, 4 figures, 6 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>