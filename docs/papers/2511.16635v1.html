<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction - Health AI Hub</title>
    <meta name="description" content="SurvAgent introduces a hierarchical CoT-enhanced multi-agent system designed for multimodal survival prediction in cancer, addressing limitations of existing me">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16635v1" target="_blank">2511.16635v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Guolin Huang, Wenting Chen, Jiaqi Yang, Xinheng Lyu, Xiaoling Luo, Sen Yang, Xiaohan Xing, Linlin Shen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16635v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16635v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SurvAgent introduces a hierarchical CoT-enhanced multi-agent system designed for multimodal survival prediction in cancer, addressing limitations of existing methods in integrating diverse data, exploring regions of interest, and leveraging experiential learning. It establishes a new paradigm for explainable AI-driven survival prediction by constructing a comprehensive case bank and employing a dichotomy-based multi-expert inference mechanism, demonstrating superior performance across multiple TCGA cohorts.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work is critical for cancer prognosis and treatment planning by providing transparent and explainable survival predictions, which are essential for clinical trust and adoption. Integrating multimodal data (pathology images and gene expression) offers a more comprehensive patient assessment, leading to personalized and effective oncology decisions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>SurvAgent is a multi-agent AI system designed to improve cancer prognosis and support treatment planning. It applies AI techniques (hierarchical CoT-enhanced multi-agent system, RAG) to integrate multimodal medical data (digital pathology and genetic information) to provide explainable survival predictions, thereby enhancing precision oncology and clinical decision-making.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses three key limitations of existing pathology agents for survival prediction: inability to integrate multimodal data, ineffective ROI exploration, and failure to leverage historical experiential learning.</li>
                    
                    <li>Proposes SurvAgent, the first hierarchical Chain-of-Thought (CoT)-enhanced multi-agent system specifically for multimodal survival prediction.</li>
                    
                    <li>Stage 1: WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical pathology analysis (Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, Confidence-Aware Patch Mining) and Gene-Stratified analysis (six functional gene categories) to generate structured reports with CoT reasoning.</li>
                    
                    <li>Stage 2: Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases using Retrieval-Augmented Generation (RAG) and integrates multimodal reports with expert predictions via progressive interval refinement.</li>
                    
                    <li>Integrates whole slide images (WSI) and gene expression data, producing structured, explainable reports that store complete analytical processes for experiential learning.</li>
                    
                    <li>Demonstrates superior performance against conventional methods, proprietary MLLMs, and medical agents across five TCGA cancer cohorts.</li>
                    
                    <li>Establishes a new paradigm for explainable AI in precision oncology, emphasizing transparency crucial for clinical adoption.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SurvAgent operates in two hierarchical stages. The first stage, "WSI-Gene CoT-Enhanced Case Bank Construction," involves hierarchical analysis of pathology images (low-magnification screening, cross-modal similarity-aware patch mining, confidence-aware patch mining) and gene expression data (gene-stratified analysis across six functional categories). Both generate structured reports with CoT reasoning, forming a case bank for experiential learning. The second stage, "Dichotomy-Based Multi-Expert Agent Inference," retrieves similar cases using RAG from the constructed bank and integrates multimodal reports with expert predictions through progressive interval refinement to make final survival predictions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SurvAgent significantly outperforms conventional survival prediction methods, proprietary Multimodal Large Language Models (MLLMs), and other medical agents across five diverse TCGA cohorts. It successfully integrates multimodal data and provides explainable, CoT-enhanced predictions, establishing a new and superior paradigm for AI-driven survival prediction that prioritizes clinical transparency and experiential learning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The clinical impact is substantial, enabling more accurate and transparent cancer prognosis, which directly aids in personalized treatment planning and risk stratification. By providing explainable reasoning alongside predictions, SurvAgent fosters greater clinician trust and facilitates the adoption of advanced AI in precision oncology, ultimately leading to improved patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *existing methods* that SurvAgent addresses. It does not explicitly detail any specific limitations or caveats of the SurvAgent system itself within the provided text.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. However, by establishing a "new paradigm," it implicitly suggests avenues for further development in explainable AI for clinical tasks, potentially including expansion to other cancer types, integration of additional data modalities, or refinement of the agent interaction mechanisms.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Cancer Prognosis</span>
                    
                    <span class="tag">Personalized Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">survival analysis</span>
                    
                    <span class="tag tag-keyword">multimodal prediction</span>
                    
                    <span class="tag tag-keyword">hierarchical AI</span>
                    
                    <span class="tag tag-keyword">chain-of-thought (CoT)</span>
                    
                    <span class="tag tag-keyword">multi-agent system</span>
                    
                    <span class="tag tag-keyword">pathology images</span>
                    
                    <span class="tag tag-keyword">gene expression</span>
                    
                    <span class="tag tag-keyword">explainable AI</span>
                    
                    <span class="tag tag-keyword">precision oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>20 pages</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>