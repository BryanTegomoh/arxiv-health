<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression - Health AI Hub</title>
    <meta name="description" content="This paper presents the first automated method for classifying phonotrauma severity from vocal fold images, addressing the current reliance on subjective and co">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.09702v1" target="_blank">2511.09702v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-12
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Katie Matton, Purvaja Balaji, Hamzeh Ghasemzadeh, Jameson C. Cooper, Daryush D. Mehta, Jarrad H. Van Stan, Robert E. Hillman, Rosalind Picard, John Guttag, S. Mazdak Abulnaga
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.09702v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.09702v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents the first automated method for classifying phonotrauma severity from vocal fold images, addressing the current reliance on subjective and costly clinical judgment. It introduces a novel soft ordinal regression framework that modifies loss functions to accommodate soft labels reflecting annotator rating distributions, achieving predictive performance comparable to clinical experts with well-calibrated uncertainty estimates.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research addresses a critical need in laryngology by offering an objective, automated, and scalable alternative to the current subjective and resource-intensive clinical assessment of phonotrauma severity. It promises to reduce inter-rater variability and costs associated with diagnosis and treatment planning.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is an automated system for classifying the severity of phonotrauma from vocal fold images. This tool can serve as a diagnostic aid for clinicians, potentially improving the consistency and efficiency of severity assessment, facilitating large-scale medical studies, and ultimately enhancing patient care for vocal fold conditions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current phonotrauma severity assessment relies on clinician expert judgment, which is costly, subjective, and exhibits variable reliability.</li>
                    
                    <li>The work introduces the first automated method for classifying phonotrauma severity directly from vocal fold images.</li>
                    
                    <li>An ordinal regression framework is adopted to explicitly account for the natural ordinal (e.g., mild to severe) nature of phonotrauma severity labels.</li>
                    
                    <li>A novel 'soft ordinal regression' method is proposed, which modifies standard ordinal regression loss functions to operate on 'soft labels' that represent the distribution of expert ratings, thereby modeling label uncertainty.</li>
                    
                    <li>The proposed method achieves predictive performance that approaches that of human clinical experts in severity classification.</li>
                    
                    <li>The automated classification also produces well-calibrated uncertainty estimates for its predictions.</li>
                    
                    <li>This automated tool can enable large-scale studies of phonotrauma, facilitating improved clinical understanding and patient care.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a deep learning approach within an ordinal regression framework applied to vocal fold images. The core innovation is a novel 'soft ordinal regression' technique where loss functions are modified to accept 'soft labels.' These soft labels are probability distributions derived from multiple annotator ratings, allowing the model to explicitly account for and learn from label uncertainty and inter-rater variability, rather than relying on a single, crisp label.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that the developed soft ordinal regression method successfully classifies phonotrauma severity from vocal fold images with predictive performance that is comparable to, or approaches, that of human clinical experts. Furthermore, the method produces robust and well-calibrated uncertainty estimates for its classifications.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This automated tool has the potential to significantly standardize and streamline the assessment of phonotrauma severity, leading to more consistent diagnoses and tailored treatment plans. By overcoming the limitations of manual expert assessment, it can enable large-scale research studies that were previously infeasible, accelerating the understanding of phonotrauma progression and treatment efficacy, ultimately improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the developed method, such as dataset size, generalizability across diverse patient populations, or specific types of phonotrauma.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The primary future direction highlighted is that this automated tool will enable large-scale studies of phonotrauma, which are critical for advancing clinical understanding of the condition and ultimately leading to improved patient care strategies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Laryngology</span>
                    
                    <span class="tag">Otolaryngology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Voice Disorders</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Phonotrauma</span>
                    
                    <span class="tag tag-keyword">Vocal Folds</span>
                    
                    <span class="tag tag-keyword">Severity Classification</span>
                    
                    <span class="tag tag-keyword">Ordinal Regression</span>
                    
                    <span class="tag tag-keyword">Soft Labels</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Laryngology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Phonotrauma refers to vocal fold tissue damage resulting from exposure to forces during voicing. It occurs on a continuum from mild to severe, and treatment options can vary based on severity. Assessment of severity involves a clinician's expert judgment, which is costly and can vary widely in reliability. In this work, we present the first method for automatically classifying phonotrauma severity from vocal fold images. To account for the ordinal nature of the labels, we adopt a widely used ordinal regression framework. To account for label uncertainty, we propose a novel modification to ordinal regression loss functions that enables them to operate on soft labels reflecting annotator rating distributions. Our proposed soft ordinal regression method achieves predictive performance approaching that of clinical experts, while producing well-calibrated uncertainty estimates. By providing an automated tool for phonotrauma severity assessment, our work can enable large-scale studies of phonotrauma, ultimately leading to improved clinical understanding and patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>16 pages, 9 figures, 5 tables; ML4H 2025; Proceedings of Machine Learning Research 297, 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>