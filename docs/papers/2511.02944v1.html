<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics - Health AI Hub</title>
    <meta name="description" content="This paper introduces novel methods to optimize adaptive interventions in Micro-Randomized Trials (MRTs), addressing the challenge of interventions whose effect">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.02944v1" target="_blank">2511.02944v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fengxu Li, Stephanie M. Carpenter, Matthew P. Buman, Yonatan Mintz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI, math.OC, stat.ML
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.02944v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.02944v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces novel methods to optimize adaptive interventions in Micro-Randomized Trials (MRTs), addressing the challenge of interventions whose effectiveness changes over time due to habituation and recovery dynamics. It proposes ROGUE-TS, a Thompson Sampling algorithm for the ROGUE bandit framework, and a probability clipping procedure to balance personalized recommendations with the critical need for sufficient exploration to estimate population-level effects. Validated on MRT datasets for physical activity and bipolar disorder, the methods achieve lower regret and maintain high statistical power for detecting treatment effects.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for developing robust just-in-time adaptive interventions in behavioral health and medicine. It enables researchers to design MRTs that can both personalize treatments to individuals and reliably evaluate their population-level efficacy, which is vital for evidence-based practice and improving outcomes for conditions like physical inactivity and bipolar disorder.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper develops ROGUE-TS, a Thompson Sampling algorithm, and a probability clipping procedure, specifically for optimizing just-in-time adaptive interventions in health settings. This AI algorithm is designed to balance personalized recommendations for individuals (e.g., in behavioral or mental health) with the need for sufficient exploration to estimate population-level effects and ensure statistical power in micro-randomized trials, which is a critical application of AI in clinical research and personalized healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenge of nonstationary bandit problems in behavioral health interventions, where actions exhibit habituation (reduced effectiveness with use) and recovery (restoration with inactivity), modeled by the ROGUE framework.</li>
                    
                    <li>Highlights the conflict in Micro-Randomized Trials (MRTs) between optimizing personalized recommendations (exploitation) and ensuring sufficient exploration to estimate population-level intervention effects and maintain statistical power.</li>
                    
                    <li>Develops ROGUE-TS, a Thompson Sampling algorithm specifically tailored for the ROGUE bandit framework, providing theoretical guarantees of sublinear regret.</li>
                    
                    <li>Introduces a probability clipping procedure designed to enforce a minimum exploration probability, thereby explicitly balancing personalization with the need for population-level learning.</li>
                    
                    <li>Quantifies the trade-off inherent in the clipping procedure, balancing regret minimization with the maintenance of a minimum exploration probability.</li>
                    
                    <li>Validates the proposed methods using two real-world MRT datasets focused on physical activity promotion and bipolar disorder treatment.</li>
                    
                    <li>Demonstrates that ROGUE-TS with the clipping procedure achieves lower regret than existing approaches while successfully maintaining high statistical power for detecting treatment effects without significantly increasing regret.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper develops ROGUE-TS, a Thompson Sampling algorithm specifically designed for the Reducing or Gaining Unknown Efficacy (ROGUE) bandit framework, which models intervention effectiveness dynamics with habituation and recovery. To address the need for population-level inference in MRTs, a probability clipping procedure is introduced. This procedure modifies the action probabilities generated by ROGUE-TS to ensure a minimum exploration probability, balancing personalization with statistical power for detecting treatment effects. Theoretical guarantees of sublinear regret are provided for ROGUE-TS, and the clipping procedure's trade-off between regret and exploration is mathematically quantified. Validation is performed on two real-world MRT datasets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed ROGUE-TS algorithm, augmented with the probability clipping procedure, achieved lower regret compared to existing methods when tested on MRT datasets concerning physical activity promotion and bipolar disorder treatment. A critical finding is that the clipping procedure successfully maintained high statistical power for detecting treatment effects without a significant increase in regret, enabling robust population-level inference while still accounting for individual behavioral dynamics.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework provides practical guidance for researchers designing MRTs, enabling the development of more effective and statistically sound just-in-time adaptive interventions. It facilitates a critical balance between delivering personalized recommendations and ensuring the ability to reliably detect and estimate population-level treatment effects, fostering evidence-based advancements in behavioral health and mental health interventions. This can lead to better patient outcomes through tailored, yet rigorously evaluated, digital and adaptive therapies.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, the introduction of a 'quantified trade-off that balances regret and minimum exploration probability' through the clipping procedure inherently implies that there is an optimization decision where fully minimizing regret might be slightly sacrificed to achieve sufficient statistical power, or vice versa, depending on the chosen clipping parameters.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Behavioral Health</span>
                    
                    <span class="tag">Mental Health (Bipolar Disorder)</span>
                    
                    <span class="tag">Public Health (Physical Activity Promotion)</span>
                    
                    <span class="tag">Personalized Medicine</span>
                    
                    <span class="tag">Digital Therapeutics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Thompson Sampling</span>
                    
                    <span class="tag tag-keyword">Micro-Randomized Trials</span>
                    
                    <span class="tag tag-keyword">Nonstationary Bandits</span>
                    
                    <span class="tag tag-keyword">Habituation</span>
                    
                    <span class="tag tag-keyword">Recovery Dynamics</span>
                    
                    <span class="tag tag-keyword">Adaptive Interventions</span>
                    
                    <span class="tag tag-keyword">Statistical Power</span>
                    
                    <span class="tag tag-keyword">Behavioral Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>