<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multiclass Local Calibration With the Jensen-Shannon Distance - Health AI Hub</title>
    <meta name="description" content="This paper addresses a significant limitation in current multiclass machine learning calibration methods: 'proximity bias,' where predictions in sparse regions ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Multiclass Local Calibration With the Jensen-Shannon Distance</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26566v1" target="_blank">2510.26566v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Cesare Barbera, Lorenzo Perini, Giovanni De Toni, Andrea Passerini, Andrea Pugnana
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.80 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26566v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26566v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper addresses a significant limitation in current multiclass machine learning calibration methods: 'proximity bias,' where predictions in sparse regions of the feature space are systematically miscalibrated, posing a major risk in high-stakes fields like healthcare. It introduces the formal concept of multiclass local calibration and proposes a novel method for Neural Networks that utilizes the Jensen-Shannon distance to align predicted probabilities with local estimates of class frequencies, empirically demonstrating its effectiveness in enhancing trustworthiness.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly pertinent to medicine and healthcare as it directly tackles the critical issue of biased and miscalibrated AI predictions for rare or unusual patient cases. By ensuring more accurate probability estimates in these 'sparse regions,' it contributes to more trustworthy, equitable, and safe machine learning models crucial for clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research contributes to the development of more trustworthy and equitable AI models for healthcare. It helps ensure that AI predictions, such as disease risk, diagnosis probabilities, or treatment outcomes, are accurately calibrated across all patient populations, including those with rare conditions or unusual feature profiles. This directly impacts the reliability and fairness of AI tools used to assist clinicians in diagnosis, treatment planning, and patient management, reducing the risk of biased or miscalibrated advice for vulnerable patient groups.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem of Proximity Bias**: Existing multiclass calibration approaches lack a notion of input distance, leading to systematic miscalibration of predictions in sparse feature space regions, termed 'proximity bias'.</li>
                    
                    <li>**Healthcare Vulnerability**: This proximity bias is particularly critical in high-stakes settings like healthcare, where rare or atypical patient instances (sparse data points) are precisely those most susceptible to biased treatment due to miscalibrated predictions.</li>
                    
                    <li>**Formal Definition of Local Calibration**: The work formally defines 'multiclass local calibration' and establishes its theoretical relationship with the more stringent 'strong calibration.'</li>
                    
                    <li>**Critique of Evaluation Metrics**: The paper includes a theoretical analysis highlighting the pitfalls of applying existing evaluation metrics to assess multiclass local calibration.</li>
                    
                    <li>**Proposed Method for Neural Networks**: A practical method is introduced to enhance local calibration in Neural Networks by enforcing alignment between predicted probabilities and local estimates of true class frequencies.</li>
                    
                    <li>**Jensen-Shannon Distance**: The core of the proposed alignment method employs the Jensen-Shannon distance, a metric for probability distributions, to quantify and minimize the discrepancy.</li>
                    
                    <li>**Empirical Validation**: The novel approach is empirically validated against existing multiclass calibration techniques, demonstrating its superior ability to improve local calibration.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves several steps: formally defining 'multiclass local calibration' and its relationship to 'strong calibration'; theoretically analyzing the shortcomings of existing evaluation metrics for this new notion; proposing a practical method for Neural Networks that aligns predicted probabilities with local estimates of class frequencies using the Jensen-Shannon distance; and finally, empirically validating this new approach against current state-of-the-art multiclass calibration techniques.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The key finding is the successful introduction and validation of 'multiclass local calibration' as a crucial concept for trustworthy AI. The paper demonstrates that its proposed method, leveraging the Jensen-Shannon distance within Neural Networks, can effectively mitigate 'proximity bias' and enhance the calibration of predictions, particularly for sparse data points, which is vital in high-stakes applications like healthcare.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to significantly enhance the reliability and fairness of AI models in clinical practice. By improving the calibration of predictions, especially for patients with rare conditions or complex presentations, it can reduce diagnostic errors, minimize biased treatment recommendations, and increase clinician trust in AI-assisted decision-making, ultimately leading to more equitable and effective patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper primarily highlights a critical limitation of *existing* multiclass calibration approaches: their lack of a notion of distance among inputs, which makes them vulnerable to 'proximity bias' and miscalibrated predictions in sparse data regions, particularly problematic in high-stakes healthcare scenarios.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Diagnostic imaging</span>
                    
                    <span class="tag">Personalized medicine</span>
                    
                    <span class="tag">Rare disease diagnosis</span>
                    
                    <span class="tag">Clinical decision support systems</span>
                    
                    <span class="tag">Medical risk assessment</span>
                    
                    <span class="tag">Predictive analytics in healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multiclass classification</span>
                    
                    <span class="tag tag-keyword">Machine Learning calibration</span>
                    
                    <span class="tag tag-keyword">Local calibration</span>
                    
                    <span class="tag tag-keyword">Proximity bias</span>
                    
                    <span class="tag tag-keyword">Jensen-Shannon distance</span>
                    
                    <span class="tag tag-keyword">Neural Networks</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                    <span class="tag tag-keyword">Trustworthy AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Developing trustworthy Machine Learning (ML) models requires their predicted
probabilities to be well-calibrated, meaning they should reflect true-class
frequencies. Among calibration notions in multiclass classification, strong
calibration is the most stringent, as it requires all predicted probabilities
to be simultaneously calibrated across all classes. However, existing
approaches to multiclass calibration lack a notion of distance among inputs,
which makes them vulnerable to proximity bias: predictions in sparse regions of
the feature space are systematically miscalibrated. This is especially relevant
in high-stakes settings, such as healthcare, where the sparse instances are
exactly those most at risk of biased treatment. In this work, we address this
main shortcoming by introducing a local perspective on multiclass calibration.
First, we formally define multiclass local calibration and establish its
relationship with strong calibration. Second, we theoretically analyze the
pitfalls of existing evaluation metrics when applied to multiclass local
calibration. Third, we propose a practical method for enhancing local
calibration in Neural Networks, which enforces alignment between predicted
probabilities and local estimates of class frequencies using the Jensen-Shannon
distance. Finally, we empirically validate our approach against existing
multiclass calibration techniques.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>