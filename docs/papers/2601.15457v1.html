<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering - Health AI Hub</title>
    <meta name="description" content="This paper empirically evaluates Retrieval-Augmented Generation (RAG) architectures to mitigate Large Language Model (LLM) hallucinations when answering questio">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15457v1" target="_blank">2601.15457v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Anuj Maharjan, Umesh Yadav
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI, cs.IR
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15457v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15457v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper empirically evaluates Retrieval-Augmented Generation (RAG) architectures to mitigate Large Language Model (LLM) hallucinations when answering questions from public health policy documents, specifically CDC guidance. It demonstrates that Advanced RAG, employing a two-stage retrieval mechanism with cross-encoder re-ranking, significantly improves output faithfulness (0.797) compared to Basic RAG (0.621) and Vanilla LLMs (0.347), which is crucial for high-stakes information integrity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically relevant to the medical and public health sectors by providing a robust method to ensure the accuracy and reliability of LLM-generated information derived from authoritative sources like CDC policy documents, thereby reducing the risk of misinformation in high-stakes environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies AI (LLM/RAG architectures) to enhance the reliability and accuracy of question-answering systems for complex public health and healthcare policy documents. This application can aid public health officials, policymakers, and healthcare administrators in navigating vast repositories of regulatory guidance, ensuring adherence to critical health guidelines and mitigating the risks associated with incorrect information in high-stakes health environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>LLMs offer transformative potential for public health policy but are limited by their propensity for generating hallucinations (factually incorrect assertions).</li>
                    
                    <li>RAG architectures are explored as a solution to ground LLM generative outputs in authoritative document context, mitigating hallucination risks in public health regulatory guidance.</li>
                    
                    <li>The study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG, with the latter incorporating cross-encoder re-ranking for improved retrieval.</li>
                    
                    <li>Experimental setup utilized a Mistral-7B-Instruct-v0.2 LLM and an all-MiniLM-L6-v2 embedding model, processing official CDC policy analytical frameworks and guidance documents.</li>
                    
                    <li>Two chunking strategies (recursive character-based and token-based semantic splitting) were evaluated for their impact on system accuracy, measured by faithfulness and relevance.</li>
                    
                    <li>Quantitative results showed Advanced RAG achieving the highest average faithfulness of 0.797, significantly outperforming Basic RAG (0.621) and the Vanilla LLM baseline (0.347).</li>
                    
                    <li>The findings underscore the necessity of two-stage retrieval mechanisms for achieving the precision required in domain-specific policy question answering, though document segmentation remains a challenge for complex multi-step reasoning.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed an empirical evaluation comparing three LLM architectures: a Vanilla LLM baseline, Basic RAG, and Advanced RAG. The Advanced RAG configuration integrated a two-stage retrieval mechanism utilizing an all-MiniLM-L6-v2 embedding model for initial retrieval and a cross-encoder for re-ranking. A Mistral-7B-Instruct-v0.2 model served as the generative LLM. The evaluation corpus comprised official CDC policy documents. Two distinct document chunking strategies (recursive character-based and token-based semantic splitting) were tested. System accuracy was quantitatively measured using faithfulness and relevance scores across a curated set of complex policy scenarios.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Advanced RAG architectures, leveraging cross-encoder re-ranking for two-stage retrieval, achieved a superior faithfulness average of 0.797, representing a substantial improvement over Basic RAG (0.621) and Vanilla LLM baselines (0.347). This demonstrates that sophisticated RAG configurations are essential for precision in answering questions from domain-specific public health policy documents.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By drastically reducing LLM hallucinations, this research directly contributes to more reliable and trustworthy AI systems for public health. This can lead to more accurate interpretation and application of CDC guidance by healthcare professionals, policymakers, and researchers, potentially improving compliance with health regulations, facilitating evidence-based policy decisions, and ultimately enhancing public health outcomes by ensuring information integrity.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The study noted that structural constraints in document segmentation (chunking strategies) remain a significant bottleneck, particularly for LLMs tasked with multi-step reasoning challenges within complex policy scenarios.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research should focus on developing and evaluating more sophisticated document segmentation strategies to overcome current structural constraints, thereby improving the ability of RAG architectures to handle multi-step reasoning tasks and extract nuanced information from complex public health policy documents.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Health Policy</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                    <span class="tag">Regulatory Affairs</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">RAG</span>
                    
                    <span class="tag tag-keyword">LLM</span>
                    
                    <span class="tag tag-keyword">Public Health Policy</span>
                    
                    <span class="tag tag-keyword">CDC</span>
                    
                    <span class="tag tag-keyword">Hallucination</span>
                    
                    <span class="tag tag-keyword">Faithfulness</span>
                    
                    <span class="tag tag-keyword">Retrieval-Augmented Generation</span>
                    
                    <span class="tag tag-keyword">Cross-Encoder Re-ranking</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>