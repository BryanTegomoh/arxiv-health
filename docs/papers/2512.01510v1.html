<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper addresses the challenging problem of single-source domain generalization (DG) for medical image segmentation, enabling models trained on one domain t">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.01510v1" target="_blank">2512.01510v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-01
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Franz Thaler, Martin Urschler, Mateusz Kozinski, Matthias AF Gsell, Gernot Plank, Darko Stern
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.01510v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.01510v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper addresses the challenging problem of single-source domain generalization (DG) for medical image segmentation, enabling models trained on one domain to be applied directly to different domains without adaptation. The proposed method, SRCSM, leverages semantic-aware random convolution during training and intensity mapping at test-time to achieve state-of-the-art performance. SRCSM consistently outperforms previous DG techniques and remarkably matches in-domain baseline performance in several cross-modality and cross-center segmentation tasks.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly enhances the practical utility and deployability of AI in medical imaging by enabling deep learning models to generalize across diverse imaging modalities and scanner hardware without extensive re-training or the need for new, costly annotations. This directly reduces the burden of data acquisition and annotation in clinical settings, accelerating the integration of AI tools into healthcare workflows.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application developed in this paper is an advanced deep learning method for automatic and robust segmentation of anatomical structures and organs (e.g., heart, prostate, abdominal organs) from various medical images (CT, MR). This technology is crucial for improving the efficiency and accuracy of medical diagnoses, enabling precise treatment planning (e.g., surgery, radiation therapy), and facilitating quantitative disease monitoring, particularly by making AI models generalize well across diverse medical imaging data encountered in real-world hospital environments without requiring extensive re-training or adaptation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Tackles single-source domain generalization (DG) in medical image segmentation, allowing models trained on one domain (e.g., CT) to be used on another (e.g., MR) without further adaptation or target domain data.</li>
                    
                    <li>Introduces SRCSM (Semantic-aware Random Convolution and Source Matching), a novel method designed to promote DG in deep segmentation networks.</li>
                    
                    <li>During training, SRCSM employs 'semantic-aware random convolution' to diversify the source domain by augmenting different regions of an image differently, guided by their annotation labels.</li>
                    
                    <li>At test-time, the method utilizes 'source matching' by mapping the intensity of target domain images to make them semantically similar to the source domain data, thus complementing the training randomization.</li>
                    
                    <li>Extensively evaluated across various cross-modality (e.g., CT to MR) and cross-center generalization settings for abdominal, whole-heart, and prostate segmentation.</li>
                    
                    <li>Achieves new state-of-the-art performance in DG for medical image segmentation, outperforming prior techniques in a vast majority of experiments.</li>
                    
                    <li>Demonstrates a significant breakthrough by matching the segmentation performance of the in-domain baseline in several settings, indicating highly effective and practical generalization.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The SRCSM method comprises two main components. During the training phase, 'semantic-aware random convolution' is applied, where different augmentation strategies (random convolutions) are selectively applied to distinct regions of the source images based on their semantic annotation labels. This spatially intelligent augmentation aims to increase the diversity and robustness of the learned features. In the test phase, 'source matching' is performed, which involves pre-processing target domain images by mapping their intensity profiles to become more consistent with the intensity distribution of the source domain data used during training. This helps bridge the domain gap at inference time.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings indicate that SRCSM establishes a new state-of-the-art in domain generalization for medical image segmentation. It consistently and significantly outperforms existing DG techniques in diverse cross-modality and cross-center scenarios, including abdominal, whole-heart, and prostate segmentation. Most notably, SRCSM achieves a segmentation performance that, in multiple complex settings, equals the performance of models trained and evaluated on data from the same domain (in-domain baseline), demonstrating exceptional generalization capability. The method also shows promising results in highly challenging settings like generalizing to cine MR data from different scanners.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The clinical impact of SRCSM is substantial, as it addresses a critical barrier to AI adoption in medicine: the inability of models to generalize across varied clinical data. By facilitating effective generalization from a single source domain, SRCSM can dramatically reduce the need for extensive manual annotations for new scanners, hospitals, or imaging protocols. This accelerates the development and deployment of robust AI-powered segmentation tools, leading to more efficient diagnostic workflows, improved surgical planning, and personalized treatment strategies across diverse healthcare environments without increased data collection and annotation costs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the SRCSM method. However, implicit challenges for DG methods generally include potential performance degradation under extremely novel or rare domain shifts not adequately covered by training data augmentation, or the computational overhead associated with semantic-aware augmentation and test-time processing.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests future work by noting that the method makes a 'step towards closing the domain gap in this even more challenging setting' of generalizing to cine MR data from different scanner hardware. This implies that further research could focus on enhancing robustness and performance in highly dynamic, complex, and previously unseen target domains, potentially exploring more advanced domain adaptation or generalization techniques for such extreme shifts.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Abdominal Segmentation</span>
                    
                    <span class="tag">Whole-Heart Segmentation</span>
                    
                    <span class="tag">Prostate Segmentation</span>
                    
                    <span class="tag">Cardiovascular Imaging</span>
                    
                    <span class="tag">Radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Domain Generalization</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Semantic-aware Random Convolution</span>
                    
                    <span class="tag tag-keyword">Source Matching</span>
                    
                    <span class="tag tag-keyword">Cross-Modality</span>
                    
                    <span class="tag tag-keyword">CT</span>
                    
                    <span class="tag tag-keyword">MR</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">We tackle the challenging problem of single-source domain generalization (DG) for medical image segmentation. To this end, we aim for training a network on one domain (e.g., CT) and directly apply it to a different domain (e.g., MR) without adapting the model and without requiring images or annotations from the new domain during training. We propose a novel method for promoting DG when training deep segmentation networks, which we call SRCSM. During training, our method diversifies the source domain through semantic-aware random convolution, where different regions of a source image are augmented differently, based on their annotation labels. At test-time, we complement the randomization of the training domain via mapping the intensity of target domain images, making them similar to source domain data. We perform a comprehensive evaluation on a variety of cross-modality and cross-center generalization settings for abdominal, whole-heart and prostate segmentation, where we outperform previous DG techniques in a vast majority of experiments. Additionally, we also investigate our method when training on whole-heart CT or MR data and testing on the diastolic and systolic phase of cine MR data captured with different scanner hardware, where we make a step towards closing the domain gap in this even more challenging setting. Overall, our evaluation shows that SRCSM can be considered a new state-of-the-art in DG for medical image segmentation and, moreover, even achieves a segmentation performance that matches the performance of the in-domain baseline in several settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Preprint submitted to Computer Methods and Programs in Biomedicine (currently under revision)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>