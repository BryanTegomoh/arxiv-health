<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces SRCSM, a novel method addressing single-source domain generalization for medical image segmentation, enabling a model trained on one domai">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.01510v1" target="_blank">2512.01510v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-01
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Franz Thaler, Martin Urschler, Mateusz Kozinski, Matthias AF Gsell, Gernot Plank, Darko Stern
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.01510v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.01510v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SRCSM, a novel method addressing single-source domain generalization for medical image segmentation, enabling a model trained on one domain (e.g., CT) to directly segment images from a different domain (e.g., MR) without adaptation. SRCSM achieves this by combining semantic-aware random convolution during training with test-time intensity source matching, establishing a new state-of-the-art and often matching in-domain performance across various challenging cross-modality and cross-center scenarios.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for medical AI as it enables segmentation models to be more robust and transferable across the diverse imaging modalities and hardware found in real-world clinical practice, significantly reducing the need for costly and time-consuming re-training or re-annotation for every new dataset or clinical environment.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to develop more robust and generalizable deep learning models for medical image segmentation. By improving domain generalization, the proposed method (SRCSM) helps AI models trained on limited data sources to perform reliably on diverse patient populations, different scanner types, and varying imaging protocols, thus enhancing diagnostic accuracy, automating measurement for treatment planning (e.g., tumor volume, heart chamber size), and facilitating disease monitoring in real-world clinical environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenging problem of single-source domain generalization (DG) for medical image segmentation, allowing models to be trained on one domain and directly applied to different domains without adaptation or data from the new domain.</li>
                    
                    <li>Proposes SRCSM (Semantic-aware Random Convolution and Source Matching) as a novel method to promote DG when training deep segmentation networks.</li>
                    
                    <li>During training, SRCSM employs 'semantic-aware random convolution' to diversify the source domain by augmenting different regions of an image distinctively based on their annotation labels.</li>
                    
                    <li>At test-time, SRCSM complements the training randomization with 'source matching,' which maps the intensity of target domain images to make them similar to source domain data.</li>
                    
                    <li>Comprehensive evaluation was conducted on various cross-modality (e.g., CT to MR) and cross-center generalization settings for abdominal, whole-heart, and prostate segmentation.</li>
                    
                    <li>SRCSM significantly outperforms previous DG techniques in a vast majority of experiments, establishing itself as a new state-of-the-art in medical image segmentation DG.</li>
                    
                    <li>Remarkably, the method achieves segmentation performance that matches the in-domain baseline in several challenging settings and makes progress in generalizing to cine MR data with different scanner hardware.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The SRCSM method consists of two primary components. During the training phase, 'semantic-aware random convolution' is applied, which diversifies the source domain by augmenting different regions of an image (e.g., foreground vs. background, or different anatomical structures) distinctively based on their annotation labels. Subsequently, at test-time, 'source matching' is utilized to map the intensity profiles of incoming target domain images, making them structurally similar to the source domain data the model was trained on, thereby bridging the domain shift without requiring target annotations.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SRCSM consistently demonstrates superior performance over existing domain generalization techniques across a wide array of medical image segmentation tasks, including abdominal, whole-heart, and prostate segmentation under both cross-modality and cross-center conditions. A pivotal finding is SRCSM's ability to achieve segmentation performance that matches the in-domain baseline in multiple settings, effectively closing the performance gap between specialized models and generalized ones. Furthermore, it shows promising progress in generalizing to the more challenging scenario of cine MR data from different scanner hardware, establishing a new state-of-the-art.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SRCSM has the potential to dramatically accelerate the deployment and improve the utility of AI-powered medical image segmentation tools in clinical settings. By overcoming domain shifts between different scanners, manufacturers, and imaging modalities, it reduces the burden of acquiring and annotating vast amounts of new data for each unique clinical environment, leading to more efficient workflows, increased diagnostic accuracy, and broader accessibility of advanced image analysis in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly mention specific limitations of the SRCSM method, though the 'even more challenging setting' of cine MR data suggests areas where further improvements might still be beneficial compared to perfect generalization.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract implies future research could focus on further closing the domain gap in particularly challenging scenarios, such as fully generalizing to highly variable cine MR data captured with diverse scanner hardware, building upon the significant initial step made by SRCSM in this area.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">abdominal imaging</span>
                    
                    <span class="tag">cardiac imaging</span>
                    
                    <span class="tag">prostate imaging</span>
                    
                    <span class="tag">oncology</span>
                    
                    <span class="tag">radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">domain generalization</span>
                    
                    <span class="tag tag-keyword">medical image segmentation</span>
                    
                    <span class="tag tag-keyword">semantic-aware random convolution</span>
                    
                    <span class="tag tag-keyword">source matching</span>
                    
                    <span class="tag tag-keyword">cross-modality</span>
                    
                    <span class="tag tag-keyword">cross-center</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">CT</span>
                    
                    <span class="tag tag-keyword">MR</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">We tackle the challenging problem of single-source domain generalization (DG) for medical image segmentation. To this end, we aim for training a network on one domain (e.g., CT) and directly apply it to a different domain (e.g., MR) without adapting the model and without requiring images or annotations from the new domain during training. We propose a novel method for promoting DG when training deep segmentation networks, which we call SRCSM. During training, our method diversifies the source domain through semantic-aware random convolution, where different regions of a source image are augmented differently, based on their annotation labels. At test-time, we complement the randomization of the training domain via mapping the intensity of target domain images, making them similar to source domain data. We perform a comprehensive evaluation on a variety of cross-modality and cross-center generalization settings for abdominal, whole-heart and prostate segmentation, where we outperform previous DG techniques in a vast majority of experiments. Additionally, we also investigate our method when training on whole-heart CT or MR data and testing on the diastolic and systolic phase of cine MR data captured with different scanner hardware, where we make a step towards closing the domain gap in this even more challenging setting. Overall, our evaluation shows that SRCSM can be considered a new state-of-the-art in DG for medical image segmentation and, moreover, even achieves a segmentation performance that matches the performance of the in-domain baseline in several settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Preprint submitted to Computer Methods and Programs in Biomedicine (currently under revision)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>