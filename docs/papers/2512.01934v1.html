<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory - Health AI Hub</title>
    <meta name="description" content="This paper introduces AdvTraj, the first online and physical ID-manipulation attack against Multi-Object Tracking (MOT) systems that operates by generating adve">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.01934v1" target="_blank">2512.01934v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-01
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chenyi Wang, Yanmao Man, Raymond Muller, Ming Li, Z. Berkay Celik, Ryan Gerdes, Jonathan Petit
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.01934v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.01934v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces AdvTraj, the first online and physical ID-manipulation attack against Multi-Object Tracking (MOT) systems that operates by generating adversarial trajectories without directly attacking the object detection module. AdvTraj successfully transfers the attacker's ID to a target object, demonstrating 100% success in white-box simulations and high transferability to state-of-the-art MOT algorithms, revealing critical vulnerabilities in their object association mechanisms.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>While primarily a computer science paper, its findings are highly relevant to the safety and reliability of autonomous systems that may be deployed in healthcare, such as surgical robots, hospital logistics robots, or patient monitoring systems, where incorrect object identification could lead to severe patient harm or operational failures.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Multi-Object Tracking (MOT) is an AI application used in health for real-time monitoring of patients (e.g., for fall detection, tracking wandering, adherence to social distancing in clinical environments), enhancing hospital security (e.g., tracking staff and visitors in sensitive areas, monitoring valuable medical equipment), and ensuring biosecurity by tracking personnel movement within research labs or infectious disease units. This research reveals a critical vulnerability in these AI systems that, if exploited, could compromise patient safety, data privacy, hospital security, and biosecurity protocols by allowing for physical manipulation and misidentification within the tracking system.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>AdvTraj is presented as the first online and physical ID-manipulation attack against tracking-by-detection Multi-Object Tracking (MOT) systems.</li>
                    
                    <li>Unlike previous attacks, AdvTraj does not target the integrated object detection (OD) module; instead, it uses adversarial trajectories to confuse ID assignments.</li>
                    
                    <li>The attack mechanism involves an attacker executing a specifically crafted trajectory to transfer its assigned ID to a targeted object.</li>
                    
                    <li>Simulation results in CARLA demonstrate a 100% attack success rate for white-box attacks against SORT, showcasing the efficacy of AdvTraj.</li>
                    
                    <li>AdvTraj exhibits high attack transferability (up to 93% success rate) against various state-of-the-art (SOTA) MOT algorithms, highlighting common architectural vulnerabilities.</li>
                    
                    <li>The research characterizes the patterns of successful adversarial trajectories and proposes two universal adversarial maneuvers that can be performed by human walkers or drivers in real-world scenarios.</li>
                    
                    <li>The work uncovers significant, previously under-explored weaknesses in the object association phase of current MOT systems, providing critical insights for enhancing their robustness.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes AdvTraj, an online and physical attack mechanism that leverages adversarial trajectories to manipulate ID assignments in tracking-by-detection MOT systems. Simulations were conducted in the CARLA environment to test the attack's effectiveness. White-box attacks were performed against SORT, a common MOT algorithm, and the transferability of the attack was evaluated against several state-of-the-art MOT algorithms. The methodology involved characterizing successful adversarial trajectory patterns and devising universal maneuvers for physical execution.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>AdvTraj achieved a 100% success rate in ID assignment manipulation for white-box attacks against SORT in CARLA simulations. It demonstrated significant transferability, with up to 93% success against other state-of-the-art MOT algorithms. The research also identified and characterized specific adversarial trajectory patterns, enabling the proposal of two universal physical maneuvers that can be executed by humans.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>In a clinical context, the vulnerability demonstrated by AdvTraj means that autonomous systems like robotic surgical assistants or automated drug delivery robots, relying on MOT for object identification and tracking, could be tricked into misidentifying critical objects (e.g., surgical tools, patients, or medications). This could lead to serious clinical errors, patient safety incidents, or compromised operational integrity within healthcare facilities. Ensuring the robustness of MOT systems against such adversarial attacks is crucial for safe and reliable medical automation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily focuses on the strengths and novelty of AdvTraj, noting that previous attacks were model-specific, non-robust, and offline, which AdvTraj overcomes. It highlights that the work reveals 'under-explored weaknesses' in MOT systems. However, specific limitations or caveats of AdvTraj itself (e.g., environmental constraints for physical execution, detection difficulty, or required proximity) are not explicitly detailed in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The findings provide crucial insights into enhancing the robustness of Multi-Object Tracking (MOT) systems, specifically against ID-transfer attacks. Future research should focus on developing defense mechanisms to detect and mitigate adversarial trajectories and strengthen the object association phase of MOT algorithms to prevent such manipulation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Surgical Robotics Safety</span>
                    
                    <span class="tag">Hospital Logistics Automation</span>
                    
                    <span class="tag">Patient Monitoring Systems (future)</span>
                    
                    <span class="tag">Rehabilitation Robotics</span>
                    
                    <span class="tag">Medical Imaging Analysis (tracking agents/instruments)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multi-Object Tracking</span>
                    
                    <span class="tag tag-keyword">Adversarial Attack</span>
                    
                    <span class="tag tag-keyword">Physical Attack</span>
                    
                    <span class="tag tag-keyword">Trajectory Manipulation</span>
                    
                    <span class="tag tag-keyword">ID-Transfer</span>
                    
                    <span class="tag tag-keyword">Computer Vision Security</span>
                    
                    <span class="tag tag-keyword">Autonomous Systems</span>
                    
                    <span class="tag tag-keyword">Cyber-Physical Systems</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to Annual Computer Security Applications Conference (ACSAC) 2024</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>