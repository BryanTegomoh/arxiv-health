<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction - Health AI Hub</title>
    <meta name="description" content="This paper systematically evaluates the efficacy of large language models (LLMs) in detecting and correcting medical errors within clinical documentation, compa">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.19858v1" target="_blank">2511.19858v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Farzad Ahmed, Joniel Augustine Jerome, Meliha Yetisgen, √ñzlem Uzuner
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.19858v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.19858v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper systematically evaluates the efficacy of large language models (LLMs) in detecting and correcting medical errors within clinical documentation, comparing zero-shot, static, and retrieval-augmented dynamic prompting strategies. It demonstrates that Retrieval-augmented Dynamic Prompting (RDP) significantly outperforms other methods across diverse LLMs, leading to improved error detection accuracy, reduced false positives, and more contextually appropriate error corrections. The findings suggest RDP as a promising approach for enhancing patient safety through automated quality control in medical documentation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate clinical documentation is fundamental to patient safety, proper diagnosis, and effective treatment. This research provides a robust method using LLMs to automatically identify and rectify medical errors, thereby reducing preventable adverse events and improving the quality of patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using Large Language Models (LLMs), specifically with Retrieval-Augmented Dynamic Prompting (RDP), to automatically detect and correct factual, diagnostic, and management errors within clinical medical documentation. The goal is to enhance the reliability of clinical records and ultimately improve patient safety by mitigating risks associated with documentation errors.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study addresses the critical problem of factual, diagnostic, and management errors in clinical documentation that compromise patient safety.</li>
                    
                    <li>Nine instruction-tuned Large Language Models (LLMs), including GPT, Claude, Gemini, and OpenAI o-series models, were evaluated.</li>
                    
                    <li>Three distinct prompting strategies were compared: zero-shot prompting, Static Prompting with Random exemplars (SPR), and Retrieval-augmented Dynamic Prompting (RDP).</li>
                    
                    <li>Performance was assessed across three subtasks: error flag detection, error sentence detection, and error correction, utilizing the MEDEC dataset.</li>
                    
                    <li>Evaluation metrics included accuracy, recall, and false-positive rate (FPR) for detection tasks, and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction.</li>
                    
                    <li>Zero-shot prompting exhibited low recall, particularly for abbreviation-heavy or atypical errors, while SPR improved recall but increased FPR.</li>
                    
                    <li>RDP consistently outperformed other methods across all LLMs, reducing FPR by approximately 15%, improving recall in error sentence detection by 5 to 10 percent, and generating more contextually accurate corrections.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized the MEDEC dataset to evaluate nine instruction-tuned LLMs (GPT, Claude, Gemini, OpenAI o-series) on three medical error processing subtasks: error flag detection, error sentence detection, and error correction. Three prompting strategies were tested: zero-shot, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP). Performance was quantified using accuracy, recall, and false-positive rate (FPR) for detection tasks, and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. Qualitative analysis of example outputs was also conducted to identify failure modes and compare LLM vs. clinician reasoning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Zero-shot prompting resulted in low recall, particularly for complex or abbreviated errors, while SPR improved recall but increased the false-positive rate. Notably, Retrieval-augmented Dynamic Prompting (RDP) consistently demonstrated superior performance across all nine evaluated LLMs, achieving an approximate 15 percent reduction in FPR, a 5 to 10 percent improvement in recall for error sentence detection, and generating significantly more contextually accurate error corrections compared to zero-shot and SPR methods.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The implementation of RDP-enabled LLMs could revolutionize medical documentation review by offering an automated, scalable, and highly accurate system for detecting and correcting critical errors. This has the potential to substantially reduce medical errors, enhance diagnostic accuracy, streamline clinical workflows, and ultimately lead to safer and higher-quality patient care across healthcare systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Patient Safety</span>
                    
                    <span class="tag">Healthcare Quality Improvement</span>
                    
                    <span class="tag">Medical Record Review</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">Medical Error Detection</span>
                    
                    <span class="tag tag-keyword">Error Correction</span>
                    
                    <span class="tag tag-keyword">Retrieval-Augmented Generation</span>
                    
                    <span class="tag tag-keyword">Dynamic Prompting</span>
                    
                    <span class="tag tag-keyword">Clinical Documentation</span>
                    
                    <span class="tag tag-keyword">Patient Safety</span>
                    
                    <span class="tag tag-keyword">MEDEC dataset</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>