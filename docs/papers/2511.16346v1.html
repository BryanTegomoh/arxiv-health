<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture - Health AI Hub</title>
    <meta name="description" content="VersaPants introduces the first loose-fitting, textile-based capacitive sensing system for comfortable, privacy-preserving lower-body motion capture, leveraging">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16346v1" target="_blank">2511.16346v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Deniz Kasap, Taraneh Aminosharieh Najafi, J√©r√¥me Paul R√©my Thevenot, Jonathan Dan, Stefano Albini, David Atienza
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.SP, cs.LG, eess.SY
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16346v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16346v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">VersaPants introduces the first loose-fitting, textile-based capacitive sensing system for comfortable, privacy-preserving lower-body motion capture, leveraging the open-hardware VersaSens platform. It employs a lightweight Transformer-based deep learning model to accurately reconstruct hip, knee, and ankle joint angles from integrated textile sensors. This innovation delivers real-time inference on edge devices like smartwatches, offering a scalable and embedded solution for fitness, healthcare, and wellbeing applications.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This technology offers a non-invasive, comfortable, and privacy-preserving method for continuous lower-body motion monitoring, critical for remote patient care, rehabilitation progress tracking, fall risk assessment, and biomechanical analysis in sports medicine. Its embedded, real-time capabilities facilitate practical integration into daily life for continuous health monitoring and personalized feedback.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper utilizes a lightweight Transformer-based deep learning model to map capacitance signals from the smart garment to lower-body joint angles, enabling real-time pose reconstruction. When applied in a healthcare context, this AI model would provide objective, continuous, and unobtrusive monitoring of patient movement for purposes such as tracking rehabilitation progress, assessing gait abnormalities, predicting fall risk, and evaluating athletic performance and recovery, thereby serving as an AI-powered diagnostic and monitoring tool in health and medicine.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>VersaPants is a novel loose-fitting, textile-based capacitive sensing system designed for lower-body motion capture, built on the VersaSens open-hardware platform.</li>
                    
                    <li>The system integrates 6 conductive textile patches per leg into a pair of pants, alongside a compact acquisition unit, ensuring comfort and privacy by avoiding user-specific fitting or camera-based methods.</li>
                    
                    <li>It utilizes a lightweight Transformer-based deep learning model specifically designed to map capacitance signals from the textile sensors to lower-body joint angles, enabling embedded implementation on edge platforms.</li>
                    
                    <li>Testing involved 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements, demonstrating the model's ability to generalize to unseen users and movements.</li>
                    
                    <li>The system achieved a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints.</li>
                    
                    <li>Compared to existing textile-based deep learning architectures, the model achieves competitive reconstruction performance with significantly fewer parameters (up to 22 times) and FLOPs (up to 18 times).</li>
                    
                    <li>This efficiency enables real-time inference at 42 FPS on a commercial smartwatch without quantization, highlighting its practical deployability for continuous monitoring.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>VersaPants is a custom-designed smart garment featuring 6 capacitive sensing channels per leg, integrated into loose-fitting pants. Capacitance signals are acquired by a compact unit and processed by a lightweight Transformer-based deep learning model. This model maps the capacitance signals to hip, knee, and ankle joint angles. The system was validated by collecting approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The system demonstrated accurate lower-body pose reconstruction, achieving a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees. The lightweight Transformer model showed competitive performance with significantly reduced computational demands (22x fewer parameters, 18x fewer FLOPs) compared to other textile-based deep learning architectures, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. The model also exhibited good generalization to unseen users and movements.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>VersaPants has the potential to transform remote patient monitoring, rehabilitation, and preventative care by providing accurate, continuous, and unobtrusive motion data. Its comfort, privacy features, and real-time embedded capability can enhance patient adherence to monitoring protocols, enable timely intervention for fall prevention, facilitate objective assessment of rehabilitation progress, and support personalized training in sports and fitness without requiring specialized clinical environments or intrusive setups.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the VersaPants system itself. However, the phrasing describing it as a 'promising step toward scalable... solutions' suggests that further development, extensive validation across diverse populations, and integration into broader clinical workflows are ongoing or future necessities to realize its full potential.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future directions include further development and refinement of the VersaPants system, broader validation in diverse user populations and clinical conditions, and integration into comprehensive healthcare and wellbeing platforms. The goal is to evolve VersaPants into a fully scalable, comfortable, and embedded motion-capture solution for widespread application in fitness, healthcare, and wellbeing.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Rehabilitation</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Sports Medicine</span>
                    
                    <span class="tag">Telehealth</span>
                    
                    <span class="tag">Remote Patient Monitoring</span>
                    
                    <span class="tag">Fall Prevention</span>
                    
                    <span class="tag">Biomechanics</span>
                    
                    <span class="tag">Orthopedics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Motion capture</span>
                    
                    <span class="tag tag-keyword">Capacitive sensing</span>
                    
                    <span class="tag tag-keyword">Smart textiles</span>
                    
                    <span class="tag tag-keyword">Wearable technology</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Human pose estimation</span>
                    
                    <span class="tag tag-keyword">Rehabilitation</span>
                    
                    <span class="tag tag-keyword">Telehealth</span>
                    
                    <span class="tag tag-keyword">Embedded systems</span>
                    
                    <span class="tag tag-keyword">Privacy-preserving</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>14 pages, 8 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>