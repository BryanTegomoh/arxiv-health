<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture - Health AI Hub</title>
    <meta name="description" content="VersaPants introduces a novel loose-fitting, textile-based capacitive sensing system for lower-body motion capture, leveraging a lightweight Transformer-based d">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16346v1" target="_blank">2511.16346v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Deniz Kasap, Taraneh Aminosharieh Najafi, J√©r√¥me Paul R√©my Thevenot, Jonathan Dan, Stefano Albini, David Atienza
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.SP, cs.LG, eess.SY
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16346v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16346v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">VersaPants introduces a novel loose-fitting, textile-based capacitive sensing system for lower-body motion capture, leveraging a lightweight Transformer-based deep learning model to reconstruct joint angles. This system offers a comfortable, privacy-preserving alternative to traditional IMU or camera-based methods, achieving competitive accuracy with high computational efficiency. Its ability to perform real-time inference on edge devices positions it as a promising solution for scalable motion capture in fitness, healthcare, and wellbeing applications.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This technology provides a comfortable, privacy-preserving, and objective method for lower-body motion assessment, which is critical for monitoring rehabilitation progress, assessing gait abnormalities, and supporting fall prevention in clinical and home-based healthcare settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes an AI application that uses a lightweight Transformer-based deep learning model to translate raw capacitance signals from textile sensors into estimated joint angles (hip, knee, ankle). This AI model, optimized for edge platforms, enables real-time, embedded motion analysis, which can be applied in healthcare for automated assessment of patient movement during rehabilitation, continuous monitoring of gait patterns for neurological conditions, fall risk assessment, and personalized feedback for fitness and wellbeing.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>VersaPants is the first loose-fitting, textile-based capacitive sensing system designed for lower-body motion capture, integrating conductive textile patches and an acquisition unit into a pair of pants.</li>
                    
                    <li>It provides a comfortable and privacy-preserving alternative to IMU-based or camera-based systems, requiring no specific user fitting adjustments.</li>
                    
                    <li>The system features 6 capacitive sensing channels per leg and employs a lightweight Transformer-based deep learning model to map capacitance signals to hip, knee, and ankle joint angles.</li>
                    
                    <li>Data collected from 11 participants performing 16 daily and exercise-based movements (approx. 3.7 hours) was used to train and validate the model.</li>
                    
                    <li>The model achieved a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees, demonstrating generalization to unseen users and movements.</li>
                    
                    <li>Compared to existing textile-based deep learning architectures, the VersaPants model is highly efficient, using up to 22 times fewer parameters and 18 times fewer FLOPs.</li>
                    
                    <li>This efficiency enables real-time inference at 42 FPS on a commercial smartwatch without quantization, making it suitable for embedded edge platforms.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The VersaPants system utilizes a custom-designed smart garment with 6 conductive textile capacitive sensing channels integrated into each leg of loose-fitting pants, connected to a compact acquisition unit. A lightweight Transformer-based deep learning model was developed to map the acquired capacitance signals to lower-body joint angles (hip, knee, ankle). Data for model training and evaluation was collected from 11 participants performing 16 distinct daily and exercise-based movements over approximately 3.7 hours. Model performance was quantified using mean per-joint position error (MPJPE) and mean per-joint angle error (MPJAE), and its computational efficiency was compared against other textile-based deep learning architectures.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The VersaPants system achieved an impressive mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating robust generalization across users and movements. A key finding is the exceptional efficiency of its Transformer-based deep learning model, which requires up to 22 times fewer parameters and 18 times fewer FLOPs than comparative models, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization, ideal for embedded applications.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>VersaPants has the potential to revolutionize patient monitoring and therapy in clinical and home environments by offering unobtrusive, continuous, and objective lower-body motion capture. This could facilitate more precise rehabilitation tracking, early detection of gait impairments in elderly populations, personalized exercise prescription, and remote patient management, ultimately leading to improved patient outcomes and potentially reduced healthcare costs associated with in-person assessments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract positions VersaPants as a "promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications." This suggests future work will focus on scaling the technology for broader deployment, exploring diverse applications within fitness and healthcare, and further optimizing the embedded system for pervasive use.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Rehabilitation Medicine</span>
                    
                    <span class="tag">Physical Therapy</span>
                    
                    <span class="tag">Sports Medicine</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Orthopedics</span>
                    
                    <span class="tag">Remote Patient Monitoring</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Capacitive sensing</span>
                    
                    <span class="tag tag-keyword">Smart textiles</span>
                    
                    <span class="tag tag-keyword">Motion capture</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Wearable technology</span>
                    
                    <span class="tag tag-keyword">Rehabilitation</span>
                    
                    <span class="tag tag-keyword">Gait analysis</span>
                    
                    <span class="tag tag-keyword">Remote patient monitoring</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>14 pages, 8 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>