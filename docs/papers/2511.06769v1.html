<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research - Health AI Hub</title>
    <meta name="description" content="This paper introduces the BUET Polyp Dataset (BPD), a new colonoscopy image dataset collected in real-world, resource-limited clinical settings, featuring diver">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited Settings for Computer-Aided Diagnosis Research</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.06769v1" target="_blank">2511.06769v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Ridoy Chandra Shil, Ragib Abid, Tasnia Binte Mamun, Samiul Based Shuvo, Masfique Ahmed Bhuiyan, Jahid Ferdous
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.06769v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.06769v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the BUET Polyp Dataset (BPD), a new colonoscopy image dataset collected in real-world, resource-limited clinical settings, featuring diverse artifacts and expert-annotated binary masks. Benchmarking deep learning models on BPD revealed lower performance compared to curated datasets, underscoring the challenges of real-world data for computer-aided diagnosis (CAD) research in polyp detection.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Early and accurate detection of polyps during colonoscopy is critical for colorectal cancer prevention. This dataset facilitates the development of more robust and clinically applicable computer-aided diagnosis (CAD) tools that can perform effectively in diverse and challenging real-world clinical conditions, particularly in resource-constrained environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper provides a benchmark dataset (BUET Polyp Dataset) for training and evaluating AI models in computer-aided diagnosis (CADx) for detecting and segmenting colorectal polyps from colonoscopy images. This application aims to assist clinicians in identifying polyps more accurately and efficiently, particularly in challenging real-world clinical conditions and resource-limited environments, thereby improving colorectal cancer screening and prevention.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitation of existing colonoscopy datasets (small size, curated images, lack of real-world artifacts) by introducing a new dataset from routine clinical practice in resource-limited settings.</li>
                    
                    <li>The BUET Polyp Dataset (BPD) contains images captured using Olympus 170 and Pentax i-Scan series endoscopes, reflecting diverse challenges like motion blur, specular highlights, stool artifacts, blood, and low-light.</li>
                    
                    <li>The dataset includes expert-annotated binary masks for polyps, with annotations manually reviewed by clinical experts to ensure quality.</li>
                    
                    <li>It comprises 1,288 images with polyps (from 164 patients) with ground-truth masks and 1,657 polyp-free images (from 31 patients).</li>
                    
                    <li>Baseline performance benchmarks were established for binary classification (using VGG16, ResNet50, InceptionV3) and semantic segmentation (using UNet variants with VGG16, ResNet34, InceptionV4 backbones).</li>
                    
                    <li>Achieved a maximum classification accuracy of 90.8% (VGG16) and a maximum Dice score of 0.64 for segmentation (InceptionV4-UNet).</li>
                    
                    <li>The observed performance was lower compared to results on curated datasets, explicitly reflecting the real-world difficulty and variability introduced by artifacts in the BPD images.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The BUET Polyp Dataset (BPD) was created by collecting colonoscopy images from routine clinical conditions using Olympus 170 and Pentax i-Scan series endoscopes. Images captured various real-world artifacts (e.g., motion blur, stool, blood). Expert clinicians provided manual binary mask annotations for polyps, which were subsequently reviewed for quality. Baseline performance was evaluated using established deep learning models: VGG16, ResNet50, and InceptionV3 for binary classification, and UNet variants with VGG16, ResNet34, and InceptionV4 backbones for semantic segmentation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The BPD contains 1,288 polyp images with ground-truth masks and 1,657 polyp-free images, comprehensively representing real-world clinical challenges. Benchmarking experiments achieved a maximum classification accuracy of 90.8% (VGG16) and a Dice score of 0.64 for segmentation (InceptionV4-UNet). These results were notably lower than those typically reported on curated datasets, directly demonstrating the significant difficulty posed by the real-world artifacts and variable image quality within the BPD.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This dataset serves as a crucial, more realistic benchmark for developing clinically viable AI models for colonoscopy. Training and evaluating CAD systems on BPD can lead to algorithms that are more resilient to the varied and often imperfect conditions encountered in actual clinical settings, especially in resource-limited environments, thereby potentially enhancing early polyp detection rates and contributing to reduced colorectal cancer mortality.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract explicitly notes that benchmark performance on BPD was lower compared to curated datasets, which reflects the inherent difficulty posed by the dataset's real-world images, including artifacts and variable quality, suggesting current models struggle with such complexity.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract, but the identified challenges (lower performance due to real-world artifacts and variability) strongly imply a future direction for developing more robust and artifact-resilient deep learning models for polyp detection and segmentation in challenging clinical environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Gastroenterology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Colonoscopy</span>
                    
                    <span class="tag tag-keyword">Polyp Detection</span>
                    
                    <span class="tag tag-keyword">Computer-Aided Diagnosis (CAD)</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Image Classification</span>
                    
                    <span class="tag tag-keyword">Real-world Data</span>
                    
                    <span class="tag tag-keyword">Resource-Limited Settings</span>
                    
                    <span class="tag tag-keyword">Colorectal Cancer</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Background and Objective: Colorectal cancer prevention relies on early
detection of polyps during colonoscopy. Existing public datasets, such as
CVC-ClinicDB and Kvasir-SEG, provide valuable benchmarks but are limited by
small sample sizes, curated image selection, or lack of real-world artifacts.
There remains a need for datasets that capture the complexity of clinical
practice, particularly in resource-constrained settings. Methods: We introduce
a dataset, BUET Polyp Dataset (BPD), of colonoscopy images collected using
Olympus 170 and Pen- tax i-Scan series endoscopes under routine clinical
conditions. The dataset contains images with corresponding expert-annotated
binary masks, reflecting diverse challenges such as motion blur, specular
highlights, stool artifacts, blood, and low-light frames. Annotations were
manually reviewed by clinical experts to ensure quality. To demonstrate
baseline performance, we provide bench- mark results for classification using
VGG16, ResNet50, and InceptionV3, and for segmentation using UNet variants with
VGG16, ResNet34, and InceptionV4 backbones. Results: The dataset comprises
1,288 images with polyps from 164 patients with corresponding ground-truth
masks and 1,657 polyp-free images from 31 patients. Benchmarking experiments
achieved up to 90.8% accuracy for binary classification (VGG16) and a maximum
Dice score of 0.64 with InceptionV4-UNet for segmentation. Performance was
lower compared to curated datasets, reflecting the real-world difficulty of
images with artifacts and variable quality.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>