<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Diversity Over Scale: Whole-Slide Image Variety Enables H&E Foundation Model Training with Fewer Patches - Health AI Hub</title>
    <meta name="description" content="This paper introduces Athena, a histopathology foundation model trained on significantly fewer tissue patches (115 million) compared to other state-of-the-art m">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Diversity Over Scale: Whole-Slide Image Variety Enables H&E Foundation Model Training with Fewer Patches</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.10286v1" target="_blank">2511.10286v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-13
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Christoph Bosch, John K. L. Wong, Martin Paulikat, Myroslav Zapukhlyak, Bharti Arora, Manasi Aichm√ºller-Ratnaparkhe, Jens Baumann, Shivani Karn, Rutuja Kamble, Swapnil Karnik, Bhushan Khedkar, Serey Vathana Chhut, Witali Aswolinskiy, Christian Aichm√ºller
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> q-bio.TO
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.10286v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.10286v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Athena, a histopathology foundation model trained on significantly fewer tissue patches (115 million) compared to other state-of-the-art models, by prioritizing data diversity over sheer scale. Athena achieved competitive performance on multiple downstream tasks, suggesting that the diversity of whole-slide images, rather than just the quantity of patches, is the primary driver for effective learning in computational pathology.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This study offers a more resource-efficient and accessible pathway for developing powerful AI models for pathology, potentially accelerating the integration of advanced computational tools into diverse clinical and research settings globally.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes the development of an AI vision foundation model ('Athena') designed to analyze whole-slide histopathology images. This AI aims to assist in disease diagnosis, prognosis, and characterization by efficiently learning from diverse tissue samples to predict molecular and morphological features. Its application lies in improving the accuracy, efficiency, and robustness of AI-powered diagnostic tools in computational pathology, potentially aiding pathologists and researchers in clinical decision-making and biomarker discovery.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The research challenges the prevailing paradigm in computational pathology that emphasizes training vision foundation models on increasingly vast numbers of tissue patches.</li>
                    
                    <li>Athena, the proposed foundation model, was initialized from a pretrained model and trained using only 115 million tissue patches, which is several times fewer than typical large-scale histopathology foundation models.</li>
                    
                    <li>The core methodological innovation is the focus on maximizing data diversity by randomly selecting a moderate number of patches per whole-slide image from a diverse internal repository.</li>
                    
                    <li>The repository for Athena's training data spans multiple countries, institutions, and scanner types, ensuring broad data variability.</li>
                    
                    <li>Athena was rigorously evaluated on one patch-level benchmark and four slide-level downstream tasks, encompassing both molecular and morphological predictions.</li>
                    
                    <li>Despite using significantly less training data, Athena approaches state-of-the-art performance and notably surpasses several existing models trained on substantially larger datasets.</li>
                    
                    <li>The study concludes that diversity across whole-slide images is a more critical factor for driving learning in histopathology foundation models than the total quantity of patches alone.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed 'Athena,' a vision foundation model, by initializing it from a pretrained model. Their core approach emphasized data diversity rather than sheer patch volume, training Athena on 115 million tissue patches. They achieved diversity by randomly selecting a moderate number of patches from each whole-slide image sourced from a heterogeneous internal repository encompassing data from various countries, institutions, and scanner types.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Athena demonstrated performance comparable to state-of-the-art models on a patch-level benchmark and four slide-level downstream tasks (two molecular and two morphological), despite being trained on a significantly smaller dataset of 115 million patches. It even outperformed several models trained on much larger datasets, indicating that diversity across whole-slide images is a more crucial factor for effective learning in histopathology foundation models than mere patch quantity.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to significantly reduce the computational and data demands for developing high-performing AI tools in pathology. It could democratize access to advanced computational diagnostics, making them more feasible for institutions with limited resources or access to massive centralized datasets, thereby accelerating the deployment of AI in clinical practice for more accurate diagnoses and prognostic predictions worldwide.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. However, the findings implicitly suggest further investigation into optimal diversity metrics, exploration of minimal diversity requirements, and the applicability of this 'diversity over scale' principle to other medical imaging modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Digital Pathology</span>
                    
                    <span class="tag">Molecular Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">computational pathology</span>
                    
                    <span class="tag tag-keyword">vision foundation models</span>
                    
                    <span class="tag tag-keyword">histopathology</span>
                    
                    <span class="tag tag-keyword">whole-slide images</span>
                    
                    <span class="tag tag-keyword">data diversity</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">digital pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Rapid progress in computational pathology is increasingly driven by vision foundation models pretrained on vast histopathology datasets. While recent efforts have prioritized training on an ever-larger amount of patches, we take an alternative approach focused on data diversity. Our foundation model, Athena, was initialized from a pretrained model and trained on just 115 million tissue patches, several times fewer than recent histopathology foundation models. Rather than relying on patch volume or complex sampling heuristics, we maximize data diversity by randomly selecting only a moderate number of patches per whole-slide image from our diverse internal repository, which spans multiple countries, institutions, and scanner types. Evaluated on a single patch-level benchmark and four slide-level downstream tasks (two molecular and two morphological), Athena approaches the state-of-the-art and even surpasses several models trained on substantially larger datasets. This indicates that diversity across whole-slide images, rather than patch quantity alone, drives learning in histopathology foundation models.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>