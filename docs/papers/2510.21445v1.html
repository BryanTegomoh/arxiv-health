<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>REMONI: An Autonomous System Integrating Wearables and Multimodal Large Language Models for Enhanced Remote Health Monitoring - Health AI Hub</title>
    <meta name="description" content="REMONI is an autonomous remote health monitoring system designed to enhance human-machine interaction in healthcare by integrating wearables, IoT, and Multimoda">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>REMONI: An Autonomous System Integrating Wearables and Multimodal Large Language Models for Enhanced Remote Health Monitoring</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.21445v1" target="_blank">2510.21445v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-24
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Thanh Cong Ho, Farah Kharrat, Abderrazek Abid, Fakhri Karray
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI, cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.21445v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.21445v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">REMONI is an autonomous remote health monitoring system designed to enhance human-machine interaction in healthcare by integrating wearables, IoT, and Multimodal Large Language Models (MLLMs). It continuously collects physiological, activity, and visual data, utilizing anomaly detection for emergencies, and enables healthcare workers to interact with an intelligent agent for real-time patient status, activity, and emotional state. The system has been demonstrated as implementable and scalable, promising reductions in professional workload and healthcare costs.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This system significantly advances remote patient monitoring by moving beyond mere data collection to provide interactive, real-time insights into a patient's physiological state, activity, and emotional well-being, which is critical for proactive care, early intervention, and improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>REMONI applies Multimodal Large Language Models (MLLMs) and AI algorithms (anomaly detection, fall detection) to integrate and analyze real-time multimodal patient data from wearables and cameras. This enables continuous remote monitoring of vital signs, activity, and emotion, facilitating early detection of health issues and emergencies. The AI-powered intelligent agent serves as an interactive interface for doctors and nurses to access comprehensive patient information, supporting clinical workflows and potentially improving patient outcomes and healthcare efficiency.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Multimodal Integration:** REMONI uniquely integrates wearable devices (IoT), cameras for visual data, and Multimodal Large Language Models (MLLMs) to bridge the gap in human-machine interaction for remote health monitoring.</li>
                    
                    <li>**Comprehensive Data Collection:** The system automatically and continuously gathers vital signs, accelerometer data from wearables (e.g., smartwatches), and visual data from patient video clips.</li>
                    
                    <li>**Advanced Anomaly and Emergency Detection:** It incorporates an anomaly detection module, including a specific fall detection model, designed to identify and alert caregivers to emergency conditions.</li>
                    
                    <li>**MLLM-driven Natural Language Processing:** A distinctive feature is its NLP component, powered by MLLMs, capable of detecting and recognizing a patient's activity and emotional state, and responding to healthcare worker inquiries.</li>
                    
                    <li>**Seamless Information Access and Interaction:** Utilizes prompt engineering to integrate all patient information, allowing doctors and nurses to access real-time vital signs, current state, and mood via an intelligent agent in a user-friendly web application.</li>
                    
                    <li>**Practical Implementability and Scalability:** Experiments confirm the system's implementability and scalability for real-life scenarios, with a full-fledged prototype developed and undergoing robustness testing.</li>
                    
                    <li>**Potential for Healthcare Efficiency:** Aims to significantly reduce the workload of medical professionals and lower overall healthcare costs through automated, comprehensive, and interactive remote monitoring.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>REMONI continuously collects multimodal data including vital signs and accelerometer data from wearable devices and visual data from cameras. This data is fed into an anomaly detection module (e.g., fall detection). A key component is a Multimodal Large Language Model (MLLM)-based natural language processing module that interprets patient activity and emotion, and responds to queries. Prompt engineering is employed for data integration, and healthcare professionals interact with the system through an intelligent agent via a web application.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The experiments conducted demonstrate that the REMONI system is implementable and scalable for real-life healthcare scenarios. A full-fledged prototype has been developed and is currently being tested to validate the robustness and functionality of its various capabilities.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The system has the potential to significantly reduce the workload on medical professionals by automating continuous monitoring and providing an interactive, intelligent interface for comprehensive patient data. It could also lower overall healthcare costs by enabling more efficient remote care, facilitating earlier detection and intervention for emergencies (like falls), and offering a more holistic view of a patient's physical and emotional well-being.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed REMONI system.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract mentions that a full-fledged prototype is being tested to demonstrate the robustness of its various capabilities, implying ongoing validation and refinement. However, it does not explicitly outline specific future research directions or expansions beyond this immediate testing phase.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Remote patient monitoring</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Chronic disease management</span>
                    
                    <span class="tag">Emergency medicine</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                    <span class="tag">Mental health monitoring</span>
                    
                    <span class="tag">Preventive care</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Remote health monitoring</span>
                    
                    <span class="tag tag-keyword">Wearable devices</span>
                    
                    <span class="tag tag-keyword">Multimodal Large Language Models (MLLMs)</span>
                    
                    <span class="tag tag-keyword">Internet of Things (IoT)</span>
                    
                    <span class="tag tag-keyword">Anomaly detection</span>
                    
                    <span class="tag tag-keyword">Fall detection</span>
                    
                    <span class="tag tag-keyword">Natural language processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Human-machine interaction</span>
                    
                    <span class="tag tag-keyword">Telehealth</span>
                    
                    <span class="tag tag-keyword">Patient monitoring</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the widespread adoption of wearable devices in our daily lives, the
demand and appeal for remote patient monitoring have significantly increased.
Most research in this field has concentrated on collecting sensor data,
visualizing it, and analyzing it to detect anomalies in specific diseases such
as diabetes, heart disease and depression. However, this domain has a notable
gap in the aspect of human-machine interaction. This paper proposes REMONI, an
autonomous REmote health MONItoring system that integrates multimodal large
language models (MLLMs), the Internet of Things (IoT), and wearable devices.
The system automatically and continuously collects vital signs, accelerometer
data from a special wearable (such as a smartwatch), and visual data in patient
video clips collected from cameras. This data is processed by an anomaly
detection module, which includes a fall detection model and algorithms to
identify and alert caregivers of the patient's emergency conditions. A
distinctive feature of our proposed system is the natural language processing
component, developed with MLLMs capable of detecting and recognizing a
patient's activity and emotion while responding to healthcare worker's
inquiries. Additionally, prompt engineering is employed to integrate all
patient information seamlessly. As a result, doctors and nurses can access
real-time vital signs and the patient's current state and mood by interacting
with an intelligent agent through a user-friendly web application. Our
experiments demonstrate that our system is implementable and scalable for
real-life scenarios, potentially reducing the workload of medical professionals
and healthcare costs. A full-fledged prototype illustrating the functionalities
of the system has been developed and being tested to demonstrate the robustness
of its various capabilities.</p>
            </section>

            

            
            <section class="paper-section">
                <h2>Journal Reference</h2>
                <p>2024 IEEE International Symposium on Medical Measurements and
  Applications (MeMeA)</p>
            </section>
            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>