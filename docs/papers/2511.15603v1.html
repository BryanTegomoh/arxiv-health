<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="MaskMed introduces a novel medical image segmentation method featuring a unified decoupled segmentation head that separates class-agnostic mask prediction from ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15603v1" target="_blank">2511.15603v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-19
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Bin Xie, Gady Agam
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15603v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15603v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MaskMed introduces a novel medical image segmentation method featuring a unified decoupled segmentation head that separates class-agnostic mask prediction from class label prediction using shared object queries. It also incorporates a Full-Scale Aware Deformable Transformer for efficient, spatially aligned fusion of multi-resolution features. This approach achieves state-of-the-art performance, significantly outperforming nnUNet on AMOS 2022 and BTCV datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>By providing highly accurate and efficient medical image segmentation, MaskMed can significantly improve the precision of diagnostic imaging interpretations, facilitate more reliable quantitative analysis of anatomical structures or pathologies, and enhance the planning and guidance of medical interventions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is medical image segmentation. This involves using artificial intelligence to automatically delineate and identify specific structures, organs, tumors, or pathologies within medical scans (e.g., CT, MRI). This technology assists clinicians in diagnosis, surgical planning, radiation therapy, disease progression monitoring, and quantitative analysis of medical images, thereby improving efficiency and accuracy in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses limitations of traditional point-wise convolutional segmentation heads, which rigidly tie output channels to specific classes, hindering feature sharing and semantic generalization.</li>
                    
                    <li>Proposes a unified decoupled segmentation head that separates multi-class prediction into class-agnostic mask prediction and class label prediction.</li>
                    
                    <li>Utilizes shared object queries to enable this decoupling, fostering better feature sharing across classes.</li>
                    
                    <li>Introduces a Full-Scale Aware Deformable Transformer (FSADT) module for advanced feature fusion.</li>
                    
                    <li>FSADT allows low-resolution encoder features to attend across full-resolution encoder features via deformable attention, ensuring memory-efficient and spatially aligned full-scale feature fusion.</li>
                    
                    <li>The overall method, named MaskMed, establishes new state-of-the-art benchmarks in medical image segmentation.</li>
                    
                    <li>Achieves significant performance gains: +2.0% Dice over nnUNet on AMOS 2022 and +6.9% Dice over nnUNet on BTCV.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed MaskMed method integrates a novel deep learning architecture comprising two main components: a unified decoupled segmentation head that uses shared object queries to separate class-agnostic mask prediction from class label prediction, and a Full-Scale Aware Deformable Transformer module for efficient, spatially aligned fusion of multi-resolution features obtained from an encoder. Performance was validated against state-of-the-art methods like nnUNet on challenging medical datasets (AMOS 2022 and BTCV).</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MaskMed achieves state-of-the-art performance in medical image segmentation, demonstrating superior accuracy over nnUNet with a +2.0% increase in Dice score on the AMOS 2022 dataset and a substantial +6.9% increase on the BTCV dataset. This improvement stems from its ability to enhance feature sharing and semantic generalization through decoupled prediction and achieve more effective multi-scale feature fusion.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced accuracy and efficiency of MaskMed can lead to more precise delineation of organs, tumors, and other anatomical structures in medical images. This can directly support more accurate diagnosis, improved staging of diseases, better-informed treatment planning (e.g., radiation therapy, surgery), and more reliable quantitative assessment in clinical research, ultimately leading to improved patient outcomes and reduced inter-observer variability.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Surgery</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Transformer</span>
                    
                    <span class="tag tag-keyword">Deformable Attention</span>
                    
                    <span class="tag tag-keyword">Semantic Segmentation</span>
                    
                    <span class="tag tag-keyword">Decoupled Head</span>
                    
                    <span class="tag tag-keyword">Object Queries</span>
                    
                    <span class="tag tag-keyword">MaskMed</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical image segmentation typically adopts a point-wise convolutional segmentation head to predict dense labels, where each output channel is heuristically tied to a specific class. This rigid design limits both feature sharing and semantic generalization. In this work, we propose a unified decoupled segmentation head that separates multi-class prediction into class-agnostic mask prediction and class label prediction using shared object queries. Furthermore, we introduce a Full-Scale Aware Deformable Transformer module that enables low-resolution encoder features to attend across full-resolution encoder features via deformable attention, achieving memory-efficient and spatially aligned full-scale fusion. Our proposed method, named MaskMed, achieves state-of-the-art performance, surpassing nnUNet by +2.0% Dice on AMOS 2022 and +6.9% Dice on BTCV.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>