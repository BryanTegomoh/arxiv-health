<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations - Health AI Hub</title>
    <meta name="description" content="DIST-CLIP addresses the critical issue of MRI data heterogeneity, which limits deep learning's clinical generalization, by proposing a unified harmonization fra">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.07674v1" target="_blank">2512.07674v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-08
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mehmet Yigit Avci, Pedro Borges, Virginia Fernandez, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.07674v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.07674v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DIST-CLIP addresses the critical issue of MRI data heterogeneity, which limits deep learning's clinical generalization, by proposing a unified harmonization framework. It explicitly disentangles anatomical content from image contrast, leveraging CLIP encoders for contrast representation and an Adaptive Style Transfer module. The method, guided flexibly by either target images or DICOM metadata, demonstrated significant improvements in style translation fidelity and anatomical preservation on diverse clinical datasets, thereby standardizing MRI data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>MRI data heterogeneity severely impedes the development and reliability of AI models for medical diagnosis and analysis. This harmonization technique directly enhances the consistency and utility of MRI datasets, crucial for building more robust, generalizable, and clinically trustworthy AI applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is an MRI harmonization system called DIST-CLIP. It leverages disentangled anatomy-contrast representations and CLIP encoders to standardize MRI data across diverse acquisition conditions (different scanners, protocols). By reducing instrumental and acquisition variability, this AI system aims to improve the consistency and comparability of MRI scans, making deep learning models more robust for clinical use, enhancing the accuracy of AI-driven diagnostics, and facilitating more reliable medical image analysis for patient care and research.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the significant challenge of MRI data heterogeneity (scanner, protocols, sequences) that hinders deep learning model generalization in clinical settings.</li>
                    
                    <li>Introduces DIST-CLIP, a novel and unified deep learning framework for MRI harmonization capable of flexible guidance.</li>
                    
                    <li>Allows for harmonization guided by either a target MRI image or rich DICOM metadata, overcoming limitations of prior image-based or simplistic text-guided methods.</li>
                    
                    <li>Employs an explicit disentanglement strategy to separate inherent anatomical content from image contrast features within MRI scans.</li>
                    
                    <li>Utilizes pre-trained CLIP encoders to extract robust contrast representations, which are then integrated via a novel Adaptive Style Transfer module.</li>
                    
                    <li>Achieved significant improvements over state-of-the-art methods in both the accuracy of style translation (fidelity) and the preservation of critical anatomical details.</li>
                    
                    <li>Evaluated on diverse, real-world clinical datasets, highlighting its practical applicability for standardizing MRI data in complex clinical environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DIST-CLIP is a deep learning framework designed to disentangle MRI images into their underlying anatomical content and image contrast representations. Contrast representations are extracted using pre-trained CLIP encoders, which are then integrated with the anatomical content through a novel Adaptive Style Transfer module. The framework supports flexible guidance for harmonization using either a target MRI image or comprehensive DICOM metadata.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DIST-CLIP framework demonstrated significant performance improvements compared to state-of-the-art harmonization methods. It excelled in both style translation fidelity, accurately transforming image contrasts, and anatomical preservation, maintaining crucial structural details‚Äîa critical balance for clinical utility.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By enabling the standardization of MRI data across diverse acquisition environments, DIST-CLIP will facilitate the development of more reliable and generalizable AI models for medical diagnosis, prognosis, and treatment planning. This can lead to improved accuracy in clinical decision-making, support large-scale multi-center studies, and ultimately enhance patient care by reducing variability in image interpretation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats of the proposed method.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract mentions that the code and weights will be made publicly available upon publication, which implies supporting wider adoption and facilitating future research by others, though it does not specify direct future research directions for the method itself.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Neuroradiology</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">MRI Harmonization</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Data Heterogeneity</span>
                    
                    <span class="tag tag-keyword">Disentanglement</span>
                    
                    <span class="tag tag-keyword">CLIP Guidance</span>
                    
                    <span class="tag tag-keyword">Style Transfer</span>
                    
                    <span class="tag tag-keyword">DICOM Metadata</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>