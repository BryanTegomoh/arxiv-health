<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba - Health AI Hub</title>
    <meta name="description" content="FGMamba introduces a novel frequency-aware gated state-space model designed for versatile and efficient medical image super-resolution. It unifies global depend">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Versatile and Efficient Medical Image Super-Resolution Via Frequency-Gated Mamba</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27296v1" target="_blank">2510.27296v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Wenfeng Huang, Xiangyun Liao, Wei Cao, Wenjing Jia, Weixin Si
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27296v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27296v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">FGMamba introduces a novel frequency-aware gated state-space model designed for versatile and efficient medical image super-resolution. It unifies global dependency modeling and fine-detail enhancement into a lightweight architecture, addressing the challenge of capturing both long-range anatomical structures and fine-grained frequency details with low computational overhead. The method achieves superior PSNR/SSIM scores across five diverse medical imaging modalities while maintaining a compact parameter footprint, outperforming existing CNN-based and Transformer-based SOTAs.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine by enabling the generation of higher-resolution medical images from lower-quality inputs, which can significantly improve the visibility of subtle pathologies and anatomical structures for more accurate diagnoses. It also contributes to reducing imaging costs and patient scanning times.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper presents FGMamba, a novel frequency-aware gated state-space model, as an AI-driven solution for medical image super-resolution. This AI application aims to improve the quality of medical images from various modalities (Ultrasound, OCT, MRI, CT, Endoscopic) to enhance diagnostic accuracy, reduce the cost of image acquisition, and decrease scanning times, directly impacting clinical workflows and patient outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Medical image super-resolution (SR) is critical for enhancing diagnostic accuracy, reducing acquisition costs, and decreasing scanning times.</li>
                    
                    <li>The paper tackles the challenge of efficiently modeling both long-range anatomical structures and fine-grained frequency details in medical images.</li>
                    
                    <li>FGMamba, a frequency-aware gated state-space model, is proposed as a lightweight architecture for global dependency modeling and fine-detail enhancement.</li>
                    
                    <li>It features two core innovations: a Gated Attention-enhanced State-Space Module (GASM) combining state-space modeling with dual-branch spatial and channel attention.</li>
                    
                    <li>The second innovation is a Pyramid Frequency Fusion Module (PFFM) that captures high-frequency details across multiple resolutions using FFT-guided fusion.</li>
                    
                    <li>Extensive evaluations across Ultrasound, OCT, MRI, CT, and Endoscopic modalities demonstrate FGMamba's superior PSNR/SSIM performance.</li>
                    
                    <li>FGMamba maintains a highly compact parameter footprint (less than 0.75M), significantly outperforming state-of-the-art CNN-based and Transformer-based models in both accuracy and efficiency.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed FGMamba model is a frequency-aware gated state-space model. Its architecture comprises two primary modules: 1) the **Gated Attention-enhanced State-Space Module (GASM)**, which integrates efficient state-space modeling with a dual-branch mechanism for spatial and channel attention to capture global dependencies and refine features; and 2) the **Pyramid Frequency Fusion Module (PFFM)**, designed to extract and fuse high-frequency details across multiple resolutions using Fast Fourier Transform (FFT) for guided fusion. This design prioritizes lightweight architecture for computational efficiency.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>FGMamba achieved superior quantitative performance, indicated by higher PSNR and SSIM metrics, compared to existing CNN-based and Transformer-based state-of-the-art super-resolution methods. This robust performance was validated across a diverse set of five medical imaging modalities: Ultrasound, OCT, MRI, CT, and Endoscopic imaging. Notably, FGMamba accomplished these results with a highly compact parameter footprint, demonstrating high computational efficiency with less than 0.75 million parameters.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced image quality and computational efficiency of FGMamba hold significant clinical impact. It can lead to more precise and earlier disease detection, improved surgical planning, and better monitoring of treatment responses by providing clearer diagnostic images. The ability to achieve high resolution from lower-resolution inputs can also reduce patient exposure to radiation (e.g., lower dose CT scans), shorten scanning times, and potentially lower healthcare costs associated with medical imaging, making high-quality diagnostics more accessible.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats of the proposed method or the study itself. Common potential limitations for such research, not specified here, might include reliance on specific datasets, lack of prospective clinical validation, or generalizability to all possible clinical scenarios or rare pathologies.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ultrasound</span>
                    
                    <span class="tag">Optical Coherence Tomography (OCT)</span>
                    
                    <span class="tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="tag">Computed Tomography (CT)</span>
                    
                    <span class="tag">Endoscopic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Super-Resolution</span>
                    
                    <span class="tag tag-keyword">Mamba</span>
                    
                    <span class="tag tag-keyword">State-Space Models</span>
                    
                    <span class="tag tag-keyword">Frequency-Gated</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Diagnostic Imaging</span>
                    
                    <span class="tag tag-keyword">Image Enhancement</span>
                    
                    <span class="tag tag-keyword">Computational Efficiency</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical image super-resolution (SR) is essential for enhancing diagnostic
accuracy while reducing acquisition cost and scanning time. However, modeling
both long-range anatomical structures and fine-grained frequency details with
low computational overhead remains challenging. We propose FGMamba, a novel
frequency-aware gated state-space model that unifies global dependency modeling
and fine-detail enhancement into a lightweight architecture. Our method
introduces two key innovations: a Gated Attention-enhanced State-Space Module
(GASM) that integrates efficient state-space modeling with dual-branch spatial
and channel attention, and a Pyramid Frequency Fusion Module (PFFM) that
captures high-frequency details across multiple resolutions via FFT-guided
fusion. Extensive evaluations across five medical imaging modalities
(Ultrasound, OCT, MRI, CT, and Endoscopic) demonstrate that FGMamba achieves
superior PSNR/SSIM while maintaining a compact parameter footprint ($<$0.75M),
outperforming CNN-based and Transformer-based SOTAs. Our results validate the
effectiveness of frequency-aware state-space modeling for scalable and accurate
medical image enhancement.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>