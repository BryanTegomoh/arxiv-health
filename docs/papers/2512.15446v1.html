<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Toward expert-level motivational interviewing for health behavior improvement with LLMs - Health AI Hub</title>
    <meta name="description" content="This study developed and evaluated Large Language Models for Motivational Interviewing (MI-LLMs) to address the scalability issues of human-delivered MI. By fin">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Toward expert-level motivational interviewing for health behavior improvement with LLMs</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.15446v1" target="_blank">2512.15446v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-17
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Run-ze Hu, Yang Yang, Yi-hang Yang, Jing-qi Kong, Jia-hui Luo, Wen-yu Yang, Jing Chen, Jing-yao Liu, Hui-qun Zeng, Lei Zhang, Zheng Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.15446v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.15446v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study developed and evaluated Large Language Models for Motivational Interviewing (MI-LLMs) to address the scalability issues of human-delivered MI. By fine-tuning three Chinese-capable LLMs on a GPT-4-generated MI-style dialogue corpus, the researchers demonstrated that these MI-LLMs achieved core MI-consistent behaviors, with evaluation metrics approaching those of real MI dialogues, though complex MI skills require further development.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Motivational Interviewing is a powerful, evidence-based approach for improving adherence to medical advice, managing chronic conditions, and promoting healthy lifestyles. Developing scalable AI-driven MI tools could dramatically expand access to personalized behavior change support, making it available to a wider population and alleviating the burden on human counselors in healthcare settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper develops and evaluates Large Language Models (MI-LLMs) specifically designed to perform motivational interviewing, an evidence-based counseling technique, to assist individuals in achieving health behavior improvements. This application provides a scalable, AI-driven solution for health behavior change support, potentially augmenting human counselors or extending access to MI interventions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Motivational Interviewing (MI) is effective for health behavior change but limited by the need for highly trained human counselors.</li>
                    
                    <li>The study curated five Chinese psychological counseling corpora, using GPT-4 with MI-informed prompts to transform two high-quality datasets into 2,040 MI-style counseling conversations.</li>
                    
                    <li>Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat, Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this custom corpus to create MI-LLMs.</li>
                    
                    <li>Evaluation involved both automatic metrics (BLEU-4, ROUGE) and expert manual coding using the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1.</li>
                    
                    <li>Fine-tuning significantly improved automatic metric scores, and MI-LLMs achieved technical and relational global scores and MI-adherent ratios comparable to real MI dialogues based on MITI coding.</li>
                    
                    <li>A key limitation identified was the MI-LLMs' lesser frequency of complex reflections and lower reflection-to-question ratios compared to human experts.</li>
                    
                    <li>The findings suggest a scalable pathway for AI-assisted health behavior change support, highlighting the potential for LLMs to deliver MI-consistent counseling behaviors.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved curating five Chinese psychological counseling corpora and leveraging GPT-4 with an MI-informed prompt to transcribe multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style conversations. Of these, 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat, Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this custom corpus. Evaluation was conducted using both round-based automatic metrics (BLEU-4 and ROUGE scores) and expert manual coding applying the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Fine-tuning demonstrably improved BLEU-4 and ROUGE scores across all three models compared to their base versions. Manual coding via MITI 4.2.1 revealed that the MI-LLMs achieved technical and relational global scores, as well as MI-adherent ratios, that approached those observed in real MI dialogues. However, the models showed a lower frequency of complex reflections and reduced reflection-to-question ratios, indicating areas for improvement in advanced MI skill application.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides initial evidence for a scalable AI-assisted pathway to support health behavior change. By endowing general-purpose LLMs with core MI-consistent counseling behaviors, these MI-LLMs could potentially serve as valuable tools for augmenting human counselors, providing accessible first-line support, or delivering personalized behavior change interventions in various clinical and public health settings, ultimately improving health outcomes without requiring extensive human training resources.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The study noted that MI-LLMs were less adept at generating complex reflections and exhibited lower reflection-to-question ratios. The current models were evaluated on a relatively small test set (40 dialogues) and against a specific MI-style corpus generated by GPT-4, which may not fully capture the nuances of real-world MI interactions. Furthermore, the findings are based on a Chinese-language context, and the generalizability to other linguistic and cultural settings needs to be investigated. The study also acknowledges the need for further work on data scale and real-world intervention trials.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future work should focus on increasing the data scale for fine-tuning, particularly to improve the LLMs' proficiency in complex MI skills like evoking and rolling with resistance. Real-world intervention trials are necessary to validate the efficacy and practical utility of MI-LLMs in clinical and health behavior change settings. Further research could also explore the integration of these models into hybrid human-AI counseling systems and their application across diverse populations and languages.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Behavioral Health</span>
                    
                    <span class="tag">Preventive Medicine</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Chronic Disease Management</span>
                    
                    <span class="tag">Patient Education</span>
                    
                    <span class="tag">Digital Therapeutics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Motivational Interviewing</span>
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">Health Behavior Change</span>
                    
                    <span class="tag tag-keyword">AI-assisted Counseling</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                    <span class="tag tag-keyword">MITI Coding</span>
                    
                    <span class="tag tag-keyword">Scalability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>26 pages, 3 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>