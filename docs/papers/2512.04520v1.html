<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="BA-TTA-SAM is a novel test-time adaptation framework designed to address the challenges of zero-shot medical image segmentation, particularly for models like SA">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04520v1" target="_blank">2512.04520v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chenlin Xu, Lei Zhang, Lituan Wang, Xinyu Pu, Pengfei Ma, Guangwu Qian, Zizhou Wang, Yan Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04520v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04520v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">BA-TTA-SAM is a novel test-time adaptation framework designed to address the challenges of zero-shot medical image segmentation, particularly for models like SAM that struggle with domain shifts and data scarcity. It significantly enhances SAM's performance by integrating encoder-level Gaussian prompt injection and cross-layer boundary-aware attention alignment. The framework achieved an average 12.4% DICE score improvement on diverse medical datasets, outperforming state-of-the-art models without requiring source-domain training.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging by enabling more accurate and efficient zero-shot segmentation of medical images, mitigating the need for extensive manual annotations and specialized training data, which are critical bottlenecks in clinical AI adoption and development.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to improve the accuracy and generalization of zero-shot medical image segmentation. This enables AI models to segment anatomical structures, pathologies, or regions of interest in various medical images (e.g., skin lesions, polyps, tumors, optic disc) without requiring extensive prior training data for each specific task. This has direct implications for enhancing diagnostic efficiency, aiding disease screening, and supporting clinical decision-making across multiple medical specialties.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in medical image segmentation: scarcity of annotated data, high computational costs of conventional tuning, and limitations of foundation models like SAM due to domain shifts.</li>
                    
                    <li>Proposes BA-TTA-SAM, a task-agnostic test-time adaptation (TTA) framework, to enhance zero-shot segmentation performance of SAM.</li>
                    
                    <li>Introduces an encoder-level Gaussian prompt injection mechanism to embed Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning.</li>
                    
                    <li>Implements cross-layer boundary-aware attention alignment, which exploits hierarchical feature interactions within the ViT backbone to align deep semantic responses with shallow boundary cues for precise segmentation.</li>
                    
                    <li>Achieved an average improvement of 12.4% in DICE score compared to SAM's original zero-shot segmentation performance on four diverse medical datasets.</li>
                    
                    <li>Demonstrated consistent outperformance against state-of-the-art models in medical image segmentation.</li>
                    
                    <li>Significantly enhances the generalization ability of SAM for medical images without requiring any source-domain training data, promoting efficiency and adaptability.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The BA-TTA-SAM framework employs a test-time adaptation strategy, which means it adapts the pre-trained SAM model to target medical images during inference without prior training on target-domain data. It integrates two primary mechanisms: (1) Encoder-level Gaussian prompt injection, where Gaussian-based prompts are directly embedded into SAM's image encoder to guide the initial feature learning. (2) Cross-layer boundary-aware attention alignment, which leverages the hierarchical feature representations of the Vision Transformer (ViT) backbone to align high-level semantic information with low-level boundary details, thereby improving segmentation precision.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The framework successfully improved the DICE score by an average of 12.4% over SAM's baseline zero-shot segmentation performance across ISIC, Kvasir, BUSI, and REFUGE datasets. It consistently outperformed state-of-the-art models in medical image segmentation and significantly enhanced SAM's generalization capabilities on medical datasets without requiring any source-domain training data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework has substantial potential to streamline clinical workflows by enabling highly accurate and efficient automated segmentation of various medical pathologies (e.g., skin lesions, polyps, tumors, ocular structures) in diverse image modalities. It can reduce the labor-intensive burden of manual annotation for diagnosis and treatment planning, accelerate the deployment of AI in resource-limited settings, and facilitate quantitative analysis for personalized medicine without the need for domain-specific model retraining.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Dermatology (ISIC for skin lesions)</span>
                    
                    <span class="tag">Gastroenterology (Kvasir for GI tract images)</span>
                    
                    <span class="tag">Radiology/Oncology (BUSI for breast ultrasound)</span>
                    
                    <span class="tag">Ophthalmology (REFUGE for retinal fundus images/glaucoma)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical image segmentation</span>
                    
                    <span class="tag tag-keyword">Zero-shot learning</span>
                    
                    <span class="tag tag-keyword">Test-time adaptation</span>
                    
                    <span class="tag tag-keyword">SAM (Segment Anything Model)</span>
                    
                    <span class="tag tag-keyword">Vision Transformer (ViT)</span>
                    
                    <span class="tag tag-keyword">Boundary-aware attention</span>
                    
                    <span class="tag tag-keyword">Gaussian prompts</span>
                    
                    <span class="tag tag-keyword">Domain shift</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Due to the scarcity of annotated data and the substantial computational costs of model, conventional tuning methods in medical image segmentation face critical challenges. Current approaches to adapting pretrained models, including full-parameter and parameter-efficient fine-tuning, still rely heavily on task-specific training on downstream tasks. Therefore, zero-shot segmentation has gained increasing attention, especially with foundation models such as SAM demonstrating promising generalization capabilities. However, SAM still faces notable limitations on medical datasets due to domain shifts, making efficient zero-shot enhancement an urgent research goal. To address these challenges, we propose BA-TTA-SAM, a task-agnostic test-time adaptation framework that significantly enhances the zero-shot segmentation performance of SAM via test-time adaptation. This framework integrates two key mechanisms: (1) The encoder-level Gaussian prompt injection embeds Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning. (2) The cross-layer boundary-aware attention alignment exploits the hierarchical feature interactions within the ViT backbone, aligning deep semantic responses with shallow boundary cues. Experiments on four datasets, including ISIC, Kvasir, BUSI, and REFUGE, show an average improvement of 12.4\% in the DICE score compared with SAM's zero-shot segmentation performance. The results demonstrate that our method consistently outperforms state-of-the-art models in medical image segmentation. Our framework significantly enhances the generalization ability of SAM, without requiring any source-domain training data. Extensive experiments on publicly available medical datasets strongly demonstrate the superiority of our framework. Our code is available at https://github.com/Emilychenlin/BA-TTA-SAM.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>