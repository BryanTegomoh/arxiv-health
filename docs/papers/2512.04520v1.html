<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces BA-TTA-SAM, a novel test-time adaptation framework designed to enhance the zero-shot medical image segmentation performance of the Segment">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04520v1" target="_blank">2512.04520v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chenlin Xu, Lei Zhang, Lituan Wang, Xinyu Pu, Pengfei Ma, Guangwu Qian, Zizhou Wang, Yan Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04520v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04520v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces BA-TTA-SAM, a novel test-time adaptation framework designed to enhance the zero-shot medical image segmentation performance of the Segment Anything Model (SAM). It tackles critical challenges like data scarcity and domain shifts by integrating encoder-level Gaussian prompt injection and cross-layer boundary-aware attention alignment. The framework achieved an average 12.4% DICE score improvement over SAM's zero-shot performance across four medical datasets, outperforming state-of-the-art methods without requiring source-domain training.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research offers a crucial solution for efficiently deploying advanced AI models like SAM in medical imaging, overcoming the common hurdles of limited annotated data and high computational demands for training. It enables more accurate and accessible zero-shot medical image segmentation, potentially accelerating diagnosis and treatment planning across various specialties.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to significantly improve the accuracy and efficiency of zero-shot medical image segmentation. This technology can be used to automate or assist in the precise delineation of anatomical structures, pathologies (e.g., tumors, lesions), or organs in various medical images (e.g., MRI, CT, ultrasound, endoscopy, fundus images). This aids in faster and more accurate diagnosis, disease monitoring, treatment planning (e.g., radiation therapy, surgery), and quantitative analysis in clinical and research settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in medical image segmentation: scarcity of annotated data, substantial computational costs of model tuning, and domain shift limitations of foundation models like SAM on medical datasets.</li>
                    
                    <li>Proposes BA-TTA-SAM, a task-agnostic test-time adaptation (TTA) framework for significantly enhancing SAM's zero-shot segmentation performance in medical imaging.</li>
                    
                    <li>Introduces 'encoder-level Gaussian prompt injection,' which embeds Gaussian-based prompts directly into the image encoder to provide explicit guidance for initial representation learning.</li>
                    
                    <li>Implements 'cross-layer boundary-aware attention alignment,' exploiting hierarchical feature interactions within the ViT backbone to align deep semantic responses with shallow, precise boundary cues.</li>
                    
                    <li>Achieves an average improvement of 12.4% in the DICE score compared to SAM's baseline zero-shot segmentation performance.</li>
                    
                    <li>Consistently outperforms state-of-the-art models on diverse medical image datasets, including ISIC, Kvasir, BUSI, and REFUGE.</li>
                    
                    <li>Enhances the generalization ability of SAM for medical images without requiring any source-domain training data, promoting efficient deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The BA-TTA-SAM framework performs task-agnostic test-time adaptation of the SAM model. Its core mechanisms include: (1) Encoder-level Gaussian prompt injection, where Gaussian-based prompts are directly embedded into the image encoder to guide initial representation learning. (2) Cross-layer boundary-aware attention alignment, which leverages hierarchical feature interactions within the ViT backbone to align deep semantic features with shallow, precise boundary information, thereby refining segmentation outputs.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed BA-TTA-SAM framework achieved an average improvement of 12.4% in the DICE score over SAM's baseline zero-shot segmentation performance across four diverse medical datasets (ISIC, Kvasir, BUSI, REFUGE). It consistently demonstrated superior performance compared to existing state-of-the-art models in medical image segmentation, significantly enhancing SAM's generalization capabilities without requiring any source-domain training data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework could significantly reduce the need for extensive manual annotation in medical imaging, allowing for faster development and deployment of AI-assisted diagnostic tools. It promises more accurate and robust segmentation across various medical specialties, potentially improving clinical workflows, aiding in disease detection (e.g., skin lesions, polyps, tumors, retinal pathologies), and supporting treatment planning, especially in resource-constrained environments where large labeled datasets are scarce.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the BA-TTA-SAM framework. However, as a test-time adaptation approach, its real-time computational overhead during inference could be a consideration, and its performance might still be influenced by the initial generalization capabilities of the base SAM model and the specific characteristics of highly anomalous or rare medical conditions not well represented in general datasets.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly outline future research directions. Potential avenues could include investigating the framework's robustness across an even wider array of medical imaging modalities (e.g., MRI, CT, X-ray) and pathologies, exploring its integration with other zero-shot or few-shot learning paradigms, or optimizing the computational efficiency of the test-time adaptation process for real-time clinical deployment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">dermatology</span>
                    
                    <span class="tag">gastroenterology</span>
                    
                    <span class="tag">breast imaging</span>
                    
                    <span class="tag">ophthalmology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical image segmentation</span>
                    
                    <span class="tag tag-keyword">zero-shot learning</span>
                    
                    <span class="tag tag-keyword">test-time adaptation</span>
                    
                    <span class="tag tag-keyword">SAM</span>
                    
                    <span class="tag tag-keyword">foundation models</span>
                    
                    <span class="tag tag-keyword">boundary-aware</span>
                    
                    <span class="tag tag-keyword">Gaussian prompts</span>
                    
                    <span class="tag tag-keyword">domain adaptation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Due to the scarcity of annotated data and the substantial computational costs of model, conventional tuning methods in medical image segmentation face critical challenges. Current approaches to adapting pretrained models, including full-parameter and parameter-efficient fine-tuning, still rely heavily on task-specific training on downstream tasks. Therefore, zero-shot segmentation has gained increasing attention, especially with foundation models such as SAM demonstrating promising generalization capabilities. However, SAM still faces notable limitations on medical datasets due to domain shifts, making efficient zero-shot enhancement an urgent research goal. To address these challenges, we propose BA-TTA-SAM, a task-agnostic test-time adaptation framework that significantly enhances the zero-shot segmentation performance of SAM via test-time adaptation. This framework integrates two key mechanisms: (1) The encoder-level Gaussian prompt injection embeds Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning. (2) The cross-layer boundary-aware attention alignment exploits the hierarchical feature interactions within the ViT backbone, aligning deep semantic responses with shallow boundary cues. Experiments on four datasets, including ISIC, Kvasir, BUSI, and REFUGE, show an average improvement of 12.4\% in the DICE score compared with SAM's zero-shot segmentation performance. The results demonstrate that our method consistently outperforms state-of-the-art models in medical image segmentation. Our framework significantly enhances the generalization ability of SAM, without requiring any source-domain training data. Extensive experiments on publicly available medical datasets strongly demonstrate the superiority of our framework. Our code is available at https://github.com/Emilychenlin/BA-TTA-SAM.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>