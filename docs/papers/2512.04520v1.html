<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces BA-TTA-SAM, a novel task-agnostic test-time adaptation framework designed to significantly enhance the zero-shot medical image segmentatio">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04520v1" target="_blank">2512.04520v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chenlin Xu, Lei Zhang, Lituan Wang, Xinyu Pu, Pengfei Ma, Guangwu Qian, Zizhou Wang, Yan Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04520v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04520v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces BA-TTA-SAM, a novel task-agnostic test-time adaptation framework designed to significantly enhance the zero-shot medical image segmentation performance of foundational models like SAM. It integrates encoder-level Gaussian prompt injection and cross-layer boundary-aware attention alignment to address domain shifts and improve representation learning. The framework achieves an average 12.4% DICE score improvement over SAM on diverse medical datasets, outperforming state-of-the-art models without requiring source-domain training data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging as it offers a practical solution to deploy high-performance segmentation models with minimal or no labeled data, accelerating the development and clinical adoption of AI tools for diagnosis, treatment planning, and monitoring across various medical specialties.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to significantly improve the accuracy and generalization capability of zero-shot image segmentation models (specifically building upon SAM) for various medical imaging tasks. This advancement allows AI systems to perform detailed segmentation of structures in medical images (e.g., skin lesions, polyps, breast abnormalities, retinal structures) more effectively, even with limited annotated data or without extensive task-specific training. This capability directly supports clinical applications such as automated disease detection, diagnosis, surgical planning, and quantitative analysis of medical images, thereby enhancing efficiency and potentially improving patient outcomes in healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in medical image segmentation: scarcity of annotated data, high computational costs, and SAM's notable limitations on medical datasets due to domain shifts.</li>
                    
                    <li>Proposes BA-TTA-SAM, a novel task-agnostic test-time adaptation framework for efficient zero-shot enhancement of SAM's performance.</li>
                    
                    <li>Integrates encoder-level Gaussian prompt injection, embedding Gaussian-based prompts directly into the image encoder to provide explicit guidance for initial representation learning.</li>
                    
                    <li>Utilizes cross-layer boundary-aware attention alignment, exploiting hierarchical feature interactions within the ViT backbone to align deep semantic responses with shallow boundary cues.</li>
                    
                    <li>Achieves an average improvement of 12.4% in the DICE score compared to SAM's zero-shot segmentation performance across four diverse medical datasets (ISIC, Kvasir, BUSI, REFUGE).</li>
                    
                    <li>Consistently outperforms state-of-the-art models in medical image segmentation, demonstrating superior generalization ability.</li>
                    
                    <li>Enhances SAM's capabilities significantly without requiring any source-domain training data, thereby reducing annotation burden and computational resources.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The BA-TTA-SAM framework is a task-agnostic test-time adaptation approach designed to enhance zero-shot segmentation. It operates by integrating two key mechanisms: (1) **Encoder-level Gaussian prompt injection**, which embeds Gaussian-based prompts directly into the image encoder to guide initial representation learning. (2) **Cross-layer boundary-aware attention alignment**, which leverages hierarchical feature interactions within the Vision Transformer (ViT) backbone to align deep semantic features with precise shallow boundary information, thereby adapting the model to target domains during inference without prior training on new data.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed BA-TTA-SAM framework achieved an average improvement of 12.4% in the DICE score when compared to SAM's zero-shot segmentation performance across four diverse medical datasets (ISIC, Kvasir, BUSI, REFUGE). The method consistently demonstrated superior performance against state-of-the-art models in medical image segmentation, significantly enhancing SAM's generalization ability without requiring any source-domain training data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework holds significant potential for clinical application by enabling faster and more accurate automated segmentation of medical images, reducing the critical bottleneck of manual annotation by expert clinicians. This could streamline diagnostic workflows, facilitate quantitative analysis for disease progression, and accelerate medical research, ultimately leading to improved patient care, more precise interventions, and more efficient healthcare delivery, especially in resource-constrained settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations specific to the proposed BA-TTA-SAM framework itself. It highlights the challenges of conventional methods and SAM's limitations on medical datasets due to domain shifts, which BA-TTA-SAM aims to address.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research directions are not explicitly mentioned in the abstract for the proposed framework.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Dermatology (skin lesion analysis)</span>
                    
                    <span class="tag">Gastroenterology (GI tract endoscopy)</span>
                    
                    <span class="tag">Radiology / Breast Imaging (breast ultrasound)</span>
                    
                    <span class="tag">Ophthalmology (optic disc/cup segmentation)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Zero-shot segmentation</span>
                    
                    <span class="tag tag-keyword">Test-time adaptation</span>
                    
                    <span class="tag tag-keyword">Medical image segmentation</span>
                    
                    <span class="tag tag-keyword">SAM (Segment Anything Model)</span>
                    
                    <span class="tag tag-keyword">Foundation models</span>
                    
                    <span class="tag tag-keyword">Boundary-aware attention</span>
                    
                    <span class="tag tag-keyword">Gaussian prompts</span>
                    
                    <span class="tag tag-keyword">Domain shift</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Due to the scarcity of annotated data and the substantial computational costs of model, conventional tuning methods in medical image segmentation face critical challenges. Current approaches to adapting pretrained models, including full-parameter and parameter-efficient fine-tuning, still rely heavily on task-specific training on downstream tasks. Therefore, zero-shot segmentation has gained increasing attention, especially with foundation models such as SAM demonstrating promising generalization capabilities. However, SAM still faces notable limitations on medical datasets due to domain shifts, making efficient zero-shot enhancement an urgent research goal. To address these challenges, we propose BA-TTA-SAM, a task-agnostic test-time adaptation framework that significantly enhances the zero-shot segmentation performance of SAM via test-time adaptation. This framework integrates two key mechanisms: (1) The encoder-level Gaussian prompt injection embeds Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning. (2) The cross-layer boundary-aware attention alignment exploits the hierarchical feature interactions within the ViT backbone, aligning deep semantic responses with shallow boundary cues. Experiments on four datasets, including ISIC, Kvasir, BUSI, and REFUGE, show an average improvement of 12.4\% in the DICE score compared with SAM's zero-shot segmentation performance. The results demonstrate that our method consistently outperforms state-of-the-art models in medical image segmentation. Our framework significantly enhances the generalization ability of SAM, without requiring any source-domain training data. Extensive experiments on publicly available medical datasets strongly demonstrate the superiority of our framework. Our code is available at https://github.com/Emilychenlin/BA-TTA-SAM.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>