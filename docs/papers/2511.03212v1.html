<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction - Health AI Hub</title>
    <meta name="description" content="This paper introduces MvBody, a novel multi-view-based Transformer network designed to predict Cesarean Section (CS) risk using self-reported medical data and 3">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03212v1" target="_blank">2511.03212v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Ruting Cheng, Boyuan Feng, Yijiang Zheng, Chuhui Qiu, Aizierjiang Aiersilan, Joaquin A. Calderon, Wentao Zhao, Qing Pan, James K. Hahn
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, 68T10, 68T45
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03212v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03212v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MvBody, a novel multi-view-based Transformer network designed to predict Cesarean Section (CS) risk using self-reported medical data and 3D optical body scans acquired during late gestation. The model achieves an 84.62% accuracy and 0.724 AUC-ROC, demonstrating superior performance while providing explainable predictions for critical factors like maternal age, obstetric history, and specific body shape characteristics.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research offers a novel, accessible, and explainable approach to early Cesarean Section risk assessment, vital for improving prenatal care decisions and maternal-neonatal outcomes, especially in regions with limited medical resources.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes MvBody, a multi-view-based hybrid Transformer network, as an AI model designed to predict the risk of Cesarean Section delivery. It utilizes self-reported medical data and 3D optical body scans obtained during gestation. This AI application aims to provide early and reliable risk assessment to improve prenatal care decisions and ultimately enhance maternal and neonatal outcomes, particularly for populations in resource-limited or home-based settings where traditional in-hospital predictive models are often impractical.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical need for early and reliable Cesarean Section (CS) risk assessment, particularly in resource-limited settings where traditional in-hospital data is unavailable.</li>
                    
                    <li>Proposes MvBody, a novel multi-view-based Hybrid Transformer network, for CS risk prediction.</li>
                    
                    <li>Utilizes a unique data combination: self-reported medical data and 3D optical body scans collected between 31 and 38 weeks of gestation.</li>
                    
                    <li>Incorporates a metric learning loss to enhance training efficiency and model generalizability, especially crucial in data-scarce environments.</li>
                    
                    <li>Achieves superior performance with an 84.62% accuracy and an AUC-ROC of 0.724 on an independent test set, surpassing existing machine learning and advanced 3D analysis methods.</li>
                    
                    <li>Employs the Integrated Gradients algorithm to provide explainability, detailing the theoretical basis for the model's predictions and building trust.</li>
                    
                    <li>Identifies key predictive features for CS risk: pre-pregnancy weight, maternal age, obstetric history, previous CS history, and specific body shape characteristics, particularly around the head and shoulders.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes MvBody, a multi-view-based Hybrid Transformer network, designed to predict CS risk. It integrates self-reported medical data with features derived from 3D optical body scans obtained between 31 and 38 weeks of gestation. A metric learning loss is incorporated to improve training efficiency and model generalizability in data-scarce settings. The Integrated Gradients algorithm is applied to provide explainable insights into the model's decision-making process.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MvBody achieved an accuracy of 84.62% and an AUC-ROC of 0.724 on an independent test set, demonstrating superior performance compared to widely used machine learning models and advanced 3D analysis methods. Key factors contributing to CS risk prediction were identified as pre-pregnancy weight, maternal age, obstetric history, previous CS history, and body shape, particularly around the head and shoulders.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This model provides a potentially transformative tool for early, non-invasive CS risk assessment that is less dependent on traditional in-hospital parameters, making it highly valuable for resource-limited settings or home-based care. The explainability feature can enhance trust among clinicians and patients, facilitating personalized prenatal counseling, enabling better-informed decisions, and potentially optimizing resource allocation and patient transfers.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>As a 'pilot investigation,' the findings are preliminary and may require further large-scale validation. The model was developed in 'data-scarce environments,' which might suggest the need for larger and more diverse datasets to ensure broader generalizability. While aiming for 'more affordable general devices' in the future, the current reliance on '3D optical body scans' might still pose accessibility challenges in the most resource-constrained settings.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future work aims to transition towards applications using more affordable and general devices to make 3D body scanning technology broadly accessible. Further validation on larger, more diverse populations is also implied to move beyond the pilot investigation phase and ensure robust clinical applicability and generalizability.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Obstetrics</span>
                    
                    <span class="tag">Maternal-Fetal Medicine</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">AI in Healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Cesarean section</span>
                    
                    <span class="tag tag-keyword">Risk prediction</span>
                    
                    <span class="tag tag-keyword">3D body scan</span>
                    
                    <span class="tag tag-keyword">Transformer network</span>
                    
                    <span class="tag tag-keyword">Explainable AI</span>
                    
                    <span class="tag tag-keyword">Maternal health</span>
                    
                    <span class="tag tag-keyword">Prenatal care</span>
                    
                    <span class="tag tag-keyword">Machine learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurately assessing the risk of cesarean section (CS) delivery is critical,
especially in settings with limited medical resources, where access to
healthcare is often restricted. Early and reliable risk prediction allows
better-informed prenatal care decisions and can improve maternal and neonatal
outcomes. However, most existing predictive models are tailored for in-hospital
use during labor and rely on parameters that are often unavailable in
resource-limited or home-based settings. In this study, we conduct a pilot
investigation to examine the feasibility of using 3D body shape for CS risk
assessment for future applications with more affordable general devices. We
propose a novel multi-view-based Transformer network, MvBody, which predicts CS
risk using only self-reported medical data and 3D optical body scans obtained
between the 31st and 38th weeks of gestation. To enhance training efficiency
and model generalizability in data-scarce environments, we incorporate a metric
learning loss into the network. Compared to widely used machine learning models
and the latest advanced 3D analysis methods, our method demonstrates superior
performance, achieving an accuracy of 84.62% and an Area Under the Receiver
Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set.
To improve transparency and trust in the model's predictions, we apply the
Integrated Gradients algorithm to provide theoretically grounded explanations
of the model's decision-making process. Our results indicate that pre-pregnancy
weight, maternal age, obstetric history, previous CS history, and body shape,
particularly around the head and shoulders, are key contributors to CS risk
prediction.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>19 pages, 4 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>