<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging - Health AI Hub</title>
    <meta name="description" content="BTB3D introduces a novel causal convolutional encoder-decoder that unifies 2D and 3D training for vision-language modeling in 3D medical imaging, generating com">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">← Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20639v1" target="_blank">2510.20639v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Ibrahim Ethem Hamamci, Sezgin Er, Suprosanna Shit, Hadrien Reynaud, Dong Yang, Pengfei Guo, Marc Edgar, Daguang Xu, Bernhard Kainz, Bjoern Menze
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20639v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20639v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">BTB3D introduces a novel causal convolutional encoder-decoder that unifies 2D and 3D training for vision-language modeling in 3D medical imaging, generating compact, frequency-aware volumetric tokens. This approach addresses limitations of existing models in handling high-resolution CT volumes, significantly improving performance in both automated medical report generation and text-to-CT synthesis. It underscores that precise three-dimensional tokenization is critical for scalable vision-language modeling in this domain.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly enhances the capability of AI to process and interpret complex 3D medical images, leading to more accurate and efficient automated medical reporting and the generation of high-fidelity synthetic CT scans, which are vital for diagnostic support, training, and research.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI model (BTB3D) directly applies to automated medical report generation, assisting radiologists by potentially improving report consistency, efficiency, and reducing workload. It also enables text-conditioned 3D medical image synthesis, which can be valuable for medical education, data augmentation for training other AI models, research in disease progression, or potentially for creating patient-specific models for surgical planning or personalized medicine applications.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenge of current 3D medical vision-language models struggling with high-resolution, long-sequence volumes due to misaligned encoders and blurred fine anatomy from slice-wise tokenization.</li>
                    
                    <li>BTB3D employs a causal convolutional encoder-decoder architecture that unifies 2D and 3D training and inference, producing compact, frequency-aware volumetric tokens.</li>
                    
                    <li>Utilizes a three-stage training curriculum: local reconstruction, overlapping-window tiling, and long-context decoder refinement, enabling generalization from short slice excerpts to large volumes (>300 slices) without additional memory overhead.</li>
                    
                    <li>Achieves state-of-the-art performance in automated medical report generation, significantly increasing clinical F1 by 40% over leading models like CT2Rep, CT-CHAT, and Merlin.</li>
                    
                    <li>Demonstrates superior text-to-CT synthesis, reducing FID by 75% and halving FVD compared to GenerateCT and MedSyn, while generating anatomically consistent 512x512x241 CT volumes.</li>
                    
                    <li>The core insight is that precise three-dimensional tokenization, rather than merely larger language backbones, is essential for scalable and effective vision-language modeling in 3D medical imaging.</li>
                    
                    <li>The model learns effectively from large-scale computed tomography (CT) corpora with paired free-text reports.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>BTB3D is a causal convolutional encoder-decoder model that unifies 2D and 3D training and inference. It uses a three-stage training curriculum: (i) local reconstruction of tokens, (ii) an overlapping-window tiling strategy for handling larger volumetric contexts, and (iii) long-context decoder refinement. This allows the model to learn from short slice excerpts and generalize to full-resolution CT scans exceeding 300 slices efficiently, producing compact, frequency-aware volumetric tokens.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>BTB3D establishes a new state-of-the-art across two key tasks: for automated report generation, it improves BLEU scores and increases clinical F1 by 40% compared to existing models like CT2Rep, CT-CHAT, and Merlin. For text-to-CT synthesis, it reduces FID by 75% and halves FVD when compared to GenerateCT and MedSyn, producing anatomically consistent 512x512x241 CT volumes.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced automated report generation capabilities can streamline radiologists' workflows by providing high-quality preliminary reports, reducing diagnostic turnaround times, and improving report consistency. The ability to synthesize anatomically consistent 3D CT volumes from text descriptions opens avenues for generating synthetic training data for rare conditions, enhancing medical education, assisting in surgical planning simulations, and developing privacy-preserving datasets for research without direct patient data.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of existing approaches that BTB3D overcomes, such as issues with high-resolution volumes, misaligned vision encoders, and blurred fine anatomy from slice-wise tokenization. It does not explicitly state specific limitations of the BTB3D model itself within the provided text.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated in the abstract, the success of precise 3D tokenization suggests future research could focus on applying this methodology to other 3D medical imaging modalities (e.g., MRI, PET), extending its use to additional 3D analysis tasks beyond report generation and synthesis (e.g., automated disease classification, precise segmentation), and exploring its integration into multi-modal clinical decision support systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">3D medical imaging</span>
                    
                    <span class="tag tag-keyword">vision-language modeling</span>
                    
                    <span class="tag tag-keyword">computed tomography (CT)</span>
                    
                    <span class="tag tag-keyword">tokenization</span>
                    
                    <span class="tag tag-keyword">report generation</span>
                    
                    <span class="tag tag-keyword">image synthesis</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Recent progress in vision-language modeling for 3D medical imaging has been
fueled by large-scale computed tomography (CT) corpora with paired free-text
reports, stronger architectures, and powerful pretrained models. This has
enabled applications such as automated report generation and text-conditioned
3D image synthesis. Yet, current approaches struggle with high-resolution,
long-sequence volumes: contrastive pretraining often yields vision encoders
that are misaligned with clinical language, and slice-wise tokenization blurs
fine anatomy, reducing diagnostic performance on downstream tasks. We introduce
BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder
that unifies 2D and 3D training and inference while producing compact,
frequency-aware volumetric tokens. A three-stage training curriculum enables
(i) local reconstruction, (ii) overlapping-window tiling, and (iii)
long-context decoder refinement, during which the model learns from short slice
excerpts yet generalizes to scans exceeding 300 slices without additional
memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it
improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and
Merlin for report generation; and it reduces FID by 75% and halves FVD compared
to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically
consistent 512*512*241 volumes. These results confirm that precise
three-dimensional tokenization, rather than larger language backbones alone, is
essential for scalable vision-language modeling in 3D medical imaging. The
codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">← Back to all papers</a></p>
    </footer>
</body>
</html>