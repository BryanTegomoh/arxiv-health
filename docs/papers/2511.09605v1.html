<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks - Health AI Hub</title>
    <meta name="description" content="TomoGraphView introduces a novel framework for 3D medical image classification that addresses the limitations of conventional slice-based methods by integrating">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>TomoGraphView: 3D Medical Image Classification with Omnidirectional Slice Representations and Graph Neural Networks</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.09605v1" target="_blank">2511.09605v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-12
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Johannes Kiechle, Stefan M. Fischer, Daniel M. Lang, Cosmin I. Bercea, Matthew J. Nyflot, Lina Felsner, Julia A. Schnabel, Jan C. Peeken
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.AI, cs.LG, q-bio.QM
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.09605v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.09605v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">TomoGraphView introduces a novel framework for 3D medical image classification that addresses the limitations of conventional slice-based methods by integrating omnidirectional volume slicing with spherical graph-based feature aggregation. This approach leverages powerful 2D vision foundation models for feature extraction, aiming to more comprehensively capture complex spatial relationships and preserve volumetric coherence in medical tomography data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing automated medical image analysis, particularly in tasks like tumor characterization from tomography scans, by developing more robust and accurate classification methods that better reflect the complex 3D reality of anatomical structures, thereby assisting physicians and managing their workload.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes an AI framework, TomoGraphView, designed for automated classification of 3D medical images. This AI application aims to improve the accuracy and efficiency of diagnosing medical conditions, particularly for tasks like tumor characterization, thereby assisting physicians in managing their workload and enhancing diagnostic capabilities in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** Challenges in 3D medical image classification, including complex spatial relationships, long-range dependencies, low data regimes for 3D models, and the absence of large-scale 3D datasets.</li>
                    
                    <li>**Limitations of Existing Methods:** Conventional 2D slice-based decomposition of 3D volumes (axial, sagittal, coronal) often fails to adequately capture target structures misaligned with standardized planes and loses spatial coherence during slice-wise aggregation.</li>
                    
                    <li>**Novel Framework: TomoGraphView:** Proposes a new methodology combining omnidirectional volume slicing and spherical graph-based feature aggregation to overcome these limitations.</li>
                    
                    <li>**Leveraging 2D Foundation Models:** The framework utilizes 2D vision foundation models, pre-trained on natural images, as robust feature extractors for individual slices.</li>
                    
                    <li>**Graph Neural Networks for Aggregation:** Implies the use of Graph Neural Networks (GNNs) for aggregating features from omnidirectional slices on a spherical graph, thereby preserving volumetric structure and spatial relationships.</li>
                    
                    <li>**Enhanced Feature Capture:** Designed to better capture the spatial extent of target structures regardless of their orientation and maintain volumetric structural integrity across slices.</li>
                    
                    <li>**Open-Source Contribution:** The authors provide a public codebase for TomoGraphView and a user-friendly library for omnidirectional volume slicing (OmniSlicer).</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>TomoGraphView employs a multi-step approach: 1) It generates omnidirectional slices from 3D medical volumes, moving beyond canonical planes. 2) Features are extracted from these individual 2D slices using pre-trained 2D vision foundation models. 3) These features are then aggregated using a spherical graph-based approach, likely involving Graph Neural Networks (GNNs), to preserve volumetric structure and spatial coherence for the final 3D classification task.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The abstract proposes TomoGraphView as a novel framework specifically designed to overcome critical limitations of existing 3D medical image classification methods. While specific experimental results are not detailed in the abstract, the framework is presented as being capable of more accurately capturing the spatial extent of target structures (even when misaligned) and effectively preserving volumetric structure and spatial coherence across slices during feature aggregation, implying superior performance compared to conventional approaches.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework has the potential to significantly improve the accuracy and robustness of automated analyses of medical tomography images, leading to more reliable tumor characterization, earlier detection of pathologies, and better support for clinical decision-making. By reducing the reliance on manual interpretation and addressing the limitations of current AI methods, it can help manage the growing workload of radiologists and oncologists, ultimately enhancing patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights the general challenges in 3D medical imaging that TomoGraphView aims to address: complex spatial relationships, long-range dependencies, low data regimes for training 3D models from scratch, and the absence of large-scale 3D multimodal datasets. It also points out the suboptimal nature of existing slice-based decomposition methods in capturing misaligned structures and preserving volumetric coherence. The abstract does not explicitly state limitations of the TomoGraphView framework itself, but rather positions it as a solution to these existing problems.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated in the abstract, the provision of a public codebase and a user-friendly library for omnidirectional slicing (OmniSlicer) suggests an intention to foster broader adoption and encourage further research and development using this novel approach within the medical imaging and AI communities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">3D Medical Image Classification</span>
                    
                    <span class="tag tag-keyword">Omnidirectional Slicing</span>
                    
                    <span class="tag tag-keyword">Graph Neural Networks</span>
                    
                    <span class="tag tag-keyword">Vision Foundation Models</span>
                    
                    <span class="tag tag-keyword">Tomography</span>
                    
                    <span class="tag tag-keyword">Tumor Characterization</span>
                    
                    <span class="tag tag-keyword">Spatial Coherence</span>
                    
                    <span class="tag tag-keyword">Automated Diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The growing number of medical tomography examinations has necessitated the development of automated methods capable of extracting comprehensive imaging features to facilitate downstream tasks such as tumor characterization, while assisting physicians in managing their growing workload. However, 3D medical image classification remains a challenging task due to the complex spatial relationships and long-range dependencies inherent in volumetric data. Training models from scratch suffers from low data regimes, and the absence of 3D large-scale multimodal datasets has limited the development of 3D medical imaging foundation models. Recent studies, however, have highlighted the potential of 2D vision foundation models, originally trained on natural images, as powerful feature extractors for medical image analysis. Despite these advances, existing approaches that apply 2D models to 3D volumes via slice-based decomposition remain suboptimal. Conventional volume slicing strategies, which rely on canonical planes such as axial, sagittal, or coronal, may inadequately capture the spatial extent of target structures when these are misaligned with standardized viewing planes. Furthermore, existing slice-wise aggregation strategies rarely account for preserving the volumetric structure, resulting in a loss of spatial coherence across slices. To overcome these limitations, we propose TomoGraphView, a novel framework that integrates omnidirectional volume slicing with spherical graph-based feature aggregation. We publicly share our accessible code base at http://github.com/compai-lab/2025-MedIA-kiechle and provide a user-friendly library for omnidirectional volume slicing at https://pypi.org/project/OmniSlicer.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Preprint submitted to Medical Image Analysis (MedIA)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>