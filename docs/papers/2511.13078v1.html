<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning - Health AI Hub</title>
    <meta name="description" content="This paper introduces EMSGlass, a smart-glasses system for Emergency Medical Services (EMS) designed to alleviate cognitive load and improve decision-making for">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.13078v1" target="_blank">2511.13078v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-17
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Liuyi Jin, Pasan Gunawardena, Amran Haroon, Runzhi Wang, Sangwoo Lee, Radu Stoleru, Michael Middleton, Zepeng Huo, Jeeeun Kim, Jason Moats
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, eess.AS, eess.IV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.13078v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.13078v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces EMSGlass, a smart-glasses system for Emergency Medical Services (EMS) designed to alleviate cognitive load and improve decision-making for EMTs. It leverages EMSNet, the first multimodal multitask AI model for EMS, and EMSServe, a low-latency serving framework, to integrate text, vital signs, and images for real-time situational understanding and decision support. User studies demonstrate EMSGlass enhances situational awareness, decision-making speed, and operational efficiency.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This technology directly addresses critical challenges faced by EMTs in pre-hospital emergency care, potentially leading to faster, more accurate life-saving decisions and improved patient outcomes by providing real-time, AI-powered situational awareness and decision support.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using multimodal multitask learning (EMSNet) within smart-glasses (EMSGlass) to provide real-time decision support, enhance situational awareness, and improve operational efficiency for Emergency Medical Technicians (EMTs) during emergency medical incidents. It processes various types of medical and scene data to assist with critical EMS tasks, effectively bridging AI intelligence with real-world emergency response workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>EMSGlass is a smart-glasses system aimed at assisting Emergency Medical Technicians (EMTs) by reducing cognitive and operational loads in high-pressure environments.</li>
                    
                    <li>It is powered by EMSNet, a novel multimodal multitask AI model that integrates text, vital signs, and scene images to create a unified real-time understanding of EMS incidents.</li>
                    
                    <li>EMSNet, trained on real-world multimodal EMS datasets, simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines.</li>
                    
                    <li>EMSServe is a low-latency multimodal serving framework built on PyTorch, featuring a modality-aware model splitter and a feature caching mechanism.</li>
                    
                    <li>EMSServe optimizes inference across heterogeneous hardware and addresses asynchronous modality arrival, achieving 1.9x to 11.7x speedup over direct PyTorch multimodal inference.</li>
                    
                    <li>A user study with six professional EMTs demonstrated that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction.</li>
                    
                    <li>Qualitative insights from the user study provide actionable directions for extending EMSGlass towards next-generation AI-enabled EMS systems.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The EMSGlass system comprises smart glasses integrating EMSNet and EMSServe. EMSNet is a multimodal multitask deep learning model, trained on real-world EMS data, processing text, vital signs, and images for unified incident understanding and supporting multiple critical tasks. EMSServe is a PyTorch-based low-latency inference framework employing a modality-aware model splitter and feature caching for efficient processing across diverse hardware and asynchronous data inputs. System efficacy was evaluated through quantitative inference speed benchmarks and a qualitative user study with six professional EMTs.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>EMSNet achieved superior accuracy across up to five critical EMS tasks compared to unimodal baselines. EMSServe significantly accelerated multimodal inference, demonstrating a 1.9x to 11.7x speedup over direct PyTorch methods. User study participants (EMTs) reported that EMSGlass improved real-time situational awareness, decision-making speed, and overall operational efficiency via its intuitive on-glass interaction.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>EMSGlass has the potential to significantly improve pre-hospital emergency care by providing EMTs with critical, context-aware information and AI-driven decision support directly in their field of view. This could translate to quicker, more accurate assessments, reduced cognitive load, fewer medical errors, and ultimately enhanced patient care and survival rates in time-sensitive emergency situations.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific technical or methodological limitations of the EMSGlass system. However, the mention of 'actionable directions for extending EMSGlass' implies ongoing development and refinement are needed, and the user study size (six EMTs) might be considered a limitation for broad generalizability.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research aims to extend EMSGlass towards next-generation AI-enabled EMS systems, specifically focusing on integrating multimodal intelligence more deeply into real-world emergency response workflows based on the qualitative insights gathered from the user study.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Pre-hospital Care</span>
                    
                    <span class="tag">Paramedicine</span>
                    
                    <span class="tag">Critical Care Transport</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Smart glasses</span>
                    
                    <span class="tag tag-keyword">Emergency Medical Services</span>
                    
                    <span class="tag tag-keyword">Multimodal learning</span>
                    
                    <span class="tag tag-keyword">Multitask learning</span>
                    
                    <span class="tag tag-keyword">Artificial intelligence</span>
                    
                    <span class="tag tag-keyword">Real-time inference</span>
                    
                    <span class="tag tag-keyword">Decision support systems</span>
                    
                    <span class="tag tag-keyword">Pre-hospital care</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Emergency Medical Technicians (EMTs) operate in high-pressure environments, making rapid, life-critical decisions under heavy cognitive and operational loads. We present EMSGlass, a smart-glasses system powered by EMSNet, the first multimodal multitask model for Emergency Medical Services (EMS), and EMSServe, a low-latency multimodal serving framework tailored to EMS scenarios. EMSNet integrates text, vital signs, and scene images to construct a unified real-time understanding of EMS incidents. Trained on real-world multimodal EMS datasets, EMSNet simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines. Built on top of PyTorch, EMSServe introduces a modality-aware model splitter and a feature caching mechanism, achieving adaptive and efficient inference across heterogeneous hardware while addressing the challenge of asynchronous modality arrival in the field. By optimizing multimodal inference execution in EMS scenarios, EMSServe achieves 1.9x -- 11.7x speedup over direct PyTorch multimodal inference. A user study evaluation with six professional EMTs demonstrates that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction. In addition, qualitative insights from the user study provide actionable directions for extending EMSGlass toward next-generation AI-enabled EMS systems, bridging multimodal intelligence with real-world emergency response workflows.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>