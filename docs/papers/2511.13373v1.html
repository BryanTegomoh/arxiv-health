<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs - Health AI Hub</title>
    <meta name="description" content="This paper addresses critical challenges in distributed healthcare LLMs, such as knowledge consolidation, computational overhead, and catastrophic forgetting, b">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.13373v1" target="_blank">2511.13373v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-17
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Prakrit Timilsina, Anuj Nepal, Rajan Kadel, Robin Doss
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.13373v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.13373v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper addresses critical challenges in distributed healthcare LLMs, such as knowledge consolidation, computational overhead, and catastrophic forgetting, by evaluating six parameter-space merging techniques, including a novel hierarchical method. It demonstrates that for architecturally compatible medical LLMs (derived from Mistral-7B), simple averaging methods like Task Arithmetic significantly outperform complex approaches, achieving 45.80% accuracy on MedQA. This establishes simple averaging as a robust and computationally efficient baseline for scalable medical AI in resource-constrained IoT environments.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is vital for advancing federated learning and distributed AI in healthcare, enabling LLMs to consolidate specialized medical knowledge across institutions while addressing critical concerns like privacy, computational efficiency, and preventing catastrophic forgetting during updates, crucial for real-world clinical utility.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research is directly applicable to developing and deploying efficient, scalable, and robust Large Language Models (LLMs) tailored for medical use in distributed healthcare settings. It focuses on consolidating specialized medical knowledge from various institutions into unified models while minimizing computational resources, addressing privacy concerns, and preventing knowledge loss. This facilitates applications such as advanced clinical decision support systems, medical information retrieval, patient monitoring, and diagnostic assistance, particularly in environments with limited computational power.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study tackles significant challenges in distributed healthcare LLMs, including consolidating specialized domain knowledge, reducing computational overhead, and preventing catastrophic forgetting.</li>
                    
                    <li>A systematic evaluation was conducted on six parameter-space merging techniques: Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and a newly introduced Hierarchical approach.</li>
                    
                    <li>The evaluation targeted two architecturally compatible medical LLMs, both fine-tuned from the Mistral-7B base model.</li>
                    
                    <li>The novel hierarchical method integrates selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to mitigate permutation variance and minimize computational burden for edge deployments.</li>
                    
                    <li>Performance was assessed across five distinct medical benchmarks.</li>
                    
                    <li>Key finding: Simple averaging methods are highly effective for architecturally compatible medical LLMs, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based methods.</li>
                    
                    <li>The findings provide crucial insights for deploying computationally efficient and compatible distributed medical AI systems in resource-constrained IoT environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study systematically evaluated six parameter-space merging techniques (Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and a novel Hierarchical method). These techniques were applied to two architecturally compatible medical LLMs, both derived from the Mistral-7B base model. The introduced hierarchical method combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation to address permutation variance and reduce computational overhead. Performance was benchmarked across five medical datasets, with accuracy on MedQA explicitly reported.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary discovery is that for architecturally compatible medical LLMs, simple averaging methods are remarkably effective. Specifically, Task Arithmetic achieved 45.80% accuracy on the MedQA benchmark, significantly outperforming more complex, pruning-based model merging techniques. This highlights that computational simplicity can yield superior results in specific model compatibility scenarios for knowledge consolidation.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work offers practical and efficient strategies for deploying scalable and robust medical AI in distributed healthcare settings, particularly within resource-constrained IoT environments. By establishing simple averaging as a computationally efficient baseline, it facilitates faster knowledge consolidation from multiple specialized medical models and reduces the computational footprint required for edge devices, which is critical for real-time clinical applications and maintaining data privacy in federated learning architectures.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The findings are primarily established for architecturally compatible models, implying that the generalizability of these conclusions to models with differing or incompatible architectures would require further investigation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions beyond the implications of its current findings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Distributed healthcare AI</span>
                    
                    <span class="tag">Medical natural language processing</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                    <span class="tag">Resource-constrained medical devices (IoT)</span>
                    
                    <span class="tag">Federated Learning in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLM merging</span>
                    
                    <span class="tag tag-keyword">Distributed AI</span>
                    
                    <span class="tag tag-keyword">Medical LLM</span>
                    
                    <span class="tag tag-keyword">Parameter merging</span>
                    
                    <span class="tag tag-keyword">Optimal Transport</span>
                    
                    <span class="tag tag-keyword">Task Arithmetic</span>
                    
                    <span class="tag tag-keyword">Computational efficiency</span>
                    
                    <span class="tag tag-keyword">Edge AI</span>
                    
                    <span class="tag tag-keyword">Catastrophic forgetting</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>