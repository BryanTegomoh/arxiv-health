<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Causality for Longitudinal Data - Health AI Hub</title>
    <meta name="description" content="This thesis presents three novel contributions in causal inference and causal representation learning (CRL) for high-dimensional, time-varying data. It introduc">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Learning Causality for Longitudinal Data</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04980v1" target="_blank">2512.04980v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mouad EL Bouchattaoui
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> stat.ML, cs.IT, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04980v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04980v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This thesis presents three novel contributions in causal inference and causal representation learning (CRL) for high-dimensional, time-varying data. It introduces the Causal Dynamic Variational Autoencoder (CDVAE) for improved Individual Treatment Effect (ITE) estimation by modeling unobserved heterogeneity, an efficient RNN-based framework utilizing Contrastive Predictive Coding (CPC) for long-term counterfactuals, and a model-agnostic interpretability layer to uncover how latent causes manifest in observed features.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>These methods are vital for precision medicine, enabling more accurate individual treatment effect predictions, understanding long-term disease progression under different interventions, and deciphering underlying biological mechanisms from complex, longitudinal patient data.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The methods developed could be applied to build advanced medical AI systems that: 1) Predict individual patient responses to various treatments (ITEs) to recommend personalized therapies. 2) Model long-term patient outcomes under different care pathways or lifestyle changes (counterfactuals) to guide clinical decision-making. 3) Uncover hidden biological mechanisms or patient subgroups (latent causes) from complex medical data like Electronic Health Records (EHRs), sensor data, or omics data, thereby improving diagnostic accuracy and target identification for new therapies. 4) Enhance the interpretability of AI models in healthcare by showing how latent factors influence observable patient features.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Introduces the Causal Dynamic Variational Autoencoder (CDVAE) for estimating Individual Treatment Effects (ITEs), specifically designed to capture unobserved heterogeneity driven by latent risk factors affecting only outcomes.</li>
                    
                    <li>CDVAE provides theoretical guarantees for valid latent adjustment and generalization bounds for ITE error, demonstrating superior performance against baselines and enhancing state-of-the-art models to near oracle levels.</li>
                    
                    <li>Proposes an efficient RNN-based framework for long-term counterfactual regression, enhanced with Contrastive Predictive Coding (CPC) and InfoMax, which captures long-range dependencies under time-varying confounding while avoiding high computational costs of transformers.</li>
                    
                    <li>Achieves state-of-the-art results in long-term counterfactual regression and introduces Contrastive Predictive Coding (CPC) as a novel technique within causal inference.</li>
                    
                    <li>Advances Causal Representation Learning (CRL) through a model-agnostic interpretability layer based on the geometry of the decoder Jacobian, addressing how latent causes manifest in observed variables.</li>
                    
                    <li>Employs a sparse self-expression prior to induce modular, potentially overlapping groups of observed features that align with shared latent influences, with provided recovery guarantees without strong assumptions.</li>
                    
                    <li>Develops scalable Jacobian-based regularization techniques to further enhance the interpretability and recovery of latent-to-observed structure.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper utilizes a Causal Dynamic Variational Autoencoder (CDVAE) for ITE estimation with theoretical guarantees. For long-term counterfactuals, it employs Recurrent Neural Networks (RNNs) augmented with Contrastive Predictive Coding (CPC) and InfoMax. Causal Representation Learning is advanced through a model-agnostic interpretability layer based on decoder Jacobian geometry and a sparse self-expression prior, complemented by scalable Jacobian-based regularization.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>CDVAE significantly improves Individual Treatment Effect estimation by capturing unobserved heterogeneity, outperforming baselines and enabling near-oracle performance. The RNN-based framework with CPC and InfoMax achieves state-of-the-art results in efficient long-term counterfactual regression, effectively handling time-varying confounding. A novel interpretability layer allows for the recovery of meaningful, modular, and potentially overlapping latent-to-observed feature groups with theoretical guarantees, advancing the understanding of latent causal structures.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research could lead to more precise and personalized treatment recommendations by accurately predicting individual patient responses. It enables better long-term forecasting of disease progression under various interventions, aiding in proactive care planning for chronic conditions. Furthermore, the interpretability methods can help identify novel biomarkers and elucidate the mechanistic links between latent biological processes and observable clinical manifestations, informing drug development and diagnostic strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Personalized Treatment</span>
                    
                    <span class="tag">Chronic Disease Management</span>
                    
                    <span class="tag">Drug Discovery and Development</span>
                    
                    <span class="tag">Prognostics</span>
                    
                    <span class="tag">Biomarker Discovery</span>
                    
                    <span class="tag">Public Health Interventions</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Causal Inference</span>
                    
                    <span class="tag tag-keyword">Causal Representation Learning</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                    <span class="tag tag-keyword">Individual Treatment Effects</span>
                    
                    <span class="tag tag-keyword">Counterfactuals</span>
                    
                    <span class="tag tag-keyword">Variational Autoencoder</span>
                    
                    <span class="tag tag-keyword">Recurrent Neural Networks</span>
                    
                    <span class="tag tag-keyword">Contrastive Predictive Coding</span>
                    
                    <span class="tag tag-keyword">Interpretability</span>
                    
                    <span class="tag tag-keyword">High-dimensional Data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.
  The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.
  The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.
  The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>PhD thesis manuscript</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>