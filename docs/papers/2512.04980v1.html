<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Causality for Longitudinal Data - Health AI Hub</title>
    <meta name="description" content="This thesis introduces novel methods for causal inference and causal representation learning (CRL) specifically designed for high-dimensional, time-varying data">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Learning Causality for Longitudinal Data</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04980v1" target="_blank">2512.04980v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mouad EL Bouchattaoui
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> stat.ML, cs.IT, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04980v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04980v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This thesis introduces novel methods for causal inference and causal representation learning (CRL) specifically designed for high-dimensional, time-varying data. It proposes the Causal Dynamic Variational Autoencoder (CDVAE) for robust Individual Treatment Effect (ITE) estimation under unobserved confounding, develops an efficient RNN-based framework for long-term counterfactual regression, and advances CRL interpretability by revealing how latent causes map to observed variables. The work demonstrates state-of-the-art performance across various tasks and provides theoretical guarantees for its contributions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine by enabling more precise predictions of individual treatment responses, unraveling complex disease mechanisms influenced by hidden factors, and predicting long-term health trajectories, thereby informing personalized medicine and public health interventions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The methods developed could be applied to create AI systems for personalized treatment recommendation (based on ITEs), predicting a patient's long-term health outcomes under different intervention scenarios (counterfactual regression), identifying hidden patient subgroups with unique disease mechanisms or treatment responses (latent risk factors), and providing interpretable insights into complex patient data to support clinical understanding and trust in AI-driven healthcare solutions. It could also aid in early detection of disease or risk factors by uncovering latent causes from observed clinical features.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Causal Dynamic Variational Autoencoder (CDVAE)**: A novel model designed to estimate Individual Treatment Effects (ITEs) by effectively capturing unobserved heterogeneity in treatment response, driven by latent risk factors that impact only outcomes.</li>
                    
                    <li>**Theoretical Guarantees for CDVAE**: The CDVAE framework comes with theoretical guarantees for valid latent adjustment and provides generalization bounds for ITE error, enhancing its reliability and trustworthiness.</li>
                    
                    <li>**Performance of CDVAE**: Experiments show CDVAE significantly outperforms existing baselines, and state-of-the-art models demonstrate considerable improvement when augmented with CDVAE's latent substitutes, closely approaching oracle performance without needing true adjustment variables.</li>
                    
                    <li>**Efficient Long-Term Counterfactual Regression**: Introduces a new framework for long-term counterfactual regression based on RNNs, enhanced with Contrastive Predictive Coding (CPC) and InfoMax, which efficiently captures long-range dependencies under time-varying confounding.</li>
                    
                    <li>**Novel Application of CPC**: This research marks the introduction of Contrastive Predictive Coding (CPC) into the field of causal inference, offering a computationally efficient alternative to transformers for sequential causal modeling and achieving state-of-the-art results.</li>
                    
                    <li>**Interpretable Causal Representation Learning (CRL)**: Advances CRL by proposing a model-agnostic interpretability layer, grounded in the geometry of the decoder Jacobian, to elucidate how latent causes manifest in observed variables.</li>
                    
                    <li>**Latent-to-Observed Structure Recovery**: Utilizes a sparse self-expression prior to identify modular, potentially overlapping groups of observed features aligned with shared latent influences, providing recovery guarantees without relying on anchor features or single-parent assumptions, and developing scalable Jacobian-based regularization techniques.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper leverages a combination of deep learning architectures and causal inference principles. It employs **Causal Dynamic Variational Autoencoders (CDVAE)** for latent variable modeling and ITE estimation. For long-term counterfactual regression, it uses **Recurrent Neural Networks (RNNs)** augmented with **Contrastive Predictive Coding (CPC)** and **InfoMax**. To enhance interpretability in Causal Representation Learning, it utilizes **decoder Jacobian geometry analysis** combined with **sparse self-expression priors** and **Jacobian-based regularization techniques**.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The CDVAE demonstrates superior performance in ITE estimation, significantly improving existing state-of-the-art models by effectively accounting for unobserved heterogeneity. The RNN-CPC-InfoMax framework achieves state-of-the-art results in long-term counterfactual regression with improved computational efficiency. Furthermore, a novel model-agnostic interpretability layer successfully recovers meaningful latent-to-observed causal structures, including modular and overlapping feature groups, without restrictive prior assumptions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>These advancements have the potential to significantly impact clinical practice by facilitating more accurate, personalized treatment decisions based on individual responses and hidden risk factors. They can enable clinicians to better predict long-term outcomes of interventions, optimize therapeutic strategies, and monitor disease progression with higher precision. The interpretability features can help uncover underlying biological mechanisms, potentially leading to the discovery of new biomarkers, drug targets, and a deeper mechanistic understanding of diseases.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the developed methods.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Epidemiology</span>
                    
                    <span class="tag">Pharmacogenomics</span>
                    
                    <span class="tag">Chronic Disease Management</span>
                    
                    <span class="tag">Drug Discovery</span>
                    
                    <span class="tag">Clinical Trials</span>
                    
                    <span class="tag">Digital Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Causal Inference</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                    <span class="tag tag-keyword">Individual Treatment Effects</span>
                    
                    <span class="tag tag-keyword">Causal Representation Learning</span>
                    
                    <span class="tag tag-keyword">Variational Autoencoder</span>
                    
                    <span class="tag tag-keyword">Recurrent Neural Networks</span>
                    
                    <span class="tag tag-keyword">Contrastive Predictive Coding</span>
                    
                    <span class="tag tag-keyword">Interpretability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.
  The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.
  The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.
  The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>PhD thesis manuscript</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>