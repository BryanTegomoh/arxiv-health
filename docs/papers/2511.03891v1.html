<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition - Health AI Hub</title>
    <meta name="description" content="This paper introduces Class-Based Image Composition (CoImg) to address challenges of small and imbalanced datasets in deep learning diagnostics. By fusing multi">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03891v1" target="_blank">2511.03891v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Hlali Azzeddine, Majid Ben Yakhlef, Soulaiman El Hazzat
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.DB
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03891v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03891v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Class-Based Image Composition (CoImg) to address challenges of small and imbalanced datasets in deep learning diagnostics. By fusing multiple images of the same class into composite inputs, the method enhances intra-class variance and information density, leading to significantly improved diagnostic performance on an Optical Coherence Tomography (OCT) retina dataset.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical diagnostics as it provides a novel method to improve the accuracy and reliability of deep learning models for identifying diseases from medical images, particularly in scenarios where data is scarce or unevenly distributed, which is common for rare diseases or new conditions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This paper presents an AI application for automated diagnosis of retinal diseases using OCT scans. Specifically, it introduces a novel method (Class-Based Image Composition) to improve the robustness and accuracy of deep learning models when trained on challenging medical datasets that are small and/or imbalanced, leading to significantly enhanced diagnostic results.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the problem of high false prediction rates in deep learning models due to small, imbalanced datasets and poor input image quality.</li>
                    
                    <li>Proposes Class-Based Image Composition (CoImg) which fuses multiple images of the same class into combined visual composites, termed Composite Input Images (CoImg).</li>
                    
                    <li>The method enhances intra-class variance, improves valuable information density per training sample, and helps models distinguish subtle disease patterns.</li>
                    
                    <li>Evaluated on the OCTDL dataset, consisting of 2,064 high-resolution OCT scans of the human retina, representing seven distinct diseases with significant class imbalance.</li>
                    
                    <li>A class-balanced version, Co-OCTDL, was constructed where each scan is represented as a 3x1 layout composite image.</li>
                    
                    <li>A VGG16 model trained on Co-OCTDL achieved near-perfect accuracy (99.6%), F1-score (0.995), and AUC (0.9996), significantly outperforming the baseline trained on the raw dataset.</li>
                    
                    <li>The proposed approach markedly reduced the false prediction rate, demonstrating its effectiveness for datasets affected by class imbalance or small sample size.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The core methodology involves Class-Based Image Composition (CoImg), which reformulates training inputs by fusing multiple images belonging to the same class into a single composite visual representation, increasing intra-class variance and information density. A VGG16 deep learning model was then trained and comparatively evaluated on two versions of the OCTDL dataset: the original imbalanced dataset and a new, perfectly class-balanced Co-OCTDL dataset constructed using the CoImg approach (each scan as a 3x1 layout composite).</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study found that using the Class-Based Image Composition method dramatically improved diagnostic performance. The VGG16 model trained on the Co-OCTDL (composite) dataset achieved a near-perfect accuracy of 99.6%, an F1-score of 0.995, and an AUC of 0.9996. This represents a significant improvement over the baseline model trained on the original, raw OCTDL dataset, with a substantially lower false prediction rate.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This method has significant potential to enhance clinical diagnostic accuracy, especially in specialties like ophthalmology where subtle visual patterns are critical for disease detection. It could lead to more reliable automated screening and diagnostic tools for retinal diseases, particularly for rare conditions where limited patient data makes traditional deep learning approaches less effective. Improved diagnostic precision could facilitate earlier intervention and better patient outcomes, reducing the burden on expert clinicians.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed method or study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Medical Imaging Diagnostics</span>
                    
                    <span class="tag">Retinal Disease Diagnosis</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Class-Based Image Composition</span>
                    
                    <span class="tag tag-keyword">Optical Coherence Tomography</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Diagnostic Performance</span>
                    
                    <span class="tag tag-keyword">Class Imbalance</span>
                    
                    <span class="tag tag-keyword">Retinal Diseases</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>