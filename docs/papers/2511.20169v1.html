<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ADNet: A Large-Scale and Extensible Multi-Domain Benchmark for Anomaly Detection Across 380 Real-World Categories - Health AI Hub</title>
    <meta name="description" content="This paper introduces ADNet, a novel large-scale and multi-domain benchmark comprising 380 real-world categories, including medical imaging, designed to evaluat">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ADNet: A Large-Scale and Extensible Multi-Domain Benchmark for Anomaly Detection Across 380 Real-World Categories</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20169v1" target="_blank">2511.20169v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Hai Ling, Jia Guo, Zhulin Tao, Yunkang Cao, Donglin Di, Hongyan Xu, Xiu Su, Yang Song, Lei Fan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20169v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20169v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ADNet, a novel large-scale and multi-domain benchmark comprising 380 real-world categories, including medical imaging, designed to evaluate anomaly detection models. It highlights a critical scalability challenge for existing state-of-the-art methods in multi-class settings and proposes Dinomaly-m, a context-guided Mixture-of-Experts model, which achieves superior performance on this challenging benchmark.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>ADNet provides a crucial multi-domain benchmark that explicitly includes medical categories, enabling the development and evaluation of anomaly detection models capable of generalizing across diverse medical imaging tasks. The identified scalability challenge and proposed solution directly address the need for robust, multi-task AI systems in healthcare, moving beyond single-domain, single-task models.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The benchmark facilitates the development and testing of AI models for detecting anomalies in various medical contexts. This includes automated detection of diseases (e.g., tumors, lesions) from medical images (X-rays, MRIs, CT scans), identifying manufacturing defects in medical equipment, or pinpointing unusual patterns in patient vital signs or other clinical data that may indicate a health issue.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**ADNet Benchmark Creation**: Introduction of ADNet, a large-scale, multi-domain benchmark aggregating 380 categories from 49 publicly available datasets across Electronics, Industry, Agrifood, Infrastructure, and Medical domains.</li>
                    
                    <li>**Comprehensive Data & Annotation**: The benchmark consists of 196,294 RGB images (116,192 normal, 80,102 test with 60,311 anomalous) standardized with MVTec-style pixel-level annotations and structured text descriptions for multimodal tasks.</li>
                    
                    <li>**Identified Scalability Challenge**: Extensive experiments reveal a significant scalability problem where SOTA methods' image-level AUROC (I-AUROC) drops from 90.6% in one-for-one settings to 78.5% in a multi-class, all-380-category setting.</li>
                    
                    <li>**Proposed Dinomaly-m Model**: To address scalability, the authors propose Dinomaly-m, a context-guided Mixture-of-Experts (MoE) extension of Dinomaly, designed to expand decoder capacity without increasing inference cost.</li>
                    
                    <li>**Improved Performance**: Dinomaly-m achieves 83.2% I-AUROC and 93.1% P-AUROC (pixel-level AUROC), demonstrating superior performance over existing approaches in the challenging multi-category scenario.</li>
                    
                    <li>**Extensibility and Foundation Model Support**: ADNet is designed as a standardized and extensible resource, fostering community expansion of AD datasets and serving as a scalable foundation for future anomaly detection foundation models.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper's methodology involves aggregating 380 real-world categories from 49 existing datasets into ADNet, standardizing all images with MVTec-style pixel-level annotations and adding structured text descriptions. To tackle the observed scalability challenge of existing anomaly detection methods on this large-scale benchmark, the authors propose Dinomaly-m, a context-guided Mixture-of-Experts extension of the Dinomaly model, aimed at enhancing decoder capacity efficiently.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary key finding is the significant performance degradation of state-of-the-art anomaly detection methods when scaling from single-category evaluation (90.6% I-AUROC) to a multi-class setting across 380 categories (78.5% I-AUROC). The proposed Dinomaly-m model effectively mitigates this, achieving improved performance with 83.2% I-AUROC and 93.1% P-AUROC, demonstrating its superiority in large-scale anomaly detection.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has substantial clinical impact by paving the way for more generalizable and scalable AI diagnostic tools. A single AD foundation model trained on ADNet could potentially detect a wide array of anomalies across various medical imaging modalities (e.g., radiology, pathology) without requiring separate, specialized models for each. This would streamline diagnostic workflows, reduce development costs, facilitate earlier and more consistent detection of pathologies, and enhance quality control in medical image analysis, ultimately leading to improved patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the ADNet benchmark or the Dinomaly-m model itself. However, the observed performance drop of state-of-the-art methods to 78.5% I-AUROC, even with Dinomaly-m's improvement to 83.2%, indicates that there is still significant room for advancements in multi-category anomaly detection. The specific types of medical anomalies or imaging modalities covered within the 'Medical domains' are not detailed, which could be a limitation for targeted clinical applications.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests ADNet will serve as a scalable foundation for future anomaly detection foundation models, encouraging the community to expand AD datasets across diverse domains. This implies future research will focus on developing more advanced, robust, and truly generalizable AD models capable of handling the vast complexity and variability across a multitude of anomaly types and contexts, building upon this benchmark.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Anomaly Detection</span>
                    
                    <span class="tag tag-keyword">Multi-Domain Benchmark</span>
                    
                    <span class="tag tag-keyword">Scalability</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Mixture-of-Experts</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Pixel-level Annotation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Anomaly detection (AD) aims to identify defects using normal-only training data. Existing anomaly detection benchmarks (e.g., MVTec-AD with 15 categories) cover only a narrow range of categories, limiting the evaluation of cross-context generalization and scalability. We introduce ADNet, a large-scale, multi-domain benchmark comprising 380 categories aggregated from 49 publicly available datasets across Electronics, Industry, Agrifood, Infrastructure, and Medical domains. The benchmark includes a total of 196,294 RGB images, consisting of 116,192 normal samples for training and 80,102 test images, of which 60,311 are anomalous. All images are standardized with MVTec-style pixel-level annotations and structured text descriptions spanning both spatial and visual attributes, enabling multimodal anomaly detection tasks. Extensive experiments reveal a clear scalability challenge: existing state-of-the-art methods achieve 90.6% I-AUROC in one-for-one settings but drop to 78.5% when scaling to all 380 categories in a multi-class setting. To address this, we propose Dinomaly-m, a context-guided Mixture-of-Experts extension of Dinomaly that expands decoder capacity without increasing inference cost. It achieves 83.2% I-AUROC and 93.1% P-AUROC, demonstrating superior performance over existing approaches. ADNet is designed as a standardized and extensible benchmark, supporting the community in expanding anomaly detection datasets across diverse domains and providing a scalable foundation for future anomaly detection foundation models. Dataset: https://grainnet.github.io/ADNet</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>