<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Iterative Diffusion-Refined Neural Attenuation Fields for Multi-Source Stationary CT Reconstruction: NAF Meets Diffusion Model - Health AI Hub</title>
    <meta name="description" content="This paper introduces Diffusion-Refined Neural Attenuation Fields (Diff-NAF), an iterative framework designed to overcome the challenges of ultra-sparse-view sa">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Iterative Diffusion-Refined Neural Attenuation Fields for Multi-Source Stationary CT Reconstruction: NAF Meets Diffusion Model</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.14310v1" target="_blank">2511.14310v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-18
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jiancheng Fang, Shaoyu Wang, Junlin Wang, Weiwen Wu, Yikun Zhang, Qiegen Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.14310v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.14310v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Diffusion-Refined Neural Attenuation Fields (Diff-NAF), an iterative framework designed to overcome the challenges of ultra-sparse-view sampling in multi-source stationary CT. By combining Neural Attenuation Fields with a dual-branch conditional diffusion model, Diff-NAF iteratively synthesizes and refines projections, progressively enhancing completeness and fidelity to achieve high-quality CT reconstructions from very limited data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging by enabling rapid, high-quality CT scans with significantly fewer projections, which can reduce radiation dose, mitigate motion artifacts, and improve diagnostic accuracy in time-sensitive clinical scenarios.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research proposes an AI-driven method (Diffusion-Refined Neural Attenuation Fields, utilizing neural networks and diffusion models) to enhance the quality of CT image reconstruction from ultra-sparse-view data. This application directly impacts health by potentially enabling faster, lower-dose, or more accurate CT scans for diagnosis and treatment planning in various clinical scenarios, especially where rapid imaging is critical.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of degraded CT reconstruction quality in multi-source stationary CT systems operating under ultra-sparse-view sampling conditions.</li>
                    
                    <li>Proposes Diff-NAF, an iterative framework that integrates a Neural Attenuation Field (NAF) representation with a dual-branch conditional diffusion model.</li>
                    
                    <li>The process initiates by training an initial NAF using the inherently limited ultra-sparse-view projections.</li>
                    
                    <li>Employs an 'Angle-Prior Guided Projection Synthesis' strategy to generate new projections, leveraging inter-view contextual information.</li>
                    
                    <li>Refines the synthesized projections using a 'Diffusion-driven Reuse Projection Refinement Module,' progressively improving their quality and completeness.</li>
                    
                    <li>Incorporates the refined projections as pseudo-labels into the training set for subsequent iterations, enabling iterative enhancement of projection and reconstruction fidelity.</li>
                    
                    <li>Achieves superior performance under ultra-sparse-view conditions, yielding the best reconstruction quality compared to traditional and contemporary methods on both simulated 3D CT volumes and real projection data.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The Diff-NAF framework operates iteratively. It starts by training an initial Neural Attenuation Field (NAF) using ultra-sparse-view projections. In each iteration, an 'Angle-Prior Guided Projection Synthesis' strategy generates new projections, which are then refined by a 'Diffusion-driven Reuse Projection Refinement Module' based on a dual-branch conditional diffusion model. These refined projections are subsequently incorporated as pseudo-labels into the training data for the next iteration, thereby progressively enhancing the NAF and ultimately the reconstructed CT image quality.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Diff-NAF demonstrated superior performance in reconstructing high-quality CT images from ultra-sparse-view projections, outperforming existing methods. It successfully enhances projection completeness and reconstruction fidelity through its iterative refinement process, validated across simulated 3D CT volumes and real projection data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology has the potential to significantly impact clinical practice by allowing for faster CT acquisitions, crucial for acute conditions like stroke or trauma. It could also reduce radiation exposure, benefiting pediatric patients and those requiring serial scans, while simultaneously improving diagnostic confidence by mitigating artifacts from patient motion during conventional longer scans.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed method or experimental setup.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Interventional Radiology</span>
                    
                    <span class="tag">Radiation Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">computed tomography</span>
                    
                    <span class="tag tag-keyword">CT reconstruction</span>
                    
                    <span class="tag tag-keyword">ultra-sparse-view</span>
                    
                    <span class="tag tag-keyword">neural attenuation fields</span>
                    
                    <span class="tag tag-keyword">diffusion models</span>
                    
                    <span class="tag tag-keyword">iterative reconstruction</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">image synthesis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multi-source stationary computed tomography (CT) has recently attracted attention for its ability to achieve rapid image reconstruction, making it suitable for time-sensitive clinical and industrial applications. However, practical systems are often constrained by ultra-sparse-view sampling, which significantly degrades reconstruction quality. Traditional methods struggle under ultra-sparse-view settings, where interpolation becomes inaccurate and the resulting reconstructions are unsatisfactory. To address this challenge, this study proposes Diffusion-Refined Neural Attenuation Fields (Diff-NAF), an iterative framework tailored for multi-source stationary CT under ultra-sparse-view conditions. Diff-NAF combines a Neural Attenuation Field representation with a dual-branch conditional diffusion model. The process begins by training an initial NAF using ultra-sparse-view projections. New projections are then generated through an Angle-Prior Guided Projection Synthesis strategy that exploits inter view priors, and are subsequently refined by a Diffusion-driven Reuse Projection Refinement Module. The refined projections are incorporated as pseudo-labels into the training set for the next iteration. Through iterative refinement, Diff-NAF progressively enhances projection completeness and reconstruction fidelity under ultra-sparse-view conditions, ultimately yielding high-quality CT reconstructions. Experimental results on multiple simulated 3D CT volumes and real projection data demonstrate that Diff-NAF achieves the best performance under ultra-sparse-view conditions.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>