<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>D-PerceptCT: Deep Perceptual Enhancement for Low-Dose CT Images - Health AI Hub</title>
    <meta name="description" content="D-PerceptCT is a novel deep learning architecture inspired by the Human Visual System (HVS) designed to enhance low-dose CT (LDCT) images. It addresses the comm">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>D-PerceptCT: Deep Perceptual Enhancement for Low-Dose CT Images</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.14518v1" target="_blank">2511.14518v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-18
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Taifour Yousra Nabila, Azeddine Beghdadi, Marie Luong, Zuheng Ming, Habib Zaidi, Faouzi Alaya Cheikh
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.14518v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.14518v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">D-PerceptCT is a novel deep learning architecture inspired by the Human Visual System (HVS) designed to enhance low-dose CT (LDCT) images. It addresses the common problem of critical detail loss in existing enhancement methods by focusing on perceptually relevant features, thereby providing radiologists with clearer images for improved diagnosis. The method demonstrated superior preservation of structural and textural information on the Mayo2016 dataset compared to state-of-the-art techniques.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly contributes to patient safety by enabling the use of lower radiation dose CT scans without compromising diagnostic image quality. It enhances the visibility of critical anatomical structures and subtle pathologies, potentially leading to more accurate and earlier diagnoses while reducing the risk of secondary cancer development from radiation exposure.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research proposes D-PerceptCT, a deep learning architecture for enhancing the perceptual quality of Low-Dose CT images. This AI application aims to provide radiologists with clearer images for improved diagnosis, effectively leveraging AI for medical image processing and quality improvement in a clinical setting.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Low-Dose CT (LDCT) images suffer from quality degradation due to reduced radiation dose, which can lead to loss of critical details and diagnostic challenges.</li>
                    
                    <li>Existing LDCT enhancement methods often over-smooth images and overestimate noise, resulting in the loss of crucial anatomical and pathological information.</li>
                    
                    <li>D-PerceptCT introduces a novel HVS-inspired deep learning architecture to specifically enhance perceptually relevant features in LDCT images.</li>
                    
                    <li>The architecture comprises a Visual Dual-path Extractor (ViDex) that integrates semantic priors from a pretrained DINOv2 model with local spatial features, and a Global-Local State-Space block to capture long-range and multiscale information.</li>
                    
                    <li>A novel Deep Perceptual Relevancy Loss Function (DPRLF), inspired by human contrast sensitivity, is proposed to further guide the model in emphasizing perceptually important details.</li>
                    
                    <li>The objective is to provide radiologists with CT images where critical anatomical structures and fine pathological details are more perceptually visible.</li>
                    
                    <li>Extensive experiments on the Mayo2016 dataset confirm D-PerceptCT's effectiveness, showing better preservation of structural and textural information in LDCT images compared to current state-of-the-art methods.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>D-PerceptCT is a deep learning architecture consisting of a Visual Dual-path Extractor (ViDex) that integrates semantic priors from a pretrained DINOv2 model with local spatial features, and a Global-Local State-Space block designed to capture long-range and multiscale information. It utilizes a novel Deep Perceptual Relevancy Loss Function (DPRLF) inspired by human contrast sensitivity to emphasize perceptually important features. The method's effectiveness was evaluated through extensive experiments on the Mayo2016 dataset.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>D-PerceptCT effectively enhances low-dose CT images, demonstrating superior preservation of both structural and textural information compared to existing state-of-the-art methods. The HVS-inspired design and novel perceptual loss function successfully guide the model to enhance and preserve perceptually relevant features crucial for diagnosis.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This method has the potential to significantly improve clinical practice by allowing for confident diagnoses from lower radiation dose CT scans, thereby reducing patient exposure to ionizing radiation and associated long-term health risks. It can lead to clearer visualization of subtle pathologies, aiding radiologists in making more accurate and timely diagnostic decisions, potentially impacting treatment planning and patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights the limitations of existing LDCT enhancement techniques (overestimation of noise, excessive smoothing, loss of critical details) which D-PerceptCT aims to overcome. However, it does not explicitly state specific limitations of the D-PerceptCT method itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future directions are not explicitly mentioned in the provided abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Medical Physics</span>
                    
                    <span class="tag">Image Processing in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Low-Dose CT</span>
                    
                    <span class="tag tag-keyword">Image Enhancement</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Perceptual Loss</span>
                    
                    <span class="tag tag-keyword">Human Visual System</span>
                    
                    <span class="tag tag-keyword">Radiology</span>
                    
                    <span class="tag tag-keyword">DINOv2</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Low Dose Computed Tomography (LDCT) is widely used as an imaging solution to aid diagnosis and other clinical tasks. However, this comes at the price of a deterioration in image quality due to the low dose of radiation used to reduce the risk of secondary cancer development. While some efficient methods have been proposed to enhance LDCT quality, many overestimate noise and perform excessive smoothing, leading to a loss of critical details. In this paper, we introduce D-PerceptCT, a novel architecture inspired by key principles of the Human Visual System (HVS) to enhance LDCT images. The objective is to guide the model to enhance or preserve perceptually relevant features, thereby providing radiologists with CT images where critical anatomical structures and fine pathological details are perceptu- ally visible. D-PerceptCT consists of two main blocks: 1) a Visual Dual-path Extractor (ViDex), which integrates semantic priors from a pretrained DINOv2 model with local spatial features, allowing the network to incorporate semantic-awareness during enhancement; (2) a Global-Local State-Space block that captures long-range information and multiscale features to preserve the important structures and fine details for diagnosis. In addition, we propose a novel deep perceptual loss, designated as the Deep Perceptual Relevancy Loss Function (DPRLF), which is inspired by human contrast sensitivity, to further emphasize perceptually important features. Extensive experiments on the Mayo2016 dataset demonstrate the effectiveness of D-PerceptCT method for LDCT enhancement, showing better preservation of structural and textural information within LDCT images compared to SOTA methods.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>