<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool - Health AI Hub</title>
    <meta name="description" content="This paper introduces a multi-agent Large Language Model (LLM) framework designed to automatically assess the performance of a clinical AI triage tool for intra">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26498v1" target="_blank">2510.26498v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Adam E. Flanders, Yifan Peng, Luciano Prevedello, Robyn Ball, Errol Colak, Prahlad Menon, George Shih, Hui-Ming Lin, Paras Lakhani
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26498v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26498v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a multi-agent Large Language Model (LLM) framework designed to automatically assess the performance of a clinical AI triage tool for intracranial hemorrhage (ICH) detection. The study demonstrated that an ensemble of LLMs provides a more consistent and reliable method for retrospective evaluation of clinical AI tools compared to using a single LLM alone, suggesting a scalable approach for AI performance validation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for the accelerated and automated validation of clinical AI diagnostic tools, allowing for more efficient assessment of their performance in real-world settings and potentially speeding up the deployment of safe and effective AI in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes using a multi-agent Large Language Model (LLM) framework to automatically evaluate the performance of a pixel-based AI triage tool. This AI triage tool itself is a medical AI application designed for detecting intracranial hemorrhage (ICH) in non-contrast CT head exams. Therefore, the LLM framework is an AI application for assessing and validating other AI applications in a clinical setting.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study aimed to determine if an ensemble of multiple LLM agents could offer a more reliable assessment of a pixel-based AI triage tool for ICH than a single LLM.</li>
                    
                    <li>A large dataset of 29,766 non-contrast CT head exams and their radiology reports from 14 hospitals was processed by a commercial ICH AI detection tool.</li>
                    
                    <li>An ensemble of eight open-source LLM models and a HIPAA-compliant internal GPT-4o analyzed radiology reports for ICH presence using a single multi-shot prompt.</li>
                    
                    <li>1,726 examples were manually reviewed, likely serving as a reference or validation set for comparison.</li>
                    
                    <li>Llama3.3:70b exhibited the highest individual F1 score (0.81), recall (0.85), precision (0.78), specificity (0.72), and MCC (0.57), while sharing the highest AUC (0.78) and Average Precision (0.75-0.76) with GPT-4o.</li>
                    
                    <li>Ensemble LLM configurations (Full-9, Top-3, Consensus) consistently outperformed a single GPT-4o in terms of MCC (0.571, 0.558, 0.556 vs. 0.522), indicating superior reliability in assessment.</li>
                    
                    <li>No statistically significant differences were found between the Top-3, Full-9, and Consensus ensemble configurations, suggesting robustness across different ensemble sizes.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized 29,766 non-contrast CT head exams and their radiology reports, which were processed by a commercial intracranial hemorrhage (ICH) AI detection tool. Radiology reports were then analyzed for ICH presence using a single multi-shot prompt by an ensemble of eight open-source LLM models and a HIPAA-compliant internal version of GPT-4o. A subset of 1,726 examples underwent manual review. Performance metrics (AUC, Average Precision, F1 score, recall, precision, specificity, MCC) of individual LLMs and three different consensus LLM ensembles (Full-9, Top-3, Consensus) were compared against GPT-4o to determine their reliability in assessing the AI triage tool.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The highest individual AUC (0.78) and Average Precision (0.75-0.76) were achieved by llama3.3:70b and GPT-4o. Llama3.3:70b demonstrated superior performance in F1 score (0.81), recall (0.85), precision (0.78), specificity (0.72), and MCC (0.57). Critically, ensemble LLM methods (Full-9 Ensemble MCC=0.571, Top-3 Ensemble MCC=0.558, Consensus MCC=0.556) consistently outperformed GPT-4o alone (MCC=0.522) in reliability metrics, with no statistically significant differences observed among the various ensemble configurations.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This multi-agent LLM framework offers a robust and scalable solution for automatically evaluating the performance of clinical AI tools, such as ICH triage systems. By streamlining the retrospective assessment of AI algorithms, it can reduce the manual burden on radiologists and clinicians, accelerate the development and validation cycles of medical AI, and potentially lead to quicker integration of more reliable and effective AI into routine clinical workflows, ultimately enhancing patient care and diagnostic efficiency.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Medical AI/Machine Learning</span>
                    
                    <span class="tag">Clinical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Model</span>
                    
                    <span class="tag tag-keyword">LLM Ensemble</span>
                    
                    <span class="tag tag-keyword">Clinical AI</span>
                    
                    <span class="tag tag-keyword">Intracranial Hemorrhage</span>
                    
                    <span class="tag tag-keyword">CT Head</span>
                    
                    <span class="tag tag-keyword">AI Triage</span>
                    
                    <span class="tag tag-keyword">Performance Assessment</span>
                    
                    <span class="tag tag-keyword">Ground Truth</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Purpose: The purpose of this study was to determine if an ensemble of
multiple LLM agents could be used collectively to provide a more reliable
assessment of a pixel-based AI triage tool than a single LLM.
  Methods: 29,766 non-contrast CT head exams from fourteen hospitals were
processed by a commercial intracranial hemorrhage (ICH) AI detection tool.
Radiology reports were analyzed by an ensemble of eight open-source LLM models
and a HIPAA compliant internal version of GPT-4o using a single multi-shot
prompt that assessed for presence of ICH. 1,726 examples were manually
reviewed. Performance characteristics of the eight open-source models and
consensus were compared to GPT-4o. Three ideal consensus LLM ensembles were
tested for rating the performance of the triage tool.
  Results: The cohort consisted of 29,766 head CTs exam-report pairs. The
highest AUC performance was achieved with llama3.3:70b and GPT-4o (AUC= 0.78).
The average precision was highest for Llama3.3:70b and GPT-4o (AP=0.75 & 0.76).
Llama3.3:70b had the highest F1 score (0.81) and recall (0.85), greater
precision (0.78), specificity (0.72), and MCC (0.57). Using MCC (95% CI) the
ideal combination of LLMs were: Full-9 Ensemble 0.571 (0.552-0.591), Top-3
Ensemble 0.558 (0.537-0.579), Consensus 0.556 (0.539-0.574), and GPT4o 0.522
(0.500-0.543). No statistically significant differences were observed between
Top-3, Full-9, and Consensus (p > 0.05).
  Conclusion: An ensemble of medium to large sized open-source LLMs provides a
more consistent and reliable method to derive a ground truth retrospective
evaluation of a clinical AI triage tool over a single LLM alone.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>29 pages, 3 figures, 4 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>