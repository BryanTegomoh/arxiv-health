<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology - Health AI Hub</title>
    <meta name="description" content="This paper introduces PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual search and decision-making processes of pathologists during ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24653v1" target="_blank">2510.24653v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Veronica Thai, Rui Li, Meng Ling, Shuning Jiang, Jeremy Wolfe, Raghu Machiraju, Yan Hu, Zaibo Li, Anil Parwani, Jian Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.HC, J.3
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24653v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24653v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual search and decision-making processes of pathologists during digital cancer diagnosis. It addresses the significant gap in behavioral data needed to understand diagnostic errors and inconsistencies, which contribute to the average 70% accuracy rate in pathology. The dataset aims to facilitate research into human diagnostic cognition and improve the training of both pathologists and AI diagnostic systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This dataset is critically important for advancing diagnostic accuracy in pathology by providing granular insights into the cognitive processes and potential failure points of human diagnosticians. It offers a unique foundation for developing evidence-based training programs and creating more effective, human-centered AI tools to assist in cancer diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The dataset is designed to train and improve AI systems that assist pathologists in interpreting whole-slide images for cancer diagnosis. This could involve AI systems that identify critical regions, suggest diagnoses, or help improve the consistency and accuracy of human experts in medical image analysis. It also provides data for developing AI-driven educational tools for pathologists.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Pathologists' diagnostic accuracy averages around 70%, with inconsistencies not substantially improved by a second opinion, indicating a need for better behavioral understanding.</li>
                    
                    <li>PathoGaze1.0 is a novel dataset providing Eye-tracking, Mouse interaction, Stimulus tracking, Viewport navigation, and Diagnostic decision (EMSVD) data.</li>
                    
                    <li>The dataset comprises 18.69 hours of recorded activity from 19 pathologists interpreting 397 giga-pixel whole-slide images (WSIs) for cancer diagnosis.</li>
                    
                    <li>It includes a vast amount of behavioral data: 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events.</li>
                    
                    <li>Data collection prioritized ecological validity through an application-grounded testbed called PTAH, simulating a real diagnostic workflow.</li>
                    
                    <li>The dataset's primary purpose is to enable research into the explanations for diagnostic errors and inconsistencies in digital pathology.</li>
                    
                    <li>It is also intended to serve as a resource for improving the training methodologies for both human pathologists and AI systems designed to support medical diagnosis.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved collecting comprehensive behavioral data (EMSVD: Eye-tracking, Mouse interaction, Stimulus tracking, Viewport navigation, Diagnostic decisions) from 19 board-certified pathologists. Participants interpreted 397 whole-slide images (WSIs) during a simulated cancer diagnosis workflow within an application-grounded testbed named PTAH, designed for ecological validity. The collection captured detailed visual search patterns (fixations, saccades) and user interactions (mouse events) throughout the diagnostic process.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The main 'finding' presented in the abstract is the successful creation, compilation, and public release of PathoGaze1.0, a uniquely comprehensive and ecologically valid behavioral dataset. This includes the demonstration of its substantial scale (18.69 hours of data, millions of events) and its capacity to capture the full diagnostic workflow, thereby addressing a critical gap in behavioral data for digital pathology research.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By providing granular behavioral data, PathoGaze1.0 can significantly impact clinical practice by enabling a deeper understanding of human diagnostic performance and errors in digital pathology. This could lead to more targeted and effective training programs for pathologists, potentially improving diagnostic accuracy and consistency. Furthermore, it offers a crucial resource for developing and validating AI diagnostic support systems that are better tailored to human cognitive processes, thereby enhancing the overall quality and efficiency of cancer diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the PathoGaze1.0 dataset itself or its collection methodology. However, inherent limitations in such a study could include the sample size of 19 pathologists and the specific set of 397 WSIs, which may not fully represent the diversity of all pathologists or all possible diagnostic challenges. The focus is primarily on the successful creation and availability of the dataset, rather than a detailed critique of its scope or potential biases.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The authors explicitly state that the dataset can be used to explain diagnostic errors and inconsistencies in digital pathology. Furthermore, it is intended to improve the training of both human pathologists (e.g., via skill acquisition studies, error analysis) and artificial intelligence systems designed to support human experts (e.g., for explainable AI, gaze-aware AI, or AI for workflow optimization).</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Anatomic Pathology</span>
                    
                    <span class="tag">Digital Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                    <span class="tag">Medical Education</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Digital pathology</span>
                    
                    <span class="tag tag-keyword">Eye-tracking</span>
                    
                    <span class="tag tag-keyword">Mouse tracking</span>
                    
                    <span class="tag tag-keyword">Whole-slide imaging</span>
                    
                    <span class="tag tag-keyword">Diagnostic errors</span>
                    
                    <span class="tag tag-keyword">Behavioral data</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">Cancer diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Interpretation of giga-pixel whole-slide images (WSIs) is an important but
difficult task for pathologists. Their diagnostic accuracy is estimated to
average around 70%. Adding a second pathologist does not substantially improve
decision consistency. The field lacks adequate behavioral data to explain
diagnostic errors and inconsistencies. To fill in this gap, we present
PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual
search and decision-making processes of the full diagnostic workflow during
cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse
interaction, stimulus tracking, viewport navigation, and diagnostic decision
data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data
collection process emphasizes ecological validity through an
application-grounded testbed, called PTAH. In total, we recorded 171,909
fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In
addition, such data could also be used to improve the training of both
pathologists and AI systems that might support human experts. All experiments
were preregistered at https://osf.io/hj9a7, and the complete dataset along with
analysis code is available at https://go.osu.edu/pathogaze.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>16 pages, 9 figures, submitted to Nature Scientific Data</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>