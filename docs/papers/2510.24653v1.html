<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology - Health AI Hub</title>
    <meta name="description" content="This paper introduces PathoGaze1.0, a novel and comprehensive behavioral dataset designed to analyze and understand diagnostic errors and inconsistencies in dig">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24653v1" target="_blank">2510.24653v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Veronica Thai, Rui Li, Meng Ling, Shuning Jiang, Jeremy Wolfe, Raghu Machiraju, Yan Hu, Zaibo Li, Anil Parwani, Jian Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.HC, J.3
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24653v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24653v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces PathoGaze1.0, a novel and comprehensive behavioral dataset designed to analyze and understand diagnostic errors and inconsistencies in digital pathology. It captures dynamic visual search and decision-making processes from pathologists interpreting giga-pixel whole-slide images (WSIs) during cancer diagnosis, aiming to improve human training and AI system development.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically important for medicine as it directly addresses the challenge of suboptimal and inconsistent diagnostic accuracy in pathology, particularly in cancer diagnosis using digital WSIs. By providing a rich behavioral dataset, it enables a deeper understanding of human diagnostic processes, which is essential for developing effective interventions to reduce errors and enhance patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The collected eye-tracking, mouse interaction, and decision-making data from pathologists can be used to train, validate, and improve AI systems designed to assist or automate aspects of digital pathology, particularly for cancer diagnosis. This could involve developing AI models that identify diagnostic patterns, predict diagnoses, provide decision support, explain diagnostic reasoning, or enhance the training of human pathologists by mimicking expert visual search strategies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Pathologists' diagnostic accuracy averages approximately 70%, with a lack of behavioral data to explain errors and inconsistencies, even with a second opinion.</li>
                    
                    <li>PathoGaze1.0 is an ecologically valid dataset comprising 18.69 hours of Eye-tracking, Mouse interaction, Stimulus tracking, Viewport navigation, and Diagnostic decision data (EMSVD).</li>
                    
                    <li>The dataset was collected from 19 pathologists interpreting 397 Whole-Slide Images (WSIs) as part of a cancer diagnosis workflow.</li>
                    
                    <li>Data collection utilized an application-grounded testbed, PTAH, to ensure high ecological validity for the diagnostic workflow simulation.</li>
                    
                    <li>Quantitatively, the dataset includes 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events.</li>
                    
                    <li>The dataset is intended to facilitate research into the cognitive mechanisms underlying diagnostic errors and inconsistencies in digital pathology.</li>
                    
                    <li>The collected behavioral data is posited to be valuable for improving training programs for both human pathologists and AI systems designed to support diagnostic workflows.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved collecting comprehensive behavioral data from 19 pathologists interpreting 397 giga-pixel Whole-Slide Images (WSIs) for cancer diagnosis. The data captured included eye-tracking, mouse interaction, stimulus tracking, viewport navigation, and diagnostic decisions (EMSVD). Data collection was conducted within an application-grounded testbed called PTAH, emphasizing ecological validity for the diagnostic workflow.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful creation and extensive quantification of PathoGaze1.0, a novel behavioral dataset. This dataset provides 18.69 hours of detailed interaction data, recording 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events across 397 WSI interpretations, establishing a rich resource for understanding diagnostic processes.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This dataset has significant potential for clinical impact by enabling the development of evidence-based training for pathologists, leading to improved diagnostic accuracy and consistency. It can also serve as a foundational resource for training and validating AI systems, allowing them to better understand and support human experts, ultimately contributing to more reliable and efficient cancer diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the PathoGaze1.0 dataset or its collection methodology.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The authors suggest that the dataset can be used to improve the training of both pathologists and AI systems designed to support human experts. Future research could focus on analyzing the captured behavioral data to identify specific patterns associated with diagnostic accuracy or errors, and leveraging this data to develop and validate novel AI algorithms for diagnostic assistance and educational tools.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                    <span class="tag">Medical Education</span>
                    
                    <span class="tag">Artificial Intelligence in Healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Digital pathology</span>
                    
                    <span class="tag tag-keyword">Whole-slide imaging</span>
                    
                    <span class="tag tag-keyword">Eye-tracking</span>
                    
                    <span class="tag tag-keyword">Mouse tracking</span>
                    
                    <span class="tag tag-keyword">Diagnostic decision-making</span>
                    
                    <span class="tag tag-keyword">Behavioral data</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">Cancer diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Interpretation of giga-pixel whole-slide images (WSIs) is an important but
difficult task for pathologists. Their diagnostic accuracy is estimated to
average around 70%. Adding a second pathologist does not substantially improve
decision consistency. The field lacks adequate behavioral data to explain
diagnostic errors and inconsistencies. To fill in this gap, we present
PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual
search and decision-making processes of the full diagnostic workflow during
cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse
interaction, stimulus tracking, viewport navigation, and diagnostic decision
data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data
collection process emphasizes ecological validity through an
application-grounded testbed, called PTAH. In total, we recorded 171,909
fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In
addition, such data could also be used to improve the training of both
pathologists and AI systems that might support human experts. All experiments
were preregistered at https://osf.io/hj9a7, and the complete dataset along with
analysis code is available at https://go.osu.edu/pathogaze.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>16 pages, 9 figures, submitted to Nature Scientific Data</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>