<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI summaries in online search influence users' attitudes - Health AI Hub</title>
    <meta name="description" content="This study, a preregistered randomized controlled experiment (N=2,004), investigated how AI-generated summaries in online search results influence users' attitu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>AI summaries in online search influence users' attitudes</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.22809v1" target="_blank">2511.22809v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-27
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yiwei Xu, Saloni Dash, Sungha Kang, Wang Liao, Emma S. Spiro
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.HC, cs.AI, cs.CY
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.80 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.22809v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.22809v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study, a preregistered randomized controlled experiment (N=2,004), investigated how AI-generated summaries in online search results influence users' attitudes, behavioral intentions, and policy support across debated topics. It found that these summaries consistently shift user perceptions to align with the summary's stance, with top placement causing stronger attitudinal shifts and harm-framed summaries being perceived as more useful.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine and health as it demonstrates how AI-generated information in online searches can significantly influence public attitudes, behavioral intentions, and policy support concerning health topics. This directly impacts patient education, health literacy, and the effectiveness of public health initiatives, especially given the observed differential impact of 'harm-framed' information.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This paper does not describe a direct medical AI application (e.g., diagnostic AI). Instead, it analyzes the societal and public health implications of general AI applications (AI-generated search summaries) on how users consume and perceive health-related information. It is crucial for understanding the impact of AI on public understanding of health topics, patient education, and the responsible design of AI systems that interact with health information.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A preregistered randomized controlled experiment involving 2,004 participants was conducted using mock search pages.</li>
                    
                    <li>Variables manipulated included the presence, placement (top vs. middle), and stance (benefit-framed vs. harm-framed) of AI summaries across four public debate topics.</li>
                    
                    <li>AI-generated summaries significantly shifted participants' issue attitudes, behavioral intentions, and policy support to align with the summary's presented stance, compared to a no-summary control.</li>
                    
                    <li>Summaries placed at the top of the search page produced stronger shifts in users' issue attitudes than those placed in the middle, though this effect did not extend to behavioral intentions or policy support.</li>
                    
                    <li>The influence of AI summaries was moderated by participants' issue familiarity and their general trust towards AI.</li>
                    
                    <li>Users perceived AI summaries emphasizing health harms as more useful than those emphasizing health benefits.</li>
                    
                    <li>These findings highlight the significant power of AI-generated summaries in shaping public perceptions, with implications for the design and regulation of AI information ecosystems.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>A preregistered randomized controlled experiment was conducted with 2,004 participants. Participants viewed mock online search result pages where the presence (vs. absence), placement (top vs. middle), and framing stance (benefit-framed vs. harm-framed) of AI-generated summaries were systematically varied across four publicly debated topics. Outcome measures included self-reported issue attitudes, behavioral intentions, and policy support.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>['Participants exposed to AI-generated summaries reported issue attitudes, behavioral intentions, and policy support that aligned more closely with the AI summary stance, compared to a no-summary control group.', "AI summaries placed at the top of the search page produced stronger shifts in users' issue attitudes than those placed in the middle of the page, though this effect was not observed for behavioral intentions or policy support.", "The influence of AI summaries was moderated by participants' issue familiarity with the topic and their general trust toward AI.", 'Users perceived AI summaries as more useful when the summary emphasized health harms compared to when it emphasized health benefits.']</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This study has several potential clinical and practical impacts:
*   **Patient Engagement & Adherence**: AI summaries can shape patient perceptions of treatments, health risks, and preventive measures, potentially influencing adherence to medical advice or participation in health programs.
*   **Informed Consent & Shared Decision-Making**: Healthcare providers need to recognize that patients may arrive with pre-formed biases or specific framings of health issues derived from AI summaries, necessitating more deliberate communication to ensure truly informed consent.
*   **Public Health Strategies**: Public health campaigns disseminating information on vaccines, disease prevention, or lifestyle changes must strategically counter or leverage AI summary dynamics to ensure factual and balanced information uptake.
*   **Digital Health Tool Design**: Developers of health-related AI tools and information platforms must prioritize ethical summary generation and presentation to avoid unintended persuasive effects that could misguide users on critical health choices.
*   **Misinformation Management**: Understanding how AI summaries exert influence, particularly regarding perceived harms, can inform strategies to combat health misinformation spread through search engines and AI-integrated systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly detail specific limitations of the study. Potential implicit limitations might include the reliance on self-reported measures, the use of mock search pages rather than real-world environments, and the generalizability of findings across all demographics or health literacy levels.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The study raises important implications for the design and regulation of AI-integrated information ecosystems. Future research could explore optimal summary design strategies to mitigate unwanted persuasive effects, investigate the long-term impact of AI summaries on health behaviors, and examine how regulatory frameworks can ensure responsible deployment of AI in health-related information dissemination. Further studies could also explore the effects across diverse user demographics and varying levels of health literacy.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Health Communication</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Patient Education</span>
                    
                    <span class="tag">Health Policy</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">AI summaries</span>
                    
                    <span class="tag tag-keyword">online search</span>
                    
                    <span class="tag tag-keyword">user attitudes</span>
                    
                    <span class="tag tag-keyword">information influence</span>
                    
                    <span class="tag tag-keyword">health communication</span>
                    
                    <span class="tag tag-keyword">public perception</span>
                    
                    <span class="tag tag-keyword">AI ethics</span>
                    
                    <span class="tag tag-keyword">human-computer interaction</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This study examined how AI-generated summaries, which have become visually prominent in online search results, affect how users think about different issues. In a preregistered randomized controlled experiment, participants (N = 2,004) viewed mock search result pages varying in the presence (vs. absence), placement (top vs. middle), and stance (benefit-framed vs. harm-framed) of AI-generated summaries across four publicly debated topics. Compared to a no-summary control group, participants exposed to AI-generated summaries reported issue attitudes, behavioral intentions, and policy support that aligned more closely with the AI summary stance. The summaries placed at the top of the page produced stronger shifts in users' issue attitudes (but not behavioral intentions or policy support) than those placed at the middle of the page. We also observed moderating effects from issue familiarity and general trust toward AI. In addition, users perceived the AI summaries more useful when it emphasized health harms versus benefits. These findings suggest that AI-generated search summaries can significantly shape public perceptions, raising important implications for the design and regulation of AI-integrated information ecosystems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>