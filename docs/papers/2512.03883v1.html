<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Dual Cross-Attention Siamese Swin Transformer (SSDCA) for objective and early detection of local tumor regrowth in rectal cancer patie">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.03883v1" target="_blank">2512.03883v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jorge Tapias Gomez, Despoina Kanata, Aneesh Rangnekar, Christina Lee, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.03883v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.03883v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Dual Cross-Attention Siamese Swin Transformer (SSDCA) for objective and early detection of local tumor regrowth in rectal cancer patients undergoing watch-and-wait surveillance using longitudinal endoscopy images. SSDCA effectively distinguishes local regrowth from complete clinical response by leveraging pretrained Swin transformers and a novel dual cross-attention mechanism to fuse features from two endoscopic scans without spatial alignment, achieving high balanced accuracy, sensitivity, and robustness to image artifacts.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a vital non-invasive tool for the early and objective detection of rectal tumor regrowth, which is paramount for guiding treatment decisions in watch-and-wait patients. Early and accurate identification of regrowth can prevent distant metastases and allow timely intervention, improving patient outcomes and potentially avoiding unnecessary radical surgery for those with sustained complete responses.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is a Dual Cross-Attention Siamese Transformer (SSDCA) designed to automatically assess rectal tumor regrowth from longitudinal endoscopic images. Its purpose is to assist clinicians in accurately distinguishing between a clinical complete response and local tumor regrowth in watch-and-wait rectal cancer patients, thereby improving surveillance strategies and patient management.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical need for objectively accurate methods to early detect local regrowth (LR) in rectal cancer patients on a watch-and-wait (WW) protocol, distinguishing it from clinical complete response (cCR).</li>
                    
                    <li>Proposes a novel deep learning architecture: Siamese Swin Transformer with Dual Cross-Attention (SSDCA) for analyzing longitudinal endoscopic image pairs (restaging and follow-up).</li>
                    
                    <li>SSDCA leverages pretrained Swin transformers for robust, domain-agnostic feature extraction, enhancing generalizability despite imaging variations.</li>
                    
                    <li>Employs a dual cross-attention mechanism to emphasize features from the two endoscopic scans, crucially without requiring any spatial alignment of images.</li>
                    
                    <li>Trained on image pairs from 135 patients and evaluated on a held-out set of 62 patients, SSDCA outperformed Swin-based baselines.</li>
                    
                    <li>Achieved a balanced accuracy of 81.76% ¬± 0.04, sensitivity of 90.07% ¬± 0.08 (for LR), and specificity of 72.86% ¬± 0.05 (for cCR).</li>
                    
                    <li>Demonstrated robust performance against common endoscopic artifacts including blood, stool, telangiectasia, and poor image quality.</li>
                    
                    <li>UMAP clustering confirmed discriminative representation learning with maximal inter-cluster separation (1.45 ¬± 0.18) and minimal intra-cluster dispersion (1.07 ¬± 0.19).</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA). This model utilizes two branches, each with a pretrained Swin Transformer, to extract features from longitudinal endoscopic image pairs (restaging and follow-up). A dual cross-attention mechanism is then applied to integrate and emphasize features from both scans, specifically designed to function without requiring explicit spatial alignment of the images. The model was trained on image pairs from 135 patients and evaluated on a distinct held-out dataset comprising image pairs from 62 patients. Performance metrics included balanced accuracy, sensitivity, specificity, and robustness analysis against artifacts. UMAP clustering was used to assess the discriminative quality of the learned feature representations.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SSDCA achieved superior performance over baseline models with a balanced accuracy of 81.76% ¬± 0.04, sensitivity of 90.07% ¬± 0.08 (for local regrowth detection), and specificity of 72.86% ¬± 0.05 (for complete clinical response). The model exhibited strong robustness to various endoscopic artifacts. Furthermore, UMAP clustering of the extracted features confirmed highly discriminative representation learning, showing maximal inter-cluster separation (1.45 ¬± 0.18) and minimal intra-cluster dispersion (1.07 ¬± 0.19) for distinguishing between cCR and LR.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The SSDCA model has the potential to significantly improve the precision and timeliness of care for rectal cancer patients managed with a watch-and-wait approach. By providing an objective and highly accurate method for early detection of local regrowth from routine endoscopy, it can empower clinicians to make more informed decisions, prevent disease progression, tailor treatment strategies, and potentially spare patients from unnecessary invasive procedures, thereby enhancing patient safety and quality of life.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Gastroenterology</span>
                    
                    <span class="tag">Colorectal Surgery</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical Artificial Intelligence</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Rectal Cancer</span>
                    
                    <span class="tag tag-keyword">Watch-and-Wait</span>
                    
                    <span class="tag tag-keyword">Tumor Regrowth</span>
                    
                    <span class="tag tag-keyword">Endoscopy</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Siamese Transformer</span>
                    
                    <span class="tag tag-keyword">Cross-Attention</span>
                    
                    <span class="tag tag-keyword">Clinical Complete Response</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Artificial Intelligence</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>6 pages, 5 figures, 1 table, submitted to ISBI conference</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>