<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Dual Cross-Attention Siamese Transformer (SSDCA), a novel deep learning model designed for the early and objective detection of local ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.03883v1" target="_blank">2512.03883v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jorge Tapias Gomez, Despoina Kanata, Aneesh Rangnekar, Christina Lee, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.03883v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.03883v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Dual Cross-Attention Siamese Transformer (SSDCA), a novel deep learning model designed for the early and objective detection of local tumor regrowth in rectal cancer patients undergoing watch-and-wait surveillance. By analyzing longitudinal endoscopic images from restaging and follow-up, SSDCA accurately distinguishes clinical complete response from local regrowth, achieving high sensitivity and robustness to imaging variations.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly medically relevant as it provides an objectively accurate and robust method for the early detection of local tumor regrowth in rectal cancer patients undergoing watch-and-wait surveillance. This is critical for optimizing patient management, enabling timely intervention to prevent disease progression, and ultimately improving outcomes by averting distant metastases.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI system (SSDCA) is developed to serve as an objective, automated tool for assessing rectal tumor regrowth from follow-up endoscopic images. This application assists clinicians in the 'watch-and-wait' strategy for rectal cancer patients by providing an early and accurate method to detect local recurrence, thereby guiding clinical decisions, managing patient care, and potentially preventing distant metastases.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The SSDCA model utilizes a Siamese Swin Transformer architecture enhanced with Dual Cross-Attention to process pairs of longitudinal endoscopic images.</li>
                    
                    <li>Its primary objective is to differentiate between clinical complete response (cCR) and local tumor regrowth (LR) in rectal cancer patients adhering to a watch-and-wait (WW) protocol after total neoadjuvant treatment (TNT).</li>
                    
                    <li>The model leverages pretrained Swin Transformers to extract robust, domain-agnostic features and employs dual cross-attention to emphasize relevant features from both scans without requiring explicit spatial alignment.</li>
                    
                    <li>SSDCA demonstrated superior performance, achieving the best balanced accuracy (81.76% ¬± 0.04), sensitivity (90.07% ¬± 0.08), and specificity (72.86% ¬± 0.05) compared to Swin-based baselines.</li>
                    
                    <li>A robustness analysis confirmed the model's stable performance even in the presence of common endoscopic artifacts such as blood, stool, telangiectasia, and poor image quality.</li>
                    
                    <li>UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 ¬± 0.18) and minimal intra-cluster dispersion (1.07 ¬± 0.19) with SSDCA, indicating highly discriminative representation learning.</li>
                    
                    <li>The model was trained on image pairs from 135 patients and rigorously evaluated on a held-out set of image pairs from 62 patients.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involved developing a Siamese Swin Transformer with Dual Cross-Attention (SSDCA). This architecture uses pretrained Swin Transformers to extract robust, domain-agnostic features from longitudinal endoscopic image pairs (restaging and follow-up). Dual cross-attention then processes these features, emphasizing crucial information across the two scans without requiring explicit spatial alignment. The model was trained on image pairs from 135 patients and evaluated on a held-out set of 62 patients, comparing its performance against Swin-based baselines. Robustness to image artifacts and discriminative feature learning via UMAP clustering were also assessed.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The SSDCA model achieved superior performance metrics, including a balanced accuracy of 81.76% (¬± 0.04), sensitivity of 90.07% (¬± 0.08), and specificity of 72.86% (¬± 0.05). It demonstrated robust and stable performance across endoscopic images containing various artifacts like blood, stool, telangiectasia, and poor image quality. UMAP clustering analysis confirmed the model's ability to learn highly discriminative representations, showing optimal inter-cluster separation (1.45 ¬± 0.18) and minimal intra-cluster dispersion (1.07 ¬± 0.19) between response categories.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The SSDCA model has the potential to significantly improve clinical decision-making during rectal cancer watch-and-wait surveillance by providing an objective and accurate tool for early detection of local tumor regrowth. This can lead to more personalized treatment pathways, allowing for earlier and more targeted interventions for patients with recurrence, thereby potentially preventing metastatic disease and enhancing overall patient survival and quality of life.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Limitations are not explicitly mentioned in the provided abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research directions are not explicitly mentioned in the provided abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Gastroenterology</span>
                    
                    <span class="tag">Colorectal Surgery</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Rectal Cancer</span>
                    
                    <span class="tag tag-keyword">Watch-and-Wait</span>
                    
                    <span class="tag tag-keyword">Tumor Regrowth</span>
                    
                    <span class="tag tag-keyword">Endoscopy</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Swin Transformer</span>
                    
                    <span class="tag tag-keyword">Cross-Attention</span>
                    
                    <span class="tag tag-keyword">Clinical Complete Response</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>6 pages, 5 figures, 1 table, submitted to ISBI conference</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>