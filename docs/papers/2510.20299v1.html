<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability - Health AI Hub</title>
    <meta name="description" content="This paper introduces DB-FGA-Net, a novel dual-backbone deep learning architecture combining VGG16 and Xception with a Frequency-Gated Attention Block for highl">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20299v1" target="_blank">2510.20299v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Saraf Anzum Shreya, MD. Abu Ismail Siddique, Sharaf Tasnim
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20299v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20299v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces DB-FGA-Net, a novel dual-backbone deep learning architecture combining VGG16 and Xception with a Frequency-Gated Attention Block for highly accurate and interpretable multi-class brain tumor classification. Notably, the model achieves state-of-the-art performance without data augmentation, demonstrating robustness, and integrates Grad-CAM for visual interpretability of tumor regions. A graphical user interface (GUI) is also developed to facilitate real-time clinical usability.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Early and precise diagnosis of brain tumors is critical for effective treatment in neuro-oncology. This model offers an augmentation-free, highly accurate, and interpretable solution, which is crucial for building trust and facilitating clinical adoption of AI in a high-stakes diagnostic area.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is a deep learning model (DB-FGA-Net) designed for multi-class classification of brain tumors from medical images. It aims to provide accurate, interpretable, and deployable tools for clinicians to improve early and precise brain tumor diagnosis, thereby enhancing patient care and treatment planning. The integration of Grad-CAM offers visual interpretability of tumor regions, bridging the gap between AI prediction and clinical understanding.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>DB-FGA-Net is a dual-backbone network architecture, integrating VGG16 and Xception models to capture complementary local and global image features.</li>
                    
                    <li>It incorporates a novel Frequency-Gated Attention (FGA) Block, which likely aids in focusing on relevant frequency components for feature extraction.</li>
                    
                    <li>The model achieves state-of-the-art classification performance for brain tumors *without* the use of data augmentation, indicating inherent robustness and better generalization.</li>
                    
                    <li>Grad-CAM is integrated for interpretability, allowing visualization of tumor regions the model uses for prediction, bridging the gap between AI output and clinical understanding.</li>
                    
                    <li>Achieved impressive accuracies: 99.24% for 4-class, 98.68% for 3-class, and 99.85% for 2-class classification on the 7K-DS dataset.</li>
                    
                    <li>Demonstrated strong generalization with 95.77% accuracy on an independent 3K-DS dataset, outperforming existing baseline and state-of-the-art methods.</li>
                    
                    <li>A graphical user interface (GUI) was developed to provide real-time classification and Grad-CAM based tumor localization, supporting practical clinical deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes DB-FGA-Net, a double-backbone neural network architecture. It combines VGG16 and Xception models to leverage their distinct feature extraction capabilities (local vs. global). A custom Frequency-Gated Attention (FGA) Block is integrated to enhance feature relevance. Grad-CAM (Gradient-weighted Class Activation Mapping) is employed to generate visual explanations of the model's predictions. The model's performance was evaluated on the 7K-DS dataset (for 4-, 3-, and 2-class settings) and an independent 3K-DS dataset for generalization assessment.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DB-FGA-Net achieved 99.24% accuracy for 4-class brain tumor classification on the 7K-DS dataset, with 98.68% and 99.85% for 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, it generalized effectively with 95.77% accuracy, outperforming existing methods. A key finding is its ability to achieve state-of-the-art performance without relying on heavy data augmentation, indicating enhanced robustness and generalization.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This model offers a significant step towards reliable AI-assisted brain tumor diagnosis. Its high accuracy, robustness without data augmentation (implying less sensitivity to dataset variations), and crucial interpretability via Grad-CAM can increase clinician trust and adoption. The developed real-time GUI makes the technology readily deployable, providing a practical tool for quick and verifiable classification and tumor localization, potentially aiding in faster and more accurate diagnostic decisions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights that a common limitation of previous deep learning-based brain tumor classification methods is their reliance on heavy data augmentation, which can restrict generalization and clinical trust. DB-FGA-Net explicitly addresses and overcomes this limitation by achieving robust performance without such augmentation, thus implying the lack of this common limitation rather than presenting new ones for the proposed method itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The findings suggest a strong potential for reliable clinical translation of augmentation-free, interpretable, and deployable deep learning models like DB-FGA-Net in brain tumor diagnosis. This implies future work will focus on further clinical validation, real-world deployment, and integration into existing clinical workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neuro-oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging Diagnostics</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Brain Tumor Classification</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Multi-Class Classification</span>
                    
                    <span class="tag tag-keyword">Frequency-Gated Attention</span>
                    
                    <span class="tag tag-keyword">Grad-CAM</span>
                    
                    <span class="tag tag-keyword">Neuro-oncology</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Interpretability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Brain tumors are a challenging problem in neuro-oncology, where early and
precise diagnosis is important for successful treatment. Deep learning-based
brain tumor classification methods often rely on heavy data augmentation which
can limit generalization and trust in clinical applications. In this paper, we
propose a double-backbone network integrating VGG16 and Xception with a
Frequency-Gated Attention (FGA) Block to capture complementary local and global
features. Unlike previous studies, our model achieves state-of-the-art
performance without augmentation which demonstrates robustness to variably
sized and distributed datasets. For further transparency, Grad-CAM is
integrated to visualize the tumor regions based on which the model is giving
prediction, bridging the gap between model prediction and clinical
interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS
dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class
and 2-class settings, respectively. On the independent 3K-DS dataset, the model
generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art
methods. To further support clinical usability, we developed a graphical user
interface (GUI) that provides real-time classification and Grad-CAM-based tumor
localization. These findings suggest that augmentation-free, interpretable, and
deployable deep learning models such as DB-FGA-Net hold strong potential for
reliable clinical translation in brain tumor diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>25 pages, 14 figures, 12 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>