<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability - Health AI Hub</title>
    <meta name="description" content="DB-FGA-Net is a novel deep learning model for multi-class brain tumor classification that integrates VGG16 and Xception backbones with a Frequency-Gated Attenti">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">← Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20299v1" target="_blank">2510.20299v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Saraf Anzum Shreya, MD. Abu Ismail Siddique, Sharaf Tasnim
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20299v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20299v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DB-FGA-Net is a novel deep learning model for multi-class brain tumor classification that integrates VGG16 and Xception backbones with a Frequency-Gated Attention (FGA) Block. It achieves state-of-the-art accuracy across multiple classification settings (up to 99.85% for 2-class) without requiring data augmentation, enhancing robustness and generalization. The model also incorporates Grad-CAM for interpretability and a GUI for real-time clinical deployment.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research directly addresses the critical need for early and precise brain tumor diagnosis by offering a highly accurate, robust, and interpretable deep learning solution. Its augmentation-free nature and visual interpretability enhance trust and practical utility in clinical settings, potentially improving patient outcomes through more reliable and explainable diagnoses.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automated classification and localization of brain tumors from medical images (implied, likely MRI/CT) to assist in early and precise diagnosis. The model aims to provide an interpretable and deployable tool for clinicians to improve diagnostic accuracy and efficiency in neuro-oncology.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Novel Dual-Backbone Architecture**: DB-FGA-Net utilizes a double-backbone structure combining VGG16 and Xception networks, enhanced with a Frequency-Gated Attention (FGA) Block, to capture complementary local and global image features.</li>
                    
                    <li>**Augmentation-Free State-of-the-Art Performance**: Achieves top-tier accuracy (e.g., 99.24% for 4-class, 99.85% for 2-class) without relying on heavy data augmentation, demonstrating superior robustness to varied datasets and improved generalization capabilities.</li>
                    
                    <li>**Grad-CAM Interpretability**: Integrates Grad-CAM to visually highlight the specific tumor regions that influence the model's predictions, providing crucial transparency and bridging the gap for clinical understanding and trust.</li>
                    
                    <li>**High Accuracy Across Classification Settings**: Achieved 99.24% accuracy on the 7K-DS dataset for 4-class classification, 98.68% for 3-class, and 99.85% for 2-class settings.</li>
                    
                    <li>**Strong Generalization**: Demonstrated effective generalization with 95.77% accuracy on the independent 3K-DS dataset, outperforming baseline and existing state-of-the-art methods.</li>
                    
                    <li>**Clinical Deployability**: A graphical user interface (GUI) has been developed, enabling real-time classification and Grad-CAM-based tumor localization, facilitating practical clinical integration.</li>
                    
                    <li>**Enhanced Clinical Trust**: By providing an augmentation-free, robust, and interpretable deep learning model, the research addresses key limitations in clinical translation, aiming for more reliable diagnostic tools.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed DB-FGA-Net is a deep learning architecture featuring a dual-backbone system, integrating VGG16 and Xception networks to extract diverse local and global features. A custom Frequency-Gated Attention (FGA) Block is incorporated to enhance feature fusion and selection. Crucially, the model is designed to achieve high performance without relying on extensive data augmentation. For interpretability, Grad-CAM (Gradient-weighted Class Activation Mapping) is integrated to visually highlight the specific image regions driving the model's predictions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>DB-FGA-Net demonstrated state-of-the-art performance on the 7K-DS dataset, achieving 99.24% accuracy for 4-class, 98.68% for 3-class, and 99.85% for 2-class brain tumor classification. These high accuracies were obtained without data augmentation, showcasing superior robustness. On the independent 3K-DS dataset, the model generalized effectively with 95.77% accuracy, outperforming existing baseline and state-of-the-art methods. The integrated Grad-CAM successfully visualizes critical tumor regions, providing transparent interpretability for model predictions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The DB-FGA-Net offers significant clinical impact by providing a highly accurate, robust, and interpretable tool for brain tumor diagnosis. Its augmentation-free nature mitigates concerns about data variability, while Grad-CAM visualization enhances clinical trust by explaining prediction rationale. The developed graphical user interface (GUI) enables real-time classification and tumor localization, making the technology user-friendly and potentially deployable for neuro-oncologists and radiologists, leading to earlier and more precise treatment decisions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed DB-FGA-Net.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state specific future research directions, beyond the overall goal of achieving 'reliable clinical translation' for augmentation-free, interpretable, and deployable deep learning models in brain tumor diagnosis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neuro-oncology</span>
                    
                    <span class="tag">Diagnostic Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">brain tumor classification</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">DB-FGA-Net</span>
                    
                    <span class="tag tag-keyword">Grad-CAM</span>
                    
                    <span class="tag tag-keyword">interpretable AI</span>
                    
                    <span class="tag tag-keyword">multi-class classification</span>
                    
                    <span class="tag tag-keyword">VGG16</span>
                    
                    <span class="tag tag-keyword">Xception</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Brain tumors are a challenging problem in neuro-oncology, where early and
precise diagnosis is important for successful treatment. Deep learning-based
brain tumor classification methods often rely on heavy data augmentation which
can limit generalization and trust in clinical applications. In this paper, we
propose a double-backbone network integrating VGG16 and Xception with a
Frequency-Gated Attention (FGA) Block to capture complementary local and global
features. Unlike previous studies, our model achieves state-of-the-art
performance without augmentation which demonstrates robustness to variably
sized and distributed datasets. For further transparency, Grad-CAM is
integrated to visualize the tumor regions based on which the model is giving
prediction, bridging the gap between model prediction and clinical
interpretability. The proposed framework achieves 99.24\% accuracy on the 7K-DS
dataset for the 4-class setting, along with 98.68\% and 99.85\% in the 3-class
and 2-class settings, respectively. On the independent 3K-DS dataset, the model
generalizes with 95.77\% accuracy, outperforming baseline and state-of-the-art
methods. To further support clinical usability, we developed a graphical user
interface (GUI) that provides real-time classification and Grad-CAM-based tumor
localization. These findings suggest that augmentation-free, interpretable, and
deployable deep learning models such as DB-FGA-Net hold strong potential for
reliable clinical translation in brain tumor diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>25 pages, 14 figures, 12 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">← Back to all papers</a></p>
    </footer>
</body>
</html>