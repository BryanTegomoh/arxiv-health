<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces `eval`, a framework to assess the robustness of procedures designed to mitigate the dual-use risks of open-weight bio-foundation models. I">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27629v2" target="_blank">2510.27629v2</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Boyi Wei, Zora Che, Nathaniel Li, Udari Madhushani Sehwag, Jasper G√∂tting, Samira Nedungadi, Julian Michael, Summer Yue, Dan Hendrycks, Peter Henderson, Zifan Wang, Seth Donoughe, Mantas Mazeika
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CR, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27629v2" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27629v2" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces `eval`, a framework to assess the robustness of procedures designed to mitigate the dual-use risks of open-weight bio-foundation models. It finds that current data filtering methods are insufficient, as malicious knowledge can be recovered and generalized through fine-tuning, and dangerous capabilities may already be present in pre-trained models. The research highlights the critical need for more robust safety strategies beyond data filtering for these powerful AI models.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critical for ensuring the safe and ethical development of AI in drug discovery and accelerating biological research, directly impacting public health by addressing the potential for AI-enabled bioweapon development and enhancing biosecurity against infectious threats.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper focuses on AI bio-foundation models. Their applications to health include accelerating drug discovery and development, understanding pathogen characteristics (e.g., virulence, mutational impact), and critically, developing AI-driven risk assessment and mitigation strategies for biological threats to enhance global health security.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Open-weight bio-foundation models pose a dual-use dilemma, offering benefits for accelerating scientific research and drug development but also potential for bioweapon creation.</li>
                    
                    <li>Existing risk mitigation efforts primarily focus on filtering biohazardous data during pre-training, but their effectiveness against determined malicious actors is unclear.</li>
                    
                    <li>The `eval` framework is proposed to rigorously evaluate the robustness of procedures intended to reduce the dual-use capabilities of these bio-foundation models.</li>
                    
                    <li>`eval` assesses models' virus understanding via three specific lenses: sequence modeling, mutational effects prediction, and virulence prediction.</li>
                    
                    <li>Findings indicate that knowledge intended to be excluded by filtering can be rapidly recovered through fine-tuning and exhibits broader generalizability in sequence modeling.</li>
                    
                    <li>Crucially, dual-use signals appear to be embedded within the pre-trained representations of these models and can be elicited via simple linear probing.</li>
                    
                    <li>These results underscore the inadequacy of data filtering as a standalone safety measure, necessitating the development of more robust safety and security strategies.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors propose `eval`, a framework designed to evaluate the robustness of procedures intended to reduce the dual-use capabilities of open-weight bio-foundation models. `eval` assesses models' virus understanding through three specific lenses: sequence modeling (analyzing viral genetic sequences), mutational effects prediction (forecasting the functional impact of viral mutations), and virulence prediction (estimating the pathogenicity or severity of disease caused by viruses).</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Current data filtering practices for bio-foundation models are largely ineffective at preventing dual-use capabilities. Knowledge deemed biohazardous and excluded during pre-training can be rapidly recovered by fine-tuning the models and demonstrates broader generalizability in sequence modeling. Furthermore, significant dual-use signals are already present within the pre-trained representations of these models and can be elicited via simple linear probing, suggesting inherent dangerous capabilities regardless of filtering.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings present a critical challenge for safely harnessing powerful AI in clinical and public health contexts. Unmitigated dual-use risks could inadvertently enable the design of more potent bioweapons, posing catastrophic global health threats. Conversely, developing robust safety and security measures, as advocated by this research, is essential to ethically leverage AI's potential for accelerating drug discovery, vaccine development, pandemic preparedness, and understanding infectious disease mechanisms without compromising biosecurity.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper highlights that current data filtering practices are not particularly effective as a standalone procedure for mitigating dual-use risks, especially against determined actors who might fine-tune models. It implies that these methods fail to prevent the recovery and generalization of hazardous knowledge, and overlook inherent risks in pre-trained models.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The research underscores the urgent need for further investigation into more robust safety and security strategies for open-weight bio-foundation models. This includes developing advanced techniques beyond simple data filtering to effectively prevent the recovery and elicitation of dual-use capabilities, ensuring these powerful AI tools are used for beneficial purposes only.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Infectious Diseases</span>
                    
                    <span class="tag">Drug Discovery</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Biodefense</span>
                    
                    <span class="tag">AI in Medicine</span>
                    
                    <span class="tag">Vaccinology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">bio-foundation models</span>
                    
                    <span class="tag tag-keyword">dual-use dilemma</span>
                    
                    <span class="tag tag-keyword">biorisk evaluation</span>
                    
                    <span class="tag tag-keyword">AI safety</span>
                    
                    <span class="tag tag-keyword">biosecurity</span>
                    
                    <span class="tag tag-keyword">virus understanding</span>
                    
                    <span class="tag tag-keyword">machine learning</span>
                    
                    <span class="tag tag-keyword">drug development</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Open-weight bio-foundation models present a dual-use dilemma. While holding
great promise for accelerating scientific research and drug development, they
could also enable bad actors to develop more deadly bioweapons. To mitigate the
risk posed by these models, current approaches focus on filtering biohazardous
data during pre-training. However, the effectiveness of such an approach
remains unclear, particularly against determined actors who might fine-tune
these models for malicious use. To address this gap, we propose \eval, a
framework to evaluate the robustness of procedures that are intended to reduce
the dual-use capabilities of bio-foundation models. \eval assesses models'
virus understanding through three lenses, including sequence modeling,
mutational effects prediction, and virulence prediction. Our results show that
current filtering practices may not be particularly effective: Excluded
knowledge can be rapidly recovered in some cases via fine-tuning, and exhibits
broader generalizability in sequence modeling. Furthermore, dual-use signals
may already reside in the pretrained representations, and can be elicited via
simple linear probing. These findings highlight the challenges of data
filtering as a standalone procedure, underscoring the need for further research
into robust safety and security strategies for open-weight bio-foundation
models.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>17 Pages, 5 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>