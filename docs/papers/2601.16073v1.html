<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces DSFedMed, a novel dual-scale federated framework designed to efficiently deploy powerful Foundation Models (FMs) for medical image segment">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.16073v1" target="_blank">2601.16073v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-22
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Hanwen Zhang, Qiaojin Shen, Yuxi Liu, Yuesheng Zhu, Guibo Luo
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.DC
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.16073v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.16073v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces DSFedMed, a novel dual-scale federated framework designed to efficiently deploy powerful Foundation Models (FMs) for medical image segmentation in resource-constrained federated settings. It achieves this by employing mutual knowledge distillation between a centralized foundation model and lightweight client models, significantly reducing computational and communication overhead while enhancing segmentation accuracy. The framework leverages generated medical images and a learnability-guided sample selection strategy to facilitate effective knowledge transfer.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical AI by enabling the practical and scalable deployment of powerful, generalizable foundation models for crucial tasks like medical image segmentation. It allows healthcare institutions to collaboratively develop and leverage advanced AI while preserving data privacy and overcoming the significant resource limitations often present in clinical environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI framework to enhance the accuracy and efficiency of automated medical image segmentation. This directly applies to assisting clinicians in diagnosis, treatment planning, and disease monitoring by segmenting anatomical structures, lesions, or pathologies from various medical scans (e.g., MRI, CT). The federated learning approach also addresses critical data privacy and distributed learning challenges prevalent in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges (high computational demands, communication overhead, inference costs) associated with deploying Foundation Models (FMs) in federated learning for medical imaging.</li>
                    
                    <li>Proposes DSFedMed, a dual-scale federated framework featuring mutual knowledge distillation between a centralized FM and lightweight client models.</li>
                    
                    <li>Enables bidirectional knowledge transfer: the foundation model disseminates general knowledge to clients, while client-specific insights are used to refine and improve the foundation model.</li>
                    
                    <li>Utilizes a novel approach of generating high-quality medical images to facilitate knowledge distillation, serving as a substitute for real public datasets.</li>
                    
                    <li>Implements a learnability-guided sample selection strategy to optimize the efficiency and effectiveness of the dual-scale distillation process.</li>
                    
                    <li>Achieves an average 2% improvement in Dice score for medical image segmentation across five diverse datasets.</li>
                    
                    <li>Demonstrates significant efficiency gains, reducing communication costs and inference time by nearly 90% compared to existing federated foundation model baselines.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed DSFedMed, a dual-scale federated framework for medical image segmentation. This framework incorporates mutual knowledge distillation, where a powerful, centralized foundation model interacts with lightweight models located at client nodes. Knowledge transfer is facilitated by using a set of synthetically generated high-quality medical images, replacing reliance on real public datasets. A learnability-guided sample selection strategy is employed to enhance the efficiency and effectiveness of this distillation process. The framework's performance was evaluated on five distinct medical imaging segmentation datasets and compared against existing federated foundation model baselines.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DSFedMed framework demonstrated superior performance, achieving an average 2% improvement in Dice score for medical image segmentation accuracy. Crucially, it delivered substantial efficiency enhancements, reducing both communication costs and inference time by nearly 90% when compared to existing federated foundation model baselines. These results highlight significant gains in both accuracy and operational efficiency.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>DSFedMed has the potential to revolutionize the adoption of advanced AI in clinical settings by making powerful foundation models for medical image analysis both accessible and sustainable. By drastically cutting down computational and communication resource requirements, it enables even resource-limited hospitals to deploy high-performing segmentation models. This can lead to faster, more accurate diagnoses, improved treatment planning, and fosters collaborative AI development across healthcare institutions while strictly adhering to patient data privacy through federated learning.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the DSFedMed framework itself. It primarily focuses on the challenges that DSFedMed aims to resolve regarding existing Foundation Models in federated settings.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Image Analysis</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Federated Learning</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Knowledge Distillation</span>
                    
                    <span class="tag tag-keyword">Dual-Scale</span>
                    
                    <span class="tag tag-keyword">Computational Efficiency</span>
                    
                    <span class="tag tag-keyword">Mutual Distillation</span>
                    
                    <span class="tag tag-keyword">Lightweight Models</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>