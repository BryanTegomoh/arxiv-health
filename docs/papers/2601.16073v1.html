<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models - Health AI Hub</title>
    <meta name="description" content="DSFedMed proposes a novel dual-scale federated framework addressing the high computational and communication demands of deploying Foundation Models (FMs) in fed">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.16073v1" target="_blank">2601.16073v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-22
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Hanwen Zhang, Qiaojin Shen, Yuxi Liu, Yuesheng Zhu, Guibo Luo
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.DC
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.16073v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.16073v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DSFedMed proposes a novel dual-scale federated framework addressing the high computational and communication demands of deploying Foundation Models (FMs) in federated medical image segmentation. It achieves this by enabling mutual knowledge distillation between a centralized FM and lightweight client models, leveraging generated high-quality medical images and a learnability-guided sample selection strategy. This approach significantly improves segmentation accuracy by 2% (Dice score) while reducing communication and inference costs by nearly 90% compared to existing federated FM baselines.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This framework significantly advances the practical deployment of powerful AI models (FMs) in clinical settings by overcoming privacy concerns and computational limitations inherent in medical federated learning. It promises more accurate and efficient medical image segmentation, crucial for improved diagnosis, treatment planning, and monitoring across various medical specialties.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>DSFedMed is a medical AI application that utilizes federated learning and knowledge distillation to create more efficient and accurate models for medical image segmentation. This technology can significantly improve the diagnosis, monitoring, and treatment planning of various medical conditions by providing precise segmentation of anatomical structures or anomalies from medical scans, while also addressing data privacy concerns inherent in healthcare settings through its federated approach.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of high computational demands, communication overhead, and inference costs of Foundation Models (FMs) in federated learning for medical imaging.</li>
                    
                    <li>Introduces DSFedMed, a dual-scale federated framework that integrates a centralized Foundation Model with distributed lightweight client models.</li>
                    
                    <li>Employs mutual knowledge distillation, allowing the FM to transfer general knowledge to clients and clients to incorporate specific insights back into the FM.</li>
                    
                    <li>Utilizes a set of generated high-quality medical images for distillation, circumventing the need for real public datasets and enhancing data privacy.</li>
                    
                    <li>Proposes a learnability-guided sample selection strategy to optimize the efficiency and effectiveness of the dual-scale distillation process.</li>
                    
                    <li>Achieves an average 2% improvement in Dice score on five medical imaging segmentation datasets.</li>
                    
                    <li>Demonstrates significant efficiency gains, reducing communication costs and inference time by nearly 90% compared to existing federated foundation model baselines.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DSFedMed is a dual-scale federated framework comprising a centralized Foundation Model (FM) and distributed Lightweight Client Models (LCMs). It employs mutual knowledge distillation: the FM transfers general knowledge to the LCMs, which in turn refine the FM with client-specific insights. To facilitate distillation without real public data, high-quality synthetic medical images are generated. A learnability-guided sample selection strategy is implemented to enhance the efficiency and effectiveness of this distillation process. The framework was evaluated on five diverse medical imaging segmentation datasets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DSFedMed framework achieved an average 2% improvement in Dice score for medical image segmentation. Crucially, it demonstrated significant efficiency enhancements, reducing both communication costs and inference time by nearly 90% when compared to established federated foundation model baselines.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>DSFedMed has the potential to enable the widespread adoption of powerful Foundation Models in clinical practice, even in resource-constrained environments. By improving segmentation accuracy and reducing computational/communication overhead, it can lead to faster and more precise diagnoses, better-informed treatment planning (e.g., tumor contouring for radiation therapy), and more efficient clinical workflows, ultimately benefiting patient care and outcomes. Its privacy-preserving nature, using federated learning and synthetic data, aligns well with stringent healthcare data regulations.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations. While the use of generated medical images is presented as a solution, its potential limitations in capturing the full complexity and variability of real-world patient data are not discussed.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Federated Learning</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Knowledge Distillation</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Dual-Scale</span>
                    
                    <span class="tag tag-keyword">Lightweight Models</span>
                    
                    <span class="tag tag-keyword">Computational Efficiency</span>
                    
                    <span class="tag tag-keyword">Data Privacy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>