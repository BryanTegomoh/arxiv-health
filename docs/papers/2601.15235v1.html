<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification - Health AI Hub</title>
    <meta name="description" content="This study introduces a multi-stage, projection-driven deep learning pipeline for automated cervical spine fracture identification from 3D CT volumes. It levera">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15235v1" target="_blank">2601.15235v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fabi Nahian Madhurja, Rusab Sarmun, Muhammad E. H. Chowdhury, Adam Mushtak, Israa Al-Hashimi, Sohaib Bassam Zoghoul
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15235v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15235v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study introduces a multi-stage, projection-driven deep learning pipeline for automated cervical spine fracture identification from 3D CT volumes. It leverages optimized 2D axial, sagittal, and coronal projections for efficient localization and segmentation of vertebrae (C1-C7), followed by an ensemble of 2.5D models for fracture detection, achieving high accuracy comparable to expert radiologists while reducing computational complexity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This automated system provides a high-performing tool to aid clinicians in rapid and accurate diagnosis, potentially improving patient outcomes and streamlining workflows in emergency and trauma settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves an end-to-end deep learning pipeline for automated detection and localization of cervical spine fractures (C1-C7) from 3D CT scans. It uses multi-stage projection-based methods with models like YOLOv8 and DenseNet121-Unet for identifying regions of interest, segmenting vertebrae, and subsequently analyzing individual vertebra volumes for fractures. The system aims to serve as a diagnostic aid, improving the accuracy and efficiency of fracture identification, and includes an explainability study to highlight diagnostically relevant anatomical regions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study addresses the critical need for precise and efficient detection of cervical spine fractures from 3D CT volumes using a novel automated approach.</li>
                    
                    <li>A projection-based localization strategy uses YOLOv8 on optimized 2D axial, sagittal, and coronal projections to identify the 3D cervical spine area, achieving a 3D mIoU of 94.45% and reducing computational complexity compared to traditional 3D methods.</li>
                    
                    <li>Vertebra-level segmentation (C1-C7) is performed using a DenseNet121-Unet model, leveraging variance- and energy-based projections, resulting in a Dice score of 87.86%.</li>
                    
                    <li>Individual vertebra volumes are extracted from the 2D segmentation masks and analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models that incorporate both raw slices and projections.</li>
                    
                    <li>The fracture detection ensemble achieves vertebra-level F1 and ROC-AUC scores of 68.15% and 91.62%, respectively, and patient-level F1 and ROC-AUC scores of 82.26% and 83.04%, respectively.</li>
                    
                    <li>Validation includes an explainability study providing saliency map visualizations for diagnostic relevance and an interobserver variability analysis demonstrating competitive performance of the model against expert radiologists.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology employs a multi-stage deep learning pipeline. First, 3D CT volumes are approximated by optimized 2D axial, sagittal, and coronal projections. YOLOv8 identifies regions of interest from these 2D views, which are then combined to approximate the 3D cervical spine area. Second, a DenseNet121-Unet model, using variance- and energy-based projections, performs multi-label segmentation of individual vertebrae (C1-C7). Third, individual vertebra volumes are extracted from the 2D segmentation masks and analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models, incorporating both raw slices and projections. The approach is further validated through an explainability study (saliency maps) and an interobserver variability analysis.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The projection-based localization achieved a high 3D mIoU of 94.45% for the cervical spine area, demonstrating computational efficiency. Vertebra segmentation yielded a Dice score of 87.86%. For fracture detection, the ensemble model achieved competitive vertebra-level F1 (68.15%) and ROC-AUC (91.62%) scores, and patient-level F1 (82.26%) and ROC-AUC (83.04%) scores. The model's performance was validated as competitive with expert radiologists, and explainability maps highlighted relevant anatomical regions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a robust, automated, and computationally efficient solution for cervical spine fracture identification from CT scans. It has the potential to significantly enhance diagnostic accuracy and speed, reducing the burden on radiologists and emergency physicians. Faster and more precise diagnoses can lead to earlier appropriate clinical management, potentially improving patient prognosis and reducing complications associated with delayed fracture detection.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Orthopedics</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Neurosurgery</span>
                    
                    <span class="tag">Traumatology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Cervical spine fracture</span>
                    
                    <span class="tag tag-keyword">CT imaging</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">2D projections</span>
                    
                    <span class="tag tag-keyword">3D segmentation</span>
                    
                    <span class="tag tag-keyword">YOLOv8</span>
                    
                    <span class="tag tag-keyword">DenseNet121-Unet</span>
                    
                    <span class="tag tag-keyword">Fracture detection</span>
                    
                    <span class="tag tag-keyword">Medical artificial intelligence</span>
                    
                    <span class="tag tag-keyword">Radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>