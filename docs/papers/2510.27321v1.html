<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data - Health AI Hub</title>
    <meta name="description" content="MedM2T is a novel time-aware multimodal framework designed to integrate diverse medical data, such as Electronic Health Records (EHR) and Electrocardiograms (EC">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic Health Record and Electrocardiogram Data</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27321v1" target="_blank">2510.27321v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yu-Chen Kuo, Yi-Ju Tseng
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27321v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27321v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedM2T is a novel time-aware multimodal framework designed to integrate diverse medical data, such as Electronic Health Records (EHR) and Electrocardiograms (ECGs), by effectively handling temporal complexities and granularity gaps. It employs specialized encoders, hierarchical fusion, and cross-modal attention, demonstrating superior performance in critical clinical prediction tasks like cardiovascular disease prediction, in-hospital mortality, and ICU length-of-stay. The framework's robustness and broad applicability position it as a promising tool for clinical prediction.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant as it provides a sophisticated deep learning framework capable of leveraging the full spectrum of complex, multimodal patient data. By accurately modeling irregular EHR and dense physiological signals like ECGs, MedM2T can significantly enhance prognostic accuracy for critical health outcomes, thereby supporting more proactive and personalized clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedM2T is an AI/Machine Learning framework designed to enhance clinical prediction by integrating and analyzing diverse medical data sources (EHR and ECGs). It can be applied as a decision support tool for prognostic assessments, such as predicting disease onset, patient mortality risk, and resource utilization (like ICU length of stay) in healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>MedM2T is a time-aware multimodal framework specifically developed to integrate heterogeneous medical data, including sparse/irregular EHR and dense ECG time series.</li>
                    
                    <li>It incorporates a Sparse Time Series Encoder to manage irregular EHR data and a Hierarchical Time-Aware Fusion module to capture micro- and macro-temporal patterns from dense time series like ECGs.</li>
                    
                    <li>A Bi-Modal Attention mechanism is utilized to extract crucial cross-modal interactions, with extensibility designed for any number of modalities.</li>
                    
                    <li>To address granularity differences, MedM2T employs modality-specific pre-trained encoders and aligns their resulting features within a shared encoder.</li>
                    
                    <li>The framework was evaluated on the MIMIC-IV and MIMIC-IV-ECG datasets across three diverse clinical tasks: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality prediction, and ICU Length-of-Stay (LOS) regression.</li>
                    
                    <li>MedM2T significantly outperformed state-of-the-art multimodal learning frameworks and existing time series models in all evaluated tasks.</li>
                    
                    <li>Specific performance metrics include an AUROC of 0.947 for CVD prediction, an AUROC of 0.901 for mortality prediction, and a Mean Absolute Error (MAE) of 2.31 for LOS regression.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MedM2T is a deep learning-based multimodal framework. Its architecture includes a Sparse Time Series Encoder for irregular data (e.g., EHR), a Hierarchical Time-Aware Fusion module for dense time series (e.g., ECG), and a Bi-Modal Attention mechanism to identify cross-modal interactions. Granularity gaps between modalities are addressed by using modality-specific pre-trained encoders, followed by feature alignment within a shared encoder. The framework processes these integrated features to generate predictions for various clinical outcomes.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedM2T achieved superior performance compared to existing state-of-the-art models. For 90-day cardiovascular disease prediction, it yielded an AUROC of 0.947 and an AUPRC of 0.706. In-hospital mortality prediction demonstrated an AUROC of 0.901 and an AUPRC of 0.558. For ICU length-of-stay regression, MedM2T achieved a Mean Absolute Error (MAE) of 2.31. These results underscore its effectiveness across chronic and acute disease dynamics.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedM2T has the potential to significantly impact clinical practice by enabling more accurate and timely prediction of crucial patient outcomes, such as the risk of cardiovascular events, in-hospital mortality, and required ICU resources. This capability could facilitate earlier interventions, optimize resource allocation, guide personalized treatment plans, and ultimately improve patient safety and outcomes in acute and chronic care settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The provided abstract does not explicitly state any specific limitations of the MedM2T framework or its evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The provided abstract does not explicitly mention future research directions for MedM2T.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Critical Care Medicine</span>
                    
                    <span class="tag">Internal Medicine</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Predictive Analytics in Healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">electronic health records</span>
                    
                    <span class="tag tag-keyword">electrocardiogram</span>
                    
                    <span class="tag tag-keyword">multimodal learning</span>
                    
                    <span class="tag tag-keyword">time series analysis</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">clinical prediction</span>
                    
                    <span class="tag tag-keyword">cardiovascular disease</span>
                    
                    <span class="tag tag-keyword">mortality prediction</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The inherent multimodality and heterogeneous temporal structures of medical
data pose significant challenges for modeling. We propose MedM2T, a time-aware
multimodal framework designed to address these complexities. MedM2T integrates:
(i) Sparse Time Series Encoder to flexibly handle irregular and sparse time
series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and
macro-temporal patterns from multiple dense time series, such as ECGs, and
(iii) Bi-Modal Attention to extract cross-modal interactions, which can be
extended to any number of modalities. To mitigate granularity gaps between
modalities, MedM2T uses modality-specific pre-trained encoders and aligns
resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and
MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease
dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality
prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed
state-of-the-art multimodal learning frameworks and existing time series
models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction;
an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean
Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the
robustness and broad applicability of MedM2T, positioning it as a promising
tool in clinical prediction. We provide the implementation of MedM2T at
https://github.com/DHLab-TSENG/MedM2T.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This preprint version of the manuscript has been submitted to the
  IEEE Journal of Biomedical and Health Informatics (JBHI) for review. The
  implementation of MedM2T is available at
  https://github.com/DHLab-TSENG/MedM2T</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>