<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3DFETUS: Standardizing Fetal Facial Planes in 3D Ultrasound - Health AI Hub</title>
    <meta name="description" content="This paper introduces 3DFETUS, a deep learning model, and GT++, an algorithm, aimed at standardizing the acquisition and localization of fetal facial planes in ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>3DFETUS: Standardizing Fetal Facial Planes in 3D Ultrasound</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.10412v1" target="_blank">2511.10412v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-13
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Alomar Antonia, Rubio Ricardo, Albaiges Gerard, Salort-Benejam Laura, Caminal Julia, Prat Maria, Rueda Carolina, Cortes Berta, Piella Gemma, Sukno Federico
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.10412v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.10412v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces 3DFETUS, a deep learning model, and GT++, an algorithm, aimed at standardizing the acquisition and localization of fetal facial planes in 3D ultrasound. By automating this challenging process, the methods reduce operator dependency and improve accuracy, addressing inconsistencies and potential diagnostic bias in prenatal examinations.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Standardizing fetal facial planes in 3D ultrasound is critical for consistent and accurate prenatal diagnosis of craniofacial abnormalities, reducing examination time, minimizing operator variability, and decreasing potential diagnostic bias in fetal assessments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI models (GT++ and 3DFETUS) are applied to automate and standardize the estimation of fetal facial planes from 3D ultrasound volumes. This improves the accuracy and consistency of medical image analysis, which is crucial for early and reliable diagnosis of potential issues during prenatal care, thereby directly impacting fetal health outcomes and clinical workflow efficiency.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Routine fetal ultrasound often struggles with acquiring standard facial planes due to fetal movement, orientation variability, and operator expertise.</li>
                    
                    <li>GT++ is presented as a robust algorithm that estimates standard facial planes from 3D US volumes using annotated anatomical landmarks.</li>
                    
                    <li>3DFETUS is a deep learning model developed to automate and standardize the localization of these fetal facial planes in 3D ultrasound volumes.</li>
                    
                    <li>The proposed methods were evaluated both quantitatively (translation and rotation errors) and qualitatively (expert clinical review).</li>
                    
                    <li>Quantitatively, the approach achieved a mean translation error of 4.13 mm and a mean rotation error of 7.93 degrees per plane.</li>
                    
                    <li>The methods significantly outperformed other state-of-the-art techniques on 3D US volumes.</li>
                    
                    <li>Clinical assessments confirmed statistically significant improvements in plane estimation accuracy, highlighting practical effectiveness.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes two primary methods: GT++, an algorithm that estimates standard facial planes from 3D US volumes using pre-annotated anatomical landmarks, and 3DFETUS, a deep learning model trained to automate and standardize the localization of these planes. Evaluation involved both quantitative analysis of translation and rotation errors and qualitative assessment through expert clinical review.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed 3DFETUS and GT++ approach achieved superior performance, demonstrating a mean translation error of 4.13 mm and a mean rotation error of 7.93 degrees per plane. This significantly outperformed existing state-of-the-art methods in 3D US volumes. Clinical assessments further validated these findings, confirming statistically significant improvements in the accuracy of fetal facial plane estimation.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology promises to significantly enhance the consistency and efficiency of routine fetal ultrasound examinations. By standardizing facial plane acquisition, it can reduce operator-dependent variability, shorten examination times, and improve the reliability of detecting fetal craniofacial anomalies, ultimately leading to more accurate and timely prenatal diagnoses.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the developed methods.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Obstetrics</span>
                    
                    <span class="tag">Fetal Medicine</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Perinatology</span>
                    
                    <span class="tag">Radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Fetal ultrasound</span>
                    
                    <span class="tag tag-keyword">3D ultrasound</span>
                    
                    <span class="tag tag-keyword">Facial planes</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Standardization</span>
                    
                    <span class="tag tag-keyword">Prenatal diagnosis</span>
                    
                    <span class="tag tag-keyword">Image processing</span>
                    
                    <span class="tag tag-keyword">Anatomical landmarks</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Acquiring standard facial planes during routine fetal ultrasound (US) examinations is often challenging due to fetal movement, variability in orientation, and operator-dependent expertise. These factors contribute to inconsistencies, increased examination time, and potential diagnostic bias.
  To address these challenges in the context of facial assessment, we present: 1) GT++, a robust algorithm that estimates standard facial planes from 3D US volumes using annotated anatomical landmarks; and 2) 3DFETUS, a deep learning model that automates and standardizes their localization in 3D fetal US volumes.
  We evaluated our methods both qualitatively, through expert clinical review, and quantitatively. The proposed approach achieved a mean translation error of 4.13 mm and a mean rotation error of 7.93 degrees per plane, outperforming other state-of-the-art methods on 3D US volumes. Clinical assessments further confirmed the effectiveness of both GT++ and 3DFETUS, demonstrating statistically significant improvements in plane estimation accuracy.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>