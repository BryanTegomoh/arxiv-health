<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset - Health AI Hub</title>
    <meta name="description" content="This paper audits the fairness of automated tumor segmentation within the MAMA-MIA breast cancer dataset, uncovering significant age-related bias against younge">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the MAMA-MIA Dataset</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27421v1" target="_blank">2510.27421v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Aditya Parikh, Sneha Das, Aasa Feragen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27421v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27421v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper audits the fairness of automated tumor segmentation within the MAMA-MIA breast cancer dataset, uncovering significant age-related bias against younger patients that persists even after accounting for data source. It also reveals how aggregating data influences site-specific ethnic biases, emphasizing the critical need for granular data analysis in fairness evaluations. The findings highlight potential disparities in diagnostic quality for specific demographic groups if such biases remain unaddressed.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Unaddressed segmentation bias in breast cancer diagnostics can lead to disparities in the quality of care for younger patients and certain ethnic populations, potentially resulting in delayed or inaccurate diagnoses and compounded negative impacts across clinical decision points.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper investigates fairness and bias in deep learning models designed for automated breast cancer tumor segmentation, a critical application of AI in diagnostic medicine. These models aim to improve diagnostic workflows by assisting or potentially automating the identification of tumors in medical images, which directly impacts patient care and outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study investigates fairness in deep learning image segmentation for breast cancer tumors, a domain underexplored beyond classification tasks.</li>
                    
                    <li>It audits the automated segmentation labels of the MAMA-MIA dataset, evaluating quality across age, ethnicity, and data source.</li>
                    
                    <li>A significant intrinsic age-related bias against younger patients was discovered in automated segmentation performance.</li>
                    
                    <li>This age bias remains persistent even after controlling for confounding factors, such as the data source of the images.</li>
                    
                    <li>The authors hypothesize that physiological factors, known challenges for both human radiologists and automated systems, may contribute to the observed age bias.</li>
                    
                    <li>The research demonstrates that aggregating data from multiple sources impacts and influences site-specific ethnic biases.</li>
                    
                    <li>The findings underscore the critical necessity of investigating data and biases at a granular level rather than relying solely on aggregated results.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study conducted an audit of the automated segmentation labels within the MAMA-MIA breast cancer tumor segmentation dataset. This involved evaluating the quality of these automated segmentations specifically across patient age, ethnicity, and the original data source, while also employing controls for confounding factors like data source to isolate intrinsic biases.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings include an intrinsic age-related bias against younger patients in automated breast tumor segmentation, which persisted even after controlling for confounding factors like data source. This age bias is hypothesized to be linked to physiological factors. Additionally, the study found that aggregating data from multiple sources significantly influences and can obscure site-specific ethnic biases.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The identified age and ethnic biases in automated breast cancer segmentation carry the risk of leading to suboptimal diagnostic performance for vulnerable patient populations, potentially increasing misdiagnosis rates or delaying critical interventions. This underscores the need for rigorous fairness evaluations in AI-driven medical tools to ensure equitable and high-quality care, preventing the exacerbation of existing health disparities.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract suggests that the observed age-related bias may be linked to physiological factors, which are recognized as challenges for both human radiologists and automated systems. This implies an inherent difficulty in the task for specific patient groups, rather than solely a limitation of the current AI model or this specific analysis.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper explicitly calls for the necessity of investigating data at a granular level to better understand and address biases. Future research should delve deeper into the physiological factors contributing to age-related segmentation challenges and explore effective bias-mitigation strategies tailored to demographic and source-specific disparities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Health Disparities</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">image segmentation</span>
                    
                    <span class="tag tag-keyword">breast cancer</span>
                    
                    <span class="tag tag-keyword">bias</span>
                    
                    <span class="tag tag-keyword">fairness</span>
                    
                    <span class="tag tag-keyword">age bias</span>
                    
                    <span class="tag tag-keyword">ethnic bias</span>
                    
                    <span class="tag tag-keyword">MAMA-MIA</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">health equity</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep learning models aim to improve diagnostic workflows, but fairness
evaluation remains underexplored beyond classification, e.g., in image
segmentation. Unaddressed segmentation bias can lead to disparities in the
quality of care for certain populations, potentially compounded across clinical
decision points and amplified through iterative model development. Here, we
audit the fairness of the automated segmentation labels provided in the breast
cancer tumor segmentation dataset MAMA-MIA. We evaluate automated segmentation
quality across age, ethnicity, and data source. Our analysis reveals an
intrinsic age-related bias against younger patients that continues to persist
even after controlling for confounding factors, such as data source. We
hypothesize that this bias may be linked to physiological factors, a known
challenge for both radiologists and automated systems. Finally, we show how
aggregating data from multiple data sources influences site-specific ethnic
biases, underscoring the necessity of investigating data at a granular level.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Medical Imaging Meets EurIPS (NeurIPS-endorsed workshop) - MedEurIPS</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>