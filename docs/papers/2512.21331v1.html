<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning - Health AI Hub</title>
    <meta name="description" content="TICON introduces a novel transformer-based tile contextualizer that generates rich, slide-level contextualized embeddings for histopathology images, addressing ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.21331v1" target="_blank">2512.21331v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-24
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Varun Belagali, Saarthak Kapse, Pierre Marza, Srijan Das, Zilinghan Li, Sofi√®ne Boutaj, Pushpak Pati, Srikar Yellapragada, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Prateek Prasanna, Stergios Christodoulidis Maria Vakalopoulou, Dimitris Samaras
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.21331v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.21331v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">TICON introduces a novel transformer-based tile contextualizer that generates rich, slide-level contextualized embeddings for histopathology images, addressing the limitations of context-stripped tile encoders. By unifying and enhancing representations from diverse tile-level foundation models via a masked modeling objective, TICON achieves new state-of-the-art performance across various computational pathology benchmarks and enables the training of a superior slide-level foundation model with significantly less data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>By providing contextually richer and more accurate representations of histopathology tiles, TICON can significantly enhance the reliability and performance of AI models in digital pathology, aiding precise disease diagnosis, prognosis, and personalized treatment planning.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>TICON is an AI model designed to improve the accuracy and robustness of deep learning models for analyzing whole slide images (WSIs) in histopathology. This has direct applications in assisting pathologists with tasks such as automated cancer detection, tumor grading, disease subtyping, and predicting patient prognosis, thereby enhancing diagnostic efficiency and potentially improving patient care outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>TICON (Tile Contextualizer) is a transformer-based model designed to infuse slide-level context into tile representations, crucial for accurate interpretation of Whole Slide Images (WSIs).</li>
                    
                    <li>It addresses the challenge of standard tile encoders, which extract embeddings without critical slide-level information, and unifies outputs from various specialized tile-level foundation models.</li>
                    
                    <li>TICON utilizes a single, shared encoder, pretrained with a masked modeling objective, to simultaneously unify and contextualize diverse tile-level pathology foundation models' representations.</li>
                    
                    <li>The model significantly improves performance, establishing new state-of-the-art results on multiple tile-level benchmarks (HEST-Bench, THUNDER, CATCH) and a slide-level benchmark (Patho-Bench).</li>
                    
                    <li>A slide-level foundation model built on TICON, using only 11K WSIs, notably outperforms existing state-of-the-art slide-level models that required up to 350K WSIs for pretraining.</li>
                    
                    <li>TICON aims to produce 'rich, contextualized embeddings for 'any' application in computational pathology,' indicating broad applicability.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>TICON employs a transformer-based architecture as a shared encoder, specifically designed to contextualize tile embeddings. Its pretraining leverages a masked modeling objective, enabling it to learn unified and context-aware representations from various existing tile-level foundation models. The contextualized tile embeddings can then be used directly for downstream tile-level tasks or aggregated by a separately pretrained aggregator to form a slide-level foundation model.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>TICON-contextualized embeddings consistently and significantly improve performance across a multitude of computational pathology tasks, setting new state-of-the-art benchmarks for both tile-level (HEST-Bench, THUNDER, CATCH) and slide-level (Patho-Bench) analyses. Furthermore, a slide-level foundation model trained on TICON demonstrated superior performance compared to previous state-of-the-art models, remarkably achieving this with a substantially smaller dataset (11K WSIs vs. up to 350K WSIs).</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The development of TICON has the potential to revolutionize AI in digital pathology by providing more robust and context-aware image analysis. This can lead to more accurate and efficient AI-assisted diagnoses, improved disease classification, better prediction of patient outcomes, and optimized treatment selection, ultimately benefiting patient care and accelerating pathology research.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly detail any limitations of the TICON model. Further evaluation in the full paper would likely address aspects such as generalizability across diverse scanning platforms, staining protocols, and rare disease subtypes, as well as computational overhead.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. However, the superior performance with significantly less data suggests potential for wider applicability in settings with limited data, and further exploration of TICON's ability to adapt to extremely diverse and novel computational pathology tasks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Digital Pathology</span>
                    
                    <span class="tag">Anatomic Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Whole Slide Images</span>
                    
                    <span class="tag tag-keyword">Tile Contextualization</span>
                    
                    <span class="tag tag-keyword">Transformer Models</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Computational Pathology</span>
                    
                    <span class="tag tag-keyword">Representation Learning</span>
                    
                    <span class="tag tag-keyword">Masked Modeling</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ''any'' application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from ''any'' tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>