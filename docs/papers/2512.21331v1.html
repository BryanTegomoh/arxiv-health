<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning - Health AI Hub</title>
    <meta name="description" content="TICON is a novel transformer-based model designed to contextualize and unify tile embeddings from whole slide images (WSIs), addressing the critical need for la">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.21331v1" target="_blank">2512.21331v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-24
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Varun Belagali, Saarthak Kapse, Pierre Marza, Srijan Das, Zilinghan Li, Sofi√®ne Boutaj, Pushpak Pati, Srikar Yellapragada, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Prateek Prasanna, Stergios Christodoulidis Maria Vakalopoulou, Dimitris Samaras
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.21331v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.21331v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">TICON is a novel transformer-based model designed to contextualize and unify tile embeddings from whole slide images (WSIs), addressing the critical need for larger image context in computational pathology. By pretraining a shared encoder with a masked modeling objective, TICON generates rich, contextualized representations that significantly improve performance across diverse tile and slide-level tasks. This approach enables the creation of highly efficient and accurate slide-level foundation models using substantially less data than previous state-of-the-art methods.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical diagnostics as it improves the accuracy and interpretability of AI models in digital histopathology by mimicking how human pathologists consider the broader context of tissue slides. It enhances the reliability of AI tools for disease detection, classification, and prognosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>TICON is an AI model designed to enhance representation learning for whole slide images in histopathology. It acts as a 'tile contextualizer' to create richer, more unified embeddings from diverse tile-level pathology models. This improved representation learning leads to more accurate and efficient AI systems for tasks like disease diagnosis, prognosis, and biomarker identification from tissue biopsies, thereby directly assisting pathologists and clinicians in medical decision-making.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the fundamental challenge in computational pathology where individual tiles, when stripped of context, fail to capture essential slide-level information for diagnostic tasks.</li>
                    
                    <li>Introduces TICON, a transformer-based tile representation contextualizer that produces rich, context-aware embeddings for various applications in computational pathology.</li>
                    
                    <li>Solves the problem of disparate tile-encoder performance by providing a unified model to contextualize embeddings from any existing tile-level foundation model.</li>
                    
                    <li>Employs a single, shared encoder, pretrained using a masked modeling objective, to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models.</li>
                    
                    <li>Achieves new state-of-the-art (SoTA) performance across multiple tile-level benchmarks (HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (Patho-Bench).</li>
                    
                    <li>Demonstrates the ability to pretrain a powerful slide-level foundation model on TICON-contextualized embeddings using only 11K WSIs.</li>
                    
                    <li>Outperforms existing SoTA slide-level foundation models that require significantly larger training datasets (up to 350K WSIs).</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>TICON is a transformer-based architecture featuring a single, shared encoder. This encoder is pretrained using a masked modeling objective, enabling it to learn and generate contextualized embeddings from input tile embeddings. It acts as a universal contextualizer for embeddings derived from various pre-existing tile-level pathology foundation models. An additional aggregator can then be pretrained on the TICON-contextualized embeddings to construct slide-level foundation models.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>TICON-contextualized embeddings consistently achieve significant performance improvements, establishing new state-of-the-art results on multiple tile-level (HEST-Bench, THUNDER, CATCH) and slide-level (Patho-Bench) benchmarks. Notably, TICON facilitates the development of a slide-level foundation model using only 11,000 WSIs that outperforms existing state-of-the-art models trained with up to 350,000 WSIs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>TICON can revolutionize AI-assisted diagnostics in clinical pathology by providing more accurate, reliable, and context-aware insights from whole slide images. It can aid pathologists in making more precise diagnoses, better predicting patient outcomes, and potentially streamlining workflows by improving the performance of automated tissue analysis. The reduced data requirement for powerful slide-level models also makes advanced AI tools more accessible and scalable for clinical implementation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the TICON model or its current evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract implies broad applicability to 'any' application in computational pathology, suggesting future work could involve extending TICON's use to a wider array of diagnostic, prognostic, and predictive tasks within digital pathology beyond the evaluated benchmarks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Digital Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Histology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Whole Slide Imaging (WSI)</span>
                    
                    <span class="tag tag-keyword">Computational Pathology</span>
                    
                    <span class="tag tag-keyword">Transformer Models</span>
                    
                    <span class="tag tag-keyword">Tile Contextualization</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Medical Image Analysis</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ''any'' application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from ''any'' tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>