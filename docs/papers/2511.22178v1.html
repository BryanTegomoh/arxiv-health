<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph Attention for Autism Spectrum Disorder Classification - Health AI Hub</title>
    <meta name="description" content="This paper introduces an enhanced Graph Convolutional Network (GCN) model, integrating Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph Attention for Autism Spectrum Disorder Classification</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.22178v1" target="_blank">2511.22178v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-27
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Adnan Ferdous Ashrafi, Hasanul Kabir
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.22178v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.22178v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces an enhanced Graph Convolutional Network (GCN) model, integrating Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), to improve the classification accuracy of Autism Spectrum Disorder (ASD). Leveraging multimodal neuroimaging and phenotypic data from the ABIDE I dataset, the model achieved a test accuracy of 74.82% and an AUC of 0.82, outperforming existing state-of-the-art baselines for ASD diagnosis.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a more objective and potentially earlier diagnostic tool for Autism Spectrum Disorder, which is critical given the disorder's varied clinical presentation and current diagnostic challenges. Improved diagnostic accuracy can lead to earlier and more targeted interventions, ultimately enhancing patient care and outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to develop a more accurate and objective diagnostic tool for Autism Spectrum Disorder (ASD) using multimodal neuroimaging and phenotypic data. This involves classifying individuals as having ASD or not, which can aid clinicians in early diagnosis and intervention, thereby improving patient outcomes in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A novel GCN model is proposed, enhanced with Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), specifically for ASD classification.</li>
                    
                    <li>The model utilizes multimodal data: resting-state functional MRI (rs-fMRI), structural MRI (sMRI), and phenotypic variables from the ABIDE I dataset (870 patients).</li>
                    
                    <li>It employs a multi-branch architecture, processing each modality individually before merging them via concatenation for comprehensive feature integration.</li>
                    
                    <li>A population graph structure is generated using site-based similarity, which helps encode and leverage relationship connections across individuals.</li>
                    
                    <li>Chebyshev polynomial filters are incorporated for localized spectral learning, contributing to lower computational complexity.</li>
                    
                    <li>GAT layers enhance node representations by performing attention-weighted aggregation of information from surrounding nodes, improving feature learning.</li>
                    
                    <li>The model achieved a test accuracy of 74.82% and an AUC of 0.82, significantly surpassing conventional GCNs, autoencoder-based deep neural networks, and multimodal CNNs.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed an enhanced Graph Convolutional Network (GCN) that integrates Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT). This model utilizes a multi-branch architecture to process multimodal data (rs-fMRI, sMRI, phenotypic variables) individually before concatenating the features. A population graph was constructed based on site-based similarity to capture inter-individual relationships. Chebyshev polynomial filters were used for localized spectral learning, while GAT layers facilitated attention-weighted aggregation of node information. The model was trained using stratified five-fold cross-validation on the ABIDE I dataset.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed enhanced GCN model achieved a test accuracy of 74.82% and an AUC of 0.82 for Autism Spectrum Disorder classification. This performance significantly surpassed several state-of-the-art baseline models, including conventional GCNs, autoencoder-based deep neural networks, and multimodal convolutional neural networks, demonstrating its superior capability in leveraging complex multimodal data for diagnostic prediction.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This model has the potential to offer a more accurate and objective diagnostic aid for Autism Spectrum Disorder, complementing existing clinical assessments. Such an objective tool could facilitate earlier and more precise diagnosis, enabling timely therapeutic interventions and the development of personalized management strategies, thereby improving the long-term prognosis and quality of life for individuals with ASD.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the provided abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the provided abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Developmental Pediatrics</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Neuroscience</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Autism Spectrum Disorder</span>
                    
                    <span class="tag tag-keyword">Graph Convolutional Network</span>
                    
                    <span class="tag tag-keyword">Chebyshev Spectral Graph</span>
                    
                    <span class="tag tag-keyword">Graph Attention Networks</span>
                    
                    <span class="tag tag-keyword">Multimodal Neuroimaging</span>
                    
                    <span class="tag tag-keyword">rs-fMRI</span>
                    
                    <span class="tag tag-keyword">sMRI</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">ASD is a complicated neurodevelopmental disorder marked by variation in symptom presentation and neurological underpinnings, making early and objective diagnosis extremely problematic. This paper presents a Graph Convolutional Network (GCN) model, incorporating Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), to increase the classification accuracy of ASD utilizing multimodal neuroimaging and phenotypic data. Leveraging the ABIDE I dataset, which contains resting-state functional MRI (rs-fMRI), structural MRI (sMRI), and phenotypic variables from 870 patients, the model leverages a multi-branch architecture that processes each modality individually before merging them via concatenation. Graph structure is encoded using site-based similarity to generate a population graph, which helps in understanding relationship connections across individuals. Chebyshev polynomial filters provide localized spectral learning with lower computational complexity, whereas GAT layers increase node representations by attention-weighted aggregation of surrounding information. The proposed model is trained using stratified five-fold cross-validation with a total input dimension of 5,206 features per individual. Extensive trials demonstrate the enhanced model's superiority, achieving a test accuracy of 74.82\% and an AUC of 0.82 on the entire dataset, surpassing multiple state-of-the-art baselines, including conventional GCNs, autoencoder-based deep neural networks, and multimodal CNNs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>6 pages, 2 figures, 2 tables, Accepted and presented at Image and Vision Computing New Zealand (IVCNZ) 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>