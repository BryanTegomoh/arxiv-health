<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics - Health AI Hub</title>
    <meta name="description" content="ErrEval proposes an innovative Error-aware Evaluation framework for Automatic Question Generation (QG) to address critical defects like factual hallucinations a">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.10406v1" target="_blank">2601.10406v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-15
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.80 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.10406v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.10406v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">ErrEval proposes an innovative Error-aware Evaluation framework for Automatic Question Generation (QG) to address critical defects like factual hallucinations and answer mismatches, which are often overlooked by existing holistic evaluation methods. It reformulates evaluation as a two-stage process involving explicit error diagnosis followed by informed LLM scoring. Experiments confirm ErrEval's effectiveness in improving alignment with human judgments and mitigating the overestimation of low-quality questions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>In medical and health contexts, accurate and reliable information is paramount, making robust quality control for automatically generated content critical. ErrEval can significantly improve the quality assurance of AI-generated medical questions for applications like patient education, clinical decision support systems, or medical chatbot interactions, directly addressing potential factual inaccuracies and preventing misinformation or misguidance.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>ErrEval provides a critical tool for evaluating the quality and safety of AI systems that generate questions for medical and healthcare contexts. By explicitly diagnosing and categorizing errors like factual hallucinations and answer mismatches, it enables the development of more reliable medical AI applications used in areas such as creating medical exam questions, generating patient-friendly health FAQs, formulating clinical queries, or powering health information chatbots.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing QG evaluation methods, including LLM-based ones, predominantly use a black-box, holistic paradigm, leading to the neglect of critical defects like factual hallucinations and answer mismatches.</li>
                    
                    <li>This oversight results in an overestimation of the quality of generated questions, failing to accurately reflect their real utility and reliability.</li>
                    
                    <li>ErrEval is introduced as a flexible, Error-aware Evaluation framework designed to enhance QG evaluation through explicit error diagnostics.</li>
                    
                    <li>The framework operates in a two-stage process: first, a lightweight, plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects.</li>
                    
                    <li>Second, these diagnostic error signals are explicitly incorporated as evidence to guide LLM evaluators, enabling them to make more fine-grained and grounded quality judgments.</li>
                    
                    <li>Extensive experiments across three benchmarks demonstrated that the incorporation of explicit diagnostics significantly improves the alignment of automatic evaluations with human judgments.</li>
                    
                    <li>ErrEval effectively mitigates the common problem of overestimating the quality of low-quality questions, providing a more accurate and reliable assessment of QG system outputs.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ErrEval employs a two-stage evaluation process. The first stage utilizes a lightweight, plug-and-play Error Identifier to detect and categorize common errors in generated questions, spanning structural, linguistic, and content-related aspects. In the second stage, these explicit diagnostic error signals are provided as evidence to guide LLM evaluators, enabling them to produce more fine-grained and grounded quality judgments.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings demonstrate that ErrEval significantly improves the alignment of automatic Question Generation (QG) evaluations with human judgments. A crucial finding is its effectiveness in mitigating the overestimation of low-quality questions, leading to more accurate and reliable assessments of QG system performance.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework has the potential to enhance the trustworthiness and utility of AI-powered tools in healthcare by ensuring the high quality and accuracy of automatically generated medical questions. It can improve patient safety and outcomes by reducing the risk of misinformation from generative AI systems used in patient education, symptom checkers, clinical guidelines, or AI-assisted diagnostic tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly mention specific limitations of the ErrEval framework itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for ErrEval.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical education</span>
                    
                    <span class="tag">Clinical informatics</span>
                    
                    <span class="tag">Patient engagement</span>
                    
                    <span class="tag">Diagnostic support systems</span>
                    
                    <span class="tag">Medical natural language processing (NLP)</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Question Generation (QG)</span>
                    
                    <span class="tag tag-keyword">LLM evaluation</span>
                    
                    <span class="tag tag-keyword">Error detection</span>
                    
                    <span class="tag tag-keyword">Factual hallucination</span>
                    
                    <span class="tag tag-keyword">Answer mismatch</span>
                    
                    <span class="tag tag-keyword">Evaluation metrics</span>
                    
                    <span class="tag tag-keyword">Error diagnostics</span>
                    
                    <span class="tag tag-keyword">AI in healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>