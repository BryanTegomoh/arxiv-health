<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics - Health AI Hub</title>
    <meta name="description" content="This paper introduces ErrEval, an Error-aware Evaluation framework designed to address critical defects like factual hallucinations and answer mismatches in aut">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.10406v1" target="_blank">2601.10406v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-15
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.80 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.10406v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.10406v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ErrEval, an Error-aware Evaluation framework designed to address critical defects like factual hallucinations and answer mismatches in automatic Question Generation (QG) outputs, which are often overlooked by existing black-box evaluation methods. ErrEval reformulates evaluation as a two-stage process: explicit error diagnosis by a lightweight identifier, followed by informed scoring using LLM evaluators guided by these diagnostic signals. Experiments show ErrEval significantly improves alignment with human judgments and effectively mitigates the overestimation of low-quality generated questions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Question Generation models have significant potential in medicine for applications like medical education (generating quiz questions), clinical decision support (formulating diagnostic queries from patient data), and patient information systems. The accuracy and reliability of these generated questions are paramount in healthcare, as defects like factual hallucinations or answer mismatches could lead to severe consequences, including misdiagnosis, inappropriate treatment, or patient misinformation.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research provides a more robust evaluation framework for AI systems that generate questions or information in healthcare settings. It enhances the reliability and safety of medical AI applications by ensuring that generated content, crucial for tasks like medical training or patient information, is factually accurate and free from critical defects. This is vital for AI-powered medical tutors, patient information chatbots, AI assistants for clinicians, and systems generating explanations or summaries of medical data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current QG evaluation methods, including LLM-based ones, are black-box and holistic, leading to the neglect of critical defects (e.g., factual hallucinations, answer mismatches) and overestimation of question quality.</li>
                    
                    <li>ErrEval proposes a flexible, Error-aware Evaluation framework that incorporates explicit error diagnostics to enhance QG evaluation.</li>
                    
                    <li>The framework operates in two stages: first, a lightweight, plug-and-play Error Identifier detects and categorizes common structural, linguistic, and content-related errors.</li>
                    
                    <li>Second, these explicit diagnostic signals serve as evidence to guide LLM evaluators, enabling more fine-grained and grounded judgments of question quality.</li>
                    
                    <li>Extensive experiments on three benchmarks demonstrate that ErrEval significantly improves alignment between automatic evaluations and human judgments.</li>
                    
                    <li>A key finding is that ErrEval effectively mitigates the overestimation of low-quality questions, providing a more realistic assessment of QG model performance.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ErrEval employs a two-stage evaluation process: an initial error diagnosis stage utilizing a lightweight, plug-and-play Error Identifier to detect and categorize common errors across structural, linguistic, and content-related aspects of generated questions. This is followed by an informed scoring stage, where the identified diagnostic signals are explicitly incorporated to guide Large Language Model (LLM) evaluators, enabling them to make more fine-grained and grounded judgments of question quality.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings are that ErrEval significantly improves the alignment of automatic QG evaluations with human judgments. It effectively mitigates the common problem of overestimating the quality of low-quality questions, providing a more accurate and critical assessment of QG model outputs through explicit error diagnostics.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>ErrEval's ability to explicitly identify and account for critical errors such as factual hallucinations and answer mismatches is vital for enhancing the trustworthiness and safety of AI-generated content in healthcare. This framework enables the development and deployment of more reliable QG systems for medical training, patient education materials, and tools that extract knowledge from complex clinical texts, thereby reducing the risk of medical errors stemming from inaccurate or misleading AI output.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the ErrEval framework itself, but rather frames ErrEval as a solution to the limitations of existing QG evaluation methods.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for ErrEval.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Education</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Patient Information Systems</span>
                    
                    <span class="tag">Biomedical Natural Language Processing</span>
                    
                    <span class="tag">Healthcare AI Safety</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Question Generation (QG)</span>
                    
                    <span class="tag tag-keyword">AI Evaluation</span>
                    
                    <span class="tag tag-keyword">Error Diagnosis</span>
                    
                    <span class="tag tag-keyword">LLM Evaluation</span>
                    
                    <span class="tag tag-keyword">Factual Hallucination</span>
                    
                    <span class="tag tag-keyword">Answer Mismatch</span>
                    
                    <span class="tag tag-keyword">Human Alignment</span>
                    
                    <span class="tag tag-keyword">AI Reliability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>