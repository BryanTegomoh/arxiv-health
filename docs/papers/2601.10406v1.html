<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics - Health AI Hub</title>
    <meta name="description" content="ErrEval is an error-aware evaluation framework designed to improve automatic Question Generation (QG) assessment by explicitly diagnosing critical defects like ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.10406v1" target="_blank">2601.10406v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-15
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Weiping Fu, Bifan Wei, Jingyi Hao, Yushun Zhang, Jian Zhang, Jiaxin Wang, Bo Li, Yu He, Lingling Zhang, Jun Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.75 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.10406v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.10406v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">ErrEval is an error-aware evaluation framework designed to improve automatic Question Generation (QG) assessment by explicitly diagnosing critical defects like factual hallucinations and answer mismatches. It employs a two-stage process involving a dedicated error identifier and subsequent informed LLM-based scoring, demonstrating enhanced alignment with human judgments and effectively mitigating the overestimation of low-quality generated questions. This approach addresses the limitations of existing black-box evaluation methods that often overlook significant errors.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>In medical and health contexts, the accuracy and reliability of information are paramount. AI-generated questions, if critically flawed by factual hallucinations or answer mismatches, could lead to severe misinformation for patients, misguidance for clinicians, or ineffective learning in medical education. ErrEval's ability to explicitly detect and mitigate these critical errors ensures higher trustworthiness and safety for AI applications leveraging Question Generation in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>An AI application in health could use QG to automatically create study questions for medical students from textbooks or clinical cases, generate FAQs for patients about their conditions or treatments, or assist clinicians by formulating precise questions to query large medical knowledge bases or electronic health records for diagnostic or treatment guidance. ErrEval would serve as a critical component in validating the quality and factual accuracy of the questions generated by such medical AI systems, thereby enhancing their reliability and mitigating risks associated with inaccurate or misleading information.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing QG evaluation methods, including LLM-based evaluators, adopt a black-box, holistic paradigm that often neglects critical defects (e.g., factual hallucinations, answer mismatches), leading to an overestimation of question quality.</li>
                    
                    <li>ErrEval proposes a flexible, two-stage, error-aware evaluation framework that first diagnoses explicit errors before performing informed scoring.</li>
                    
                    <li>The first stage utilizes a lightweight, plug-and-play Error Identifier to detect and categorize common errors across structural, linguistic, and content-related aspects of generated questions.</li>
                    
                    <li>Diagnostic signals from the Error Identifier are then incorporated as explicit evidence to guide Large Language Model (LLM) evaluators toward more fine-grained and grounded judgments.</li>
                    
                    <li>Extensive experiments on three benchmarks demonstrate that ErrEval significantly improves alignment with human judgments compared to existing evaluation methods.</li>
                    
                    <li>ErrEval effectively mitigates the overestimation of low-quality questions, providing a more accurate and reliable assessment of QG system performance.</li>
                    
                    <li>The framework enhances QG evaluation through explicit error diagnostics, making the evaluation process more transparent and robust.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ErrEval reformulates QG evaluation into a two-stage process. The first stage employs a lightweight, plug-and-play Error Identifier to automatically detect and categorize errors, including structural, linguistic, and content-related defects such as factual hallucinations and answer mismatches. The second stage uses these explicit diagnostic signals to inform and guide LLM evaluators, enabling them to make more fine-grained and grounded judgments on question quality. The effectiveness of ErrEval was validated through extensive experiments conducted on three distinct QG benchmarks, measuring its alignment with human judgments.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>ErrEval significantly improves the alignment of automatic QG evaluations with human judgments. It effectively addresses and mitigates the problem of overestimating the quality of low-quality questions generated by QG systems. The framework's explicit error diagnostics lead to more fine-grained and grounded evaluations by LLM-based systems, enhancing the overall reliability and accuracy of QG assessment.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By providing a more robust and accurate method for evaluating AI-generated questions, ErrEval can directly enhance the reliability and safety of AI tools in clinical practice. This includes ensuring the quality of questions generated for patient education materials, clinical decision support prompts, medical quizzes for training, or summarizing complex medical literature, thereby reducing the risk of medical errors or misinformation stemming from flawed AI outputs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the ErrEval framework itself; instead, it highlights how ErrEval addresses the limitations of existing evaluation methods (e.g., black-box nature, neglect of critical defects).</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions for ErrEval.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical education</span>
                    
                    <span class="tag">Clinical decision support</span>
                    
                    <span class="tag">Patient information systems</span>
                    
                    <span class="tag">Health informatics</span>
                    
                    <span class="tag">Medical research data analysis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Question Generation (QG)</span>
                    
                    <span class="tag tag-keyword">AI evaluation</span>
                    
                    <span class="tag tag-keyword">Error detection</span>
                    
                    <span class="tag tag-keyword">LLM evaluators</span>
                    
                    <span class="tag tag-keyword">Factual hallucination</span>
                    
                    <span class="tag tag-keyword">Answer mismatch</span>
                    
                    <span class="tag tag-keyword">Diagnostic AI</span>
                    
                    <span class="tag tag-keyword">Medical informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>