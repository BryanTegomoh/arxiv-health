<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Filtering instances and rejecting predictions to obtain reliable models in healthcare - Health AI Hub</title>
    <meta name="description" content="This research proposes a novel two-step data-centric approach to enhance the reliability of Machine Learning (ML) models, particularly for high-stakes healthcar">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Filtering instances and rejecting predictions to obtain reliable models in healthcare</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24368v1" target="_blank">2510.24368v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Maria Gabriela Valeriano, David Kohan Marzag√£o, Alfredo Montelongo, Carlos Roberto Veiga Kiffer, Natan Katz, Ana Carolina Lorena
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24368v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24368v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This research proposes a novel two-step data-centric approach to enhance the reliability of Machine Learning (ML) models, particularly for high-stakes healthcare applications. It combines Instance Hardness (IH) filtering during training to improve data quality with a confidence-based rejection mechanism during inference to ensure only reliable predictions are retained, demonstrating improved model reliability on real-world healthcare datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work addresses the critical need for reliable and trustworthy predictions from ML models in high-stakes healthcare settings, where incorrect or low-confidence outputs can have severe consequences for patient care and safety. By ensuring predictions are only made when confidence is high and by improving the quality of training data, it enhances the safety and clinical utility of AI tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This paper addresses a critical challenge in the deployment of AI/ML models in healthcare: ensuring the reliability and trustworthiness of predictions. By proposing methods to filter problematic data and reject low-confidence predictions, it aims to enhance the safety and utility of AI systems used for tasks such as diagnosis, prognosis, and treatment planning, thereby facilitating their responsible adoption in clinical practice.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Introduces a novel two-step data-centric methodology to improve ML model reliability by enhancing data quality and filtering low-confidence predictions.</li>
                    
                    <li>Step 1: Leverages Instance Hardness (IH) to identify and filter out 'problematic instances' from the training dataset, thereby refining data quality.</li>
                    
                    <li>Step 2: Implements a confidence-based rejection mechanism during the inference phase, ensuring that only predictions exceeding a certain confidence threshold are retained and utilized.</li>
                    
                    <li>Evaluated on three distinct real-world healthcare datasets, demonstrating its effectiveness in significantly improving model reliability.</li>
                    
                    <li>The approach successfully balances predictive performance with a controlled rejection rate, ensuring useful model output while minimizing unreliable predictions.</li>
                    
                    <li>The proposed method was compared against alternative baseline criteria ‚Äì influence values for filtering and uncertainty for rejection ‚Äì highlighting its efficiency and superior performance.</li>
                    
                    <li>The integration of IH filtering with confidence-based rejection was shown to effectively enhance model performance while preserving a large proportion of the original data instances, making it practical for deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a two-step data-centric approach. First, during the training phase, Instance Hardness (IH) is employed as a criterion to identify and filter out 'problematic instances' from the training dataset, thereby refining the data quality and enhancing model learning. Second, during the inference phase, a confidence-based rejection mechanism is applied. This mechanism assesses the confidence of each prediction and only retains those that meet a pre-defined confidence threshold, rejecting low-confidence predictions. The approach was evaluated on three real-world healthcare datasets and compared against baseline methods utilizing influence values for filtering and uncertainty for rejection.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The integration of Instance Hardness (IH) filtering with confidence-based prediction rejection significantly enhances the reliability and overall performance of Machine Learning models in healthcare. This combined approach effectively improves data quality and ensures that only high-confidence predictions are presented, successfully balancing predictive performance with a manageable rejection rate while preserving a substantial portion of the dataset. The proposed method demonstrated superior efficiency compared to alternative filtering and rejection criteria.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This approach offers a practical and robust method for deploying ML systems in safety-critical clinical applications. By providing clinicians with only high-confidence predictions and ensuring the underlying models are trained on higher quality, less ambiguous data, it significantly reduces the risk of erroneous medical decisions. This can improve trust in AI-powered diagnostic, prognostic, and clinical decision support tools, leading to safer and more effective patient care by minimizing the propagation of unreliable model outputs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any specific limitations of the proposed method itself, but rather highlights the limitations of existing ML models (failing to account for uncertainty) which their method aims to address.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Diagnostics</span>
                    
                    <span class="tag">Prognostics</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Risk Stratification</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Healthcare</span>
                    
                    <span class="tag tag-keyword">Model Reliability</span>
                    
                    <span class="tag tag-keyword">Instance Hardness</span>
                    
                    <span class="tag tag-keyword">Confidence-based Rejection</span>
                    
                    <span class="tag tag-keyword">Data Quality</span>
                    
                    <span class="tag tag-keyword">Uncertainty Quantification</span>
                    
                    <span class="tag tag-keyword">Safety-critical Systems</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Machine Learning (ML) models are widely used in high-stakes domains such as
healthcare, where the reliability of predictions is critical. However, these
models often fail to account for uncertainty, providing predictions even with
low confidence. This work proposes a novel two-step data-centric approach to
enhance the performance of ML models by improving data quality and filtering
low-confidence predictions. The first step involves leveraging Instance
Hardness (IH) to filter problematic instances during training, thereby refining
the dataset. The second step introduces a confidence-based rejection mechanism
during inference, ensuring that only reliable predictions are retained. We
evaluate our approach using three real-world healthcare datasets, demonstrating
its effectiveness at improving model reliability while balancing predictive
performance and rejection rate. Additionally, we use alternative criteria -
influence values for filtering and uncertainty for rejection - as baselines to
evaluate the efficiency of the proposed method. The results demonstrate that
integrating IH filtering with confidence-based rejection effectively enhances
model performance while preserving a large proportion of instances. This
approach provides a practical method for deploying ML systems in
safety-critical applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This paper is under review at Machine Learning (Springer)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>