<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Filtering instances and rejecting predictions to obtain reliable models in healthcare - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel two-step data-centric approach to enhance the reliability of Machine Learning (ML) models, particularly in high-stakes domains lik">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Filtering instances and rejecting predictions to obtain reliable models in healthcare</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24368v1" target="_blank">2510.24368v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Maria Gabriela Valeriano, David Kohan Marzag√£o, Alfredo Montelongo, Carlos Roberto Veiga Kiffer, Natan Katz, Ana Carolina Lorena
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24368v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24368v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel two-step data-centric approach to enhance the reliability of Machine Learning (ML) models, particularly in high-stakes domains like healthcare, by addressing prediction uncertainty. The method involves filtering problematic instances during training using Instance Hardness (IH) and implementing a confidence-based rejection mechanism during inference. Evaluated on real-world healthcare datasets, the approach significantly improves model reliability by retaining only high-confidence predictions while balancing predictive performance and rejection rates.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Reliable ML predictions are paramount in healthcare for accurate diagnosis, treatment planning, and risk assessment. This work directly addresses the critical issue of uncertainty in ML models, offering a robust method to ensure that clinical decisions supported by AI are based on highly confident and trustworthy predictions, thereby enhancing patient safety and care quality.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research focuses on improving the reliability and trustworthiness of Machine Learning models specifically for deployment in healthcare settings. This involves filtering problematic data instances and rejecting low-confidence predictions to ensure that AI systems used in medicine provide more dependable outputs, which is crucial for patient safety and effective clinical decision-making. It aims to make AI applications in healthcare safer and more robust.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>ML models in healthcare often provide low-confidence predictions without accounting for uncertainty, posing reliability risks.</li>
                    
                    <li>A two-step data-centric approach is proposed: Instance Hardness (IH) for filtering problematic training instances and a confidence-based rejection mechanism for inference.</li>
                    
                    <li>IH filtering refines the training dataset, improving data quality and model learning.</li>
                    
                    <li>Confidence-based rejection ensures only reliable, high-confidence predictions are retained during deployment.</li>
                    
                    <li>The approach was evaluated using three real-world healthcare datasets, demonstrating improved model reliability.</li>
                    
                    <li>It effectively balances enhanced predictive performance with a controlled rejection rate, preserving a large proportion of instances.</li>
                    
                    <li>Baselines using influence values for filtering and uncertainty for rejection were used for comparative evaluation, highlighting the efficiency of the proposed method.</li>
                    
                    <li>Provides a practical solution for deploying more trustworthy ML systems in safety-critical applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed methodology is a two-step data-centric approach. The first step utilizes Instance Hardness (IH) values to identify and filter 'problematic' or hard-to-learn instances from the training dataset, thereby enhancing data quality and model training. The second step introduces a confidence-based rejection mechanism applied during the inference phase, where predictions below a certain confidence threshold are rejected, ensuring only highly reliable predictions are presented. The approach was evaluated on three real-world healthcare datasets and compared against baselines that used influence values for filtering and uncertainty quantification for rejection.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study found that integrating Instance Hardness (IH) filtering with confidence-based prediction rejection significantly enhances the overall reliability and performance of ML models in healthcare. This method effectively balances improved predictive performance with a controlled rejection rate, ensuring that a large proportion of instances are still utilized for predictions. The proposed approach was demonstrated to be effective and efficient compared to alternative baseline criteria.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a crucial practical method for the safer and more reliable deployment of Machine Learning systems in clinical settings. By proactively filtering problematic data and rejecting low-confidence predictions, clinicians can have greater trust in AI-driven decision support tools, reducing the risk of errors from uncertain predictions. This can lead to more accurate diagnoses, optimized treatment pathways, and ultimately, improved patient outcomes, accelerating the adoption of AI in critical healthcare workflows.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the proposed method or its evaluation. Potential limitations, not stated in the abstract, could include the computational cost of IH calculation, the generalizability of optimal confidence thresholds across diverse healthcare tasks, or the impact of rejected instances on specific clinical workflows.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. Potential future work, not stated in the abstract, could involve exploring dynamic confidence thresholds, applying the approach to a wider range of high-stakes medical AI tasks (e.g., medical imaging, genomics), or investigating the ethical implications and user acceptance of prediction rejection in clinical practice.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Personalized Medicine</span>
                    
                    <span class="tag">Predictive Analytics (e.g., disease risk, treatment response)</span>
                    
                    <span class="tag">Patient Monitoring</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                    <span class="tag tag-keyword">Model Reliability</span>
                    
                    <span class="tag tag-keyword">Uncertainty Quantification</span>
                    
                    <span class="tag tag-keyword">Instance Hardness</span>
                    
                    <span class="tag tag-keyword">Prediction Rejection</span>
                    
                    <span class="tag tag-keyword">Data Quality</span>
                    
                    <span class="tag tag-keyword">Safety-Critical Applications</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Machine Learning (ML) models are widely used in high-stakes domains such as
healthcare, where the reliability of predictions is critical. However, these
models often fail to account for uncertainty, providing predictions even with
low confidence. This work proposes a novel two-step data-centric approach to
enhance the performance of ML models by improving data quality and filtering
low-confidence predictions. The first step involves leveraging Instance
Hardness (IH) to filter problematic instances during training, thereby refining
the dataset. The second step introduces a confidence-based rejection mechanism
during inference, ensuring that only reliable predictions are retained. We
evaluate our approach using three real-world healthcare datasets, demonstrating
its effectiveness at improving model reliability while balancing predictive
performance and rejection rate. Additionally, we use alternative criteria -
influence values for filtering and uncertainty for rejection - as baselines to
evaluate the efficiency of the proposed method. The results demonstrate that
integrating IH filtering with confidence-based rejection effectively enhances
model performance while preserving a large proportion of instances. This
approach provides a practical method for deploying ML systems in
safety-critical applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This paper is under review at Machine Learning (Springer)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>