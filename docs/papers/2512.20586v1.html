<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent - Health AI Hub</title>
    <meta name="description" content="This paper introduces SAGE (Secure Agent for Generative Dose Expertise), a large language model (LLM) agent designed for automated stereotactic radiosurgery (SR">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.20586v1" target="_blank">2512.20586v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI, cs.CL, cs.HC
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.20586v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.20586v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SAGE (Secure Agent for Generative Dose Expertise), a large language model (LLM) agent designed for automated stereotactic radiosurgery (SRS) planning, focusing on improving transparency through chain-of-thought reasoning. The reasoning variant of SAGE produced plan dosimetry comparable to human experts, significantly reduced cochlear dose, and generated auditable planning logs demonstrating systematic deliberative processes, addressing key barriers to AI adoption in radiation oncology.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine as it introduces a transparent AI solution for highly precise radiation therapy planning, potentially improving treatment quality (e.g., organ-at-risk sparing) and operational efficiency. By providing auditable planning logs, it addresses a major hurdle in AI adoption within oncology by fostering trust and accountability in automated decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The development and evaluation of SAGE, an LLM-based agent, for automated, transparent, and explainable treatment planning in stereotactic radiosurgery (SRS) for patients with brain metastases. This aims to improve precision, efficiency, and safety in radiation treatment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed**: The study targets the complexity and precision demands of SRS planning, particularly the lack of clinical adoption of opaque 'black-box' AI systems due to trust and transparency concerns.</li>
                    
                    <li>**Novel LLM Agent**: SAGE, an LLM-based agent, was developed for automated SRS treatment planning, incorporating a 'human-in-the-loop' reasoning mechanism.</li>
                    
                    <li>**Comparative Study Design**: A retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS was used to compare plans generated by SAGE's reasoning and non-reasoning variants against human planners.</li>
                    
                    <li>**Dosimetric Performance**: The reasoning SAGE variant achieved comparable plan dosimetry to human planners across primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) and significantly reduced cochlear dose (p = 0.022) below human baselines.</li>
                    
                    <li>**Enhanced Transparency and Deliberation**: The reasoning model demonstrated systematic planning behaviors, including 457 instances of prospective constraint verification and 609 instances of trade-off deliberation, processes entirely absent or minimal in the non-reasoning model.</li>
                    
                    <li>**Auditable Planning Logs**: The optimization traces produced by the reasoning agent serve as auditable logs, offering clear insights into planning decisions and causal explanations, thereby providing a path toward transparent automated planning.</li>
                    
                    <li>**Clinical Feasibility**: The findings suggest that LLM-driven agents can not only match human performance in complex medical planning but also provide the necessary transparency and justification for clinical integration and trust.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved developing an LLM-based planning agent, SAGE, with two variants: a non-reasoning model and a reasoning model employing chain-of-thought. These variants generated SRS plans for a retrospective cohort of 41 brain metastasis patients (18 Gy single-fraction SRS). Plan dosimetry metrics (PTV coverage, max dose, conformity, gradient index, cochlear dose) were quantitatively compared against human-generated plans. Qualitative content analysis of optimization traces was conducted to assess deliberative processes like constraint verification and trade-off deliberation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The reasoning LLM agent achieved dosimetric equivalence to human planners for primary plan quality metrics (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) and significantly reduced cochlear dose (p = 0.022). Critically, the reasoning model exhibited systematic planning behaviors, including 457 instances of prospective constraint verification and 609 instances of trade-off deliberation, processes largely absent in the non-reasoning model. These optimization traces provide auditable logs for transparent planning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research paves the way for automating complex SRS planning, potentially improving efficiency, consistency, and plan quality, particularly in organ-at-risk sparing. The provision of auditable, transparent planning logs could significantly increase clinician trust and accelerate the clinical adoption of AI in radiation therapy, leading to safer and more personalized treatments for patients with brain metastases and similar conditions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The study was conducted on a retrospective cohort, which may limit the generalizability of the findings compared to prospective studies. The focus was on single-fraction SRS for brain metastases, suggesting that applicability to other anatomical sites, fractionation schemes, or tumor types requires further validation. The term "human-in-the-loop" in the title implies that full autonomous planning without human oversight is not yet the immediate objective or fully demonstrated.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests that the auditable optimization traces offer a promising avenue for truly transparent automated planning. Future work could involve expanding SAGE's capabilities to a broader range of tumor sites and fractionation protocols, further prospective validation, and developing intuitive interfaces for clinicians to interact with and verify the detailed planning logs to ensure seamless integration into clinical workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiation Oncology</span>
                    
                    <span class="tag">Neurosurgery</span>
                    
                    <span class="tag">Medical Physics</span>
                    
                    <span class="tag">Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">stereotactic radiosurgery</span>
                    
                    <span class="tag tag-keyword">LLM</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">radiation oncology</span>
                    
                    <span class="tag tag-keyword">treatment planning</span>
                    
                    <span class="tag tag-keyword">explainable AI</span>
                    
                    <span class="tag tag-keyword">brain metastases</span>
                    
                    <span class="tag tag-keyword">dose optimization</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>