<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images - Health AI Hub</title>
    <meta name="description" content="This paper introduces VessShape, a novel methodology for generating large-scale 2D synthetic datasets designed to instill a strong shape bias in blood vessel se">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>VessShape: Few-shot 2D blood vessel segmentation by leveraging shape priors from synthetic images</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27646v1" target="_blank">2510.27646v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Cesar H. Comin, Wesley N. Galv√£o
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27646v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27646v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces VessShape, a novel methodology for generating large-scale 2D synthetic datasets designed to instill a strong shape bias in blood vessel segmentation models. By leveraging procedurally generated tubular geometries with diverse textures, VessShape enables models to learn geometric priors rather than texture-based features, leading to robust few-shot and zero-shot segmentation performance on real-world medical images across different modalities. The research demonstrates that pre-training with this shape bias effectively overcomes data scarcity and improves model generalization in a critical medical imaging task.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate blood vessel segmentation is fundamental for diagnosis, prognosis, and treatment planning in numerous medical conditions. This work directly tackles the significant hurdles of limited annotated medical data and models' inability to generalize across diverse imaging modalities, which are major bottlenecks for AI adoption in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI application for automated and highly accurate segmentation of blood vessels in medical images. This can assist clinicians in diagnosing diseases like strokes, aneurysms, diabetic retinopathy, and cancerous tumors by providing precise anatomical measurements and visualizations. It also helps in surgical planning, image-guided interventions, and monitoring disease progression, making AI models more adaptable to diverse real-world clinical data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenges of data scarcity and poor generalization across imaging modalities in blood vessel segmentation, attributing it to CNNs' tendency to learn texture-based features.</li>
                    
                    <li>Proposes the hypothesis that leveraging geometric shape priors (tubular, branching nature) can lead to more robust and data-efficient segmentation models.</li>
                    
                    <li>Introduces VessShape, a methodology for creating synthetic 2D datasets with procedurally generated tubular geometries and diverse textures, specifically designed to instill a shape bias in learning models.</li>
                    
                    <li>A model pre-trained on VessShape images achieved strong few-shot segmentation performance on two real-world datasets from different medical domains.</li>
                    
                    <li>The few-shot fine-tuning required remarkably few samples, ranging from only four to ten per target dataset.</li>
                    
                    <li>The pre-trained model exhibited notable zero-shot capabilities, successfully segmenting vessels in unseen domains without any target-specific training.</li>
                    
                    <li>Concludes that pre-training with a strong shape bias is an effective strategy to mitigate data scarcity and enhance model generalization in blood vessel segmentation.</li>
                    
                    <li>The synthetic data generation method encourages models to prioritize learning shape cues over texture cues, improving adaptability to new visual characteristics.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>VessShape is a methodology for generating large-scale 2D synthetic datasets. These datasets are procedurally created with intricate tubular vessel geometries combined with a wide variety of foreground and background textures. This design explicitly encourages Convolutional Neural Networks (CNNs) to learn geometric shape cues (a 'shape bias') rather than texture-based features. A segmentation model is then pre-trained on these synthetic images and subsequently evaluated for few-shot performance (with 4-10 samples for fine-tuning) and zero-shot generalization on real-world medical imaging datasets from different domains.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings indicate that pre-training models on VessShape's shape-biased synthetic data significantly improves generalization. Specifically, models achieved strong few-shot segmentation performance on two different real-world medical datasets, requiring only 4 to 10 samples for fine-tuning. Furthermore, the pre-trained model demonstrated notable zero-shot capabilities, effectively segmenting blood vessels in unseen imaging domains without any target-specific training or fine-tuning, demonstrating robust generalization across diverse visual characteristics.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to substantially accelerate the development and clinical deployment of AI-powered blood vessel segmentation tools. By drastically reducing the need for extensive, costly, and time-consuming manual annotations, it can make advanced diagnostic and therapeutic planning accessible for more diseases and patient populations. Improved generalization across modalities could lead to more consistent and reliable clinical assessments, assisting in early disease detection, treatment monitoring, and surgical guidance, particularly in resource-constrained environments or for rare conditions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, potential limitations could include the inherent 'reality gap' between synthetic and complex real-world medical data, and the current focus on 2D segmentation, whereas many clinical applications benefit from 3D or 4D analysis. The specific types and diversity of the 'two real-world datasets' used for evaluation are also not detailed.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated, future research directions could involve extending the VessShape methodology to 3D vessel segmentation, exploring its applicability to other tubular or branching structures in medical imaging (e.g., airways, nerve fibers), and validating its performance on a broader range of clinical datasets and diverse imaging modalities. Further investigation into combining this shape-bias pre-training with other domain adaptation or few-shot learning techniques could also be beneficial.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Vascular Surgery</span>
                    
                    <span class="tag">Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Blood vessel segmentation</span>
                    
                    <span class="tag tag-keyword">Few-shot learning</span>
                    
                    <span class="tag tag-keyword">Zero-shot learning</span>
                    
                    <span class="tag tag-keyword">Synthetic data</span>
                    
                    <span class="tag tag-keyword">Shape priors</span>
                    
                    <span class="tag tag-keyword">Medical image analysis</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Semantic segmentation of blood vessels is an important task in medical image
analysis, but its progress is often hindered by the scarcity of large annotated
datasets and the poor generalization of models across different imaging
modalities. A key aspect is the tendency of Convolutional Neural Networks
(CNNs) to learn texture-based features, which limits their performance when
applied to new domains with different visual characteristics. We hypothesize
that leveraging geometric priors of vessel shapes, such as their tubular and
branching nature, can lead to more robust and data-efficient models. To
investigate this, we introduce VessShape, a methodology for generating
large-scale 2D synthetic datasets designed to instill a shape bias in
segmentation models. VessShape images contain procedurally generated tubular
geometries combined with a wide variety of foreground and background textures,
encouraging models to learn shape cues rather than textures. We demonstrate
that a model pre-trained on VessShape images achieves strong few-shot
segmentation performance on two real-world datasets from different domains,
requiring only four to ten samples for fine-tuning. Furthermore, the model
exhibits notable zero-shot capabilities, effectively segmenting vessels in
unseen domains without any target-specific training. Our results indicate that
pre-training with a strong shape bias can be an effective strategy to overcome
data scarcity and improve model generalization in blood vessel segmentation.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>