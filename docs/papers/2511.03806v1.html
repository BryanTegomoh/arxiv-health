<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features - Health AI Hub</title>
    <meta name="description" content="FusionDP addresses the critical challenge of preserving patient privacy while maintaining model utility when only a subset of features is sensitive. This two-st">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03806v1" target="_blank">2511.03806v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Linghui Zeng, Ruixuan Liu, Atiquer Rahman Sarkar, Xiaoqian Jiang, Joyce C. Ho, Li Xiong
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03806v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03806v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">FusionDP addresses the critical challenge of preserving patient privacy while maintaining model utility when only a subset of features is sensitive. This two-step framework leverages large foundation models to impute sensitive features, then employs a modified differentially private stochastic gradient descent (DP-SGD) algorithm to train models on both original and imputed features, rigorously protecting the privacy of the original sensitive features. Evaluated on medical tasks like sepsis prediction and clinical note classification, FusionDP significantly enhances model performance compared to privacy-preserving baselines while maintaining strong feature-level privacy guarantees.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is paramount for healthcare as it enables the development of more accurate and robust AI models for critical applications, such as sepsis prediction, by allowing the safe and private utilization of sensitive patient data (e.g., age, gender) from sources like ICU records and EHRs without excessive utility degradation.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper focuses on developing a differentially private machine learning framework (FusionDP) that leverages foundation models to enable the training of high-utility AI models (e.g., for sepsis prediction, clinical note classification) using sensitive medical data, such as patient demographics and lab results, while rigorously protecting patient privacy. This directly contributes to making AI applications in healthcare more ethical, deployable, and effective by overcoming privacy barriers.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the problem of excessive noise and utility degradation in traditional DP-SGD when privacy protection is only required for a subset of features (e.g., demographic data in ICU vs. lab results).</li>
                    
                    <li>Proposes FusionDP, a novel two-step framework designed to enhance model utility under feature-level differential privacy.</li>
                    
                    <li>Step 1: Utilizes large foundation models to impute sensitive features based on non-sensitive features, treating these imputations as high-quality external priors without accessing the true sensitive values during model training.</li>
                    
                    <li>Step 2: Introduces a modified DP-SGD algorithm that trains models using both the original non-sensitive features and the foundation model-imputed sensitive features, ensuring formal privacy preservation specifically for the original sensitive features.</li>
                    
                    <li>Evaluated on two medical modalities: a sepsis prediction task using tabular data from PhysioNet and a clinical note classification task from MIMIC-III.</li>
                    
                    <li>FusionDP consistently outperforms privacy-preserving baselines by significantly improving model performance while maintaining rigorous feature-level differential privacy.</li>
                    
                    <li>Demonstrates the potential of foundation model-driven imputation to enhance the privacy-utility trade-off across various data modalities, particularly in healthcare settings.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>FusionDP employs a two-step process: 1) High-quality imputation of sensitive features is performed by leveraging pre-trained large foundation models, using only non-sensitive features as input. These imputed features act as external priors. 2) A custom-designed differentially private stochastic gradient descent (DP-SGD) algorithm trains the machine learning model. This modified algorithm processes both the original non-sensitive features and the foundation model-imputed sensitive features, while rigorously enforcing differential privacy specifically on the true sensitive features, not the imputed ones.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that FusionDP significantly improves the predictive performance (utility) of machine learning models on medical tasks, such as sepsis prediction and clinical note classification, when compared to standard privacy-preserving baselines. This performance gain is achieved while strictly adhering to rigorous feature-level differential privacy for sensitive patient attributes.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>FusionDP has the potential to facilitate the ethical and effective deployment of AI in healthcare by providing a method to build more accurate predictive models using sensitive patient data from sources like EHRs and ICU databases. This can lead to improved clinical decision support, better patient outcomes (e.g., earlier sepsis detection), and enhanced trust in AI systems by robustly protecting patient privacy without severely compromising model capabilities.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the FusionDP framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly outline specific future research directions for FusionDP, beyond demonstrating its potential to enhance the privacy-utility trade-off across various modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Intensive Care Unit (ICU) medicine</span>
                    
                    <span class="tag">Sepsis management</span>
                    
                    <span class="tag">Clinical decision support systems</span>
                    
                    <span class="tag">Health informatics</span>
                    
                    <span class="tag">Electronic Health Records (EHR) analysis</span>
                    
                    <span class="tag">Medical Natural Language Processing (NLP)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Differential Privacy</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Feature Imputation</span>
                    
                    <span class="tag tag-keyword">Sepsis Prediction</span>
                    
                    <span class="tag tag-keyword">Clinical Notes</span>
                    
                    <span class="tag tag-keyword">Privacy-Utility Trade-off</span>
                    
                    <span class="tag tag-keyword">Partially Sensitive Features</span>
                    
                    <span class="tag tag-keyword">DP-SGD</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>