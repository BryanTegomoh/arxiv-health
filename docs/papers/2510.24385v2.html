<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>When are radiology reports useful for training medical image classifiers? - Health AI Hub</title>
    <meta name="description" content="This paper systematically investigates the utility of integrating radiology reports during both pre-training and fine-tuning phases for medical image classifier">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>When are radiology reports useful for training medical image classifiers?</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24385v2" target="_blank">2510.24385v2</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Herman Bergstr√∂m, Zhongqi Yue, Fredrik D. Johansson
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24385v2" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24385v2" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper systematically investigates the utility of integrating radiology reports during both pre-training and fine-tuning phases for medical image classifiers, across diverse diagnostic and prognostic tasks. It reveals that while pre-training with reports benefits tasks where labels are explicit in text, fine-tuning with reports consistently yields significant improvements, often having a greater impact than the pre-training strategy itself. The findings provide actionable insights into optimizing the leverage of privileged text data in medical AI development.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for medicine as it provides a data-driven framework for effectively utilizing rich, expert-generated radiology reports to enhance the accuracy and reliability of AI models in medical image analysis, potentially leading to improved diagnostic precision and prognostic prediction in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application described is the development of more effective and accurate medical image classifiers. These classifiers can assist healthcare professionals in diagnosing diseases from medical images, predicting patient outcomes (like hospital readmission), and generally enhancing clinical prediction, ultimately leading to improved patient care and operational efficiency in healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study addresses a gap in prior research by systematically evaluating radiology report integration during both pre-training and fine-tuning for image-only classification.</li>
                    
                    <li>It examines the utility of reports across a spectrum of tasks, including both diagnostic labels (well-represented in text) and prognostic tasks (e.g., 12-month readmission, potentially weakly associated with text).</li>
                    
                    <li>The impact of leveraging reports is analyzed under varying training set sizes, providing insights into data efficiency and model robustness.</li>
                    
                    <li>Findings indicate that pre-training with reports is beneficial when the downstream task's label is well-represented in the text.</li>
                    
                    <li>Conversely, pre-training through explicit image-text alignment can be detrimental for tasks where the label is not strongly associated with the report text.</li>
                    
                    <li>Fine-tuning image classifiers with the aid of radiology reports consistently leads to significant performance improvements.</li>
                    
                    <li>The impact of fine-tuning with reports can, in certain settings, be more substantial than the choice of the pre-training method itself.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors conducted a systematic experimental study contrasting prior work's limitations. They evaluated the performance of medical image classifiers by incorporating radiology reports during both the pre-training and fine-tuning phases. The study encompassed diverse tasks, including diagnostic classifications where labels are explicit in text, and prognostic tasks (e.g., 12-month readmission) where labels may be weakly associated. The analysis also varied the training set sizes to assess performance under different data availability scenarios.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>1. Leveraging radiology reports during pre-training is advantageous for downstream classification tasks where the label is well-represented in the text; however, pre-training via explicit image-text alignment can be detrimental when the label is not well-represented in the text. 2. Fine-tuning medical image classifiers with the inclusion of radiology reports leads to significant performance improvements, with this impact sometimes surpassing the influence of the chosen pre-training method.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This study provides actionable guidance for developers of medical AI tools on when and how to integrate privileged textual data from radiology reports to train more effective image classifiers. This can lead to the development of more accurate and robust AI systems for diagnostic and prognostic predictions, ultimately improving clinical decision support, potentially reducing radiologist workload, and enhancing patient care through better-informed medical interventions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights limitations of prior research (e.g., being limited to pre-trained representations, focusing only on diagnostic labels, ignoring tasks weakly associated with text) which this study aims to address. It also notes that the work highlights "gaps in current research" generally, but does not explicitly detail limitations of this specific study within the provided abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The explicit mention of "highlighting gaps in current research" implies future research directions. These likely include further investigation into optimal image-text alignment strategies, especially for tasks with weak textual associations, exploring different architectural approaches for text-image fusion, and expanding the systematic analysis to a broader range of medical imaging modalities and complex clinical prediction problems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Healthcare AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Radiology Reports</span>
                    
                    <span class="tag tag-keyword">Medical Image Classification</span>
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Pre-training</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                    <span class="tag tag-keyword">Image-Text Alignment</span>
                    
                    <span class="tag tag-keyword">Diagnostic Tasks</span>
                    
                    <span class="tag tag-keyword">Prognostic Tasks</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical images used to train machine learning models are often accompanied by
radiology reports containing rich expert annotations. However, relying on these
reports as inputs for clinical prediction requires the timely manual work of a
trained radiologist. This raises a natural question: when can radiology reports
be leveraged during training to improve image-only classification? Prior works
are limited to evaluating pre-trained image representations by fine-tuning them
to predict diagnostic labels, often extracted from reports, ignoring tasks with
labels that are weakly associated with the text. To address this gap, we
conduct a systematic study of how radiology reports can be used during both
pre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,
12-month readmission), and under varying training set sizes. Our findings
reveal that: (1) Leveraging reports during pre-training is beneficial for
downstream classification tasks where the label is well-represented in the
text; however, pre-training through explicit image-text alignment can be
detrimental in settings where it's not; (2) Fine-tuning with reports can lead
to significant improvements and even have a larger impact than the pre-training
method in certain settings. These results provide actionable insights into when
and how to leverage privileged text data to train medical image classifiers
while highlighting gaps in current research.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>