<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study - Health AI Hub</title>
    <meta name="description" content="This application-grounded user study evaluates the real-world utility of Explainable AI (XAI) for scoring nocturnal arousal events in polysomnography, comparing">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.21389v1" target="_blank">2510.21389v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-24
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Stefan Kraft, Andreas Theissler, Vera Wienhausen-Wilke, Gjergji Kasneci, Hendrik Lensch
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI, cs.HC
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.21389v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.21389v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This application-grounded user study evaluates the real-world utility of Explainable AI (XAI) for scoring nocturnal arousal events in polysomnography, comparing black-box (BB) and white-box (WB) AI assistance at different integration points. It demonstrates that strategically timed, transparent AI assistance significantly enhances diagnostic accuracy and reduces inter-rater variability among sleep medicine practitioners, while also achieving high user acceptance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing the trustworthy integration of AI into clinical sleep medicine, addressing the need for clinicians to understand and trust algorithmic recommendations for diagnosing sleep disorders, thereby potentially improving diagnostic consistency and patient outcomes in polysomnography interpretation.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI system assists professional sleep medicine practitioners in scoring nocturnal arousal events from polysomnographic data. It evaluates different modes (black-box vs. transparent white-box) and timings (start-time vs. quality-control review) of AI assistance to optimize accuracy, efficiency, and user acceptance in clinical diagnostic workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A user study involved eight professional sleep medicine practitioners scoring nocturnal arousal events under three conditions: manual, black-box (BB) AI, and transparent white-box (WB) AI assistance.</li>
                    
                    <li>Assistance timing was systematically varied, provided either from the `start` of scoring or as a post-hoc `quality-control` (QC) review.</li>
                    
                    <li>Both AI and human-AI teams significantly outperformed unaided expert practitioners when evaluated against the AI's training standard, and collaboration also reduced inter-rater variability.</li>
                    
                    <li>Transparent WB AI assistance, particularly when applied as a targeted QC step, yielded approximately 30% improvement in median event-level performance over BB assistance.</li>
                    
                    <li>QC timing further enhanced clinically most relevant count-based outcomes, suggesting its importance for overall diagnostic utility.</li>
                    
                    <li>While WB and QC approaches increased the time required for scoring, start-time assistance was faster and generally preferred by most participants.</li>
                    
                    <li>Participants overwhelmingly favored transparency, with seven out of eight expressing willingness to adopt the system with minor or no modifications, highlighting strong user acceptance.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized an application-grounded user study design with eight professional sleep medicine practitioners. Participants scored nocturnal arousal events from polysomnographic data under three assistance conditions: manual scoring, black-box AI assistance, and transparent white-box AI assistance. Assistance was provided either at the start of scoring or as a post-hoc quality-control review. Performance was evaluated at event-level and count-based metrics (clinically relevant), alongside time requirements and user experience, using a clinical standard for AI training.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>AI-assisted and human-AI collaborative teams significantly surpassed the performance of unaided expert scorers in arousal diagnostics, concurrently reducing inter-rater variability. Specifically, transparent white-box AI assistance, when deployed as a quality control step, achieved a median ~30% improvement in event-level performance over black-box assistance, with QC timing also enhancing count-based outcomes. While WB and QC methods increased scoring time, start-time assistance was faster and preferred by most participants. Crucially, there was overwhelming user preference for transparency, with 7 out of 8 participants willing to adopt the system.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This study demonstrates that strategically timed transparent AI assistance can significantly improve the accuracy and consistency of nocturnal arousal event scoring in polysomnography, which is vital for diagnosing sleep disorders. By enhancing clinician trust and understanding through explainability and optimal timing (e.g., QC), it provides a viable pathway for integrating AI into routine clinical workflows that balances diagnostic quality, efficiency, and high user acceptance among medical practitioners.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats of the study, such as sample size of practitioners, specific generalizability constraints of the AI model, or potential long-term effects on clinician skill development.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests that its findings provide a "promising pathway toward trustworthy AI integration and user acceptance in clinical workflows." This implies future research will focus on further developing and implementing strategically timed transparent AI systems into broader clinical practice, evaluating their long-term impact on diagnostic quality, efficiency, and continued user acceptance, potentially expanding to other biomedical signal interpretation tasks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Sleep Medicine</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Pulmonology (related to sleep-disordered breathing)</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Explainable AI</span>
                    
                    <span class="tag tag-keyword">Polysomnography</span>
                    
                    <span class="tag tag-keyword">Arousal Diagnostics</span>
                    
                    <span class="tag tag-keyword">Sleep Medicine</span>
                    
                    <span class="tag tag-keyword">Human-AI Collaboration</span>
                    
                    <span class="tag tag-keyword">Clinical Workflow</span>
                    
                    <span class="tag tag-keyword">Trustworthy AI</span>
                    
                    <span class="tag tag-keyword">User Study</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>