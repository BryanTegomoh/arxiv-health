<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content - Health AI Hub</title>
    <meta name="description" content="This research evaluates the faithfulness and accuracy of Large Language Models (LLMs) (GPT-4o, Ansari AI, Fanar) in generating Islamic content, using a novel du">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24438v1" target="_blank">2510.24438v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Abdullah Mushtaq, Rafay Naeem, Ezieddin Elmahjub, Ibrahim Ghaznavi, Shawqi Al-Maliki, Mohamed Abdallah, Ala Al-Fuqaha, Junaid Qadir
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI, cs.CY, cs.MA
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.65 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24438v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24438v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This research evaluates the faithfulness and accuracy of Large Language Models (LLMs) (GPT-4o, Ansari AI, Fanar) in generating Islamic content, using a novel dual-agent evaluation framework. It found that while GPT-4o performed best quantitatively, and Ansari AI qualitatively, all models still fall short in reliably producing accurate and cited faith-sensitive content. The study highlights the critical need for robust, community-driven benchmarks for LLM content, especially in high-stakes domains like medicine.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine because it evaluates LLM fidelity in a 'high-stakes domain,' directly paralleling the critical need for accuracy and reliability in medical information. The identified risks of misinformation, misapplication of knowledge, and lack of reliable citation in Islamic content translate directly to potential patient harm if LLMs are similarly unreliable in medical guidance, diagnostics, or patient education.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research contributes foundational insights and evaluation methodologies for ensuring the faithfulness, accuracy, and reliability of Large Language Models (LLMs) used in medical and healthcare contexts. For example, LLMs deployed in clinical decision support, medical diagnostics, drug information dissemination, or patient-facing health information systems must avoid factual errors, misapplication of guidelines, or culturally/ethically inconsistent responses. The paper's approach to verifying citations, assessing consistency, and measuring accuracy is directly applicable to building robust benchmarks and evaluation frameworks for medical AI applications, thereby enhancing their safety and trustworthiness in high-stakes clinical scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>LLMs face significant risks (misquoting, misapplying, cultural inconsistency) when generating faith-sensitive content, necessitating rigorous evaluation.</li>
                    
                    <li>A dual-agent evaluation framework was piloted, featuring a quantitative agent for citation verification and six-dimensional scoring (e.g., Islamic Consistency, Citations) and a qualitative agent for five-dimensional side-by-side comparison (e.g., Tone, Depth).</li>
                    
                    <li>GPT-4o achieved the highest scores in Islamic Accuracy (3.93/5) and Citation (3.38/5), and the highest mean quantitative score (3.90/5) among the tested models.</li>
                    
                    <li>Ansari AI followed in quantitative performance and led in qualitative pairwise wins (116/200), demonstrating a different strength profile.</li>
                    
                    <li>Fanar, despite lagging in overall scores, introduces valuable innovations for Islamic and Arabic linguistic contexts.</li>
                    
                    <li>Despite relatively strong performance by leading models, none reliably produced accurate Islamic content and citations, which is deemed paramount for faith-sensitive writing.</li>
                    
                    <li>The study emphasizes the urgent need for community-driven benchmarks focusing on domain-specific perspectives to improve AI reliability in high-stakes fields like medicine, law, and journalism.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed a novel dual-agent evaluation framework to assess GPT-4o, Ansari AI, and Fanar. Prompts were sourced from authentic Islamic blogs. A quantitative agent performed citation verification and six-dimensional scoring (Structure, Islamic Consistency, Citations, etc.) on a 1-5 scale. Concurrently, a qualitative agent conducted five-dimensional side-by-side comparisons (Tone, Depth, Originality, etc.) for deeper insights into content quality.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>GPT-4o showed the highest Islamic Accuracy (3.93) and Citation scores (3.38), and the best overall mean quantitative score (3.90/5). Ansari AI followed quantitatively (Accuracy 3.68, Citation 3.32) but led in qualitative pairwise wins (116/200). Fanar significantly lagged in both accuracy (2.76) and citations (1.82). Crucially, despite relative strengths, no model consistently achieved reliable accuracy and citation fidelity, which is considered essential for faith-sensitive content.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings underscore significant risks for integrating LLMs into clinical or health-related applications. Unreliable content, misquoted information, or misapplied medical guidelines generated by LLMs could lead to incorrect diagnoses, inappropriate treatments, patient anxiety from misinformation, or ethical breaches. This necessitates extremely stringent validation and the development of domain-specific, medically-grounded benchmarks to ensure LLM outputs are consistently factual, contextually appropriate, and reliably cited before widespread clinical adoption.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While not explicitly detailed as limitations of this study's methodology in the abstract, the overarching conclusion implies a limitation in the current state of LLM evaluation, highlighting the critical need for 'community-driven benchmarks centering Muslim perspectives.' This suggests that existing general evaluation metrics might not fully capture the nuances or specific requirements of high-stakes, domain-sensitive content, which would apply equally to medical contexts.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The study strongly advocates for the development of community-driven benchmarks that center the perspectives of domain experts (e.g., Muslim scholars for Islamic content, medical professionals for health content). This is seen as an early, crucial step toward achieving more reliable AI in Islamic knowledge and other high-stakes domains, including medicine, law, and journalism, where accuracy and fidelity are paramount.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Patient Education</span>
                    
                    <span class="tag">Medical Research Synthesis</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                    <span class="tag">Public Health Information</span>
                    
                    <span class="tag">Medical Ethics</span>
                    
                    <span class="tag">Pharmacovigilance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">AI Evaluation</span>
                    
                    <span class="tag tag-keyword">Fidelity</span>
                    
                    <span class="tag tag-keyword">High-Stakes Domains</span>
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                    <span class="tag tag-keyword">Content Generation</span>
                    
                    <span class="tag tag-keyword">Reliability</span>
                    
                    <span class="tag tag-keyword">Benchmarks</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models are increasingly used for Islamic guidance, but risk
misquoting texts, misapplying jurisprudence, or producing culturally
inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar
on prompts from authentic Islamic blogs. Our dual-agent framework uses a
quantitative agent for citation verification and six-dimensional scoring (e.g.,
Structure, Islamic Consistency, Citations) and a qualitative agent for
five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).
GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI
followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong
performance, models still fall short in reliably producing accurate Islamic
content and citations -- a paramount requirement in faith-sensitive writing.
GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led
qualitative pairwise wins (116/200). Fanar, though trailing, introduces
innovations for Islamic and Arabic contexts. This study underscores the need
for community-driven benchmarks centering Muslim perspectives, offering an
early step toward more reliable AI in Islamic knowledge and other high-stakes
domains such as medicine, law, and journalism.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted at 39th Conference on Neural Information Processing Systems
  (NeurIPS 2025) Workshop: 5th Muslims in Machine Learning (MusIML) Workshop</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>