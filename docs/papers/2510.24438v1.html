<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content - Health AI Hub</title>
    <meta name="description" content="This computer science research evaluates the faithfulness and reliability of GPT-4o, Ansari AI, and Fanar in generating Islamic content, addressing risks like m">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24438v1" target="_blank">2510.24438v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Abdullah Mushtaq, Rafay Naeem, Ezieddin Elmahjub, Ibrahim Ghaznavi, Shawqi Al-Maliki, Mohamed Abdallah, Ala Al-Fuqaha, Junaid Qadir
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI, cs.CY, cs.MA
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.70 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24438v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24438v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This computer science research evaluates the faithfulness and reliability of GPT-4o, Ansari AI, and Fanar in generating Islamic content, addressing risks like misquoting and misapplying religious texts. Using a novel dual-agent evaluation framework, the study found that while models showed relatively strong performance (GPT-4o highest quantitatively, Ansari AI qualitatively), they consistently fall short in reliably producing accurate content and citations‚Äîa critical requirement for faith-sensitive and other high-stakes domains like medicine.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research, though focused on Islamic content, is highly relevant to medicine by explicitly drawing parallels between faith-sensitive writing and other high-stakes domains like medicine. The identified challenges of LLM misquoting, misapplying knowledge, and producing inconsistent responses directly translate to critical risks in medical contexts, such as providing incorrect diagnoses, inappropriate treatment advice, or culturally insensitive patient information.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research provides a framework for evaluating LLM 'faithfulness' and reliability in a high-stakes context, which is directly applicable to medical AI. The study's findings highlight the critical need for robust evaluation and benchmarks to ensure accuracy and prevent misinformation from LLMs in healthcare applications, such as generating clinical summaries, providing patient information, or assisting with diagnostic decision-making. It serves as a cautionary tale regarding LLM reliability in sensitive domains and offers a methodological approach to address these concerns for AI in health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Evaluates the faithfulness of Large Language Models (LLMs) (GPT-4o, Ansari AI, Fanar) in generating Islamic content against risks of misquotation, misapplication, and cultural inconsistency.</li>
                    
                    <li>Introduces a novel dual-agent evaluation framework: a quantitative agent for citation verification and six-dimensional scoring (e.g., Structure, Islamic Consistency, Citations), and a qualitative agent for five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).</li>
                    
                    <li>Prompts for evaluation were sourced from authentic Islamic blogs, ensuring real-world relevance to the domain.</li>
                    
                    <li>GPT-4o achieved the highest scores in quantitative metrics, particularly Islamic Accuracy (3.93/5) and Citation reliability (3.38/5), and the highest mean quantitative score (3.90/5).</li>
                    
                    <li>Ansari AI followed GPT-4o in quantitative metrics but led in qualitative pairwise wins (116/200), indicating strengths in aspects like tone or depth.</li>
                    
                    <li>Despite some strong performances, the overall finding highlights that LLMs still lack the consistent reliability and accuracy in content and citations paramount for faith-sensitive writing.</li>
                    
                    <li>The study emphasizes the need for community-driven benchmarks from Muslim perspectives and frames its findings as crucial for improving AI reliability in other high-stakes domains, including medicine, law, and journalism.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed a dual-agent evaluation framework. A quantitative agent performed citation verification and scored content across six dimensions: Structure, Islamic Consistency, Citations, Faithfulness, Clarity, and Relevance. A qualitative agent conducted a five-dimensional side-by-side comparison (Tone, Depth, Originality, Engagement, Coherence) of responses from GPT-4o, Ansari AI, and Fanar to prompts derived from authentic Islamic blogs.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>GPT-4o demonstrated the highest quantitative performance with an Islamic Accuracy score of 3.93/5, a Citation score of 3.38/5, and the highest mean quantitative score of 3.90/5. Ansari AI followed with 3.68 and 3.32 respectively, and led in qualitative pairwise wins (116/200). Fanar trailed in most metrics. Crucially, all evaluated LLMs were found to consistently fall short in reliably producing accurate content and citations, which is deemed a paramount requirement for faith-sensitive and other high-stakes content.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings imply that current LLMs, despite their advancements, are not yet sufficiently reliable for direct application in critical medical scenarios without extensive, domain-specific validation frameworks. For clinical settings, this means caution is warranted when considering LLMs for tasks such as generating patient advice, drafting clinical summaries, or providing diagnostic support, as inaccuracies or misinterpretations could lead to adverse patient outcomes. It underscores the necessity of robust, ethically sound, and contextually aware evaluation systems before deploying AI in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While the abstract doesn't explicitly list limitations of *this study*, it hints that this is a 'pilot' and 'early step,' suggesting the scope may be limited. The models evaluated, while prominent, represent a snapshot. The primary limitation highlighted is that *LLMs themselves* still fall short in reliable accuracy and citation, especially in high-stakes domains, underscoring inherent limitations of current general-purpose models for specialized, sensitive content.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The study strongly advocates for the development of community-driven benchmarks that incorporate specific Muslim perspectives to enhance AI reliability in Islamic knowledge. It also positions this work as a foundational step towards improving AI reliability across other critical high-stakes domains, including medicine, law, and journalism, suggesting future research should focus on developing more robust, domain-specific evaluation methodologies and potentially specialized LLMs for these sensitive fields.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Patient Education</span>
                    
                    <span class="tag">Medical Information Retrieval</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                    <span class="tag">Ethical AI in Healthcare</span>
                    
                    <span class="tag">Digital Health Literacy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">AI evaluation</span>
                    
                    <span class="tag tag-keyword">faithfulness</span>
                    
                    <span class="tag tag-keyword">reliability</span>
                    
                    <span class="tag tag-keyword">high-stakes domains</span>
                    
                    <span class="tag tag-keyword">medical AI</span>
                    
                    <span class="tag tag-keyword">ethical AI</span>
                    
                    <span class="tag tag-keyword">content generation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models are increasingly used for Islamic guidance, but risk
misquoting texts, misapplying jurisprudence, or producing culturally
inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar
on prompts from authentic Islamic blogs. Our dual-agent framework uses a
quantitative agent for citation verification and six-dimensional scoring (e.g.,
Structure, Islamic Consistency, Citations) and a qualitative agent for
five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).
GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI
followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong
performance, models still fall short in reliably producing accurate Islamic
content and citations -- a paramount requirement in faith-sensitive writing.
GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led
qualitative pairwise wins (116/200). Fanar, though trailing, introduces
innovations for Islamic and Arabic contexts. This study underscores the need
for community-driven benchmarks centering Muslim perspectives, offering an
early step toward more reliable AI in Islamic knowledge and other high-stakes
domains such as medicine, law, and journalism.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted at 39th Conference on Neural Information Processing Systems
  (NeurIPS 2025) Workshop: 5th Muslims in Machine Learning (MusIML) Workshop</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>