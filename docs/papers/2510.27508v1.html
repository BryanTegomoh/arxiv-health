<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation - Health AI Hub</title>
    <meta name="description" content="This study introduces vMambaX, a lightweight multimodal framework that integrates PET and CT images using a Context-Gated Cross-Modal Perception Module (CGM) bu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27508v1" target="_blank">2510.27508v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Elena Mulero Ayll√≥n, Linlin Shen, Pierangelo Veltri, Fabrizia Gelardi, Arturo Chiti, Paolo Soda, Matteo Tortora
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27508v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27508v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study introduces vMambaX, a lightweight multimodal framework that integrates PET and CT images using a Context-Gated Cross-Modal Perception Module (CGM) built on Visual Mamba for accurate lung tumor segmentation. The framework adaptively enhances inter-modality feature interaction, leading to improved performance over baseline models on the PCLT20K dataset while maintaining lower computational complexity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate lung tumor segmentation is paramount for precise diagnosis, optimal treatment planning (e.g., radiation therapy targeting), and monitoring disease progression in lung cancer patients. This research offers an advanced, efficient, and potentially more precise computational tool to achieve this vital task, which can lead to improved patient management and outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>An AI model (vMambaX, based on Visual Mamba) that performs automated and accurate segmentation of lung tumors from combined PET and CT medical images. This application is intended to assist clinicians in the diagnosis and treatment planning of lung cancer, by providing precise identification of tumor boundaries.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of accurately segmenting lung tumors by effectively combining anatomical (CT) and functional (PET) information from medical images.</li>
                    
                    <li>Proposes vMambaX, a novel lightweight multimodal framework specifically designed for integrating PET and CT scan images.</li>
                    
                    <li>Introduces a Context-Gated Cross-Modal Perception Module (CGM) within vMambaX to facilitate adaptive feature interaction between the two modalities.</li>
                    
                    <li>The vMambaX architecture leverages the capabilities of Visual Mamba, a state-space model-based vision architecture, for efficient image processing.</li>
                    
                    <li>The CGM adaptively enhances inter-modality feature interaction, emphasizing informative regions relevant to the tumor while actively suppressing noise.</li>
                    
                    <li>Evaluated on the PCLT20K dataset, vMambaX demonstrates superior performance in lung tumor segmentation compared to established baseline models.</li>
                    
                    <li>The model achieves its enhanced segmentation accuracy while simultaneously maintaining lower computational complexity, highlighting its efficiency and scalability.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes vMambaX, a lightweight multimodal framework that integrates PET and CT images through a novel Context-Gated Cross-Modal Perception Module (CGM). This module is built upon the Visual Mamba architecture and is designed to adaptively enhance inter-modality feature interaction, thereby emphasizing informative regions and suppressing noise. The effectiveness and computational efficiency of vMambaX were evaluated by comparing its performance against baseline models on the PCLT20K dataset for lung tumor segmentation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The vMambaX framework significantly outperforms baseline models in accurate lung tumor segmentation when evaluated on the PCLT20K dataset. A crucial finding is that this improved performance is achieved while maintaining lower computational complexity, indicating its efficiency and practical applicability.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework holds significant potential for clinical application by enabling more accurate and efficient lung tumor segmentation, which is critical for personalized diagnosis and treatment planning. It could facilitate more precise targeting for radiotherapy, better surgical planning, and more reliable monitoring of treatment response, ultimately improving patient care and prognoses for individuals with lung cancer.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract, but the results highlight the 'potential of vMambaX as an efficient and scalable framework for advanced lung cancer analysis,' suggesting future work could involve broader validation, clinical translation, and application to other tumor types or multimodal imaging scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Pulmonology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Lung Tumor Segmentation</span>
                    
                    <span class="tag tag-keyword">PET-CT</span>
                    
                    <span class="tag tag-keyword">Multimodal Imaging</span>
                    
                    <span class="tag tag-keyword">Visual Mamba</span>
                    
                    <span class="tag tag-keyword">Context-Gated Perception</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Image Analysis</span>
                    
                    <span class="tag tag-keyword">Lung Cancer</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate lung tumor segmentation is vital for improving diagnosis and
treatment planning, and effectively combining anatomical and functional
information from PET and CT remains a major challenge. In this study, we
propose vMambaX, a lightweight multimodal framework integrating PET and CT scan
images through a Context-Gated Cross-Modal Perception Module (CGM). Built on
the Visual Mamba architecture, vMambaX adaptively enhances inter-modality
feature interaction, emphasizing informative regions while suppressing noise.
Evaluated on the PCLT20K dataset, the model outperforms baseline models while
maintaining lower computational complexity. These results highlight the
effectiveness of adaptive cross-modal gating for multimodal tumor segmentation
and demonstrate the potential of vMambaX as an efficient and scalable framework
for advanced lung cancer analysis. The code is available at
https://github.com/arco-group/vMambaX.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>