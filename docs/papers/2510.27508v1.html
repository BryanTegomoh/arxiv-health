<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces vMambaX, a lightweight multimodal framework utilizing a Context-Gated Cross-Modal Perception Module (CGM) and Visual Mamba architecture fo">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27508v1" target="_blank">2510.27508v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Elena Mulero Ayll√≥n, Linlin Shen, Pierangelo Veltri, Fabrizia Gelardi, Arturo Chiti, Paolo Soda, Matteo Tortora
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27508v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27508v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces vMambaX, a lightweight multimodal framework utilizing a Context-Gated Cross-Modal Perception Module (CGM) and Visual Mamba architecture for accurate PET-CT lung tumor segmentation. It adaptively integrates anatomical and functional information to enhance inter-modality features while suppressing noise. Evaluated on the PCLT20K dataset, vMambaX demonstrated superior performance compared to baseline models with reduced computational complexity, showcasing its potential for efficient lung cancer analysis.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate lung tumor segmentation is paramount for precise diagnosis, staging, and personalized treatment planning (e.g., radiation therapy, surgery) in lung cancer, directly impacting patient outcomes and reducing treatment-related toxicities.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This paper presents an AI model (vMambaX) built on the Visual Mamba architecture, designed for automated or semi-automated segmentation of lung tumors from combined PET and CT scans. This application aims to enhance the accuracy and efficiency of lung cancer diagnosis, staging, and treatment planning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of accurately segmenting lung tumors by effectively combining anatomical (CT) and functional (PET) imaging data.</li>
                    
                    <li>Proposes vMambaX, a lightweight multimodal framework designed specifically for PET-CT lung tumor segmentation, built upon the efficient Visual Mamba architecture.</li>
                    
                    <li>Integrates a novel Context-Gated Cross-Modal Perception Module (CGM) to adaptively enhance feature interaction between PET and CT modalities.</li>
                    
                    <li>The CGM mechanism emphasizes informative regions relevant to the tumor while simultaneously suppressing noise, leading to more robust segmentation.</li>
                    
                    <li>Evaluated on the PCLT20K dataset, vMambaX significantly outperforms established baseline models in segmentation accuracy.</li>
                    
                    <li>Crucially, the framework achieves superior performance while maintaining lower computational complexity, indicating high efficiency and scalability.</li>
                    
                    <li>Highlights the effectiveness of adaptive cross-modal gating as a strategy for multimodal tumor segmentation and positions vMambaX as a promising, efficient tool for advanced lung cancer analysis.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes vMambaX, a lightweight multimodal deep learning framework for PET-CT lung tumor segmentation. It is built on the Visual Mamba architecture and integrates a Context-Gated Cross-Modal Perception Module (CGM). The CGM is designed to adaptively enhance inter-modality feature interaction between PET and CT images, emphasizing informative regions and suppressing noise. The model's performance was evaluated against baseline models using the PCLT20K dataset.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The vMambaX framework significantly outperforms existing baseline models in the task of PET-CT lung tumor segmentation. Furthermore, it achieves this enhanced segmentation accuracy with lower computational complexity, demonstrating superior efficiency and scalability.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework offers the potential for more precise and efficient automated lung tumor segmentation in clinical settings. This can lead to improved accuracy in cancer diagnosis and staging, more optimized and personalized radiation therapy planning, and better guidance for surgical interventions, ultimately benefiting patient management and prognosis in lung cancer.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed method or study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Nuclear Medicine</span>
                    
                    <span class="tag">Pulmonology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">lung tumor segmentation</span>
                    
                    <span class="tag tag-keyword">PET-CT</span>
                    
                    <span class="tag tag-keyword">multimodal imaging</span>
                    
                    <span class="tag tag-keyword">Visual Mamba</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">cross-modal perception</span>
                    
                    <span class="tag tag-keyword">medical image analysis</span>
                    
                    <span class="tag tag-keyword">computational efficiency</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate lung tumor segmentation is vital for improving diagnosis and
treatment planning, and effectively combining anatomical and functional
information from PET and CT remains a major challenge. In this study, we
propose vMambaX, a lightweight multimodal framework integrating PET and CT scan
images through a Context-Gated Cross-Modal Perception Module (CGM). Built on
the Visual Mamba architecture, vMambaX adaptively enhances inter-modality
feature interaction, emphasizing informative regions while suppressing noise.
Evaluated on the PCLT20K dataset, the model outperforms baseline models while
maintaining lower computational complexity. These results highlight the
effectiveness of adaptive cross-modal gating for multimodal tumor segmentation
and demonstrate the potential of vMambaX as an efficient and scalable framework
for advanced lung cancer analysis. The code is available at
https://github.com/arco-group/vMambaX.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>