<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis - Health AI Hub</title>
    <meta name="description" content="This paper introduces an interactive evaluation framework for medical diagnostic agents, addressing the oversight of evidence-gathering processes in existing ev">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.19773v1" target="_blank">2601.19773v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-27
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhuohan Long, Zhijie Bao, Zhongyu Wei
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.19773v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.19773v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces an interactive evaluation framework for medical diagnostic agents, addressing the oversight of evidence-gathering processes in existing evaluations. It proposes Information Coverage Rate (ICR) and the EviMed benchmark to quantify and systematically study evidence elicitation. The core finding is that strong diagnostic reasoning alone is insufficient for effective information collection, leading to a performance bottleneck, which is mitigated by the proposed REFINE strategy.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing AI in clinical diagnosis by ensuring that automated agents not only possess strong reasoning but also effectively gather comprehensive patient information. This can lead to more accurate and reliable diagnostic support systems, reducing misdiagnoses and improving patient outcomes in interactive medical consultations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper focuses on developing and evaluating AI agents (likely large language models or similar) to conduct effective interactive medical consultations. The goal is to improve the AI's ability to proactively gather necessary clinical evidence, leading to more accurate diagnoses. This could be applied in AI-powered diagnostic assistants for healthcare professionals, intelligent symptom checkers for patients, or training tools for medical students simulating patient interactions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Identifies a critical gap in current evaluations of interactive medical diagnostic agents: the neglect of the evidence-gathering process.</li>
                    
                    <li>Proposes an interactive evaluation framework utilizing a simulated patient and reporter, grounded in atomic evidences, to model the consultation process explicitly.</li>
                    
                    <li>Introduces Information Coverage Rate (ICR) as a novel metric to quantify the completeness of evidence elicitation by an agent during interaction.</li>
                    
                    <li>Develops EviMed, an evidence-based benchmark dataset encompassing diverse medical conditions, from common complaints to rare diseases, for systematic study.</li>
                    
                    <li>Demonstrates through evaluating 10 models that strong diagnostic reasoning capabilities do not guarantee effective evidence elicitation, pinpointing this insufficiency as a primary performance bottleneck.</li>
                    
                    <li>Proposes REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving diagnostic uncertainties and improving evidence collection.</li>
                    
                    <li>Shows that REFINE consistently outperforms baselines, facilitates effective model collaboration, and enables smaller agents to achieve superior performance under strong reasoning supervision.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves an interactive evaluation framework with a simulated patient and a simulated reporter, both grounded in atomic evidences. It introduces a new metric, Information Coverage Rate (ICR), to quantify evidence collection completeness. An evidence-based benchmark, EviMed, was developed and used to evaluate 10 different diagnostic models. The proposed REFINE strategy integrates diagnostic verification to guide evidence elicitation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that strong diagnostic reasoning is not sufficient for effective evidence elicitation, creating a significant bottleneck in interactive diagnostic performance. The proposed REFINE strategy, leveraging diagnostic verification, consistently improves evidence collection and diagnostic accuracy, outperforming baselines and enabling efficient model collaboration.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work has the potential to significantly enhance the clinical utility of AI-powered diagnostic tools by addressing a fundamental limitation: incomplete information gathering. By improving the ability of AI agents to proactively elicit necessary evidence, it could lead to more thorough and accurate diagnoses, fewer diagnostic errors, and more efficient clinical workflows in real-world medical consultations. It could also contribute to developing better training systems for medical professionals.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations or caveats of the study, but the use of a simulated patient and reporter, while useful for systematic evaluation, inherently carries the limitation of not fully replicating the complexities and nuances of real-world human-patient interactions.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly detailing future research, the paper's focus on addressing the 'primary bottleneck' of insufficient information collection with the REFINE strategy suggests continued efforts would be directed towards refining such elicitation strategies and integrating them into more robust diagnostic AI systems. Further work could explore the transition from simulated to real-world clinical data and interactions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">General Medicine</span>
                    
                    <span class="tag">Clinical Diagnostics</span>
                    
                    <span class="tag">Rare Diseases</span>
                    
                    <span class="tag">Common Complaints</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Interactive Diagnosis</span>
                    
                    <span class="tag tag-keyword">Evidence Elicitation</span>
                    
                    <span class="tag tag-keyword">Information Coverage Rate (ICR)</span>
                    
                    <span class="tag tag-keyword">EviMed Benchmark</span>
                    
                    <span class="tag tag-keyword">Diagnostic Reasoning</span>
                    
                    <span class="tag tag-keyword">Simulated Patient</span>
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                    <span class="tag tag-keyword">Clinical Consultation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Interactive medical consultation requires an agent to proactively elicit missing clinical evidence under uncertainty. Yet existing evaluations largely remain static or outcome-centric, neglecting the evidence-gathering process. In this work, we propose an interactive evaluation framework that explicitly models the consultation process using a simulated patient and a \rev{simulated reporter} grounded in atomic evidences. Based on this representation, we introduce Information Coverage Rate (ICR) to quantify how completely an agent uncovers necessary evidence during interaction. To support systematic study, we build EviMed, an evidence-based benchmark spanning diverse conditions from common complaints to rare diseases, and evaluate 10 models with varying reasoning abilities. We find that strong diagnostic reasoning does not guarantee effective information collection, and this insufficiency acts as a primary bottleneck limiting performance in interactive settings. To address this, we propose REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving uncertainties. Extensive experiments demonstrate that REFINE consistently outperforms baselines across diverse datasets and facilitates effective model collaboration, enabling smaller agents to achieve superior performance under strong reasoning supervision. Our code can be found at https://github.com/NanshineLoong/EID-Benchmark .</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>