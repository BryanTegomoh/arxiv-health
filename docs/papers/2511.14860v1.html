<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation - Health AI Hub</title>
    <meta name="description" content="This study performed the first comprehensive benchmarking of CNN, Vision Transformer, and State-Space Mamba architectures for automated dental caries segmentati">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.14860v1" target="_blank">2511.14860v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-18
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Aashish Ghimire, Jun Zeng, Roshan Paudel, Nikhil Kumar Tomar, Deepak Ranjan Nayak, Harshith Reddy Nalla, Vivek Jha, Glenda Reynolds, Debesh Jha
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.14860v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.14860v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study performed the first comprehensive benchmarking of CNN, Vision Transformer, and State-Space Mamba architectures for automated dental caries segmentation on panoramic radiographs using the DC1000 dataset. Contrary to the growing trend towards complex attention-based models, the CNN-based DoubleU-Net significantly outperformed all Transformer and Mamba variants, achieving the highest segmentation metrics. These findings underscore that architecture-task alignment and domain-specific considerations are more critical than model complexity for effective medical image segmentation, particularly with limited data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate automated dental caries segmentation in panoramic radiographs is vital for early diagnosis and personalized treatment planning, directly improving patient outcomes. This research provides evidence-based guidance for developing effective AI tools in dentistry by identifying the most suitable deep learning architectures for specific medical imaging challenges.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automated segmentation of dental caries in panoramic radiographs. This aims to assist dentists in the early diagnosis of tooth decay and improve the accuracy and efficiency of treatment planning, thereby enhancing dental healthcare outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study conducted the first comprehensive benchmarking of three deep learning architecture types (CNNs, Vision Transformers, State-Space Mambas) for automated dental caries segmentation.</li>
                    
                    <li>Twelve state-of-the-art architectures, including DoubleU-Net, TransNetR, MambaUNet, and ResUNet++, were evaluated on the DC1000 dataset under identical training configurations.</li>
                    
                    <li>The CNN-based DoubleU-Net achieved the highest segmentation performance with a Dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145.</li>
                    
                    <li>CNN-based architectures secured the top three positions across all performance metrics, demonstrating superior performance over all Transformer and Mamba variants in this specific task.</li>
                    
                    <li>Transformer and Mamba models underperformed due to factors like limited annotated data and weaker inherent spatial priors, despite their theoretical advantages in global context modeling.</li>
                    
                    <li>The research highlights that architecture-task alignment is a more crucial factor than model complexity for successful domain-specific medical image segmentation.</li>
                    
                    <li>Accurate automated dental caries segmentation is critical for early diagnosis and effective treatment planning, addressing challenges like low lesion contrast and morphological variability.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study performed a comprehensive benchmarking experiment comparing twelve state-of-the-art deep learning architectures from three distinct families: Convolutional Neural Networks (CNNs), Vision Transformers, and State-Space Mamba models. These models were trained under identical configurations for automated dental caries segmentation on a specific dataset, DC1000, consisting of panoramic radiographs. Performance was quantitatively evaluated using standard segmentation metrics including Dice coefficient, mean Intersection over Union (mIoU), and precision.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The CNN-based DoubleU-Net achieved the highest segmentation accuracy for dental caries, with a Dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145. Notably, the top three performing architectures across all metrics were CNN-based, consistently outperforming all Vision Transformer and State-Space Mamba variants. The underperformance of Transformers and Mambas was attributed to their weaker spatial priors and requirements for larger datasets, making them less suitable than CNNs for this particular medical imaging task with the given data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides critical insights for clinicians and developers in selecting appropriate AI models for dental imaging, potentially leading to the deployment of more accurate and reliable automated diagnostic tools. By validating the superior performance of CNNs for dental caries segmentation, it can accelerate the integration of AI into routine dental practice, enhancing the early detection of caries, improving treatment planning precision, and ultimately contributing to better patient care and oral health outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract points to the underperformance of Transformer and Mamba models being due to factors such as limited annotated data and weaker inherent spatial priors. This implies a limitation of these complex architectures when applied to domain-specific medical imaging tasks, especially where data availability is constrained and strong spatial inductive biases are beneficial. The findings are specific to panoramic radiographs and the DC1000 dataset, potentially limiting immediate generalizability to other imaging modalities or larger, more diverse datasets.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly detailed as future directions, the study's findings implicitly suggest avenues for future research including: exploring methods to incorporate stronger spatial priors into Transformer and Mamba architectures for medical imaging; investigating their performance with significantly larger and more diverse annotated datasets; and potentially developing hybrid architectures that leverage the local feature extraction strengths of CNNs alongside the global context modeling capabilities of Transformers or Mambas.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Dentistry</span>
                    
                    <span class="tag">Oral and Maxillofacial Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Preventive Dentistry</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Dental Caries Segmentation</span>
                    
                    <span class="tag tag-keyword">Panoramic Radiographs</span>
                    
                    <span class="tag tag-keyword">Convolutional Neural Networks (CNNs)</span>
                    
                    <span class="tag tag-keyword">Vision Transformers</span>
                    
                    <span class="tag tag-keyword">State-Space Models (Mamba)</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Deep Learning Benchmarking</span>
                    
                    <span class="tag tag-keyword">Early Diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate identification and segmentation of dental caries in panoramic radiographs are critical for early diagnosis and effective treatment planning. Automated segmentation remains challenging due to low lesion contrast, morphological variability, and limited annotated data. In this study, we present the first comprehensive benchmarking of convolutional neural networks, vision transformers and state-space mamba architectures for automated dental caries segmentation on panoramic radiographs through a DC1000 dataset. Twelve state-of-the-art architectures, including VMUnet, MambaUNet, VMUNetv2, RMAMamba-S, TransNetR, PVTFormer, DoubleU-Net, and ResUNet++, were trained under identical configurations. Results reveal that, contrary to the growing trend toward complex attention based architectures, the CNN-based DoubleU-Net achieved the highest dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. In the study, the top 3 results across all performance metrics were achieved by CNN-based architectures. Here, Mamba and transformer-based methods, despite their theoretical advantage in global context modeling, underperformed due to limited data and weaker spatial priors. These findings underscore the importance of architecture-task alignment in domain-specific medical image segmentation more than model complexity. Our code is available at: https://github.com/JunZengz/dental-caries-segmentation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>8 pages, 4 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>