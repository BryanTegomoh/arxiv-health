<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection - Health AI Hub</title>
    <meta name="description" content="This paper introduces Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised learning framework for objective and accurate fetal m">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">← Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20214v1" target="_blank">2510.20214v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Talha Ilyas, Duong Nhu, Allison Thomas, Arie Levin, Lim Wei Yap, Shu Gong, David Vera Anaya, Yiwen Jiang, Deval Mehta, Ritesh Warty, Vinayak Smith, Maya Reddy, Euan Wallace, Wenlong Cheng, Zongyuan Ge, Faezeh Marzbanrad
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20214v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20214v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised learning framework for objective and accurate fetal movement (FM) detection from extended ultrasound videos. By employing a dual-contrastive loss and a task-specific sampling strategy, CURL learns robust motion representations, achieving a sensitivity of 78.01% and an AUROC of 81.60% on an in-house dataset. The framework holds significant potential for enhancing prenatal health monitoring and clinical decision-making by providing an objective assessment of fetal activity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and objective detection of fetal movement patterns is critical for assessing prenatal health, as abnormal movements can indicate underlying complications like placental dysfunction or fetal distress, necessitating timely medical intervention to improve maternal and fetal outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research proposes Contrastive Ultrasound Video Representation Learning (CURL), a self-supervised AI framework, to objectively and reliably detect fetal movement from ultrasound video recordings. This AI application aims to provide a more accurate and automated tool for prenatal monitoring, assisting clinicians in diagnosing potential complications and making informed decisions about fetal health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitations of subjective and often inaccurate traditional methods (maternal perception, cardiotocography) for fetal movement detection, which are crucial for identifying prenatal complications.</li>
                    
                    <li>Proposes Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised learning framework designed for objective fetal movement detection from extended ultrasound video recordings.</li>
                    
                    <li>CURL employs a dual-contrastive loss, integrating both spatial and temporal contrastive learning to learn robust motion representations from ultrasound data.</li>
                    
                    <li>A task-specific sampling strategy is introduced during self-supervised training to ensure effective separation of movement and non-movement segments.</li>
                    
                    <li>The framework enables flexible inference on arbitrarily long ultrasound recordings through a probabilistic fine-tuning approach.</li>
                    
                    <li>Evaluated on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions, CURL achieved a sensitivity of 78.01% and an AUROC of 81.60% for FM detection.</li>
                    
                    <li>The results demonstrate the potential of self-supervised contrastive learning for reliable and objective fetal movement analysis, promising improved prenatal monitoring and clinical decision-making.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes Contrastive Ultrasound Video Representation Learning (CURL), a self-supervised learning framework. It utilizes a dual-contrastive loss combining spatial and temporal contrastive learning to learn robust motion representations from ultrasound videos. A task-specific sampling strategy is implemented to effectively differentiate movement from non-movement segments during self-supervised training. Flexible inference on arbitrary video lengths is achieved via a probabilistic fine-tuning approach. The method was evaluated on an in-house dataset of 92 subjects with 30-minute ultrasound sessions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The CURL framework achieved a sensitivity of 78.01% and an Area Under the Receiver Operating Characteristic (AUROC) of 81.60% in detecting fetal movements from ultrasound video recordings. These results demonstrate its potential for reliable and objective fetal movement analysis, outperforming traditional subjective methods.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This objective method for fetal movement assessment could significantly enhance prenatal monitoring, offering a more reliable and quantifiable alternative to subjective traditional methods. It has the potential to aid clinicians in making more informed and timely decisions regarding fetal health, particularly in identifying early signs of distress or complications like placental dysfunction, thereby improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any specific limitations of the proposed method or the study's scope.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The research highlights the potential for improved prenatal monitoring and clinical decision-making, suggesting future work will likely involve further validation in diverse clinical settings, larger patient cohorts, and exploring the integration of this technology into routine obstetric practice for enhanced fetal health assessment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Obstetrics</span>
                    
                    <span class="tag">Perinatology</span>
                    
                    <span class="tag">Diagnostic Ultrasound</span>
                    
                    <span class="tag">Prenatal Care</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Fetal Movement Detection</span>
                    
                    <span class="tag tag-keyword">Obstetric Ultrasound</span>
                    
                    <span class="tag tag-keyword">Self-supervised Learning</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Prenatal Monitoring</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Diagnostic Aid</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate fetal movement (FM) detection is essential for assessing prenatal
health, as abnormal movement patterns can indicate underlying complications
such as placental dysfunction or fetal distress. Traditional methods, including
maternal perception and cardiotocography (CTG), suffer from subjectivity and
limited accuracy. To address these challenges, we propose Contrastive
Ultrasound Video Representation Learning (CURL), a novel self-supervised
learning framework for FM detection from extended fetal ultrasound video
recordings. Our approach leverages a dual-contrastive loss, incorporating both
spatial and temporal contrastive learning, to learn robust motion
representations. Additionally, we introduce a task-specific sampling strategy,
ensuring the effective separation of movement and non-movement segments during
self-supervised training, while enabling flexible inference on arbitrarily long
ultrasound recordings through a probabilistic fine-tuning approach. Evaluated
on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,
CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its
potential for reliable and objective FM analysis. These results highlight the
potential of self-supervised contrastive learning for fetal movement analysis,
paving the way for improved prenatal monitoring and clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This is the preprint version of the manuscript submitted to IEEE
  Journal of Biomedical and Health Informatics (JBHI) for review</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">← Back to all papers</a></p>
    </footer>
</body>
</html>