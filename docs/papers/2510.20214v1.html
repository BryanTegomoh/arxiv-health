<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection - Health AI Hub</title>
    <meta name="description" content="This paper introduces Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised framework designed for objective and accurate fetal m">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20214v1" target="_blank">2510.20214v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Talha Ilyas, Duong Nhu, Allison Thomas, Arie Levin, Lim Wei Yap, Shu Gong, David Vera Anaya, Yiwen Jiang, Deval Mehta, Ritesh Warty, Vinayak Smith, Maya Reddy, Euan Wallace, Wenlong Cheng, Zongyuan Ge, Faezeh Marzbanrad
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20214v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20214v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Contrastive Ultrasound Video Representation Learning (CURL), a novel self-supervised framework designed for objective and accurate fetal movement (FM) detection from ultrasound videos. Addressing the subjectivity of traditional methods, CURL utilizes a dual-contrastive loss and a task-specific sampling strategy to learn robust motion representations. Evaluated on an in-house dataset, it achieved a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating potential for improved prenatal monitoring.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and objective fetal movement detection is vital for assessing prenatal health, as abnormal patterns can signal underlying complications like placental dysfunction or fetal distress. This research offers a non-invasive, more reliable method to identify such critical indicators earlier and more consistently.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves a self-supervised learning framework (CURL) leveraging contrastive learning on fetal ultrasound video recordings. Its purpose is to objectively and reliably detect fetal movements, providing a more accurate and less subjective assessment than traditional methods. This AI-driven analysis of medical imaging data directly supports improved prenatal monitoring, helps clinicians in diagnosing potential complications like fetal distress or placental dysfunction, and ultimately aids in better clinical decision-making for maternal and fetal health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitations of traditional fetal movement detection methods (maternal perception, CTG) which suffer from subjectivity and limited accuracy.</li>
                    
                    <li>Proposes CURL (Contrastive Ultrasound Video Representation Learning), a novel self-supervised learning framework for detecting fetal movements from extended ultrasound video recordings.</li>
                    
                    <li>CURL employs a dual-contrastive loss mechanism, integrating both spatial and temporal contrastive learning to generate robust motion representations.</li>
                    
                    <li>Introduces a task-specific sampling strategy to effectively differentiate between movement and non-movement segments during self-supervised training.</li>
                    
                    <li>Enables flexible inference on arbitrarily long ultrasound recordings through a probabilistic fine-tuning approach.</li>
                    
                    <li>Evaluated on an in-house dataset comprising 92 subjects, each with 30-minute ultrasound sessions.</li>
                    
                    <li>Achieved a sensitivity of 78.01% and an Area Under the Receiver Operating Characteristic (AUROC) of 81.60% for fetal movement detection.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The core methodology involves CURL, a self-supervised learning framework. It leverages a dual-contrastive loss, combining both spatial and temporal contrastive learning principles to extract robust motion features from ultrasound video frames. A specific task-oriented sampling strategy is implemented during self-supervised training to ensure effective separation of fetal movement and non-movement segments. For inference, a probabilistic fine-tuning approach allows for flexible application to ultrasound recordings of varying lengths.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study found that CURL successfully detected fetal movements with a sensitivity of 78.01% and achieved an AUROC of 81.60%. These results were derived from evaluating the framework on an in-house dataset consisting of 92 subjects, each contributing 30-minute ultrasound recordings.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology holds significant potential to transform prenatal care by providing an objective and reliable method for fetal movement analysis, reducing the subjectivity and inaccuracies of current practices. It could enable earlier and more precise identification of fetal distress or other complications, leading to improved prenatal monitoring, more informed clinical decision-making, and potentially better pregnancy outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The evaluation was performed on an 'in-house dataset,' which may limit the generalizability of the results to diverse patient populations, different ultrasound machine types, or varied clinical settings. While promising, the reported sensitivity and AUROC suggest there is still room for improvement in accuracy and robustness for widespread clinical deployment. The abstract does not detail the specificity or the types of 'abnormal movement patterns' that can be identified.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The findings pave the way for further research into integrating self-supervised contrastive learning for broader fetal movement analysis. Future work could involve validating CURL on larger, more diverse external datasets, exploring its real-time application in clinical settings, and investigating its ability to differentiate specific types of fetal movements or subtle abnormalities for a more granular assessment of fetal well-being.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Obstetrics</span>
                    
                    <span class="tag">Perinatology</span>
                    
                    <span class="tag">Maternal-Fetal Medicine</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Fetal Movement Detection</span>
                    
                    <span class="tag tag-keyword">Ultrasound Video Analysis</span>
                    
                    <span class="tag tag-keyword">Self-Supervised Learning</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Prenatal Monitoring</span>
                    
                    <span class="tag tag-keyword">Obstetrics</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate fetal movement (FM) detection is essential for assessing prenatal
health, as abnormal movement patterns can indicate underlying complications
such as placental dysfunction or fetal distress. Traditional methods, including
maternal perception and cardiotocography (CTG), suffer from subjectivity and
limited accuracy. To address these challenges, we propose Contrastive
Ultrasound Video Representation Learning (CURL), a novel self-supervised
learning framework for FM detection from extended fetal ultrasound video
recordings. Our approach leverages a dual-contrastive loss, incorporating both
spatial and temporal contrastive learning, to learn robust motion
representations. Additionally, we introduce a task-specific sampling strategy,
ensuring the effective separation of movement and non-movement segments during
self-supervised training, while enabling flexible inference on arbitrarily long
ultrasound recordings through a probabilistic fine-tuning approach. Evaluated
on an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,
CURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its
potential for reliable and objective FM analysis. These results highlight the
potential of self-supervised contrastive learning for fetal movement analysis,
paving the way for improved prenatal monitoring and clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This is the preprint version of the manuscript submitted to IEEE
  Journal of Biomedical and Health Informatics (JBHI) for review</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>