<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Benchmarking LLMs for Predictive Applications in the Intensive Care Units - Health AI Hub</title>
    <meta name="description" content="This study benchmarks the performance of Large Language Models (LLMs) like GatorTron-Base, Llama 8B, and Mistral 7B against Smaller Language Models (SLMs) such ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Benchmarking LLMs for Predictive Applications in the Intensive Care Units</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.20520v1" target="_blank">2512.20520v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.20520v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.20520v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study benchmarks the performance of Large Language Models (LLMs) like GatorTron-Base, Llama 8B, and Mistral 7B against Smaller Language Models (SLMs) such as BioBERT and Word2Vec for predicting shock in critically ill ICU patients using text data from the MIMIC III database. The findings indicate that while GatorTron-Base achieved the highest weighted recall, the overall predictive performance metrics were comparable between LLMs and SLMs, suggesting that LLMs are not inherently superior for predicting future clinical events in this context.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Timely prediction of shock in critically ill patients is vital for enabling early interventions, which can significantly improve patient outcomes, reduce morbidity, and potentially save lives in Intensive Care Units.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies LLMs to create predictive models for the early detection of critical medical conditions (specifically shock) in ICU patients. The AI application aims to leverage clinical text data to identify patients at risk, thereby enabling timely clinical interventions and potentially improving patient outcomes in critical care settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study compared LLMs (GatorTron-Base, Llama 8B, Mistral 7B) against SLMs (BioBERT, DocBERT, BioClinicalBERT, Word2Vec, Doc2Vec) for shock prediction.</li>
                    
                    <li>Utilized text data from 17,294 ICU stays within the MIMIC III database.</li>
                    
                    <li>Patient data was filtered for ICU stays > 24 hours, and shock was defined by a shock index (SI) > 0.7.</li>
                    
                    <li>The dataset was highly imbalanced (355 normal vs. 87 abnormal SI patients), addressed through finetuning with both focal and cross-entropy losses.</li>
                    
                    <li>GatorTron-Base, an LLM trained on clinical data, achieved the highest weighted recall of 80.5%.</li>
                    
                    <li>Despite GatorTron-Base's specific achievement, overall performance metrics were found to be comparable between the LLMs and SLMs.</li>
                    
                    <li>The study concludes that LLMs are not inherently superior to SLMs for predicting future clinical events, contrasting with their strong performance in general text-based NLP tasks.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized text data extracted from 17,294 ICU stays of patients in the MIMIC III database. Patients were categorized based on length of stay (> 24 hours) and shock index (SI > 0.7 for abnormal SI), resulting in an imbalanced dataset (355 normal vs. 87 abnormal SI). Various LLMs (GatorTron-Base, Llama 8B, Mistral 7B) and SLMs (BioBERT, DocBERT, BioClinicalBERT, Word2Vec, Doc2Vec) were finetuned using focal and cross-entropy loss functions to address class imbalance. Performance was evaluated primarily using weighted recall and other comparable metrics.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The most significant finding was that while GatorTron-Base, a clinical-data-trained LLM, achieved the highest weighted recall of 80.5% for shock prediction, the overall performance metrics were comparable across all tested LLMs and SLMs. This indicates that LLMs, in their current application, do not inherently demonstrate superior predictive capabilities for future clinical events like shock when compared to SLMs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a crucial benchmark for the application of advanced language models in critical care predictive analytics. The finding that LLMs are not inherently superior to SLMs for this specific predictive task suggests that simpler, potentially more computationally efficient models might be adequate. This could guide resource allocation for developing AI tools, emphasizing that model complexity doesn't automatically equate to better clinical utility, particularly for text-based predictive tasks.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While not explicitly stated as 'limitations' in the abstract, the study's scope is confined to text data from the MIMIC III database and a specific predictive task (shock). The conclusion that LLMs are not inherently superior might be limited to current LLM architectures and training paradigms, or the specific characteristics of the dataset and task. The inherent class imbalance, despite mitigation, could also impact generalizability.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>To achieve more meaningful clinical outcomes, future research in training LLMs should shift its focus from simpler Natural Language Processing tasks, such as named entity recognition or phenotyping, towards developing models capable of accurately predicting complex and dynamic clinical trajectories.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Critical Care Medicine</span>
                    
                    <span class="tag">Intensive Care Units</span>
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Predictive Analytics</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">shock prediction</span>
                    
                    <span class="tag tag-keyword">intensive care</span>
                    
                    <span class="tag tag-keyword">MIMIC III</span>
                    
                    <span class="tag tag-keyword">GatorTron-Base</span>
                    
                    <span class="tag tag-keyword">clinical prediction</span>
                    
                    <span class="tag tag-keyword">class imbalance</span>
                    
                    <span class="tag tag-keyword">weighted recall</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>