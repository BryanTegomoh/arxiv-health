<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks - Health AI Hub</title>
    <meta name="description" content="This paper introduces a multi-modal information extraction method for Electronic Health Records (EHRs), integrating structured tabular data with unstructured cl">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.17056v1" target="_blank">2511.17056v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Paloma Rabaey, Adrick Tench, Stefan Heytens, Thomas Demeester
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.17056v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.17056v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a multi-modal information extraction method for Electronic Health Records (EHRs), integrating structured tabular data with unstructured clinical notes. It leverages expert-informed Bayesian networks for tabular features and neural text classifiers for text, fusing their predictions using virtual evidence augmented with a novel consistency node. The approach aims to create large, structured datasets for transparent clinical decision support systems, demonstrating improved prediction calibration and robustness to missing information and contradictions on a simulated benchmark.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This method is highly relevant to medicine as it provides a robust way to transform fragmented, multi-modal EHR data into structured, interpretable information, which is essential for developing reliable, transparent, and explainable clinical decision support systems and facilitating advanced medical research.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Development of AI systems for robust and interpretable information extraction from multi-modal Electronic Health Record data (structured and unstructured text), designed to build more accurate, transparent, and calibrated clinical decision support systems for medical applications.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of extracting comprehensive patient-level information from both structured tabular data and unstructured text within EHRs.</li>
                    
                    <li>Proposes a multi-modal methodology combining expert-informed Bayesian networks for tabular EHR features and neural text classifiers for clinical notes.</li>
                    
                    <li>Introduces a novel probabilistic fusion mechanism utilizing virtual evidence augmented with a 'consistency node' to integrate predictions from both data modalities.</li>
                    
                    <li>The consistency node is shown to significantly improve the calibration of the final predictions compared to using virtual evidence alone.</li>
                    
                    <li>This enhanced fusion allows the Bayesian network to better adjust neural classifier outputs, effectively handling missing information and resolving contradictions between tabular and textual evidence.</li>
                    
                    <li>Aims to generate large, structured tabular datasets from complex EHRs to enable the development of transparent and feature-based clinical decision support models.</li>
                    
                    <li>The method's potential was demonstrated and evaluated on the SimSUM dataset, a simulated benchmark specifically designed to link tabular EHRs with clinical notes.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed methodology for patient-level information extraction is multi-modal, leveraging both structured and unstructured EHR data. Expert-informed Bayesian networks are utilized to process and model relationships within tabular features (e.g., diagnosis codes, medications, lab results). Concurrently, neural text classifiers are employed to extract symptomatic information from unstructured clinical notes (e.g., discharge summaries). The predictions from these distinct models are then probabilistically fused using virtual evidence, which is significantly enhanced by a novel 'consistency node' designed to improve prediction calibration, handle missing data, and resolve contradictions between the different data sources.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful development of a multi-modal information extraction method that effectively integrates tabular and textual EHR data. Crucially, the introduction of a 'consistency node' into the virtual evidence fusion mechanism significantly improves the calibration of the final predictions compared to virtual evidence alone. This enhancement allows the Bayesian network to more accurately adjust the outputs of neural text classifiers, demonstrating superior capability in handling missing information and resolving contradictions between the disparate data modalities, leading to more robust patient-level feature extraction.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to profoundly impact clinical practice by enabling the creation of more complete, accurate, and structured patient datasets from existing EHRs. This will empower clinicians and researchers to build more transparent, interpretable, and reliable clinical decision support systems, ultimately leading to improved diagnostic accuracy, more personalized treatment plans, enhanced patient safety, and accelerated medical research by making complex EHR data more accessible and actionable.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The primary limitation noted is that the method's potential was demonstrated and evaluated on the 'SimSUM dataset,' which is a simulated benchmark. This suggests that the findings may require further validation and assessment of generalizability on real-world, diverse, and often messier clinical EHR data.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly detailed in the abstract, the use of a simulated dataset implies that future research would naturally involve applying and validating this multi-modal information extraction framework on real-world Electronic Health Records (EHRs) from various clinical environments. Further work could also explore extending the approach to incorporate additional EHR data modalities (e.g., medical images) or refine the expert-elicitation process for the Bayesian network construction.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Medical Data Science</span>
                    
                    <span class="tag">Decision Support Systems</span>
                    
                    <span class="tag">Health Information Technology</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">EHRs</span>
                    
                    <span class="tag tag-keyword">Information Extraction</span>
                    
                    <span class="tag tag-keyword">Bayesian Networks</span>
                    
                    <span class="tag tag-keyword">Neural Text Classifiers</span>
                    
                    <span class="tag tag-keyword">Multi-modal Data</span>
                    
                    <span class="tag tag-keyword">Clinical Decision Support</span>
                    
                    <span class="tag tag-keyword">Data Fusion</span>
                    
                    <span class="tag tag-keyword">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>