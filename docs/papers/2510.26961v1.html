<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions - Health AI Hub</title>
    <meta name="description" content="This paper introduces SYNAPSE-Net, a unified and adaptive deep learning framework designed for robust and generalized segmentation of heterogeneous brain lesion">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SYNAPSE-Net: A Unified Framework with Lesion-Aware Hierarchical Gating for Robust Segmentation of Heterogeneous Brain Lesions</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26961v1" target="_blank">2510.26961v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Md. Mehedi Hassan, Shafqat Alam, Shahriar Ahmed Seam, Maruf Ahmed
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, eess.IV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26961v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26961v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SYNAPSE-Net, a unified and adaptive deep learning framework designed for robust and generalized segmentation of heterogeneous brain lesions from multi-modal MRI. By integrating a novel hybrid architecture with multi-stream CNNs, a Swin Transformer bottleneck, dynamic cross-modal attention, and a hierarchical gated decoder, coupled with a variance reduction training strategy, the model achieves state-of-the-art performance across diverse brain pathologies. The framework demonstrates high generalization and reliability, providing a clinically feasible solution for automated lesion segmentation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Automated and robust segmentation of heterogeneous brain lesions is vital for accurate diagnosis, monitoring disease progression, and treatment planning in various neurological conditions. This unified framework offers a significant advancement by providing a reliable and generalized solution, reducing the need for specialized models and improving clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes a deep learning model (SYNAPSE-Net) designed for automated medical image segmentation. This AI application aims to assist clinicians in the diagnosis, prognosis, treatment planning, and monitoring of patients with various brain conditions including tumors, stroke, and other brain lesions, by providing robust and accurate segmentation masks from MRI scans.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of automated segmentation of heterogeneous brain lesions from multi-modal MRI, aiming to overcome limitations of existing specialized models in generalization and robustness.</li>
                    
                    <li>Proposes SYNAPSE-Net, a novel adaptive and unified framework with a hybrid architecture for high generalization and robustness.</li>
                    
                    <li>The architecture incorporates multi-stream CNN encoders, a Swin Transformer bottleneck for global context, a dynamic cross-modal attention fusion (CMAF) mechanism, and a hierarchical gated decoder.</li>
                    
                    <li>Utilizes a variance reduction training strategy, combining pathology-specific data augmentation and a difficulty-aware sampling method to enhance model stability and performance.</li>
                    
                    <li>Evaluated on three challenging public datasets: MICCAI 2017 WMH, ISLES 2022, and BraTS 2020, representing diverse brain pathologies.</li>
                    
                    <li>Achieved state-of-the-art performance metrics, including a DSC of 0.831 and HD95 of 3.03 on WMH, best boundary accuracy (HD95 9.69) on ISLES 2022, and highest DSC (0.8651) for the tumor core on BraTS 2020.</li>
                    
                    <li>Demonstrates superior generalization and robustness across multiple brain pathologies, positioning it as a reliable and clinically feasible solution for automated segmentation.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The Unified Multi-Stream SYNAPSE-Net is an adaptive framework built on a novel hybrid architecture. It integrates multi-stream Convolutional Neural Network (CNN) encoders for initial feature extraction, a Swin Transformer bottleneck to capture global contextual information, a dynamic cross-modal attention fusion (CMAF) mechanism for intelligently merging features from different MRI modalities, and a hierarchical gated decoder for high-fidelity segmentation mask reconstruction. The model is trained using a variance reduction strategy, which includes pathology-specific data augmentation and a difficulty-aware sampling method to improve generalization and robustness.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The SYNAPSE-Net framework consistently achieved state-of-the-art performance across diverse brain lesion segmentation tasks. Specifically, it attained a DSC of 0.831 and HD95 of 3.03 on the MICCAI 2017 WMH Challenge dataset. For the ISLES 2022 Challenge, it demonstrated the best boundary accuracy with a statistically significant difference (HD95 of 9.69). On the BraTS 2020 Challenge, the model achieved the highest DSC value of 0.8651 for the crucial tumor core region. These results highlight the framework's superior generalization and robustness across heterogeneous brain pathologies.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This unified, adaptive framework provides a robust and clinically feasible solution for automated segmentation of various brain lesions from multi-modal MRI. Its ability to generalize across different pathologies (e.g., white matter hyperintensities, stroke lesions, brain tumors) means a single model can be deployed, streamlining clinical workflows and reducing the need for multiple specialized tools. This can lead to more efficient, consistent, and accurate lesion quantification, aiding in faster diagnosis, precise disease monitoring, improved surgical planning, and personalized treatment strategies, ultimately enhancing patient care outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. However, the demonstrated clinical feasibility implies potential for direct clinical translation and further validation in diverse real-world settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Neuroimaging</span>
                    
                    <span class="tag">Neuroradiology</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Neurosurgery</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Brain Lesion Segmentation</span>
                    
                    <span class="tag tag-keyword">Multi-modal MRI</span>
                    
                    <span class="tag tag-keyword">Hybrid Architecture</span>
                    
                    <span class="tag tag-keyword">Swin Transformer</span>
                    
                    <span class="tag tag-keyword">Clinical Neuroimaging</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                    <span class="tag tag-keyword">Robustness</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated segmentation of heterogeneous brain lesions from multi-modal MRI
remains a critical challenge in clinical neuroimaging. Current deep learning
models are typically specialized `point solutions' that lack generalization and
high performance variance, limiting their clinical reliability. To address
these gaps, we propose the Unified Multi-Stream SYNAPSE-Net, an adaptive
framework designed for both generalization and robustness. The framework is
built on a novel hybrid architecture integrating multi-stream CNN encoders, a
Swin Transformer bottleneck for global context, a dynamic cross-modal attention
fusion (CMAF) mechanism, and a hierarchical gated decoder for high-fidelity
mask reconstruction. The architecture is trained with a variance reduction
strategy that combines pathology specific data augmentation and
difficulty-aware sampling method. The model was evaluated on three different
challenging public datasets: the MICCAI 2017 WMH Challenge, the ISLES 2022
Challenge, and the BraTS 2020 Challenge. Our framework attained a
state-of-the-art DSC value of 0.831 with the HD95 value of 3.03 in the WMH
dataset. For ISLES 2022, it achieved the best boundary accuracy with a
statistically significant difference (HD95 value of 9.69). For BraTS 2020, it
reached the highest DSC value for the tumor core region (0.8651). These
experimental findings suggest that our unified adaptive framework achieves
state-of-the-art performance across multiple brain pathologies, providing a
robust and clinically feasible solution for automated segmentation. The source
code and the pre-trained models are available at
https://github.com/mubid-01/SYNAPSE-Net-pre.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>17 pages, 10 figures, 8 tables, submitted to "Medical Image Analysis"
  journal</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>