<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB), designed to assess aphasia-like defici">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20507v1" target="_blank">2511.20507v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley, Meghan Sumner, Cory Shain, Laura Gwilliams
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB), designed to assess aphasia-like deficits in large language models (LLMs). The TAB comprises four subtests, providing a novel computational tool to study linguistic disorders. A key finding is the validation of an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a novel computational framework to explore the mechanisms of aphasia, a neurological language disorder, by studying analogous deficits in LLMs. It could offer new insights into the computational basis of linguistic impairments, potentially informing future diagnostic and therapeutic approaches in human aphasia.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper applies AI (Large Language Models) as 'model organisms' to computationally study aphasia, a human linguistic disorder. This foundational work in benchmarking aphasia-like deficits in LLMs could lead to future medical AI applications such as: developing more sophisticated AI tools for diagnosing and classifying aphasia types, creating personalized AI-powered speech therapy interventions, simulating the effects of brain damage on language for research purposes, or designing AI systems that can better understand and communicate with individuals with aphasia.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Large language models (LLMs) are proposed as 'model organisms' for studying human language and linguistic disorders like aphasia.</li>
                    
                    <li>Traditional clinical aphasia assessments are deemed unsuitable for LLMs due to their reliance on human pragmatic pressures and cognitive processes.</li>
                    
                    <li>The Text Aphasia Battery (TAB) is introduced as a clinically-grounded, text-only benchmark, adapted from the Quick Aphasia Battery (QAB).</li>
                    
                    <li>TAB consists of four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition, with detailed design and scoring criteria.</li>
                    
                    <li>An automated evaluation protocol using Gemini 2.5 Flash was developed and validated for TAB to enable large-scale use.</li>
                    
                    <li>The automated protocol demonstrated reliability (prevalence-weighted Cohen's kappa = 0.255) comparable to expert human raters (kappa = 0.286).</li>
                    
                    <li>The TAB is released as a scalable framework for analyzing language deficits in artificial systems.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved adapting a clinical aphasia assessment (QAB) into a text-only benchmark (TAB) suitable for LLMs, comprising four specific subtests and scoring criteria. An automated evaluation protocol was developed using Gemini 2.5 Flash to score the TAB. The reliability of this automated protocol was then validated by comparing its agreement with expert human raters using prevalence-weighted Cohen's kappa statistic.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful development and validation of the Text Aphasia Battery (TAB), a clinically-grounded, text-only benchmark for assessing aphasia-like deficits in LLMs. Crucially, an automated evaluation protocol based on Gemini 2.5 Flash was shown to achieve reliability (kappa = 0.255) comparable to that of expert human raters (kappa = 0.286), making the TAB scalable for widespread use.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While TAB directly assesses LLMs, its insights could deepen the understanding of the computational underpinnings of linguistic deficits seen in human aphasia, potentially guiding research into more effective diagnostic tools or rehabilitation strategies. It also provides a standardized way to evaluate the robustness of AI language systems against simulated language impairments, which is critical for their safe and effective deployment in healthcare settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, inferable limitations include that the benchmark assesses "aphasia-like" deficits in LLMs, which are not biological systems, meaning it models linguistic symptoms rather than the underlying neurobiological pathology of human aphasia. Additionally, the reported Cohen's kappa values (0.255-0.286), while comparable between automated and human raters, generally indicate only "slight" to "fair" agreement, suggesting inherent challenges in robustly assessing these language deficits or room for improved rater consistency.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly detailed beyond releasing the benchmark, the paper implies future research will utilize the TAB as a scalable framework for analyzing language deficits across various artificial systems. This could involve probing different LLM architectures, training paradigms, or exploring specific types of aphasia-like impairments in detail.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Cognitive Neuroscience</span>
                    
                    <span class="tag">Neuropsychology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Aphasia</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Benchmark</span>
                    
                    <span class="tag tag-keyword">Computational Linguistics</span>
                    
                    <span class="tag tag-keyword">Neurological Disorders</span>
                    
                    <span class="tag tag-keyword">Language Assessment</span>
                    
                    <span class="tag tag-keyword">AI in Medicine</span>
                    
                    <span class="tag tag-keyword">Speech-Language Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>