<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery (QAB) designed to assess aphasia-like d">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20507v1" target="_blank">2511.20507v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley, Meghan Sumner, Cory Shain, Laura Gwilliams
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery (QAB) designed to assess aphasia-like deficits in large language models (LLMs). It details the TAB's design, subtests (Connected Text, Word Comprehension, Sentence Comprehension, and Repetition), and scoring criteria. The authors validate an automated evaluation protocol using Gemini 2.5 Flash, demonstrating its reliability is comparable to expert human raters, providing a scalable and clinically-grounded framework for studying language deficits in artificial systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a foundational tool for using large language models as computational 'model organisms' to investigate the underlying mechanisms of linguistic disorders such as aphasia. By creating a standardized, clinically-grounded benchmark, it opens new avenues for understanding, simulating, and potentially developing AI-driven insights into diagnosis and rehabilitation strategies for aphasia.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application here is foundational: using LLMs as computational models to study human linguistic disorders like aphasia. This research aims to understand the computational basis of these conditions, which can inform: 
1.  **Basic understanding of disease mechanisms**: Gaining insights into how aphasia manifests computationally could lead to new theories about its neurological underpinnings.
2.  **Development of future diagnostic/therapeutic AI**: A deeper computational understanding of aphasia could pave the way for more sophisticated AI tools for early detection, differential diagnosis, personalized rehabilitation strategies, or even AI assistants capable of understanding and interacting more effectively with individuals with aphasia.
3.  **Evaluating AI for medical contexts**: The developed Text Aphasia Battery (TAB) could serve as a benchmark for evaluating the 'health' or robustness of AI systems themselves when applied to language-related medical tasks, ensuring they do not exhibit 'aphasia-like deficits' that could compromise their utility or safety in healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitation of traditional clinical assessments for evaluating language deficits in LLMs, which are ill-suited due to their human-centric pragmatic and cognitive assumptions.</li>
                    
                    <li>Introduces the Text Aphasia Battery (TAB), a new text-only benchmark for LLMs adapted from the clinically established Quick Aphasia Battery (QAB).</li>
                    
                    <li>The TAB is structured into four specific subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition, targeting diverse linguistic functions.</li>
                    
                    <li>Develops and validates an automated evaluation protocol for TAB using Gemini 2.5 Flash, crucial for enabling large-scale, efficient assessment of LLMs.</li>
                    
                    <li>The automated evaluation protocol demonstrates reliability comparable to expert human raters, achieving a prevalence-weighted Cohen's kappa of 0.255 for model-consensus agreement versus 0.286 for human-human agreement.</li>
                    
                    <li>The TAB is released as a clinically-grounded, scalable framework, bridging clinical understanding of aphasia with computational linguistics research.</li>
                    
                    <li>Positions LLMs as potential 'model organisms' for studying the computational basis of human language disorders like aphasia.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors designed the Text Aphasia Battery (TAB) by adapting the Quick Aphasia Battery (QAB) into a text-only format suitable for Large Language Models (LLMs), comprising subtests like Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. They then developed and validated an automated evaluation protocol for TAB using the Gemini 2.5 Flash LLM. The reliability of this automated protocol was assessed by comparing its agreement with expert human raters using prevalence-weighted Cohen's kappa.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study successfully established the Text Aphasia Battery (TAB) as a text-only, clinically-grounded benchmark for assessing aphasia-like deficits in LLMs. A key finding is the validation of an automated evaluation protocol using Gemini 2.5 Flash, which demonstrated inter-rater reliability (prevalence-weighted Cohen's kappa = 0.255) comparable to that between human experts (kappa = 0.286). This validates the scalability of the TAB for large-scale research.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While not a direct diagnostic tool for patients, the TAB framework has significant clinical impact by enabling a more rigorous and scalable computational study of aphasia. Insights gained from analyzing LLMs with TAB could deepen our understanding of language breakdown mechanisms, potentially informing the development of advanced diagnostic algorithms, personalized therapeutic interventions, or AI-powered assistive communication devices for individuals with aphasia. It bridges basic AI research with clinical neurological and speech-language pathology understanding.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly detailed in the abstract; however, the 'aphasia-like deficits' implies a distinction from actual human aphasia, and the text-only nature inherently limits its scope compared to multimodal human assessments.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly detailed in the abstract, but the release of the TAB framework implies future research will utilize it to systematically analyze language deficits in various LLMs, explore the computational underpinnings of aphasia, and potentially generate hypotheses for human language disorders.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Cognitive Neuroscience</span>
                    
                    <span class="tag">Rehabilitation Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">aphasia</span>
                    
                    <span class="tag tag-keyword">large language models</span>
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">language deficits</span>
                    
                    <span class="tag tag-keyword">clinical assessment</span>
                    
                    <span class="tag tag-keyword">benchmark</span>
                    
                    <span class="tag tag-keyword">Quick Aphasia Battery</span>
                    
                    <span class="tag tag-keyword">computational linguistics</span>
                    
                    <span class="tag tag-keyword">neurology</span>
                    
                    <span class="tag tag-keyword">speech-language pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>