<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark designed to assess aphasia-like deficits in large language models (LLMs), adap">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20507v1" target="_blank">2511.20507v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley, Meghan Sumner, Cory Shain, Laura Gwilliams
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark designed to assess aphasia-like deficits in large language models (LLMs), adapted from the Quick Aphasia Battery (QAB). It details the TAB's design, subtests, and scoring criteria, while also validating an automated evaluation protocol using Gemini 2.5 Flash, which demonstrated reliability comparable to expert human raters.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a foundational computational tool to study the mechanisms of aphasia, offering a new avenue for understanding how linguistic disorders manifest. By modeling these deficits in LLMs, it could contribute to uncovering the computational basis of language impairment, potentially informing future diagnostic or therapeutic approaches in human aphasia.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research applies AI (LLMs) to model and investigate the computational mechanisms underlying aphasia, a human language disorder. By using LLMs as a 'model organism,' this approach aims to provide fundamental insights into the pathology of aphasia, which could ultimately inform the development of better diagnostic tools, more effective therapeutic strategies, or a deeper scientific understanding of neurological language disorders in humans. The clinically-grounded benchmark itself could be a step towards AI-powered assessment tools or platforms for developing AI-driven language rehabilitation therapies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Large language models (LLMs) are proposed as 'model organisms' for studying human linguistic disorders like aphasia, but traditional clinical assessments are unsuitable due to their reliance on human-specific pragmatic and cognitive assumptions.</li>
                    
                    <li>The Text Aphasia Battery (TAB) is developed as a clinically-grounded, text-only benchmark specifically for evaluating aphasia-like deficits in LLMs.</li>
                    
                    <li>TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition, drawing inspiration from the established Quick Aphasia Battery (QAB).</li>
                    
                    <li>To enable scalable assessment, an automated evaluation protocol utilizing Gemini 2.5 Flash was created to score the TAB responses.</li>
                    
                    <li>The automated scoring protocol's reliability was validated against human expert consensus, achieving a prevalence-weighted Cohen's kappa of 0.255, which is comparable to inter-human rater agreement (kappa = 0.286).</li>
                    
                    <li>The paper details TAB's complete design, subtests, and scoring criteria, and releases it as an open framework for analyzing language pathology in artificial intelligence systems.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involved adapting components of the human-centric Quick Aphasia Battery (QAB) into a text-only format suitable for LLMs, resulting in the Text Aphasia Battery (TAB) with four distinct subtests. An automated evaluation protocol, leveraging Gemini 2.5 Flash, was then developed to score the LLMs' performance on the TAB. This automated system's reliability was validated by comparing its scoring against expert human consensus ratings using prevalence-weighted Cohen's kappa.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful development and validation of the Text Aphasia Battery (TAB) as a robust, text-only benchmark for assessing aphasia-like deficits in LLMs. Critically, the automated evaluation protocol based on Gemini 2.5 Flash achieved scoring reliability (prevalence-weighted Cohen's kappa = 0.255) comparable to that observed between human expert raters (kappa = 0.286).</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While not directly impacting clinical practice immediately, this work lays the groundwork for advanced computational research into aphasia. By providing a standardized method to study language breakdown in artificial systems, it offers a novel platform for generating hypotheses about the neural and cognitive mechanisms underlying human aphasia, potentially accelerating the development of novel diagnostic tools, therapeutic interventions, or even personalized language rehabilitation strategies in the long term.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, potential limitations include that 'aphasia-like deficits' in LLMs, lacking biological brains and human embodied experience, may not perfectly translate to the complexities of human aphasia. Additionally, while comparable, the kappa scores for agreement (0.255 and 0.286) indicate a moderate level of agreement, suggesting room for improvement in evaluation consistency.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The release of TAB as a scalable framework facilitates future large-scale analysis of language deficits across various artificial systems. This includes exploring how different LLM architectures or training methodologies impact their performance on TAB, potentially uncovering distinct computational vulnerabilities that mirror different aphasia subtypes, and further investigating the theoretical underpinnings of language impairment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Cognitive Neuroscience</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Aphasia</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Neuroscience</span>
                    
                    <span class="tag tag-keyword">Linguistic Disorders</span>
                    
                    <span class="tag tag-keyword">Clinical Assessment</span>
                    
                    <span class="tag tag-keyword">Benchmark</span>
                    
                    <span class="tag tag-keyword">Speech-Language Pathology</span>
                    
                    <span class="tag tag-keyword">Computational Neuroscience</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>