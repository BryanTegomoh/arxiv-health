<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery (QAB), designed to assess aphasia-like ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20507v1" target="_blank">2511.20507v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley, Meghan Sumner, Cory Shain, Laura Gwilliams
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery (QAB), designed to assess aphasia-like deficits in Large Language Models (LLMs). The TAB comprises four subtests, and the authors validated an automated evaluation protocol using Gemini 2.5 Flash, demonstrating reliability comparable to expert human raters. This work provides a scalable, clinically-grounded framework for analyzing language deficits in artificial intelligence systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is medically relevant as it proposes a method to use Large Language Models as 'model organisms' to study the computational underpinnings of human language disorders like aphasia. Understanding how language deficits manifest and can be assessed in artificial systems could provide novel insights into the neurological and cognitive mechanisms underlying aphasia in humans.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The primary AI health application described is the use of Large Language Models (LLMs) as a computational 'model organism' to study and understand the underlying mechanisms and computational basis of human linguistic disorders, such as aphasia. This foundational research aims to leverage AI to gain insights into human medical conditions, potentially informing future diagnostic methods, therapeutic strategies, or assistive technologies for individuals with aphasia. The development of a clinically-grounded benchmark (TAB) also facilitates scalable research in this area.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Traditional clinical aphasia assessments are ill-suited for LLMs due to their presupposition of human-like pragmatic pressures and cognitive processes.</li>
                    
                    <li>The Text Aphasia Battery (TAB) is introduced as a text-only benchmark, specifically adapted from the Quick Aphasia Battery (QAB), to assess aphasia-like deficits in LLMs.</li>
                    
                    <li>TAB consists of four distinct subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition, each with detailed design and scoring criteria.</li>
                    
                    <li>An automated evaluation protocol was developed and validated using Gemini 2.5 Flash to facilitate large-scale and efficient assessment.</li>
                    
                    <li>The automated protocol achieved reliability comparable to expert human raters, with a prevalence-weighted Cohen's kappa of 0.255 for model-consensus agreement versus 0.286 for human-human agreement.</li>
                    
                    <li>TAB is released as a clinically-grounded and scalable framework for systematic analysis of linguistic deficits in artificial systems, offering a new tool for computational aphasiology.</li>
                    
                    <li>LLMs are presented as 'model organisms' for human language, offering a novel avenue to study the computational basis of linguistic disorders like aphasia.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involved adapting items from the Quick Aphasia Battery (QAB) into a text-only format suitable for LLMs, resulting in the Text Aphasia Battery (TAB) with four subtests. The design and scoring criteria for TAB were detailed. An automated evaluation protocol using the Gemini 2.5 Flash LLM was developed to score TAB responses. The reliability of this automated protocol was then validated by comparing its agreement with a human consensus against human-human agreement using prevalence-weighted Cohen's kappa statistics.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful development and validation of the Text Aphasia Battery (TAB) as a text-only, clinically-grounded benchmark for assessing aphasia-like deficits in LLMs. Critically, an automated evaluation protocol using Gemini 2.5 Flash was found to achieve reliability (prevalence-weighted Cohen's kappa = 0.255) comparable to that of expert human raters (kappa = 0.286), indicating its feasibility for scalable use.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While not directly diagnostic for human patients, this work provides a foundational computational tool to investigate the mechanistic underpinnings of language breakdown in a controlled, artificial environment. This could indirectly inform our understanding of human aphasia, potentially leading to new hypotheses about cognitive architectures of language and novel approaches to diagnosis, rehabilitation, or the development of AI-assisted therapeutic tools for speech-language pathology. It also establishes a standard for evaluating the linguistic robustness and vulnerabilities of AI models intended for healthcare applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The benchmark assesses 'aphasia-like deficits' in artificial systems, not actual human aphasia, which limits direct clinical extrapolation. The reported Cohen's kappa values, while comparable between model and human, are relatively low (0.255 and 0.286), suggesting fair to moderate agreement and potential for refinement in scoring granularity. The reliance on a specific LLM (Gemini 2.5 Flash) for validation means generalizability to all LLMs or future models might vary.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research can utilize the TAB to systematically analyze and compare various LLM architectures to identify specific patterns and types of aphasia-like deficits. Further refinement of the automated evaluation protocol could enhance its reliability and capture more nuanced linguistic errors. Investigating correlations between deficits observed in LLMs via TAB and specific linguistic or cognitive theories of human aphasia could yield deeper insights into the computational basis of language disorders.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Cognitive Neuroscience</span>
                    
                    <span class="tag">Computational Psychiatry/Neurology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Aphasia</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Benchmark</span>
                    
                    <span class="tag tag-keyword">Text Aphasia Battery (TAB)</span>
                    
                    <span class="tag tag-keyword">Quick Aphasia Battery (QAB)</span>
                    
                    <span class="tag tag-keyword">Language Disorders</span>
                    
                    <span class="tag tag-keyword">Computational Linguistics</span>
                    
                    <span class="tag tag-keyword">AI in Medicine</span>
                    
                    <span class="tag tag-keyword">Neuroscience</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>