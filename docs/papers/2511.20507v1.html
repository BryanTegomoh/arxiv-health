<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery, designed to assess aphasia-like defici">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20507v1" target="_blank">2511.20507v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley, Meghan Sumner, Cory Shain, Laura Gwilliams
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20507v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20507v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Text Aphasia Battery (TAB), a novel text-only benchmark adapted from the Quick Aphasia Battery, designed to assess aphasia-like deficits in large language models (LLMs). It details the TAB's design, subtests, and scoring, alongside validating an automated evaluation protocol using Gemini 2.5 Flash that shows reliability comparable to expert human raters. The TAB thus provides a clinically-grounded, scalable framework for computationally studying linguistic disorders.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a novel computational tool to explore the underlying mechanisms and characteristics of aphasia, a significant neurological language disorder, by leveraging large language models. By simulating aphasic-like deficits in LLMs, it offers a new avenue for theoretical understanding of language processing and its breakdown, which could eventually inform clinical research and interventions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes the development of an AI-based benchmark (TAB) to simulate and study aphasia-like deficits in LLMs. This serves as a foundational step for medical AI applications, potentially leading to: 1) AI models that can help in understanding the underlying mechanisms of aphasia; 2) The development of AI-powered diagnostic aids for aphasia; 3) Tools for personalized therapy design or monitoring of language rehabilitation in patients; 4) AI as a research tool to test hypotheses about language disorders before human trials.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Large language models (LLMs) are proposed as candidate "model organisms" for studying the computational basis of human linguistic disorders like aphasia.</li>
                    
                    <li>Traditional clinical assessments for aphasia are deemed ill-suited for LLMs due to their reliance on human-like pragmatic pressures and cognitive processes not inherent to artificial architectures.</li>
                    
                    <li>The Text Aphasia Battery (TAB) is introduced as a novel text-only benchmark, adapted from the Quick Aphasia Battery (QAB), specifically designed to assess aphasic-like deficits in LLMs.</li>
                    
                    <li>The TAB comprises four distinct subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition, probing different aspects of language function.</li>
                    
                    <li>An automated evaluation protocol utilizing Gemini 2.5 Flash was developed and validated to enable large-scale and efficient assessment of LLMs using the TAB.</li>
                    
                    <li>The automated evaluation protocol achieved reliability comparable to expert human raters, with a prevalence-weighted Cohen's kappa of 0.255 for model-consensus agreement versus 0.286 for human-human agreement.</li>
                    
                    <li>The TAB is released as a clinically-grounded and scalable framework for analyzing language deficits in artificial systems, bridging clinical understanding with computational linguistics.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors designed the Text Aphasia Battery (TAB) by adapting the clinically established Quick Aphasia Battery (QAB) into a text-only format suitable for LLMs. This involved defining four specific subtests (Connected Text, Word Comprehension, Sentence Comprehension, Repetition) and their corresponding scoring criteria. An automated evaluation protocol, leveraging Gemini 2.5 Flash, was then developed to score LLM outputs. The reliability of this automated protocol was validated by comparing its agreement with expert human raters against human-human agreement, using prevalence-weighted Cohen's kappa statistics.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful validation of an automated evaluation protocol for the TAB using Gemini 2.5 Flash, demonstrating reliability comparable to expert human raters. Specifically, the prevalence-weighted Cohen's kappa for model-consensus agreement was 0.255, closely aligning with the human-human agreement kappa of 0.286, suggesting the protocol is suitable for large-scale, automated analysis of aphasia-like deficits in LLMs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While not a direct clinical tool for patients, the TAB offers a standardized, scalable, and objective framework for researchers to computationally model and study the characteristics of aphasia. This can deepen our theoretical understanding of language impairment, potentially generating new hypotheses about the cognitive and linguistic underpinnings of aphasia that could guide future clinical research into diagnosis, prognosis, and therapeutic strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations. However, it implicitly acknowledges that LLM deficits are "aphasia-like" rather than true aphasia, highlighting the distinction between artificial systems and human neurological conditions. The Cohen's kappa values, while comparable, indicate only fair agreement, suggesting room for refinement in evaluation precision.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The release of TAB as a "scalable framework" implicitly encourages its widespread use for analyzing various LLMs, exploring different types and severities of language deficits, and potentially comparing computational findings with clinical observations of human aphasia to advance understanding of this complex disorder.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Cognitive Neuroscience</span>
                    
                    <span class="tag">Computational Neuroscience</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">aphasia</span>
                    
                    <span class="tag tag-keyword">large language models (LLMs)</span>
                    
                    <span class="tag tag-keyword">linguistic disorders</span>
                    
                    <span class="tag tag-keyword">benchmark</span>
                    
                    <span class="tag tag-keyword">computational linguistics</span>
                    
                    <span class="tag tag-keyword">Quick Aphasia Battery (QAB)</span>
                    
                    <span class="tag tag-keyword">Text Aphasia Battery (TAB)</span>
                    
                    <span class="tag tag-keyword">natural language processing (NLP)</span>
                    
                    <span class="tag tag-keyword">evaluation reliability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>