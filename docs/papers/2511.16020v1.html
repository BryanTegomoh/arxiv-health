<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Physically Realistic Sequence-Level Adversarial Clothing for Robust Human-Detection Evasion - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel sequence-level optimization framework to generate physically realistic, printable adversarial textures for common clothing items (">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Physically Realistic Sequence-Level Adversarial Clothing for Robust Human-Detection Evasion</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16020v1" target="_blank">2511.16020v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Dingkun Zhou, Patrick P. K. Chan, Hengxu Wu, Shikang Zheng, Ruiqi Huang, Yuanjie Zhao
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16020v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16020v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel sequence-level optimization framework to generate physically realistic, printable adversarial textures for common clothing items (shirts, trousers, hats) that enable robust human-detection evasion. The generated garments maintain concealment throughout entire walking videos, demonstrating high stability, robustness to viewpoint changes, and cross-model transferability in both digital simulations and real-world physical settings.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research highlights a significant vulnerability in AI-powered human detection systems, which are increasingly deployed in healthcare settings for security, patient monitoring (e.g., fall detection, tracking in geriatric care), and access control. The ability to evade such systems poses serious risks to patient privacy, the security of medical facilities and sensitive data, and the effectiveness of safety protocols.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>AI-powered human detection systems are employed in various health contexts, including facility security (e.g., monitoring access to sensitive areas in hospitals, clinics, or research laboratories), patient monitoring (e.g., fall detection in elderly care, tracking movement in psychiatric wards), and safeguarding biosecurity assets (e.g., surveillance in high-containment biological facilities). This paper, by demonstrating how to reliably evade such AI systems through adversarial clothing, highlights a critical vulnerability in the robustness and reliability of these AI applications, underscoring a significant challenge for their secure and effective deployment in health and medical environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the vulnerability of deep neural network human detectors to adversarial manipulation, specifically focusing on wearable attacks.</li>
                    
                    <li>Proposes a sequence-level optimization framework, overcoming limitations of frame-by-frame texture optimization in existing methods.</li>
                    
                    <li>Generates natural-looking, printable adversarial textures for shirts, trousers, and hats, optimized for concealment across motion and garment deformation.</li>
                    
                    <li>Employs a physically based human-garment pipeline simulating motion, multi-angle camera viewpoints, cloth dynamics, and illumination variation.</li>
                    
                    <li>Uses an expectation-over-transformation objective with temporal weighting to minimize detection confidence across whole video sequences.</li>
                    
                    <li>Achieves strong and stable concealment, high robustness to viewpoint changes, and superior cross-model transferability against various detection models.</li>
                    
                    <li>Confirms real-world feasibility through physical garments produced with sublimation printing, demonstrating reliable suppression under indoor and outdoor recordings.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves mapping product images to UV space and converting them into a compact palette/control-point parameterization with ICC locking for printability. A physically based human-garment pipeline simulates various real-world conditions including motion, multi-angle camera viewpoints, cloth dynamics, and illumination. An expectation-over-transformation objective, enhanced with temporal weighting, is then used to optimize the control points, aiming to minimize human detection confidence across entire video sequences. The adversarial garments are physically produced via sublimation printing and tested under real-world indoor and outdoor conditions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study demonstrates that sequence-level optimization yields adversarial clothing capable of strong and stable concealment throughout dynamic walking videos. These garments exhibit high robustness to changes in viewpoint and possess superior transferability across different human detection models. Crucially, physical garments generated through this method consistently achieved reliable suppression of human detection in both indoor and outdoor real-world recordings, confirming the practical feasibility of such attacks.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings underscore the critical need for healthcare institutions and technology developers to consider adversarial robustness when deploying AI-based vision systems for security, patient safety, or asset management. It implies that current surveillance systems in clinics, hospitals, or elder care facilities could be vulnerable to sophisticated evasion techniques, potentially leading to unauthorized access, compromised patient privacy, or failed monitoring of vulnerable individuals. This research should spur the development of more resilient AI detection systems and robust security protocols in clinical environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While effective, the current approach focuses on specific garment types (shirts, trousers, hats) and a particular type of motion (walking videos). It represents an attack strategy, highlighting a vulnerability, rather than offering a direct solution for defense. The complexity and specificity of generating these textures might also limit their widespread 'casual' adoption without specialized printing capabilities. The generalizability to other complex human activities or environmental conditions beyond those simulated needs further exploration.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research could focus on developing countermeasures and more robust AI detection models resistant to such adversarial attacks. Expanding the framework to cover a wider range of garment types, human activities, and environmental conditions would enhance its real-world applicability. Investigating the ethical implications and potential misuse of such technology, particularly within sensitive sectors like healthcare, is also crucial. Developing methods to detect the presence of adversarial clothing could also be a relevant research direction.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Healthcare Security</span>
                    
                    <span class="tag">Patient Privacy</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Biomedical Engineering</span>
                    
                    <span class="tag">Geriatric Care (monitoring systems)</span>
                    
                    <span class="tag">Hospital Management</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Adversarial Attacks</span>
                    
                    <span class="tag tag-keyword">Human Detection</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Wearable Technology</span>
                    
                    <span class="tag tag-keyword">Privacy</span>
                    
                    <span class="tag tag-keyword">Surveillance</span>
                    
                    <span class="tag tag-keyword">Robust AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep neural networks used for human detection are highly vulnerable to adversarial manipulation, creating safety and privacy risks in real surveillance environments. Wearable attacks offer a realistic threat model, yet existing approaches usually optimize textures frame by frame and therefore fail to maintain concealment across long video sequences with motion, pose changes, and garment deformation. In this work, a sequence-level optimization framework is introduced to generate natural, printable adversarial textures for shirts, trousers, and hats that remain effective throughout entire walking videos in both digital and physical settings. Product images are first mapped to UV space and converted into a compact palette and control-point parameterization, with ICC locking to keep all colors printable. A physically based human-garment pipeline is then employed to simulate motion, multi-angle camera viewpoints, cloth dynamics, and illumination variation. An expectation-over-transformation objective with temporal weighting is used to optimize the control points so that detection confidence is minimized across whole sequences. Extensive experiments demonstrate strong and stable concealment, high robustness to viewpoint changes, and superior cross-model transferability. Physical garments produced with sublimation printing achieve reliable suppression under indoor and outdoor recordings, confirming real-world feasibility.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>