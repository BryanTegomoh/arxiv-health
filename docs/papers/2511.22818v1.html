<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization - Health AI Hub</title>
    <meta name="description" content="This paper evaluates the efficacy of large language models (LLMs) in psychotherapy by having them summarize Motivational Interviewing (MI) dialogues. Employing ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.22818v1" target="_blank">2511.22818v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Vivek Kumar, Pushpraj Singh Rajawat, Eirini Ntoutsi
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.22818v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.22818v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper evaluates the efficacy of large language models (LLMs) in psychotherapy by having them summarize Motivational Interviewing (MI) dialogues. Employing a mixed-methods approach with a two-stage annotation scheme based on the MITI framework and expert ground truth, the study provides insights into LLMs' understanding of psychological constructs and identifies best practices to mitigate "semantic drift" in therapeutic contexts.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for the safe and effective integration of AI into mental health services, as it rigorously evaluates LLMs' ability to comprehend nuanced therapeutic communication, which is fundamental for developing reliable AI-assisted tools for psychotherapy training, supervision, and potentially direct support.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper explores the application of LLMs to assist in psychotherapy by generating precise summaries of therapeutic dialogues (e.g., Motivational Interviewing sessions). This could lead to AI-powered tools for therapists for session analysis, supervision, training, or potentially for monitoring therapeutic fidelity and effectiveness. It aims to develop LLMs capable of precise contextual interpretation in complex behavioral therapy.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses concerns regarding LLMs' limitations (lack of sensitivity, factual incorrectness, bias, hallucinations) in low-resource and sensitive psychological domains.</li>
                    
                    <li>Utilizes LLMs to generate precise summaries of Motivational Interviewing (MI) dialogues as the primary evaluation task.</li>
                    
                    <li>Implements a two-stage annotation scheme based on key components of the Motivational Interviewing Treatment Integrity (MITI) framework (evocation, collaboration, autonomy, direction, empathy, non-judgmental attitude).</li>
                    
                    <li>Evaluates LLM performance against expert-annotated MI dialogues, framing the assessment as multi-class classification tasks.</li>
                    
                    <li>Assesses model efficacy under progressive prompting techniques, specifically one-shot and few-shot prompting.</li>
                    
                    <li>Offers critical insights into LLMs' capacity for understanding complex psychological constructs and identifies best practices to mitigate "semantic drift" in therapeutic settings.</li>
                    
                    <li>Contributes a high-quality annotated dataset for MI dialogues, addressing data scarcity in behavioral therapy research.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employs a mixed-methods approach to evaluate LLM efficacy in psychotherapy. LLMs are tasked with generating precise summaries of Motivational Interviewing (MI) dialogues. A two-stage annotation scheme is designed, drawing from key components of the Motivational Interviewing Treatment Integrity (MITI) framework, including evocation, collaboration, autonomy, direction, empathy, and non-judgmental attitude. Expert-annotated MI dialogues serve as the ground truth for evaluation. The performance is assessed using multi-class classification tasks under various progressive prompting techniques, specifically one-shot and few-shot prompting.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The research yielded insights into LLMs' capacity for understanding complex psychological constructs inherent in MI dialogues. It identified and highlighted best practices to mitigate "semantic drift," ensuring precise contextual interpretation in therapeutic settings. A significant outcome is the creation of a high-quality annotated dataset for MI, which addresses data scarcity in this low-resource domain.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to enhance the training and supervision of therapists practicing behavioral therapies like MI by providing AI-driven tools that can accurately summarize and evaluate adherence to therapeutic principles. It could lead to improved fidelity of interventions, support quality assurance in mental health services, and ultimately contribute to more effective and accessible psychotherapy by guiding the responsible integration of LLMs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the presented study's methodology or findings. It primarily focuses on addressing pre-existing general concerns about LLMs.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While the paper provides "critical insights for using LLMs for precise contextual interpretation in complex behavioral therapy," the abstract does not explicitly outline specific future research directions for this study.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Psychology</span>
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Behavioral Health</span>
                    
                    <span class="tag">Mental Health Counseling</span>
                    
                    <span class="tag">Addiction Treatment</span>
                    
                    <span class="tag">Clinical Supervision</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">Motivational Interviewing (MI)</span>
                    
                    <span class="tag tag-keyword">Psychotherapy</span>
                    
                    <span class="tag tag-keyword">Semantic Drift</span>
                    
                    <span class="tag tag-keyword">Dialogue Summarization</span>
                    
                    <span class="tag tag-keyword">MITI Framework</span>
                    
                    <span class="tag tag-keyword">Behavioral Therapy</span>
                    
                    <span class="tag tag-keyword">AI in Mental Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Recent advancements in large language models (LLMs) have shown their potential across both general and domain-specific tasks. However, there is a growing concern regarding their lack of sensitivity, factual incorrectness in responses, inconsistent expressions of empathy, bias, hallucinations, and overall inability to capture the depth and complexity of human understanding, especially in low-resource and sensitive domains such as psychology. To address these challenges, our study employs a mixed-methods approach to evaluate the efficacy of LLMs in psychotherapy. We use LLMs to generate precise summaries of motivational interviewing (MI) dialogues and design a two-stage annotation scheme based on key components of the Motivational Interviewing Treatment Integrity (MITI) framework, namely evocation, collaboration, autonomy, direction, empathy, and a non-judgmental attitude. Using expert-annotated MI dialogues as ground truth, we formulate multi-class classification tasks to assess model performance under progressive prompting techniques, incorporating one-shot and few-shot prompting. Our results offer insights into LLMs' capacity for understanding complex psychological constructs and highlight best practices to mitigate ``semantic drift" in therapeutic settings. Our work contributes not only to the MI community by providing a high-quality annotated dataset to address data scarcity in low-resource domains but also critical insights for using LLMs for precise contextual interpretation in complex behavioral therapy.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>