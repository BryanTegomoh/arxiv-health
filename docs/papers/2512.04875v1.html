<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection - Health AI Hub</title>
    <meta name="description" content="SP-Det is a novel self-prompted framework for multi-label lesion detection in chest X-rays that overcomes the limitation of labor-intensive expert annotations b">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04875v1" target="_blank">2512.04875v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Qing Xu, Yanqian Wang, Xiangjian Hea, Yue Li, Yixuan Zhang, Rong Qu, Wenting Duan, Zhen Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04875v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04875v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SP-Det is a novel self-prompted framework for multi-label lesion detection in chest X-rays that overcomes the limitation of labor-intensive expert annotations by automatically generating rich textual context. It achieves state-of-the-art detection accuracy by fusing global semantic context prompts with disease-specific beacon prompts and enhancing features bidirectionally. This approach significantly improves diagnostic capabilities while eliminating the dependency on manual expert input, making automated lesion detection more practical for clinical use.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly medically relevant as it removes a significant practical bottleneck (manual expert annotation dependency) for deploying advanced AI in diagnostic radiology. By enabling accurate, automated lesion detection in chest X-rays, it can enhance diagnostic efficiency, reduce radiologist workload, and potentially lead to earlier and more precise identification of various pathological abnormalities, ultimately improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>SP-Det is an AI system designed to automate and assist in the detection and localization of lesions (pathological abnormalities) in chest X-rays. By automatically generating textual prompts and enhancing feature representation, it aims to improve the accuracy of multi-label lesion detection and streamline clinical diagnosis, reducing the dependency on labor-intensive expert annotations for AI model training in medical imaging.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the key challenge of labor-intensive manual annotations for prompts in existing promptable detection frameworks for chest X-rays, making them impractical for clinical use.</li>
                    
                    <li>Introduces SP-Det, a self-prompted detection framework that automatically generates textual context to guide multi-label lesion detection without requiring expert annotations.</li>
                    
                    <li>Features an expert-free Dual-Text Prompt Generator (DTPG) which creates two complementary textual modalities: semantic context prompts (global pathological patterns) and disease beacon prompts (disease-specific manifestations).</li>
                    
                    <li>Incorporates a Bidirectional Feature Enhancer (BFE) designed to synergistically integrate comprehensive diagnostic context with disease-specific embeddings.</li>
                    
                    <li>The BFE significantly improves feature representation and overall detection accuracy by leveraging both broad and focused textual information.</li>
                    
                    <li>Demonstrates superior performance against state-of-the-art detection methods on two distinct chest X-ray datasets covering a diverse range of thoracic disease categories.</li>
                    
                    <li>Crucially, SP-Det completely eliminates the dependency on expert-annotated prompts, thereby making advanced AI-driven lesion detection systems more feasible and scalable for real-world clinical deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The SP-Det framework employs an expert-free Dual-Text Prompt Generator (DTPG) to automatically create two types of textual prompts: semantic context prompts for global patterns and disease beacon prompts for specific manifestations. These auto-generated prompts are then used to guide a Bidirectional Feature Enhancer (BFE), which integrates comprehensive diagnostic context with disease-specific embeddings to enrich visual feature representations. The framework was evaluated experimentally on two chest X-ray datasets with diverse thoracic disease categories.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SP-Det significantly outperforms state-of-the-art detection methods in generalized multi-label lesion detection on chest X-rays. The most critical finding is its ability to achieve this high performance while entirely eliminating the dependency on manual expert-annotated prompts, which is a major advancement over existing promptable architectures.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SP-Det has the potential for substantial clinical impact by providing highly accurate and fully automated lesion detection in chest X-rays, thereby accelerating diagnosis, reducing the burden on radiologists, and improving diagnostic consistency. This could lead to more timely interventions and better patient management, especially in high-volume settings or areas with limited specialist access, by making AI-powered diagnostic tools more practical and scalable.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the SP-Det framework itself. Instead, the paper's core contribution is directly addressing and overcoming the significant practical limitations (labor-intensive manual annotation dependency) of *prior* promptable detection architectures.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Pulmonology</span>
                    
                    <span class="tag">AI in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multi-label lesion detection</span>
                    
                    <span class="tag tag-keyword">Chest X-rays</span>
                    
                    <span class="tag tag-keyword">Self-prompted detection</span>
                    
                    <span class="tag tag-keyword">Dual-text fusion</span>
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Artificial intelligence</span>
                    
                    <span class="tag tag-keyword">Diagnostic support</span>
                    
                    <span class="tag tag-keyword">Thoracic diseases</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated lesion detection in chest X-rays has demonstrated significant potential for improving clinical diagnosis by precisely localizing pathological abnormalities. While recent promptable detection frameworks have achieved remarkable accuracy in target localization, existing methods typically rely on manual annotations as prompts, which are labor-intensive and impractical for clinical applications. To address this limitation, we propose SP-Det, a novel self-prompted detection framework that automatically generates rich textual context to guide multi-label lesion detection without requiring expert annotations. Specifically, we introduce an expert-free dual-text prompt generator (DTPG) that leverages two complementary textual modalities: semantic context prompts that capture global pathological patterns and disease beacon prompts that focus on disease-specific manifestations. Moreover, we devise a bidirectional feature enhancer (BFE) that synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve feature representation and detection accuracy. Extensive experiments on two chest X-ray datasets with diverse thoracic disease categories demonstrate that our SP-Det framework outperforms state-of-the-art detection methods while completely eliminating the dependency on expert-annotated prompts compared to existing promptable architectures.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>