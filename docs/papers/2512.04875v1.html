<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection - Health AI Hub</title>
    <meta name="description" content="SP-Det proposes a novel self-prompted detection framework for multi-label lesion detection in chest X-rays, circumventing the need for labor-intensive manual ex">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04875v1" target="_blank">2512.04875v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Qing Xu, Yanqian Wang, Xiangjian Hea, Yue Li, Yixuan Zhang, Rong Qu, Wenting Duan, Zhen Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04875v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04875v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SP-Det proposes a novel self-prompted detection framework for multi-label lesion detection in chest X-rays, circumventing the need for labor-intensive manual expert annotations. It automatically generates rich textual context through a dual-text prompt generator and enhances feature representation via a bidirectional feature enhancer, achieving state-of-the-art accuracy on diverse datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly enhances the feasibility and scalability of AI-driven chest X-ray diagnosis by automating a previously manual and labor-intensive step, thus accelerating the adoption of accurate multi-label lesion detection in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>An AI system for automated multi-label lesion detection in chest X-rays. It aims to assist clinicians in diagnosing various thoracic diseases by localizing pathological abnormalities, improving the accuracy and efficiency of medical image interpretation, and reducing the need for labor-intensive manual annotations in clinical workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical limitation of existing promptable detection frameworks that rely on impractical, labor-intensive manual expert annotations for generating prompts.</li>
                    
                    <li>Introduces SP-Det, a self-prompted framework designed for generalized multi-label lesion detection in chest X-rays.</li>
                    
                    <li>Features an 'Expert-free Dual-Text Prompt Generator (DTPG)' that automatically creates two complementary textual prompt modalities: semantic context prompts (global patterns) and disease beacon prompts (disease-specific manifestations).</li>
                    
                    <li>Incorporates a 'Bidirectional Feature Enhancer (BFE)' to synergistically integrate comprehensive diagnostic context with disease-specific embeddings, significantly improving feature representation.</li>
                    
                    <li>Demonstrates superior performance compared to state-of-the-art detection methods on two distinct chest X-ray datasets covering various thoracic disease categories.</li>
                    
                    <li>Crucially, SP-Det completely eliminates the dependency on expert-annotated prompts, making it more practical and scalable for clinical applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The SP-Det framework employs a deep learning architecture that includes an Expert-free Dual-Text Prompt Generator (DTPG) for automated prompt creation, distinguishing between semantic context prompts and disease beacon prompts. These prompts are then leveraged by a Bidirectional Feature Enhancer (BFE) that integrates comprehensive diagnostic context with disease-specific embeddings to refine feature representation, ultimately guiding the multi-label lesion detection process.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SP-Det achieved state-of-the-art detection accuracy across two diverse chest X-ray datasets. The most significant finding is its ability to perform robust and accurate multi-label lesion detection while entirely negating the requirement for expert-annotated prompts, a fundamental dependency in prior promptable architectures.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By eliminating the need for manual expert annotation for prompts, SP-Det drastically reduces the operational burden and costs associated with deploying AI for chest X-ray analysis. This enables faster, more scalable, and more accessible implementation of advanced diagnostic tools, potentially leading to more efficient workflows, quicker diagnoses, and improved patient outcomes in radiology departments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights and addresses a key limitation of *existing* promptable detection frameworks (reliance on manual expert annotations), rather than explicitly stating limitations of the proposed SP-Det itself. However, as with all AI models, generalizability to extremely rare diseases or different imaging modalities not covered in the training data may warrant further investigation, though not explicitly mentioned.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for SP-Det. However, potential avenues could include exploring its application to other medical imaging modalities, integrating real-time feedback mechanisms, or investigating explainability features for clinical adoption.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Pulmonology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Lesion detection</span>
                    
                    <span class="tag tag-keyword">Chest X-ray</span>
                    
                    <span class="tag tag-keyword">Multi-label classification</span>
                    
                    <span class="tag tag-keyword">Self-prompted learning</span>
                    
                    <span class="tag tag-keyword">Medical imaging AI</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Radiology</span>
                    
                    <span class="tag tag-keyword">Diagnostic support</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated lesion detection in chest X-rays has demonstrated significant potential for improving clinical diagnosis by precisely localizing pathological abnormalities. While recent promptable detection frameworks have achieved remarkable accuracy in target localization, existing methods typically rely on manual annotations as prompts, which are labor-intensive and impractical for clinical applications. To address this limitation, we propose SP-Det, a novel self-prompted detection framework that automatically generates rich textual context to guide multi-label lesion detection without requiring expert annotations. Specifically, we introduce an expert-free dual-text prompt generator (DTPG) that leverages two complementary textual modalities: semantic context prompts that capture global pathological patterns and disease beacon prompts that focus on disease-specific manifestations. Moreover, we devise a bidirectional feature enhancer (BFE) that synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve feature representation and detection accuracy. Extensive experiments on two chest X-ray datasets with diverse thoracic disease categories demonstrate that our SP-Det framework outperforms state-of-the-art detection methods while completely eliminating the dependency on expert-annotated prompts compared to existing promptable architectures.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>