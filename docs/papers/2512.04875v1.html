<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection - Health AI Hub</title>
    <meta name="description" content="SP-Det introduces a novel self-prompted framework for multi-label lesion detection in chest X-rays, overcoming the significant challenge of labor-intensive manu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04875v1" target="_blank">2512.04875v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Qing Xu, Yanqian Wang, Xiangjian Hea, Yue Li, Yixuan Zhang, Rong Qu, Wenting Duan, Zhen Chen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04875v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04875v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SP-Det introduces a novel self-prompted framework for multi-label lesion detection in chest X-rays, overcoming the significant challenge of labor-intensive manual annotations required by existing promptable methods. It achieves this by automatically generating rich textual prompts through a dual-text generator and enhancing feature representation via a bidirectional enhancer, ultimately outperforming state-of-the-art detection methods.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly enhances the practicality and scalability of automated lesion detection in chest X-rays by removing the bottleneck of requiring expert manual annotations for prompts, enabling more efficient and widespread clinical deployment for improved diagnostic support and reduced physician workload.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is an automated system for multi-label lesion detection in chest X-rays. It utilizes a self-prompted dual-text fusion framework to identify and localize various pathological abnormalities, assisting clinicians in making more precise and efficient diagnoses of thoracic diseases. This system aims to reduce the workload and bottlenecks associated with manual expert annotation in medical imaging analysis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical limitation of current promptable lesion detection frameworks which necessitate labor-intensive manual expert annotations for prompts.</li>
                    
                    <li>Proposes SP-Det, a novel self-prompted detection framework that automatically generates textual context to guide multi-label lesion detection.</li>
                    
                    <li>Introduces an expert-free Dual-Text Prompt Generator (DTPG) that leverages two complementary textual modalities: semantic context prompts (global patterns) and disease beacon prompts (disease-specific manifestations).</li>
                    
                    <li>Devises a Bidirectional Feature Enhancer (BFE) to synergistically integrate comprehensive diagnostic context with disease-specific embeddings, significantly improving feature representation and detection accuracy.</li>
                    
                    <li>Demonstrates superior performance against state-of-the-art detection methods across two diverse chest X-ray datasets with various thoracic disease categories.</li>
                    
                    <li>Completely eliminates the dependency on expert-annotated prompts, making the system more practical and scalable for clinical applications.</li>
                    
                    <li>Aims to improve clinical diagnosis by precisely localizing pathological abnormalities in chest X-rays more efficiently.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The SP-Det framework employs a self-prompted approach featuring an Expert-free Dual-Text Prompt Generator (DTPG) to automatically create semantic context prompts (capturing global pathological patterns) and disease beacon prompts (focusing on disease-specific manifestations). These generated textual contexts are then utilized by a Bidirectional Feature Enhancer (BFE) which synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve the feature representation and overall detection accuracy for multi-label lesions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The SP-Det framework consistently outperforms state-of-the-art detection methods on two distinct chest X-ray datasets. Crucially, it completely eliminates the dependency on expert-annotated prompts, a fundamental requirement for existing promptable architectures, making it a more practical and autonomous solution.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SP-Det has the potential to significantly streamline and enhance the diagnostic workflow in radiology by providing automated, accurate, and prompt-free multi-label lesion detection from chest X-rays. This could lead to faster turnaround times, reduce the burden on radiologists by flagging abnormalities, facilitate earlier detection of thoracic diseases, and enable more scalable deployment of advanced AI diagnostic tools in diverse clinical environments, including those with limited access to specialized expertise.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations or caveats inherent to the SP-Det framework itself. The primary limitation addressed by SP-Det is that of *prior* promptable detection methods, which rely on labor-intensive manual annotations.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for the SP-Det framework.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Thoracic Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">lesion detection</span>
                    
                    <span class="tag tag-keyword">chest X-ray</span>
                    
                    <span class="tag tag-keyword">multi-label detection</span>
                    
                    <span class="tag tag-keyword">self-prompted learning</span>
                    
                    <span class="tag tag-keyword">dual-text fusion</span>
                    
                    <span class="tag tag-keyword">computer-aided diagnosis</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">radiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated lesion detection in chest X-rays has demonstrated significant potential for improving clinical diagnosis by precisely localizing pathological abnormalities. While recent promptable detection frameworks have achieved remarkable accuracy in target localization, existing methods typically rely on manual annotations as prompts, which are labor-intensive and impractical for clinical applications. To address this limitation, we propose SP-Det, a novel self-prompted detection framework that automatically generates rich textual context to guide multi-label lesion detection without requiring expert annotations. Specifically, we introduce an expert-free dual-text prompt generator (DTPG) that leverages two complementary textual modalities: semantic context prompts that capture global pathological patterns and disease beacon prompts that focus on disease-specific manifestations. Moreover, we devise a bidirectional feature enhancer (BFE) that synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve feature representation and detection accuracy. Extensive experiments on two chest X-ray datasets with diverse thoracic disease categories demonstrate that our SP-Det framework outperforms state-of-the-art detection methods while completely eliminating the dependency on expert-annotated prompts compared to existing promptable architectures.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>