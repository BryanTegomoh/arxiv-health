<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection - Health AI Hub</title>
    <meta name="description" content="This paper introduces DA4ICL, a novel demo-centric anchoring framework designed to enhance in-context learning (ICL) in large language models (LLMs) for Alzheim">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.06826v1" target="_blank">2511.06826v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Puzhen Su, Haoran Yin, Yongzhu Miao, Jintao Tang, Shasha Li, Ting Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.06826v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.06826v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces DA4ICL, a novel demo-centric anchoring framework designed to enhance in-context learning (ICL) in large language models (LLMs) for Alzheimer's disease (AD) detection from narrative transcripts. DA4ICL addresses the limitations of standard ICL and task vector methods by improving contextual perception through diverse and contrastive demo retrieval and deep signal anchoring, leading to significant and stable performance gains across AD benchmarks. This new paradigm is particularly effective for fine-grained, out-of-distribution, and low-resource LLM adaptation in specialized domains.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and early detection of Alzheimer's disease from subtle linguistic cues in narrative speech is critical for timely clinical intervention and patient management. This research enhances the capability of AI models to precisely identify these biomarkers, offering a non-invasive diagnostic aid.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research focuses on improving the performance of AI (specifically Large Language Models) in diagnosing Alzheimer's Disease from patient narrative data. This directly applies to developing more accurate and robust AI-powered diagnostic tools for neurological conditions, potentially aiding early detection and patient management.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>LLMs struggle with Alzheimer's Disease (AD) detection from narrative transcripts because it's an out-of-distribution (OOD) task and standard ICL demos produce highly homogeneous contexts, hindering both 'task cognition' and 'contextual perception'.</li>
                    
                    <li>Standard ICL quickly saturates due to a lack of diversity ('context width') and fine-grained signals ('context depth') in its demonstration sets.</li>
                    
                    <li>Recent Task Vector (TV) approaches are ill-suited for AD detection due to mismatches in injection granularity, strength, and position within the LLM's hidden states.</li>
                    
                    <li>DA4ICL, a demo-centric anchoring framework, is proposed to jointly expand 'context width' via Diverse and Contrastive Retrieval (DCR).</li>
                    
                    <li>DA4ICL also deepens each demo's signal ('context depth') via Projected Vector Anchoring (PVA), where fine-grained signals are injected at every Transformer layer of the LLM.</li>
                    
                    <li>The framework achieved large and stable performance gains over both standard ICL and Task Vector baselines across three different AD detection benchmarks.</li>
                    
                    <li>This work establishes a new paradigm for fine-grained, OOD, and low-resource adaptation of LLMs, especially relevant for highly specialized medical diagnostic tasks.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The DA4ICL framework enhances in-context learning by employing two key components: Diverse and Contrastive Retrieval (DCR) and Projected Vector Anchoring (PVA). DCR expands 'context width' by retrieving demonstration examples that are diverse yet contrastive, thereby enriching the training context. PVA deepens 'context depth' by projecting fine-grained signals from each demo into vector anchors, which are then injected into the LLM's hidden states at every Transformer layer, enabling a more profound integration of class-discriminative information.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>DA4ICL consistently achieved large and stable performance improvements over both conventional In-Context Learning (ICL) and Task Vector (TV) approaches across three distinct Alzheimer's disease detection benchmarks. This demonstrates its efficacy in overcoming challenges posed by out-of-distribution tasks, homogeneous contexts, and low-resource scenarios in medical text analysis.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This method has significant potential for clinical impact by providing a more robust and accurate AI-powered tool for early Alzheimer's disease detection. By precisely interpreting narrative speech patterns, it could enable clinicians to identify subtle cognitive changes earlier, leading to prompt diagnosis, earlier treatment initiation, and improved patient prognosis and quality of life. It also offers a scalable and less resource-intensive diagnostic adjunct.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of existing ICL and Task Vector methods, such as ICL's saturation and lack of demo diversity/depth, and TV's mismatch for fine-grained AD detection. It does not explicitly state limitations or caveats pertaining to the DA4ICL framework itself within the provided text.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests that DA4ICL charts a new paradigm for fine-grained, out-of-distribution (OOD), and low-resource LLM adaptation. This implies future research could explore applying this demo-centric anchoring framework to other complex medical diagnostic tasks, rare disease detection, or specialized domains facing similar challenges with data scarcity and the need for nuanced contextual understanding.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Speech Pathology</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                    <span class="tag">Cognitive Assessment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Alzheimer's Disease Detection</span>
                    
                    <span class="tag tag-keyword">In-Context Learning</span>
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">Narrative Transcripts</span>
                    
                    <span class="tag tag-keyword">Demo-centric Anchoring</span>
                    
                    <span class="tag tag-keyword">Out-of-Distribution Learning</span>
                    
                    <span class="tag tag-keyword">Medical Diagnostics</span>
                    
                    <span class="tag tag-keyword">Contextual Perception</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Detecting Alzheimer's disease (AD) from narrative transcripts challenges
large language models (LLMs): pre-training rarely covers this
out-of-distribution task, and all transcript demos describe the same scene,
producing highly homogeneous contexts. These factors cripple both the model's
built-in task knowledge (\textbf{task cognition}) and its ability to surface
subtle, class-discriminative cues (\textbf{contextual perception}). Because
cognition is fixed after pre-training, improving in-context learning (ICL) for
AD detection hinges on enriching perception through better demonstration (demo)
sets. We demonstrate that standard ICL quickly saturates, its demos lack
diversity (context width) and fail to convey fine-grained signals (context
depth), and that recent task vector (TV) approaches improve broad task
adaptation by injecting TV into the LLMs' hidden states (HSs), they are
ill-suited for AD detection due to the mismatch of injection granularity,
strength and position. To address these bottlenecks, we introduce
\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands
context width via \emph{\textbf{Diverse and Contrastive Retrieval}} (DCR) and
deepens each demo's signal via \emph{\textbf{Projected Vector Anchoring}} (PVA)
at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large,
stable gains over both ICL and TV baselines, charting a new paradigm for
fine-grained, OOD and low-resource LLM adaptation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to the 40th Annual AAAI Conference on Artificial
  Intelligence (2026) - Main Technical Track (Oral)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>