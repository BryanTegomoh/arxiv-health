<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel method to generate 500k multilingual reasoning traces in English, Italian, and Spanish, grounded in factual medical knowledge from">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05658v1" target="_blank">2512.05658v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Pietro Ferrazzi, Aitor Soroa, Rodrigo Agerri
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05658v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05658v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel method to generate 500k multilingual reasoning traces in English, Italian, and Spanish, grounded in factual medical knowledge from Wikipedia, to enhance Large Language Models (LLMs) for medical Question Answering (QA). By employing a retrieval-augmented generation approach and extending existing QA datasets, these traces significantly improve LLM performance in both few-shot and fine-tuning settings, achieving state-of-the-art results among 8B-parameter models. The work provides crucial resources to develop safer and more transparent multilingual clinical decision-support tools.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work is highly relevant to medicine by improving the reliability and multilingual capabilities of AI systems for medical Question Answering. It ensures that AI-driven medical information is factually grounded and accessible to healthcare professionals in diverse linguistic environments, enhancing global healthcare equity and safety.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research develops AI (Large Language Models) capable of multilingual medical reasoning for question answering. The primary application is to enhance and develop 'clinical decision-support tools' that can assist medical professionals by providing grounded, factual medical information and reasoning in multiple languages, thereby improving healthcare delivery and patient safety.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical limitations of current medical LLMs: their predominantly English focus and concerns about medical knowledge reliability due to reliance on general-purpose model distillation.</li>
                    
                    <li>Proposes a method to generate 500,000 multilingual reasoning traces (English, Italian, Spanish) explicitly grounded in factual medical information from Wikipedia.</li>
                    
                    <li>Utilizes a retrieval-augmented generation (RAG) approach to produce these traces, designed to solve medical questions from extended MedQA and MedMCQA datasets.</li>
                    
                    <li>Demonstrates that these reasoning traces effectively improve LLM performance in medical QA, both when used for in-context learning (few-shot prompting) and supervised fine-tuning.</li>
                    
                    <li>Achieves state-of-the-art results among 8B-parameter LLMs across medical QA benchmarks, validated in both in-domain and out-of-domain settings.</li>
                    
                    <li>All developed resources, including the multilingual reasoning traces, translated QA datasets, Medical-Wikipedia corpus, and fine-tuned models, are openly released.</li>
                    
                    <li>The research aims to support the development of more reliable, transparent, and linguistically accessible clinical decision-support tools.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed a method for generating 500,000 multilingual (English, Italian, Spanish) reasoning traces. This involved a retrieval-augmented generation (RAG) pipeline leveraging factual medical knowledge extracted from Wikipedia. Medical questions were sourced from MedQA and MedMCQA datasets, which were extended and translated into Italian and Spanish to facilitate trace generation. The effectiveness of these traces was then evaluated by integrating them into LLMs via both in-context learning (few-shot) and supervised fine-tuning, with performance assessed on medical QA benchmarks in both in-domain and out-of-domain scenarios.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The reasoning traces generated through the proposed method significantly improved LLM performance in medical Question Answering. Specifically, their application via in-context learning or supervised fine-tuning enabled 8B-parameter LLMs to achieve state-of-the-art results across various medical QA benchmarks, both within and outside their training domain. This demonstrates that grounding LLM reasoning in factual, multilingual medical knowledge substantially enhances reliability and accuracy.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to significantly improve clinical practice by enabling the creation of more reliable, transparent, and linguistically inclusive clinical decision-support tools. Healthcare professionals, especially in non-English speaking regions, can leverage these AI systems for more accurate and factually grounded medical information retrieval, potentially leading to better diagnostic support, treatment planning, and ultimately, safer patient care globally.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, a potential inferred limitation is the reliance on Wikipedia as the primary source for factual medical knowledge, which, while extensive, may not always represent the most current, peer-reviewed, or clinically authoritative guidelines compared to specialized medical databases or primary literature.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly outlined as 'future directions,' the paper implies that the released resources and methodology are intended to support the ongoing development of 'safer, more transparent clinical decision-support tools in multilingual settings.' This suggests future work could involve integrating these reasoning capabilities into live clinical environments, exploring additional medical knowledge sources beyond Wikipedia, and expanding linguistic support to further enhance global applicability.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">General Medicine</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">Medical Reasoning</span>
                    
                    <span class="tag tag-keyword">Question Answering</span>
                    
                    <span class="tag tag-keyword">Multilingual AI</span>
                    
                    <span class="tag tag-keyword">Retrieval-Augmented Generation</span>
                    
                    <span class="tag tag-keyword">Clinical Decision Support</span>
                    
                    <span class="tag tag-keyword">Medical QA Benchmarks</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Under Review</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>