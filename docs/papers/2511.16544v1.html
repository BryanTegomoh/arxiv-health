<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue - Health AI Hub</title>
    <meta name="description" content="This paper challenges the standard reliance on Word Error Rate (WER) for evaluating Automatic Speech Recognition (ASR) in clinical dialogue, demonstrating its p">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16544v1" target="_blank">2511.16544v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zachary Ellis, Jared Joselowitz, Yash Deo, Yajie He, Anna Kalygina, Aisling Higham, Mana Rahimzadeh, Yan Jia, Ibrahim Habli, Ernest Lim
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16544v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16544v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper challenges the standard reliance on Word Error Rate (WER) for evaluating Automatic Speech Recognition (ASR) in clinical dialogue, demonstrating its poor correlation with the actual clinical impact of transcription errors. It introduces and validates an LLM-as-a-Judge, programmatically optimized using GEPA, which achieves human-comparable performance in replicating expert clinician assessment of error impact.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and reliable transcription of patient-facing clinical dialogue is paramount for patient safety, accurate diagnosis, and effective treatment planning. This research directly impacts the safe and responsible deployment of ASR systems in healthcare by ensuring their evaluation aligns with actual clinical risk rather than just textual accuracy.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI-driven evaluation framework (an LLM-as-a-Judge) to assess the clinical impact and safety of Automatic Speech Recognition (ASR) systems used in healthcare. The AI tool is specifically trained and validated to replicate expert clinical assessment of ASR transcription errors in doctor-patient dialogue, aiming to ensure accurate clinical understanding and minimize patient risk.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Standard ASR evaluation metrics, including WER, correlate poorly with the actual clinical impact of transcription errors in patient-facing dialogue.</li>
                    
                    <li>A gold-standard benchmark was established by expert clinicians who compared ground-truth utterances with ASR-generated counterparts, labeling discrepancies based on their clinical impact (No, Minimal, or Significant).</li>
                    
                    <li>The analysis definitively showed that WER and a comprehensive suite of other existing metrics are insufficient predictors of clinician-assigned risk.</li>
                    
                    <li>An LLM-as-a-Judge framework was developed and optimized using GEPA (Generative Pre-trained Transformer-based Evaluation Parameter Adjustment) to programmatically replicate expert clinical assessment of error impact.</li>
                    
                    <li>The optimized LLM-as-a-Judge (Gemini-2.5-Pro) achieved human-comparable performance, demonstrating 90% accuracy and a strong Cohen's Œ∫ of 0.816 in assessing clinical impact.</li>
                    
                    <li>This work provides a validated, automated framework designed for scalable assessment of ASR safety in clinical dialogue, moving beyond simple textual fidelity.</li>
                    
                    <li>The methodology addresses a critical gap in current ASR evaluation, offering a more clinically relevant metric for healthcare applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Expert clinicians manually compared ground-truth patient-doctor dialogue utterances with their ASR-generated transcriptions from two distinct datasets. They then assigned clinical impact labels (No, Minimal, Significant Impact) to any identified discrepancies, creating a gold-standard benchmark. Subsequently, an LLM-as-a-Judge framework was developed using Gemini-2.5-Pro and programmatically optimized via GEPA to automate the replication of these expert clinical assessments.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study found that standard ASR metrics, including Word Error Rate (WER), correlate poorly with the clinical impact labels assigned by expert clinicians. In contrast, the optimized LLM-as-a-Judge (Gemini-2.5-Pro) achieved human-comparable performance in assessing clinical impact, demonstrating 90% accuracy and a strong Cohen's Œ∫ of 0.816.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a crucial, scalable tool for evaluating ASR technologies specifically for clinical use, directly addressing patient safety concerns. It allows for the development and deployment of ASR systems that are optimized not just for textual accuracy, but for minimizing actual clinical risk, thereby enhancing the reliability and trustworthiness of AI in healthcare decision-making and documentation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. However, potential considerations not detailed here could include the generalizability of the trained LLM across highly diverse clinical specialties or languages not represented in the two specific dialogue datasets used, and the inherent subjective nature that can still exist even in 'expert' clinical impact labeling.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work establishes a validated, automated framework, suggesting future directions involve its widespread adoption and integration into ASR development and quality assurance pipelines for clinical applications. Further research could focus on expanding the framework's application across a broader array of medical specialties, diverse linguistic contexts, and potentially integrating it for real-time risk assessment in clinical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Medical Artificial Intelligence</span>
                    
                    <span class="tag">Patient Safety</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Speech Recognition in Healthcare</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Automatic Speech Recognition</span>
                    
                    <span class="tag tag-keyword">ASR evaluation</span>
                    
                    <span class="tag tag-keyword">Clinical impact</span>
                    
                    <span class="tag tag-keyword">Word Error Rate</span>
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">LLM-as-a-Judge</span>
                    
                    <span class="tag tag-keyword">Patient safety</span>
                    
                    <span class="tag tag-keyword">Clinical dialogue</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $Œ∫$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>