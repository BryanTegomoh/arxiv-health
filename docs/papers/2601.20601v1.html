<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification - Health AI Hub</title>
    <meta name="description" content="This paper introduces CLEAR-Mamba, an enhanced deep learning framework for accurate, adaptive, and trustworthy multi-sequence ophthalmic angiography classificat">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.20601v1" target="_blank">2601.20601v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhuonan Wang, Wenjie Yan, Wenqiao Zhang, Xiaohui Song, Jian Ma, Ke Yao, Yibo Yu, Beng Chin Ooi
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.20601v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.20601v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces CLEAR-Mamba, an enhanced deep learning framework for accurate, adaptive, and trustworthy multi-sequence ophthalmic angiography classification (FFA/ICGA). It addresses limitations of existing methods, such as poor generalization and low-confidence predictions, stemming from single-modality data, subtle lesions, and inter-device variability. CLEAR-Mamba achieves superior performance, particularly in multi-disease classification and reliability, through architectural optimizations (HaC for adaptability) and a novel training strategy (RaP for uncertainty-aware predictions), validated on a new large-scale angiography dataset.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Ophthalmic angiography (FFA and ICGA) provides crucial information for early detection, treatment planning, and prognosis assessment of retinal diseases. This research offers an advanced AI solution to automate and improve the accuracy, adaptability, and reliability of classifying these complex medical images, directly impacting diagnostic efficiency and precision in ophthalmology.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research describes an AI system (CLEAR-Mamba) for automated or assisted diagnosis of retinal diseases using ophthalmic angiography images (FFA and ICGA). The AI application aims to improve the accuracy, adaptability across different imaging devices, and trustworthiness (reliability-aware prediction) of medical image classification, thereby aiding clinicians in early disease detection and treatment planning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in ophthalmic angiography classification, including limitations in generalization and high-confidence prediction due to single-modality data, subtle lesion patterns, and significant inter-device variability.</li>
                    
                    <li>Proposes CLEAR-Mamba, an enhanced framework built upon MedMamba, specifically optimized for multi-sequence ophthalmic angiography classification tasks.</li>
                    
                    <li>Introduces HaC (Hypernetwork-based Adaptive Conditioning layer) as an architectural innovation that dynamically generates model parameters based on input feature distributions, thereby significantly improving cross-domain adaptability.</li>
                    
                    <li>Develops RaP (Reliability-aware Prediction scheme), a novel training strategy leveraging evidential uncertainty learning to encourage the model to emphasize low-confidence samples, enhancing overall stability and prediction reliability.</li>
                    
                    <li>Constructs a new large-scale ophthalmic angiography dataset encompassing both Fluorescein Fundus Angiography (FFA) and Indocyanine Green Angiography (ICGA) modalities, covering multiple retinal disease categories.</li>
                    
                    <li>Experimental results demonstrate that CLEAR-Mamba consistently outperforms multiple baseline models, including the original MedMamba, across various metrics.</li>
                    
                    <li>Shows particular advantages in multi-disease classification and in providing reliability-aware predictions, offering a balanced solution for generalizability and trustworthiness in modality-specific medical image classification.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>CLEAR-Mamba is an enhanced deep learning framework built on MedMamba. Architecturally, it integrates a HaC (Hypernetwork-based Adaptive Conditioning) layer that dynamically generates parameters based on input feature distributions to boost cross-domain adaptability. For training, it employs RaP (Reliability-aware Prediction), a scheme utilizing evidential uncertainty learning to prioritize low-confidence samples, thereby improving prediction stability and reliability. The model was trained and evaluated on a newly constructed, large-scale dataset comprising multi-sequence FFA and ICGA images across diverse retinal disease categories.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>CLEAR-Mamba consistently outperformed several baseline models, including the original MedMamba, across various evaluation metrics. It demonstrated significant advantages in its ability to classify multiple retinal diseases and in generating predictions with higher reliability and stability, attributed to its adaptive conditioning and uncertainty-aware training strategies.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology holds the potential to significantly enhance computer-aided diagnosis of retinal diseases by providing highly accurate, adaptable, and trustworthy classifications from ophthalmic angiography. Clinicians could benefit from more reliable automated analyses that generalize better across different imaging devices and patient populations, aiding in earlier disease detection, more precise treatment planning, and improved patient prognosis with an added layer of confidence in AI-generated predictions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *existing methods* that CLEAR-Mamba aims to overcome, such as their struggles with generalization and high-confidence predictions due to single-modality nature, subtle lesion patterns, and significant inter-device variability. The abstract does not explicitly state limitations inherent to the CLEAR-Mamba framework itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract states that this study provides an effective solution balancing generalizability and reliability, but does not explicitly outline specific future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Retinal Diseases</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Computer-Aided Diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">ophthalmic angiography</span>
                    
                    <span class="tag tag-keyword">medical image classification</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">Mamba</span>
                    
                    <span class="tag tag-keyword">hypernetwork</span>
                    
                    <span class="tag tag-keyword">evidential uncertainty</span>
                    
                    <span class="tag tag-keyword">cross-domain adaptability</span>
                    
                    <span class="tag tag-keyword">computer-aided diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical image classification is a core task in computer-aided diagnosis (CAD), playing a pivotal role in early disease detection, treatment planning, and patient prognosis assessment. In ophthalmic practice, fluorescein fundus angiography (FFA) and indocyanine green angiography (ICGA) provide hemodynamic and lesion-structural information that conventional fundus photography cannot capture. However, due to the single-modality nature, subtle lesion patterns, and significant inter-device variability, existing methods still face limitations in generalization and high-confidence prediction. To address these challenges, we propose CLEAR-Mamba, an enhanced framework built upon MedMamba with optimizations in both architecture and training strategy. Architecturally, we introduce HaC, a hypernetwork-based adaptive conditioning layer that dynamically generates parameters according to input feature distributions, thereby improving cross-domain adaptability. From a training perspective, we develop RaP, a reliability-aware prediction scheme built upon evidential uncertainty learning, which encourages the model to emphasize low-confidence samples and improves overall stability and reliability. We further construct a large-scale ophthalmic angiography dataset covering both FFA and ICGA modalities, comprising multiple retinal disease categories for model training and evaluation. Experimental results demonstrate that CLEAR-Mamba consistently outperforms multiple baseline models, including the original MedMamba, across various metrics-showing particular advantages in multi-disease classification and reliability-aware prediction. This study provides an effective solution that balances generalizability and reliability for modality-specific medical image classification tasks.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>10 pages,7 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>