<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes - Health AI Hub</title>
    <meta name="description" content="This study introduces a GPT-based architecture for clinical text classification that addresses challenges in modeling long EHR notes by employing a selective fi">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.21955v1" target="_blank">2601.21955v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-29
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fariba Afrin Irany
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.21955v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.21955v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study introduces a GPT-based architecture for clinical text classification that addresses challenges in modeling long EHR notes by employing a selective fine-tuning strategy on a pretrained decoder-only Transformer. By freezing most of the GPT-2 backbone and training only specific final layers and a lightweight classification head, the method achieves strong and efficient performance on radiology reports, particularly adept at handling complex findings like non-mentions and negations.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critical for leveraging the vast amounts of unstructured clinical narratives in EHRs to enable more accurate automated disease characterization, improve cohort identification for research, and enhance the efficacy of clinical decision support systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves leveraging a GPT-based language model, adapted through selective fine-tuning, to automatically analyze and classify medical text from EHR notes and radiology reports. This system aims to improve efficiency in tasks such as identifying specific radiographic findings, predicting disease outcomes, and generating insights for clinical decision support, thereby directly enhancing healthcare processes through AI.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** Tackles challenges in modeling long, domain-specific clinical text from EHRs, including limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.</li>
                    
                    <li>**Proposed Architecture:** A GPT-based (decoder-only Transformer) model adapted through a novel selective fine-tuning strategy for clinical text classification.</li>
                    
                    <li>**Selective Fine-Tuning:** The majority of the pretrained GPT-2 backbone is frozen, with training restricted to the final Transformer block, the final layer normalization, and a lightweight classification head.</li>
                    
                    <li>**Computational Efficiency:** This approach substantially reduces the number of trainable parameters, thereby decreasing computational complexity, while preserving the representational capacity needed for complex clinical language.</li>
                    
                    <li>**Evaluation Data:** The method was rigorously evaluated on radiology reports from the MIMIC-IV-Note dataset, using uncertainty-aware CheXpert-style labels derived directly from the report text.</li>
                    
                    <li>**Versatile Problem Formulations:** Experiments covered multiple classification tasks, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction.</li>
                    
                    <li>**Robust Performance:** The model demonstrated stable convergence behavior and strong classification performance across varying dataset sizes, proving particularly effective in settings dominated by non-mention and negated findings.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employs a GPT-based architecture, adapting a pretrained decoder-only Transformer (specifically, a GPT-2 backbone) using a selective fine-tuning strategy. This strategy involves freezing most of the model's parameters and restricting training to only the final Transformer block, the final layer normalization, and a lightweight classification head. The model was evaluated on radiology reports from the MIMIC-IV-Note dataset, utilizing uncertainty-aware CheXpert-style labels automatically derived from the text, across multi-label, binary per-label, and aggregate disease outcome classification tasks.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification. The proposed GPT-based architecture exhibits stable convergence and strong classification performance on clinical text, particularly excelling in scenarios dominated by non-mention and negated findings, while significantly reducing computational complexity.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This methodology enables scalable adaptation of advanced language models to real-world EHR data with substantially reduced computational costs, facilitating the development of more efficient and accurate AI tools for automated disease characterization, precise patient cohort identification for clinical studies, and robust clinical decision support systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly detail specific limitations of the proposed GPT-based architecture or its evaluation; it primarily highlights the advantages and strong performance.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for this work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                    <span class="tag">Public Health (Cohort Identification)</span>
                    
                    <span class="tag">Disease Epidemiology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">GPT-based architecture</span>
                    
                    <span class="tag tag-keyword">clinical text classification</span>
                    
                    <span class="tag tag-keyword">EHR notes</span>
                    
                    <span class="tag tag-keyword">selective fine-tuning</span>
                    
                    <span class="tag tag-keyword">Transformer</span>
                    
                    <span class="tag tag-keyword">MIMIC-IV-Note</span>
                    
                    <span class="tag tag-keyword">radiology reports</span>
                    
                    <span class="tag tag-keyword">generative modeling</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This submission is a full-length research manuscript consisting of 37 pages and 15 figures. The paper presents a GPT-based architecture with selective fine-tuning for clinical text classification, including detailed architectural diagrams, learning curves, and evaluation figures such as ROC curves and confusion matrices</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>