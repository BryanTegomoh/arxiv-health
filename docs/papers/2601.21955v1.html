<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes - Health AI Hub</title>
    <meta name="description" content="This study introduces a GPT-based architecture for clinical text classification that employs a selective fine-tuning strategy to efficiently adapt pretrained de">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.21955v1" target="_blank">2601.21955v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-29
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fariba Afrin Irany
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.21955v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.21955v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study introduces a GPT-based architecture for clinical text classification that employs a selective fine-tuning strategy to efficiently adapt pretrained decoder-only Transformers. By freezing most of the GPT-2 backbone and training only specific final layers, the model achieves strong classification performance on radiology reports from the MIMIC-IV-Note dataset, particularly for non-mention and negated findings, while significantly reducing computational complexity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research directly advances automated disease characterization, cohort identification, and clinical decision support by providing an efficient and effective method for processing and classifying complex, unstructured clinical narratives within electronic health records.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using a selectively fine-tuned GPT-based language model to analyze and classify medical information from unstructured clinical text in EHRs (specifically radiology reports). This enables automated identification of radiographic findings, disease characterization, patient cohort identification for research or treatment, and provides a foundation for clinical decision support systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in modeling long, domain-specific clinical text from EHRs, including limited labeled data, severe class imbalance, and high computational costs of large language models.</li>
                    
                    <li>Proposes a novel GPT-based architecture utilizing a 'selective fine-tuning' strategy for clinical text classification.</li>
                    
                    <li>The method freezes the majority of the pretrained GPT-2 backbone, restricting training to the final Transformer block, the final layer normalization, and a lightweight classification head.</li>
                    
                    <li>This selective approach substantially reduces the number of trainable parameters, making the adaptation computationally efficient while preserving the model's capacity to represent complex clinical language.</li>
                    
                    <li>Evaluated on radiology reports from the MIMIC-IV-Note dataset, employing uncertainty-aware CheXpert-style labels derived directly from the text.</li>
                    
                    <li>Demonstrates stable convergence behavior and strong classification performance across multiple problem formulations, including multi-label, binary per-label (under uncertainty), and aggregate disease outcome prediction.</li>
                    
                    <li>Exhibits particularly robust performance in settings dominated by non-mention and negated radiographic findings, which are crucial for accurate clinical interpretation.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employs a pretrained decoder-only Transformer (GPT-2) and adapts it using a selective fine-tuning strategy. The core GPT-2 backbone is largely frozen, with training parameters restricted to the final Transformer block, the final layer normalization, and a lightweight classification head, thereby minimizing trainable parameters. The model is evaluated on radiology reports from the MIMIC-IV-Note dataset, utilizing uncertainty-aware CheXpert-style labels derived directly from the text. Experiments cover multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The selectively fine-tuned GPT model achieved stable convergence behavior and strong classification performance across various problem formulations and dataset sizes. Notably, it performed well in challenging settings dominated by non-mention and negated radiographic findings. This efficiency stems from a substantial reduction in trainable parameters, allowing for scalable adaptation to real-world EHR data with significantly lower computational complexity.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The proposed architecture enables more efficient and scalable deployment of AI models for automated analysis of vast amounts of unstructured clinical narratives, facilitating applications like early disease detection, precise patient phenotyping for research, and enhanced decision support for clinicians. Its ability to accurately handle negated and non-mention findings is crucial for robust and reliable clinical interpretation, potentially improving diagnostic accuracy and workflow efficiency.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed method or study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Disease Characterization</span>
                    
                    <span class="tag">Cohort Identification</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">GPT-based architecture</span>
                    
                    <span class="tag tag-keyword">Clinical text classification</span>
                    
                    <span class="tag tag-keyword">EHR notes</span>
                    
                    <span class="tag tag-keyword">Selective fine-tuning</span>
                    
                    <span class="tag tag-keyword">MIMIC-IV-Note</span>
                    
                    <span class="tag tag-keyword">Radiology reports</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This submission is a full-length research manuscript consisting of 37 pages and 15 figures. The paper presents a GPT-based architecture with selective fine-tuning for clinical text classification, including detailed architectural diagrams, learning curves, and evaluation figures such as ROC curves and confusion matrices</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>