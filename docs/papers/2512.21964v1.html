<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Perceive and Calibrate: Analyzing and Enhancing Robustness of Medical Multi-Modal Large Language Models - Health AI Hub</title>
    <meta name="description" content="Medical Multi-modal Large Language Models (MLLMs) are significantly hampered by their sensitivity to real-world input perturbations like imaging artifacts and t">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Perceive and Calibrate: Analyzing and Enhancing Robustness of Medical Multi-Modal Large Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.21964v1" target="_blank">2512.21964v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-26
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Dunyuan XU, Xikai Yang, Yaoqian Li, Juzheng Miao, Jinpeng Li, Pheng-Ann Heng
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.21964v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.21964v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Medical Multi-modal Large Language Models (MLLMs) are significantly hampered by their sensitivity to real-world input perturbations like imaging artifacts and textual errors, which critically undermines their clinical applicability. This paper systematically analyzes the impact of such noise and introduces a training-free Inherent-enhanced Multi-modal Calibration (IMC) framework. IMC leverages MLLMs' intrinsic capabilities for cross-modal robustness enhancement through a Perturbation-aware Denoising Calibration (PDC) for visuals and a Self-instantiated Multi-agent System (SMS) for text, demonstrating state-of-the-art performance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research directly addresses a critical safety and reliability issue for AI in healthcare by making medical Multi-modal Large Language Models more resilient to common imperfections and errors in clinical data. This robustness is paramount for ensuring accurate diagnoses, safe treatment decisions, and overall trustworthiness of AI systems in patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research aims to develop more robust and reliable medical AI systems, specifically Multi-modal Large Language Models, for use in healthcare. By enhancing their ability to handle noisy real-world data such as medical images with artifacts and clinical text with errors, this work contributes to making these AI models safer and more effective for critical applications like diagnosis, treatment planning, and medical information processing. This improved robustness is essential for their deployment in clinical settings to support healthcare professionals and improve patient outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Medical MLLMs exhibit high sensitivity to common input perturbations (e.g., imaging artifacts, textual errors), hindering their clinical deployment and requiring solutions beyond general-domain methods.</li>
                    
                    <li>The research conducts a systematic analysis of the impact of 11 distinct types of noise across both visual and textual modalities on medical MLLMs, addressing a critical gap in current understanding.</li>
                    
                    <li>A novel, training-free Inherent-enhanced Multi-modal Calibration (IMC) framework is proposed, utilizing a 'perceive-and-calibrate' principle to leverage MLLMs' inherent denoising capabilities for robustness enhancement.</li>
                    
                    <li>For visual robustness, the IMC framework incorporates Perturbation-aware Denoising Calibration (PDC), which uses the MLLM's own vision encoder to identify noise patterns and perform prototype-guided feature calibration.</li>
                    
                    <li>For textual robustness, IMC employs a Self-instantiated Multi-agent System (SMS) that exploits the MLLM's self-assessment capabilities to refine noisy text through a cooperative, hierarchical agent structure.</li>
                    
                    <li>A comprehensive benchmark was constructed, featuring 11 types of noise across image and text modalities, evaluated on two distinct medical datasets.</li>
                    
                    <li>Experimental results demonstrate that the IMC framework achieves state-of-the-art performance in enhancing robustness across multiple modalities, validating its potential for real clinical scenarios.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study first systematically analyzes the impact of 11 distinct types of visual and textual perturbations on medical MLLMs. It then introduces the training-free Inherent-enhanced Multi-modal Calibration (IMC) framework. For visual robustness, IMC employs Perturbation-aware Denoising Calibration (PDC), which utilizes the MLLM's vision encoder to identify noise patterns and perform prototype-guided feature calibration. For textual robustness, IMC incorporates a Self-instantiated Multi-agent System (SMS) that leverages the MLLM's self-assessment abilities for hierarchical, cooperative text refinement. The framework's efficacy is evaluated using a custom benchmark consisting of 11 noise types applied to two medical datasets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed Inherent-enhanced Multi-modal Calibration (IMC) framework significantly improves the robustness of medical MLLMs across both visual and textual modalities. It achieves state-of-the-art performance against various real-world perturbations, demonstrating its effectiveness in enhancing the reliability of these models.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By making medical MLLMs robust to real-world data noise and artifacts, this research can lead to more reliable AI-assisted diagnoses, treatment recommendations, and clinical decision support. This directly enhances patient safety and trust in AI, as clinicians can rely on the models even when input data is imperfect, thereby accelerating the adoption and practical utility of advanced AI in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the proposed IMC framework. However, it highlights the inadequacy of previous general-domain, text-focused, and costly fine-tuning approaches, which IMC aims to overcome with its training-free, cross-modal approach.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. However, the demonstrated "potential to enhance MLLMs' robustness in real clinical scenarios" implies future work would involve broader clinical validation, deployment studies, and integration into existing healthcare workflows to fully realize its impact.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical MLLMs</span>
                    
                    <span class="tag tag-keyword">Robustness</span>
                    
                    <span class="tag tag-keyword">Input Perturbations</span>
                    
                    <span class="tag tag-keyword">Denoising</span>
                    
                    <span class="tag tag-keyword">Multi-modal Calibration</span>
                    
                    <span class="tag tag-keyword">Vision Encoder</span>
                    
                    <span class="tag tag-keyword">Multi-agent System</span>
                    
                    <span class="tag tag-keyword">Clinical Applicability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical Multi-modal Large Language Models (MLLMs) have shown promising clinical performance. However, their sensitivity to real-world input perturbations, such as imaging artifacts and textual errors, critically undermines their clinical applicability. Systematic analysis of such noise impact on medical MLLMs remains largely unexplored. Furthermore, while several works have investigated the MLLMs' robustness in general domains, they primarily focus on text modality and rely on costly fine-tuning. They are inadequate to address the complex noise patterns and fulfill the strict safety standards in medicine. To bridge this gap, this work systematically analyzes the impact of various perturbations on medical MLLMs across both visual and textual modalities. Building on our findings, we introduce a training-free Inherent-enhanced Multi-modal Calibration (IMC) framework that leverages MLLMs' inherent denoising capabilities following the perceive-and-calibrate principle for cross-modal robustness enhancement. For the visual modality, we propose a Perturbation-aware Denoising Calibration (PDC) which leverages MLLMs' own vision encoder to identify noise patterns and perform prototype-guided feature calibration. For text denoising, we design a Self-instantiated Multi-agent System (SMS) that exploits the MLLMs' self-assessment capabilities to refine noisy text through a cooperative hierarchy of agents. We construct a benchmark containing 11 types of noise across both image and text modalities on 2 datasets. Experimental results demonstrate our method achieves the state-of-the-art performance across multiple modalities, showing potential to enhance MLLMs' robustness in real clinical scenarios.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>