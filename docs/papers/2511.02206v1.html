<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Language-Enhanced Generative Modeling for PET Synthesis from MRI and Blood Biomarkers - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel language-enhanced generative model that synthesizes realistic amyloid-beta PET images from T1-weighted MRI scans and blood-based b">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Language-Enhanced Generative Modeling for PET Synthesis from MRI and Blood Biomarkers</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.02206v1" target="_blank">2511.02206v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhengjie Zhang, Xiaoxie Mao, Qihao Guo, Shaoting Zhang, Qi Huang, Mu Zhou, Fang Xie, Mianxin Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.02206v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.02206v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel language-enhanced generative model that synthesizes realistic amyloid-beta PET images from T1-weighted MRI scans and blood-based biomarkers. The synthetic PET images demonstrate high fidelity to real scans and significantly improve Alzheimer's disease diagnostic accuracy within an automated pipeline, outperforming models based solely on MRI or blood biomarkers. This approach offers a potential solution to the high cost and limited accessibility of traditional Abeta-PET imaging.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant as it provides a pathway to overcome the existing barriers to amyloid-beta PET imaging, a crucial diagnostic tool for Alzheimer's disease. By making Abeta pathology assessment more accessible and affordable through synthetic imaging from routine MRI and blood tests, it could accelerate diagnosis, facilitate earlier interventions, and reduce healthcare disparities.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research develops a language-enhanced generative model, incorporating a large language model (LLM) and multimodal information fusion, to synthesize realistic Abeta-PET images from MRI scans and blood biomarkers. This AI application aims to improve the accessibility and reduce the cost of Alzheimer's disease diagnosis by providing a computationally synthesized PET alternative. It further integrates this AI-synthesized imaging into a fully automatic AD diagnostic pipeline, demonstrating enhanced diagnostic performance compared to traditional methods.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of high cost and limited accessibility of Abeta-PET for Alzheimer's disease diagnosis.</li>
                    
                    <li>Develops a language-enhanced generative model, driven by a Large Language Model (LLM) and multimodal information fusion (T1-MRI, blood-based biomarkers), to synthesize Abeta-PET images.</li>
                    
                    <li>Synthesized PET images show high structural similarity (SSIM = 0.920 +/- 0.003) and regional pattern correlation (Pearson's r = 0.955 +/- 0.007) with real PET scans.</li>
                    
                    <li>Diagnostic outcomes using synthetic PET demonstrate high agreement (accuracy = 0.80) with real PET-based diagnoses.</li>
                    
                    <li>A fully automatic AD diagnostic pipeline leveraging synthetic PET (AUC = 0.78) significantly outperforms models based on T1-MRI (AUC = 0.68) or BBMs alone (AUC = 0.73).</li>
                    
                    <li>Combining synthetic PET with blood biomarkers further optimizes diagnostic performance, achieving an AUC of 0.79.</li>
                    
                    <li>Ablation analysis confirms the substantial benefits derived from LLM integration and prompt engineering in the generative model architecture.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved collecting Abeta-PET images, T1-weighted MRI scans, and blood-based biomarkers from 566 participants. A language-enhanced generative model, integrating a Large Language Model (LLM) with multimodal information fusion, was developed to synthesize PET images. The synthesized images were rigorously evaluated for image quality (SSIM, Pearson's r), diagnostic consistency (accuracy), and clinical applicability (AUC) within a fully automated AD diagnostic pipeline. Ablation analysis was performed to quantify the contribution of LLM integration and prompt engineering.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The synthesized PET images closely matched real PET scans in structural details (SSIM = 0.920 +/- 0.003) and regional patterns (Pearson's r = 0.955 +/- 0.007). Diagnostic outcomes using synthetic PET showed high agreement with real PET-based diagnoses (accuracy = 0.80). A fully automatic AD diagnostic pipeline using synthetic PET achieved an AUC of 0.78, outperforming T1-based (AUC = 0.68) and BBM-based (AUC = 0.73) models, with combined synthetic PET and BBMs further improving performance (AUC = 0.79). Ablation analysis validated the advantages of LLM integration and prompt engineering.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology has the potential to transform Alzheimer's disease diagnosis by providing a cost-effective and highly accessible alternative to traditional Abeta-PET scans. It could enable more widespread assessment of amyloid pathology, facilitate earlier and more accurate diagnoses leveraging existing MRI and blood biomarker data, and streamline the diagnostic workflow, particularly in resource-limited settings. This could lead to timelier patient management and potentially better therapeutic outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the study. Potential considerations not mentioned could include the generalizability of the model to diverse populations, the long-term prospective validation in clinical settings, or the interpretability of the LLM's contribution to the synthesis process.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. However, potential future work could involve large-scale external validation across diverse patient cohorts, exploration of additional multimodal inputs, integration into existing clinical decision support systems, and investigation into the model's capability for prognostic prediction or monitoring disease progression.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Nuclear Medicine</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Biomarker Research</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Alzheimer's Disease</span>
                    
                    <span class="tag tag-keyword">PET Synthesis</span>
                    
                    <span class="tag tag-keyword">Generative Models</span>
                    
                    <span class="tag tag-keyword">Large Language Model (LLM)</span>
                    
                    <span class="tag tag-keyword">Multimodal Fusion</span>
                    
                    <span class="tag tag-keyword">Blood Biomarkers</span>
                    
                    <span class="tag tag-keyword">MRI</span>
                    
                    <span class="tag tag-keyword">Amyloid-beta</span>
                    
                    <span class="tag tag-keyword">Diagnostic Accuracy</span>
                    
                    <span class="tag tag-keyword">Neuroimaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Background: Alzheimer's disease (AD) diagnosis heavily relies on amyloid-beta
positron emission tomography (Abeta-PET), which is limited by high cost and
limited accessibility. This study explores whether Abeta-PET spatial patterns
can be predicted from blood-based biomarkers (BBMs) and MRI scans. Methods: We
collected Abeta-PET images, T1-weighted MRI scans, and BBMs from 566
participants. A language-enhanced generative model, driven by a large language
model (LLM) and multimodal information fusion, was developed to synthesize PET
images. Synthesized images were evaluated for image quality, diagnostic
consistency, and clinical applicability within a fully automated diagnostic
pipeline. Findings: The synthetic PET images closely resemble real PET scans in
both structural details (SSIM = 0.920 +/- 0.003) and regional patterns
(Pearson's r = 0.955 +/- 0.007). Diagnostic outcomes using synthetic PET show
high agreement with real PET-based diagnoses (accuracy = 0.80). Using synthetic
PET, we developed a fully automatic AD diagnostic pipeline integrating PET
synthesis and classification. The synthetic PET-based model (AUC = 0.78)
outperforms T1-based (AUC = 0.68) and BBM-based (AUC = 0.73) models, while
combining synthetic PET and BBMs further improved performance (AUC = 0.79).
Ablation analysis supports the advantages of LLM integration and prompt
engineering. Interpretation: Our language-enhanced generative model synthesizes
realistic PET images, enhancing the utility of MRI and BBMs for Abeta spatial
pattern assessment and improving the diagnostic workflow for Alzheimer's
disease.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>31 pages, 8 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>