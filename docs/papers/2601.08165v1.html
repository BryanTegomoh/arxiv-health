<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Representation Learning with Semantic-aware Instance and Sparse Token Alignments - Health AI Hub</title>
    <meta name="description" content="This paper introduces SISTA, a novel multi-level alignment framework for medical vision-language pre-training (VLP) that addresses the common issue of false neg">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Representation Learning with Semantic-aware Instance and Sparse Token Alignments</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.08165v1" target="_blank">2601.08165v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-13
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Phuoc-Nguyen Bui, Toan Duc Nguyen, Junghyun Bum, Duc-Tai Le, Hyunseung Choo
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.08165v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.08165v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SISTA, a novel multi-level alignment framework for medical vision-language pre-training (VLP) that addresses the common issue of false negatives in contrastive learning. By incorporating inter-report semantic similarity and aligning image patches with relevant word tokens, SISTA learns more robust representations. This approach significantly improves performance across various downstream tasks, including image classification, segmentation, and object detection, particularly demonstrating effectiveness with limited labeled data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging by improving the fundamental representation learning process for a wide array of diagnostic and analytical tasks. Enhanced pre-training can lead to more accurate, robust, and generalizable AI models for interpreting complex medical images and associated reports.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies AI to health by developing improved representation learning models for medical vision-language tasks. Its direct application is enhancing the accuracy and robustness of AI systems designed for analyzing medical images (e.g., X-rays, CT scans, MRI) in conjunction with their corresponding radiology reports. This can lead to better AI assistance for tasks such as automated disease detection, lesion segmentation, abnormality localization, and overall more efficient and accurate diagnostic support for healthcare professionals, potentially even with limited labeled medical data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Traditional medical VLP contrastive learning methods suffer from false negatives, where semantically similar but unpaired medical samples are wrongly treated as negatives, disrupting learned representations.</li>
                    
                    <li>The proposed SISTA (Semantic-aware Instance and Sparse Token Alignments) framework addresses this by employing a multi-level alignment strategy.</li>
                    
                    <li>SISTA refines image-report level alignment by integrating *inter-report similarity*, effectively identifying and mitigating the impact of false negatives to preserve underlying semantic structure.</li>
                    
                    <li>It also introduces a method for fine-grained alignment, linking specific image patches to relevant word tokens within radiology reports, enhancing the localized understanding.</li>
                    
                    <li>Experimental results confirm the effectiveness of SISTA in improving transfer performance across different datasets on three crucial downstream tasks: image classification, image segmentation, and object detection.</li>
                    
                    <li>A notable finding is SISTA's ability to achieve significant improvements in fine-grained tasks, even when faced with limited labeled data, which is highly valuable in medical contexts.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SISTA employs a multi-level alignment framework. At the instance (image-report) level, it improves conventional contrastive learning by explicitly incorporating inter-report semantic similarity to identify and filter out false negative pairs. At the fine-grained (patch-word) level, it introduces a novel mechanism to effectively align specific regions of medical images (patches) with corresponding descriptive word tokens from the associated radiology reports, ensuring a more semantically aware representation learning process.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed SISTA framework significantly improves transfer performance on diverse medical datasets across three key downstream tasks: image classification, image segmentation, and object detection. Notably, it achieves substantial gains in fine-grained tasks and maintains effectiveness even when training data is limited.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By learning more robust and semantically aware representations from medical image-report pairs, SISTA can lead to more accurate and reliable AI systems for medical image analysis. This directly translates to improved diagnostic tools for radiologists, more precise detection and segmentation of abnormalities (e.g., tumors, lesions), and enhanced assistance in disease classification, potentially leading to earlier, more efficient, and more effective patient care, especially in data-scarce medical domains.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework or its experimental scope.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While the abstract mentions that codes and pre-trained models will be made available, which facilitates further research, it does not explicitly outline specific future research directions by the authors. Implicitly, this work opens avenues for exploring SISTA's applicability to other medical imaging modalities, its robustness in real-world clinical deployment, and integration with causal reasoning or explainable AI methods.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Vision-Language Pre-training</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Representation Learning</span>
                    
                    <span class="tag tag-keyword">Radiology Reports</span>
                    
                    <span class="tag tag-keyword">Image Classification</span>
                    
                    <span class="tag tag-keyword">Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Object Detection</span>
                    
                    <span class="tag tag-keyword">Semantic Alignment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical contrastive vision-language pre-training (VLP) has demonstrated significant potential in improving performance on downstream tasks. Traditional approaches typically employ contrastive learning, treating paired image-report samples as positives and unpaired ones as negatives. However, in medical datasets, there can be substantial similarities between images or reports from different patients. Rigidly treating all unpaired samples as negatives, can disrupt the underlying semantic structure and negatively impact the quality of the learned representations. In this paper, we propose a multi-level alignment framework, Representation Learning with Semantic-aware Instance and Sparse Token Alignments (SISTA) by exploiting the semantic correspondence between medical image and radiology reports at two levels, i.e., image-report and patch-word levels. Specifically, we improve the conventional contrastive learning by incorporating inter-report similarity to eliminate the false negatives and introduce a method to effectively align image patches with relevant word tokens. Experimental results demonstrate the effectiveness of the proposed framework in improving transfer performance across different datasets on three downstream tasks: image classification, image segmentation, and object detection. Notably, our framework achieves significant improvements in fine-grained tasks even with limited labeled data. Codes and pre-trained models will be made available.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Under review, 8 pages</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>