<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Surgical Agent Orchestrator Platform (SAOP), a voice-directed system for da Vinci robotic surgeons to access and manipulate multimodal">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.07392v1" target="_blank">2511.07392v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.07392v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.07392v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Surgical Agent Orchestrator Platform (SAOP), a voice-directed system for da Vinci robotic surgeons to access and manipulate multimodal patient data without interrupting procedures. Built on a hierarchical multi-agent framework powered by Large Language Models (LLMs), SAOP autonomously interprets and executes voice commands for tasks like retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models. The platform demonstrated high accuracy and robustness against speech recognition errors and ambiguous commands, showcasing its strong potential to enhance minimally invasive robotic surgery.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This innovation directly addresses a significant workflow and cognitive load issue in advanced robotic surgery, allowing surgeons to maintain focus on the procedure while accessing critical patient data. It has the potential to enhance surgical efficiency, precision, and patient safety by reducing interruptions and providing real-time, hands-free information access during complex minimally invasive operations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>An AI platform utilizing LLMs and a multi-agent framework to provide voice-directed control for surgeons in da Vinci robotic surgery. It enables hands-free access and manipulation of patient data (clinical records, CT scans, 3D anatomical models) to enhance surgical efficiency and decision-making during procedures.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of surgeons needing hands-free access to multimodal patient data during da Vinci robotic surgery due to full engagement of hands and eyes.</li>
                    
                    <li>Proposes the Surgical Agent Orchestrator Platform (SAOP), a novel voice-directed system, to facilitate uninterrupted patient data interaction.</li>
                    
                    <li>SAOP is built on a hierarchical multi-agent framework, comprising an orchestration agent and three specialized task-specific agents.</li>
                    
                    <li>The core intelligence is driven by Large Language Models (LLMs), enabling agents to autonomously plan, refine, validate, and reason in response to voice commands.</li>
                    
                    <li>Specific functionalities include retrieving clinical information, manipulating CT scans, and navigating 3D anatomical models, projected onto the surgical video.</li>
                    
                    <li>A new evaluation metric, the Multi-level Orchestration Evaluation Metric (MOEM), was developed to comprehensively assess performance and robustness at both command and category levels.</li>
                    
                    <li>The SAOP achieved high accuracy and success rates across 240 diverse voice commands, with LLM-based agents significantly improving robustness against speech recognition errors and ambiguous free-form commands.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed a hierarchical multi-agent framework called the Surgical Agent Orchestrator Platform (SAOP), which consists of an orchestration agent and three specialized task-specific agents. These agents are powered by Large Language Models (LLMs) that are programmed to autonomously plan, refine, validate, and reason to map voice commands to specific data interaction tasks. The system's performance and robustness were evaluated using a custom-designed Multi-level Orchestration Evaluation Metric (MOEM) across a dataset of 240 distinct voice commands.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The SAOP demonstrated high accuracy and success rates in executing a wide range of voice commands for patient data interaction. A crucial finding was that the integration of LLM-based agents significantly enhanced the system's robustness, enabling it to effectively mitigate the impact of speech recognition errors and accurately interpret diverse or ambiguous free-form natural language commands.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This platform promises to streamline the surgical workflow by providing surgeons with hands-free, voice-directed access to crucial patient data (e.g., clinical information, CT scans, 3D anatomical models) without diverting their attention or requiring manual interaction. This could lead to reduced operative times, improved decision-making through immediate data access, increased surgical precision, and ultimately, enhanced safety and outcomes for patients undergoing da Vinci robotic surgery.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly stated in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly stated in the abstract, but the demonstrated 'strong potential' implies further development, integration into clinical settings, and potentially broader application across various surgical platforms and data types.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Robotic Surgery</span>
                    
                    <span class="tag">Minimally Invasive Surgery</span>
                    
                    <span class="tag">Surgical Planning</span>
                    
                    <span class="tag">Intraoperative Imaging</span>
                    
                    <span class="tag">Digital Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Robotic surgery</span>
                    
                    <span class="tag tag-keyword">Da Vinci surgical system</span>
                    
                    <span class="tag tag-keyword">Voice control</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Multi-agent system</span>
                    
                    <span class="tag tag-keyword">Minimally invasive surgery</span>
                    
                    <span class="tag tag-keyword">Patient data interaction</span>
                    
                    <span class="tag tag-keyword">Surgical workflow optimization</span>
                    
                    <span class="tag tag-keyword">Human-computer interaction</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in
the procedure, making it difficult to access and manipulate multimodal patient
data without interruption. We propose a voice-directed Surgical Agent
Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework,
consisting of an orchestration agent and three task-specific agents driven by
Large Language Models (LLMs). These LLM-based agents autonomously plan, refine,
validate, and reason to map voice commands into specific tasks such as
retrieving clinical information, manipulating CT scans, or navigating 3D
anatomical models on the surgical video. We also introduce a Multi-level
Orchestration Evaluation Metric (MOEM) to comprehensively assess the
performance and robustness from command-level and category-level perspectives.
The SAOP achieves high accuracy and success rates across 240 voice commands,
while LLM-based agents improve robustness against speech recognition errors and
diverse or ambiguous free-form commands, demonstrating strong potential to
support minimally invasive da Vinci robotic surgery.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>22 pages, 12 figures, 1 table, Supplementary Information,
  Supplementary Data 1</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>