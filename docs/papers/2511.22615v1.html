<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stable-Drift: A Patient-Aware Latent Drift Replay Method for Stabilizing Representations in Continual Learning - Health AI Hub</title>
    <meta name="description" content="This paper introduces Stable-Drift, a novel latent drift-guided replay method designed to mitigate catastrophic forgetting in deep learning models continually a">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Stable-Drift: A Patient-Aware Latent Drift Replay Method for Stabilizing Representations in Continual Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.22615v1" target="_blank">2511.22615v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-27
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Paraskevi-Antonia Theofilou, Anuhya Thota, Stefanos Kollias, Mamatha Thota
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.22615v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.22615v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Stable-Drift, a novel latent drift-guided replay method designed to mitigate catastrophic forgetting in deep learning models continually adapting to new medical imaging data. By identifying and replaying samples exhibiting high representational instability‚Äîquantified as latent drift‚Äîthe method significantly reduces forgetting in a cross-hospital COVID-19 CT classification task compared to standard approaches.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This method is crucial for deploying AI in medical imaging, as it enables models to continually adapt to new data (e.g., from different hospitals or new disease variants) without compromising previously acquired diagnostic knowledge, ensuring consistent and reliable performance over time.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research focuses on developing more robust and adaptable AI models for medical imaging diagnostics. Specifically, it aims to create AI systems that can continually learn from new patient data (e.g., from different hospitals or evolving diseases like COVID-19) without losing their proficiency on previously learned diagnostic tasks, thereby improving the reliability and widespread deployment of AI in clinical settings for diagnostic support.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses catastrophic forgetting, a critical challenge where deep learning models lose performance on previously learned tasks when sequentially trained on new data, limiting AI deployment in medical imaging.</li>
                    
                    <li>Proposes Stable-Drift, a latent drift-guided replay method that selectively identifies and replays samples with high representational instability.</li>
                    
                    <li>Quantifies representational instability using 'latent drift,' defined as the change in a sample's internal feature representation after naive domain adaptation.</li>
                    
                    <li>Ensures clinical relevance and diversity by aggregating latent drift at the patient level, where the memory buffer stores specific per-patient slices exhibiting the greatest multi-layer representation shift.</li>
                    
                    <li>Evaluated on a cross-hospital COVID-19 CT classification task, utilizing both state-of-the-art Convolutional Neural Network (CNN) and Vision Transformer (ViT) backbones.</li>
                    
                    <li>Demonstrates a substantial reduction in forgetting when compared against conventional naive fine-tuning and random replay methods.</li>
                    
                    <li>Highlights latent drift as a practical and interpretable replay signal, crucial for advancing robust continual learning in real-world medical settings.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The Stable-Drift method quantifies representational instability using 'latent drift,' defined as the change in a sample's feature representation after naive domain adaptation. This drift is aggregated at the patient level to select clinically relevant slices exhibiting the highest multi-layer representation shift for storage in a memory buffer. These selected samples are then replayed during subsequent training steps to stabilize representations and prevent catastrophic forgetting.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The Stable-Drift method substantially reduces catastrophic forgetting in deep learning models, outperforming naive fine-tuning and random replay strategies on a cross-hospital COVID-19 CT classification task, thereby stabilizing representations during continual learning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This approach enables more robust and adaptable AI models for medical diagnostics. It facilitates continuous model updates with new clinical data from diverse sources (e.g., new hospitals, evolving disease presentations) without losing proficiency on existing diagnostic tasks, leading to safer, more reliable, and broadly deployable AI in clinical practice.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract beyond the general goal of advancing robust continual learning in real-world medical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Infectious Diseases (COVID-19)</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">continual learning</span>
                    
                    <span class="tag tag-keyword">catastrophic forgetting</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">latent drift</span>
                    
                    <span class="tag tag-keyword">replay methods</span>
                    
                    <span class="tag tag-keyword">COVID-19 CT</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">representation stability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">When deep learning models are sequentially trained on new data, they tend to abruptly lose performance on previously learned tasks, a critical failure known as catastrophic forgetting. This challenge severely limits the deployment of AI in medical imaging, where models must continually adapt to data from new hospitals without compromising established diagnostic knowledge. To address this, we introduce a latent drift-guided replay method that identifies and replays samples with high representational instability. Specifically, our method quantifies this instability via latent drift, the change in a sample internal feature representation after naive domain adaptation. To ensure diversity and clinical relevance, we aggregate drift at the patient level, our memory buffer stores the per patient slices exhibiting the greatest multi-layer representation shift. Evaluated on a cross-hospital COVID-19 CT classification task using state-of-the-art CNN and Vision Transformer backbones, our method substantially reduces forgetting compared to naive fine-tuning and random replay. This work highlights latent drift as a practical and interpretable replay signal for advancing robust continual learning in real world medical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>8 pages, 2 figures</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Journal Reference</h2>
                <p>Proceedings of the IEEE/CVF International Conference on Computer Vision, 2025, 7340--7349</p>
            </section>
            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>