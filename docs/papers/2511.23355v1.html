<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors - Health AI Hub</title>
    <meta name="description" content="This paper presents a novel computer vision-based pipeline designed to automatically capture and digitize physiological data from standalone bedside monitor scr">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.23355v1" target="_blank">2511.23355v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Vinh Chau, Khoa Le Dinh Van, Hon Huynh Ngoc, Binh Nguyen Thien, Hao Nguyen Thien, Vy Nguyen Quang, Phuc Vo Hong, Yen Lam Minh, Kieu Pham Tieu, Trinh Nguyen Thi Diem, Louise Thwaites, Hai Ho Bich
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.23355v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.23355v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a novel computer vision-based pipeline designed to automatically capture and digitize physiological data from standalone bedside monitor screens, specifically targeting low-resource healthcare settings lacking network connectivity. By employing a hierarchical framework with YOLOv11 for object detection, PaddleOCR for text extraction, and geometric rectification, the system reliably transforms unstructured screen information into structured digital data. It achieved an end-to-end extraction accuracy exceeding 98.9% for core vital signs, offering a practical solution to integrate legacy monitor data into EHR systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This technology directly addresses a critical challenge in digital health integration within low-resource healthcare environments. It enables the cost-effective and automated collection of vital patient physiological data, crucial for improving clinical documentation, enhancing patient monitoring, and facilitating data-driven decision-making without requiring expensive infrastructure upgrades.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This AI application uses a hierarchical computer vision pipeline (YOLOv11 for object detection, PaddleOCR for text extraction) to automatically digitize and structure real-time physiological data (e.g., heart rate, SpO2, blood pressure) displayed on legacy bedside medical monitors. The goal is to overcome interoperability issues, integrate this data into Electronic Health Record (EHR) systems, and improve clinical documentation and information accessibility in healthcare settings, particularly in low-resource environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the interoperability gap of standalone legacy bedside monitors in low-resource settings, preventing seamless data integration into EHRs.</li>
                    
                    <li>Proposes a computer vision-based pipeline for automated capture and digitization of vital sign data directly from monitor screens without costly hardware replacement.</li>
                    
                    <li>Utilizes a hierarchical detection framework: YOLOv11 for accurate monitor and vital sign Region of Interest (ROI) localization, and PaddleOCR for robust text extraction.</li>
                    
                    <li>Incorporates a geometric rectification module to standardize screen perspective, enhancing reliability across variable camera angles and lighting conditions.</li>
                    
                    <li>Evaluated on a dataset of 6,498 images from open-source corpora and real-world Intensive Care Units (ICUs) in Vietnam.</li>
                    
                    <li>Achieved a mean Average Precision (mAP@50-95) of 99.5% for monitor detection and 91.5% for vital sign ROI localization.</li>
                    
                    <li>Demonstrated an end-to-end extraction accuracy exceeding 98.9% for core physiological parameters including heart rate, oxygen saturation (SpO2), and arterial blood pressure.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a hierarchical computer vision pipeline. It begins with YOLOv11 for object detection to accurately localize the bedside monitor and specific vital sign Regions of Interest (ROIs) on its screen. A geometric rectification module is then applied to standardize the perspective of the detected screen, compensating for varying camera angles and lighting. Finally, PaddleOCR is used to perform robust optical character recognition (OCR) on the rectified ROIs to extract and digitize the physiological parameter values.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The system demonstrated high performance metrics, achieving a mean Average Precision (mAP@50-95) of 99.5% for bedside monitor detection and 91.5% for vital sign ROI localization. Most notably, the end-to-end extraction accuracy for critical physiological parameters such as heart rate, oxygen saturation (SpO2), and arterial blood pressure consistently exceeded 98.9%.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This solution offers a practical, scalable, and affordable pathway for healthcare facilities in low-resource settings to overcome the interoperability gap of legacy bedside monitors. By reliably converting unstructured physiological data from screen captures into a structured digital format, it significantly enhances information accessibility, streamlines clinical documentation, and supports better patient management and care quality without requiring costly hardware replacements.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract. Potential implicit limitations might include susceptibility to extreme screen glare or damage, the need for consistent camera placement or calibration, and the handling of highly diverse or non-standard monitor displays.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Intensive Care Medicine</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Healthcare Informatics</span>
                    
                    <span class="tag">Global Health</span>
                    
                    <span class="tag">Clinical Monitoring</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Bedside Monitor</span>
                    
                    <span class="tag tag-keyword">Vital Signs</span>
                    
                    <span class="tag tag-keyword">EHR Integration</span>
                    
                    <span class="tag tag-keyword">OCR</span>
                    
                    <span class="tag tag-keyword">Low-Resource Settings</span>
                    
                    <span class="tag tag-keyword">YOLO</span>
                    
                    <span class="tag tag-keyword">Physiological Data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">In many low-resource healthcare settings, bedside monitors remain standalone legacy devices without network connectivity, creating a persistent interoperability gap that prevents seamless integration of physiological data into electronic health record (EHR) systems. To address this challenge without requiring costly hardware replacement, we present a computer vision-based pipeline for the automated capture and digitisation of vital sign data directly from bedside monitor screens. Our method employs a hierarchical detection framework combining YOLOv11 for accurate monitor and region of interest (ROI) localisation with PaddleOCR for robust text extraction. To enhance reliability across variable camera angles and lighting conditions, a geometric rectification module standardizes the screen perspective before character recognition. We evaluated the system on a dataset of 6,498 images collected from open-source corpora and real-world intensive care units in Vietnam. The model achieved a mean Average Precision (mAP@50-95) of 99.5% for monitor detection and 91.5% for vital sign ROI localisation. The end-to-end extraction accuracy exceeded 98.9% for core physiological parameters, including heart rate, oxygen saturation SpO2, and arterial blood pressure. These results demonstrate that a lightweight, camera-based approach can reliably transform unstructured information from screen captures into structured digital data, providing a practical and scalable pathway to improve information accessibility and clinical documentation in low-resource settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>11 pages, 3 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>