<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring - Health AI Hub</title>
    <meta name="description" content="This study investigates the feasibility of approximating the complex Banff lesion scores for renal transplant biopsies using existing deep learning models withi">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>How Close Are We? Limitations and Progress of AI Models in Banff Lesion Scoring</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.27158v1" target="_blank">2510.27158v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-31
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yanfan Zhu, Juming Xiong, Ruining Deng, Yu Wang, Yaohong Wang, Shilin Zhao, Mengmeng Yin, Yuqing Liu, Haichun Yang, Yuankai Huo
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.27158v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.27158v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study investigates the feasibility of approximating the complex Banff lesion scores for renal transplant biopsies using existing deep learning models within a modular, rule-based framework. While achieving partial successes, the research identified critical limitations in current AI pipelines, including structural omission, hallucination, and detection ambiguity, ultimately highlighting the need for modular evaluation and computational grading standards to enhance interpretability and performance in transplant pathology.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and consistent Banff scoring is crucial for managing renal transplant recipients, impacting diagnosis of rejection, prognosis, and treatment decisions. AI automation could standardize this complex process, reduce inter-observer variability, and potentially accelerate analysis, leading to more timely and effective patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application described is the automated or AI-assisted grading of renal transplant biopsies for the diagnosis of rejection using the Banff Classification. This aims to improve diagnostic consistency, reduce inter-observer variability, and potentially enhance efficiency in transplant pathology by providing computational tools for lesion scoring.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The Banff Classification, a global standard for renal transplant biopsy evaluation, presents significant challenges for computational replication due to its semi-quantitative nature, complex criteria, and inter-observer variability.</li>
                    
                    <li>The methodology involved decomposing Banff indicators (e.g., glomerulitis 'g', peritubular capillaritis 'ptc', intimal arteritis 'v') into structural and inflammatory components.</li>
                    
                    <li>Existing deep learning segmentation and detection tools were used to compute these components, with model outputs mapped to Banff scores via heuristic rules aligned with expert guidelines.</li>
                    
                    <li>Evaluation against expert-annotated ground truths revealed partial successes but also critical failure modes, including structural omission, hallucination, and detection ambiguity.</li>
                    
                    <li>A key finding was that even when final AI-generated Banff scores matched expert annotations, inconsistencies in intermediate representations significantly undermined interpretability.</li>
                    
                    <li>The study demonstrates the limitations of current AI pipelines in replicating expert-level computational grading in complex pathological classifications.</li>
                    
                    <li>It emphasizes the importance of modular evaluation and the establishment of a computational Banff grading standard to guide future model development in transplant pathology.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed a modular, rule-based framework to approximate Banff scores. It decomposed specific Banff indicators (e.g., glomerulitis, peritubular capillaritis, intimal arteritis) into their constituent structural and inflammatory components. Existing deep learning models, specifically segmentation and detection tools, were then utilized to identify and quantify these components. Model outputs were subsequently mapped to Banff scores using heuristic rules aligned with expert guidelines and evaluated against expert-annotated ground truths.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The research demonstrated partial successes in approximating Banff scores but also identified critical failure modes of current AI models, including structural omission (missing elements), hallucination (detecting non-existent elements), and detection ambiguity. Crucially, even when final AI scores matched expert annotations, inconsistencies in the intermediate representations undermined interpretability, highlighting a significant limitation in replicating computational expert-level grading.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>Successfully automating Banff scoring with AI could lead to more standardized and consistent evaluation of renal transplant biopsies, reducing variability among pathologists. This improved consistency would facilitate more accurate and timely diagnosis of transplant rejection and other complications, ultimately supporting better-informed clinical decisions, optimized treatment strategies, and improved patient outcomes for renal transplant recipients.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Current AI pipelines exhibit significant limitations in achieving expert-level grading, characterized by critical failure modes such as structural omission, hallucination, and detection ambiguity. Furthermore, inconsistencies in the AI's intermediate representations severely undermine interpretability, even when final scores are accurate, making it difficult to trust the underlying decision-making process.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The authors emphasize the critical importance of implementing modular evaluation strategies for AI models in pathology. They also highlight the necessity of establishing a clear computational Banff grading standard to guide and benchmark future AI model development, ensuring more robust, interpretable, and clinically useful tools for transplant pathology.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Nephrology</span>
                    
                    <span class="tag">Transplant Medicine</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Histopathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Banff Classification</span>
                    
                    <span class="tag tag-keyword">Renal Transplant Biopsy</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Computational Pathology</span>
                    
                    <span class="tag tag-keyword">AI Limitations</span>
                    
                    <span class="tag tag-keyword">Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Object Detection</span>
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The Banff Classification provides the global standard for evaluating renal
transplant biopsies, yet its semi-quantitative nature, complex criteria, and
inter-observer variability present significant challenges for computational
replication. In this study, we explore the feasibility of approximating Banff
lesion scores using existing deep learning models through a modular, rule-based
framework. We decompose each Banff indicator - such as glomerulitis (g),
peritubular capillaritis (ptc), and intimal arteritis (v) - into its
constituent structural and inflammatory components, and assess whether current
segmentation and detection tools can support their computation. Model outputs
are mapped to Banff scores using heuristic rules aligned with expert
guidelines, and evaluated against expert-annotated ground truths. Our findings
highlight both partial successes and critical failure modes, including
structural omission, hallucination, and detection ambiguity. Even when final
scores match expert annotations, inconsistencies in intermediate
representations often undermine interpretability. These results reveal the
limitations of current AI pipelines in replicating computational expert-level
grading, and emphasize the importance of modular evaluation and computational
Banff grading standard in guiding future model development for transplant
pathology.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>