<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAMRI: Segment Anything Model for MRI - Health AI Hub</title>
    <meta name="description" content="SAMRI introduces an MRI-specialized adaptation of the Segment Anything Model (SAM) for accurate and efficient medical image segmentation. By fine-tuning only SA">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SAMRI: Segment Anything Model for MRI</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26635v1" target="_blank">2510.26635v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhao Wang, Wei Dai, Thuy Thanh Dao, Steffen Bollmann, Hongfu Sun, Craig Engstrom, Shekhar S. Chandra
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SAMRI introduces an MRI-specialized adaptation of the Segment Anything Model (SAM) for accurate and efficient medical image segmentation. By fine-tuning only SAM's mask decoder with a two-stage strategy on a large MRI dataset, SAMRI achieves state-of-the-art accuracy and robust generalization across diverse anatomical regions and pathologies. This approach significantly reduces training time and trainable parameters compared to full-model retraining.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant as accurate and efficient MRI segmentation is foundational for numerous clinical applications, including disease diagnosis, treatment planning, progression monitoring, and surgical navigation. SAMRI's ability to provide state-of-the-art accuracy and robust generalization across diverse MRI types directly translates to improved diagnostic precision and reduced clinician workload.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>SAMRI is an AI application that automates and improves the accuracy of MRI segmentation, a task currently labor-intensive when performed manually. By providing robust and generalizable segmentation of anatomical structures and pathologies, it can enhance diagnostic capabilities, assist in surgical planning, monitor disease progression, and support clinical decision-making in a wide range of medical fields.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** Manual MRI segmentation is labor-intensive, and traditional CNNs struggle with MRI's inherent variability (contrast, intensity inhomogeneity, diverse protocols) leading to poor generalization.</li>
                    
                    <li>**Novel Approach (SAMRI):** Adapts the transformer-based Segment Anything Model (SAM) specifically for MRI by addressing modality-specific challenges, rather than treating MRI as another natural image.</li>
                    
                    <li>**Efficient Training Strategy:** SAMRI is developed by fine-tuning *only the mask decoder* of SAM using a *two-stage strategy*, drastically reducing training time by 94% and trainable parameters by 96% compared to full-model retraining.</li>
                    
                    <li>**Extensive Training Data:** The model was trained and validated on a massive dataset of 1.1 million labeled MR slices, encompassing a wide range of whole-body organs and various pathologies.</li>
                    
                    <li>**State-of-the-Art Accuracy:** Achieves a mean Dice score of 0.87 across a diverse range of MRI segmentation tasks, demonstrating superior performance.</li>
                    
                    <li>**Robust Generalization:** Demonstrates state-of-the-art accuracy across different anatomical regions and robust generalization capabilities on previously unseen structures, particularly for small and clinically critical structures.</li>
                    
                    <li>**Clinical Importance:** Provides a highly accurate and efficient tool for MRI segmentation, which is crucial for clinical decision-making and various diagnostic and therapeutic applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SAMRI adapts the Segment Anything Model (SAM) for MRI by focusing on fine-tuning its pre-trained mask decoder using a specific two-stage training strategy. This approach efficiently leverages SAM's powerful image encoding capabilities while specializing its segmentation head for MRI's unique characteristics. The model was trained and validated on a large-scale dataset comprising 1.1 million labeled MR slices covering whole-body organs and pathologies.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SAMRI achieves a mean Dice score of 0.87 across a broad spectrum of MRI segmentation tasks, demonstrating state-of-the-art accuracy. The specialized fine-tuning approach resulted in significant efficiency gains, reducing training time by 94% and trainable parameters by 96% compared to retraining the full SAM model. Crucially, SAMRI exhibits robust generalization, accurately segmenting diverse anatomical regions and unseen structures, particularly small and clinically significant ones.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SAMRI has the potential to significantly enhance clinical workflows by automating and improving the accuracy of MRI segmentation, thereby reducing the intensive manual labor currently required. This can lead to faster and more precise diagnoses, more effective treatment planning for conditions involving various organs and pathologies, and better monitoring of disease progression, ultimately improving patient outcomes and alleviating the burden on radiologists.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">MRI segmentation</span>
                    
                    <span class="tag tag-keyword">Segment Anything Model (SAM)</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">fine-tuning</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">generalization</span>
                    
                    <span class="tag tag-keyword">diagnostic imaging</span>
                    
                    <span class="tag tag-keyword">convolutional neural networks</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate magnetic resonance imaging (MRI) segmentation is crucial for
clinical decision-making, but remains labor-intensive when performed manually.
Convolutional neural network (CNN)-based methods can be accurate and efficient,
but often generalize poorly to MRI's variable contrast, intensity
inhomogeneity, and protocols. Although the transformer-based Segment Anything
Model (SAM) has demonstrated remarkable generalizability in natural images,
existing adaptations often treat MRI as another imaging modality, overlooking
these modality-specific challenges. We present SAMRI, an MRI-specialized SAM
trained and validated on 1.1 million labeled MR slices spanning whole-body
organs and pathologies. We demonstrate that SAM can be effectively adapted to
MRI by simply fine-tuning its mask decoder using a two-stage strategy, reducing
training time by 94% and trainable parameters by 96% versus full-model
retraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Dice
of 0.87, delivering state-of-the-art accuracy across anatomical regions and
robust generalization on unseen structures, particularly small and clinically
important structures.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>