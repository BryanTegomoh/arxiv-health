<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAMRI: Segment Anything Model for MRI - Health AI Hub</title>
    <meta name="description" content="SAMRI addresses the challenge of accurate and generalizable MRI segmentation, which is often hindered by MRI's inherent variability and the limitations of exist">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SAMRI: Segment Anything Model for MRI</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26635v1" target="_blank">2510.26635v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhao Wang, Wei Dai, Thuy Thanh Dao, Steffen Bollmann, Hongfu Sun, Craig Engstrom, Shekhar S. Chandra
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26635v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26635v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">SAMRI addresses the challenge of accurate and generalizable MRI segmentation, which is often hindered by MRI's inherent variability and the limitations of existing CNN and general SAM approaches. By specializing the Segment Anything Model (SAM) for MRI through a targeted two-stage fine-tuning of its mask decoder on a large dataset of 1.1 million MR slices, SAMRI achieves state-of-the-art accuracy (mean Dice of 0.87) and robust generalization across diverse, including unseen, anatomical and pathological structures, while significantly reducing training resource requirements.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and automated MRI segmentation is crucial for efficient clinical decision-making, enabling precise diagnosis, treatment planning (e.g., surgery, radiotherapy), and disease monitoring, which significantly impacts patient outcomes and clinical workflow efficiency.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using a specialized deep learning model (SAMRI) to automatically and accurately segment various anatomical structures and pathologies in Magnetic Resonance Imaging (MRI) scans. This directly assists healthcare professionals by reducing the manual labor involved in image analysis, improving the efficiency and consistency of diagnoses, aiding in treatment planning, and enhancing overall clinical decision-making based on medical images.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Manual MRI segmentation is labor-intensive, and conventional CNN-based methods often fail to generalize effectively across MRI's variable contrast, intensity inhomogeneity, and diverse protocols.</li>
                    
                    <li>Existing adaptations of the transformer-based Segment Anything Model (SAM) to MRI typically treat it as another imaging modality, overlooking crucial MRI-specific challenges.</li>
                    
                    <li>SAMRI is an MRI-specialized adaptation of SAM, trained and validated on an extensive dataset of 1.1 million labeled MR slices encompassing whole-body organs and pathologies.</li>
                    
                    <li>The key methodological innovation is a two-stage fine-tuning strategy applied exclusively to SAM's mask decoder, which dramatically reduces training time by 94% and trainable parameters by 96% compared to full-model retraining.</li>
                    
                    <li>SAMRI achieves a mean Dice similarity coefficient of 0.87 across a diverse range of MRI segmentation tasks, demonstrating state-of-the-art accuracy.</li>
                    
                    <li>The model exhibits robust generalization capabilities, particularly for unseen structures and small, clinically important anatomical regions or pathologies.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SAMRI adapts the Segment Anything Model (SAM) for MRI by focusing its training on the mask decoder component. It employs a two-stage fine-tuning strategy for the mask decoder, leaving the pre-trained image encoder largely untouched. This specialized training was performed and validated on a large-scale dataset consisting of 1.1 million labeled magnetic resonance imaging slices, covering a wide array of whole-body organs and various pathologies.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SAMRI successfully demonstrates that SAM can be effectively adapted to MRI by fine-tuning only its mask decoder, resulting in a 94% reduction in training time and 96% fewer trainable parameters compared to full-model retraining. It achieved a mean Dice similarity coefficient of 0.87 across diverse MRI segmentation tasks, delivering state-of-the-art accuracy across anatomical regions and exhibiting robust generalization on unseen structures, particularly for small and clinically important entities.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>SAMRI has the potential to significantly enhance clinical workflows by providing highly accurate, automated, and generalizable MRI segmentation across a vast range of anatomical and pathological conditions. This could lead to more efficient and precise diagnoses, optimized treatment planning (e.g., surgical guidance, radiation therapy), and improved monitoring of disease progression, thereby freeing up clinician time and potentially improving patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Gastroenterology</span>
                    
                    <span class="tag">Urology</span>
                    
                    <span class="tag">Orthopedics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">MRI segmentation</span>
                    
                    <span class="tag tag-keyword">Segment Anything Model (SAM)</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                    <span class="tag tag-keyword">Artificial Intelligence</span>
                    
                    <span class="tag tag-keyword">Radiomics</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate magnetic resonance imaging (MRI) segmentation is crucial for
clinical decision-making, but remains labor-intensive when performed manually.
Convolutional neural network (CNN)-based methods can be accurate and efficient,
but often generalize poorly to MRI's variable contrast, intensity
inhomogeneity, and protocols. Although the transformer-based Segment Anything
Model (SAM) has demonstrated remarkable generalizability in natural images,
existing adaptations often treat MRI as another imaging modality, overlooking
these modality-specific challenges. We present SAMRI, an MRI-specialized SAM
trained and validated on 1.1 million labeled MR slices spanning whole-body
organs and pathologies. We demonstrate that SAM can be effectively adapted to
MRI by simply fine-tuning its mask decoder using a two-stage strategy, reducing
training time by 94% and trainable parameters by 96% versus full-model
retraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Dice
of 0.87, delivering state-of-the-art accuracy across anatomical regions and
robust generalization on unseen structures, particularly small and clinically
important structures.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>