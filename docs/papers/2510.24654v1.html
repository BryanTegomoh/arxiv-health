<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evolving Diagnostic Agents in a Virtual Clinical Environment - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel framework for training large language models (LLMs) as interactive diagnostic agents using reinforcement learning, enabling them t">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Evolving Diagnostic Agents in a Virtual Clinical Environment</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.24654v1" target="_blank">2510.24654v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Pengcheng Qiu, Chaoyi Wu, Junwei Liu, Qiaoyu Zheng, Yusheng Liao, Haowen Wang, Yun Yue, Qianrui Fan, Shuai Zhen, Jian Wang, Jinjie Gu, Yanfeng Wang, Ya Zhang, Weidi Xie
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.24654v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.24654v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel framework for training large language models (LLMs) as interactive diagnostic agents using reinforcement learning, enabling them to manage multi-turn diagnostic processes and adaptively select examinations. Leveraging a virtual clinical environment (DiagGym) and a new benchmark (DiagBench), the developed DiagAgent significantly outperforms state-of-the-art LLMs in diagnostic accuracy and the quality of examination recommendations. The findings highlight that learning diagnostic policies through interactive exploration and outcome-based feedback confers superior, clinically meaningful diagnostic management abilities compared to passive training approaches.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine as it pioneers the development of AI agents capable of engaging in dynamic, multi-turn diagnostic reasoning, potentially enhancing diagnostic accuracy, optimizing clinical resource utilization through adaptive test selection, and improving overall patient management in healthcare settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development and training of large language models (LLMs) to function as highly accurate and adaptive diagnostic agents. These agents can manage complex, multi-turn diagnostic processes, recommend appropriate medical examinations based on patient history, and arrive at diagnoses. This aims to enhance diagnostic accuracy, efficiency, and consistency in healthcare, potentially assisting clinicians or serving as a robust training tool in virtual clinical environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**DiagGym**: A virtual clinical environment, trained with electronic health records (EHRs), simulates patient responses and examination outcomes to provide a realistic setting for diagnostic agent training and evaluation.</li>
                    
                    <li>**DiagAgent**: An LLM trained via end-to-end, multi-turn reinforcement learning (RL) to learn adaptive diagnostic policies that optimize both the information yield from examinations and final diagnostic accuracy.</li>
                    
                    <li>**DiagBench**: A new diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases meticulously annotated with 973 physician-written rubrics for evaluating the diagnostic process quality.</li>
                    
                    <li>**Interactive Learning Paradigm**: The framework departs from static, instruction-tuned models by acquiring diagnostic strategies through interactive exploration and outcome-based feedback, fostering dynamic clinical reasoning.</li>
                    
                    <li>**Superior Diagnostic Accuracy**: DiagAgent demonstrated a 9.34% higher diagnostic accuracy in single-turn settings and a 15.12% increase in end-to-end settings, outperforming 10 state-of-the-art LLMs (including DeepSeek-v3, GPT-4o) and prompt-engineered agents.</li>
                    
                    <li>**Enhanced Examination Recommendation**: The agent achieved a 44.03% improvement in examination recommendation hit ratio in single-turn scenarios and a 23.09% boost in F1 score in end-to-end settings.</li>
                    
                    <li>**Clinically Meaningful Process**: In rubric-based evaluation, DiagAgent surpassed the next-best model (Claude-sonnet-4) by 7.1% in weighted rubric score, indicating a more clinically appropriate and structured diagnostic approach.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves training Large Language Models (LLMs), termed "DiagAgent," using an end-to-end, multi-turn reinforcement learning (RL) approach. This training occurs within a simulated environment called "DiagGym," which functions as a virtual clinical world model trained on electronic health records (EHRs) to generate realistic examination outcomes based on patient history and recommended tests. The agents learn diagnostic policies by iteratively selecting examinations and receiving outcome-based feedback. Performance is evaluated using a new benchmark, "DiagBench," which includes physician-validated examination recommendations and physician-written rubrics for assessing the quality of the diagnostic process.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>DiagAgent consistently demonstrated superior performance across diverse diagnostic settings. It significantly outperformed 10 state-of-the-art LLMs (e.g., DeepSeek-v3, GPT-4o) and two prompt-engineered agents. Specifically, in single-turn settings, DiagAgent achieved a 9.34% higher diagnostic accuracy and a 44.03% improvement in examination recommendation hit ratio. In end-to-end multi-turn settings, it delivered a 15.12% increase in diagnostic accuracy and a 23.09% boost in examination recommendation F1 score. Furthermore, in rubric-based evaluations of the diagnostic process, DiagAgent surpassed the next-best model (Claude-sonnet-4) by 7.1% in weighted rubric score, indicating higher quality clinical reasoning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research could significantly impact clinical practice by providing AI-powered diagnostic assistants capable of dynamic, adaptive, and multi-turn interaction with patient data. Such agents could enhance diagnostic precision, reduce unnecessary medical examinations and associated costs, streamline diagnostic pathways, and ultimately empower clinicians with more effective tools for managing complex patient cases and improving overall healthcare outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the presented framework or its evaluation. Implicitly, like all virtual environments, the fidelity of DiagGym to real-world clinical complexity and the generalizability of an agent trained purely on simulated data to actual patient encounters remain considerations.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. However, the successful development of DiagAgent in a virtual environment suggests potential for exploring its application in more specialized medical domains, integrating real-time patient data streams, or studying its impact in real-world clinical decision support systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">General Medicine</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Primary Care</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">Reinforcement Learning</span>
                    
                    <span class="tag tag-keyword">Medical Diagnosis</span>
                    
                    <span class="tag tag-keyword">Virtual Clinical Environment</span>
                    
                    <span class="tag tag-keyword">Diagnostic Agents</span>
                    
                    <span class="tag tag-keyword">Electronic Health Records</span>
                    
                    <span class="tag tag-keyword">Adaptive Examination</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">In this paper, we present a framework for training large language models
(LLMs) as diagnostic agents with reinforcement learning, enabling them to
manage multi-turn diagnostic processes, adaptively select examinations, and
commit to final diagnoses. Unlike instruction-tuned models trained on static
case summaries, our method acquires diagnostic strategies through interactive
exploration and outcome-based feedback. Our contributions are fourfold: (i) We
present DiagGym, a diagnostics world model trained with electronic health
records that emits examination outcomes conditioned on patient history and
recommended examination, serving as a virtual clinical environment for
realistic diagnosis training and evaluation; (ii) We train DiagAgent via
end-to-end, multi-turn reinforcement learning to learn diagnostic policies that
optimize both information yield and diagnostic accuracy; (iii) We introduce
DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated
examination recommendations and 99 cases annotated with 973 physician-written
rubrics on diagnosis process; (iv) we demonstrate superior performance across
diverse diagnostic settings. DiagAgent significantly outperforms 10
state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two
prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%
higher diagnostic accuracy and 44.03% improvement in examination recommendation
hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic
accuracy and 23.09% boost in examination recommendation F1 score. In
rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by
7.1% in weighted rubric score. These findings indicate that learning policies
in interactive clinical environments confers dynamic and clinically meaningful
diagnostic management abilities unattainable through passive training alone.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>