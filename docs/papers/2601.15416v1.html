<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction - Health AI Hub</title>
    <meta name="description" content="DuFal (Dual-Frequency-Aware Learning) is a novel deep learning framework designed for high-fidelity Cone-Beam Computed Tomography (CBCT) reconstruction from ext">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15416v1" target="_blank">2601.15416v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Cuong Tran Van, Trong-Thang Pham, Ngoc-Son Nguyen, Duy Minh Ho Nguyen, Ngan Le
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15416v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15416v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DuFal (Dual-Frequency-Aware Learning) is a novel deep learning framework designed for high-fidelity Cone-Beam Computed Tomography (CBCT) reconstruction from extremely sparse-view projections. It tackles the challenge of recovering fine-grained, high-frequency anatomical details, which are often lost in conventional methods, by integrating frequency-domain and spatial-domain processing through a unique dual-path architecture. Experimental results demonstrate DuFal significantly outperforms state-of-the-art methods in preserving these critical high-frequency features under severe undersampling conditions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical imaging by enabling high-quality CT reconstructions from significantly fewer X-ray projections, thereby substantially reducing patient radiation exposure without compromising the integrity of crucial fine anatomical details essential for accurate diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies advanced AI/machine learning techniques (specifically deep learning with Fourier Neural Operators) to enhance the quality and fidelity of Cone-Beam Computed Tomography (CBCT) image reconstruction. By improving reconstruction from extremely sparse-view data, it can potentially lead to reduced radiation exposure for patients during medical scans, enable faster scans, and provide clearer diagnostic images of anatomical structures, thereby improving diagnostic accuracy and patient care within healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of recovering high-frequency anatomical details in sparse-view CBCT, where traditional CNNs are biased towards low-frequency information.</li>
                    
                    <li>Introduces DuFal, a novel dual-path architecture that concurrently processes information in both frequency and spatial domains.</li>
                    
                    <li>Proposes the High-Local Factorized Fourier Neural Operator (HLF-FNO), comprising a Global High-Frequency Enhanced FNO and a Local High-Frequency Enhanced FNO, to capture global frequency patterns while preserving spatial locality.</li>
                    
                    <li>Improves computational efficiency of the Fourier Neural Operator through a novel Spectral-Channel Factorization scheme.</li>
                    
                    <li>Incorporates a Cross-Attention Frequency Fusion module designed to effectively integrate features derived from both spatial and frequency processing pathways.</li>
                    
                    <li>Utilizes an Intensity Field Decoding pipeline to reconstruct the final Computed Tomography volume from generated projection representations.</li>
                    
                    <li>Achieves state-of-the-art performance on LUNA16 and ToothFairy datasets, demonstrating superior preservation of high-frequency anatomical features, especially in extremely sparse-view scenarios.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DuFal employs a dual-path architecture that leverages both frequency-domain and spatial-domain processing. Its core is the High-Local Factorized Fourier Neural Operator (HLF-FNO), which includes a Global High-Frequency Enhanced Fourier Neural Operator for global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator for spatially partitioned patches. Efficiency is boosted by a Spectral-Channel Factorization scheme applied to the FNO. A Cross-Attention Frequency Fusion module integrates the resulting spatial and frequency features. These fused features are then processed by a Feature Decoder to generate projection representations, subsequently fed into an Intensity Field Decoding pipeline for final CT volume reconstruction. Evaluation was conducted on the LUNA16 and ToothFairy datasets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DuFal framework significantly outperforms existing state-of-the-art methods in sparse-view CBCT reconstruction, particularly in its ability to preserve high-frequency anatomical features and fine details. This superior performance is consistent across the LUNA16 and ToothFairy datasets, especially under extremely sparse-view conditions, demonstrating its robustness and efficacy.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The potential clinical impact is substantial: it could lead to a dramatic reduction in patient radiation dose during CT scans, making diagnostic imaging safer and more accessible for repeated examinations or sensitive populations. The enhanced recovery of high-frequency details promises improved diagnostic accuracy for subtle pathologies, micro-fractures, or small anatomical structures, potentially expanding the clinical utility of CBCT in scenarios where projection limitations or dose constraints are critical.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed DuFal framework or its experimental validation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention specific future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical Physics</span>
                    
                    <span class="tag">Oncology (for treatment planning)</span>
                    
                    <span class="tag">Dentistry</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">sparse-view CBCT</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">Fourier Neural Operator</span>
                    
                    <span class="tag tag-keyword">high-frequency reconstruction</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">radiation dose reduction</span>
                    
                    <span class="tag tag-keyword">anatomical detail</span>
                    
                    <span class="tag tag-keyword">cone-beam CT</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Published with J2C Certification in Transactions on Machine Learning Research (TMLR)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>