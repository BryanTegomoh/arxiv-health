<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction - Health AI Hub</title>
    <meta name="description" content="DuFal introduces a novel dual-path framework for high-fidelity sparse-view Cone-Beam Computed Tomography (CBCT) reconstruction, specifically addressing the chal">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15416v1" target="_blank">2601.15416v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Cuong Tran Van, Trong-Thang Pham, Ngoc-Son Nguyen, Duy Minh Ho Nguyen, Ngan Le
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15416v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15416v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DuFal introduces a novel dual-path framework for high-fidelity sparse-view Cone-Beam Computed Tomography (CBCT) reconstruction, specifically addressing the challenge of recovering fine-grained anatomical details (high-frequency components) often lost in undersampled data. By integrating frequency-domain and spatial-domain processing through a High-Local Factorized Fourier Neural Operator and efficient feature fusion, DuFal significantly outperforms existing state-of-the-art methods. This leads to superior preservation of high-frequency anatomical features, especially in extremely sparse-view settings, as demonstrated on LUNA16 and ToothFairy datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for medical imaging as it enables high-quality CBCT reconstruction from fewer X-ray projections, thereby reducing patient radiation exposure and scan times. The improved recovery of fine anatomical details enhances diagnostic accuracy for conditions requiring precise structural evaluation, even with limited input data.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies AI (specifically deep learning with a novel dual-frequency-aware learning framework) to improve the quality of medical images obtained from Cone-Beam Computed Tomography (CBCT). By enabling high-fidelity reconstruction from 'extremely sparse-view' settings, it can lead to reduced radiation exposure for patients, faster scan times, and more accurate diagnoses by preserving crucial anatomical details that might otherwise be lost. This directly impacts patient care and diagnostic efficacy.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of recovering high-frequency anatomical details in sparse-view CBCT reconstruction, a common failing of conventional CNNs which bias towards low-frequency information.</li>
                    
                    <li>Proposes DuFal, a novel dual-path framework that synergistically integrates frequency-domain and spatial-domain processing to capture comprehensive image information.</li>
                    
                    <li>Introduces the High-Local Factorized Fourier Neural Operator (HL-FFNO), comprising two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator for global patterns and a Local High-Frequency Enhanced Fourier Neural Operator for spatially localized details.</li>
                    
                    <li>Incorporates a Spectral-Channel Factorization scheme to enhance computational efficiency by significantly reducing the parameter count of the Fourier Neural Operator.</li>
                    
                    <li>Designs a Cross-Attention Frequency Fusion module to effectively integrate the diverse features extracted from both spatial and frequency domains.</li>
                    
                    <li>Features a comprehensive decoding pipeline from fused features to projection representations and finally to the reconstructed CT volume via Intensity Field Decoding.</li>
                    
                    <li>Achieves superior performance on the LUNA16 (lung nodule detection) and ToothFairy (dental structures) datasets, demonstrating significant outperformance over SOTA methods in preserving high-frequency anatomical features, particularly under extremely sparse-view conditions.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DuFal employs a dual-path architecture that concurrently processes spatial and frequency domain information. Its core innovation is the High-Local Factorized Fourier Neural Operator (HL-FFNO), which includes a Global High-Frequency Enhanced FNO for capturing overall frequency patterns and a Local High-Frequency Enhanced FNO that operates on partitioned patches to preserve spatial locality. Efficiency is improved through a Spectral-Channel Factorization scheme for parameter reduction. Features from both paths are integrated using a Cross-Attention Frequency Fusion module, then decoded via a Feature Decoder to projection representations, and finally converted into a 3D CT volume using an Intensity Field Decoding pipeline.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DuFal framework significantly outperforms existing state-of-the-art methods in sparse-view CBCT reconstruction. Its primary strength lies in its ability to robustly preserve high-frequency anatomical features, which are critical for diagnostic accuracy. This superior performance was consistently demonstrated on both the LUNA16 and ToothFairy datasets, especially under extremely sparse-view acquisition settings.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology has the potential to significantly reduce the radiation dose administered to patients during CBCT scans without compromising image quality, making medical imaging safer and more accessible. Clinically, it could lead to more accurate diagnosis and treatment planning by providing clearer and more detailed visualizations of subtle anatomical structures, such as small lung nodules or intricate dental roots, even when using faster or low-dose imaging protocols.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly mention any limitations or caveats of the DuFal framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Oncology (specifically lung nodule screening/diagnosis)</span>
                    
                    <span class="tag">Dentistry (orthodontics, implant planning, endodontics)</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">CBCT reconstruction</span>
                    
                    <span class="tag tag-keyword">sparse-view</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">Fourier Neural Operator</span>
                    
                    <span class="tag tag-keyword">high-frequency features</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">low-dose CT</span>
                    
                    <span class="tag tag-keyword">anatomical details</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Published with J2C Certification in Transactions on Machine Learning Research (TMLR)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>