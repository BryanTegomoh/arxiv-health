<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces FedBCS, a novel federated learning approach for medical image segmentation that tackles feature heterogeneity arising from diverse scanner">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.10945v1" target="_blank">2511.10945v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-14
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Xingyue Zhao, Wenke Huang, Xingguang Wang, Haoyu Zhao, Linghao Zhuang, Anwen Jiang, Guancheng Wan, Mang Ye
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.10945v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.10945v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces FedBCS, a novel federated learning approach for medical image segmentation that tackles feature heterogeneity arising from diverse scanners and protocols. FedBCS aligns domain-invariant contextual prototypes by incorporating frequency-domain adaptive style recalibration and a context-aware dual-level prototype alignment across encoder-decoder layers, demonstrating remarkable performance on public datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly enhances the feasibility and robustness of federated learning for medical image analysis, enabling collaborative model training across institutions without sharing sensitive patient data. This is crucial for developing generalizable and privacy-preserving AI diagnostic tools from diverse patient populations and heterogeneous imaging devices.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI method to enhance the performance and reliability of federated learning models for medical image segmentation. This application is crucial for developing AI-powered diagnostic tools, aiding in treatment planning, and monitoring disease progression by allowing medical institutions to collaboratively train robust AI models without sharing sensitive patient data, thus overcoming data privacy and heterogeneity challenges inherent in real-world healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of feature heterogeneity in federated medical image segmentation caused by diverse scanners and imaging protocols across institutions.</li>
                    
                    <li>Identifies two key limitations of existing federated learning methods: incomplete contextual representation learning (due to focusing on final-layer features) and layerwise style bias accumulation in intermediate network layers.</li>
                    
                    <li>Proposes FedBCS, a new method designed to bridge feature representation gaps through domain-invariant contextual prototypes alignment.</li>
                    
                    <li>Introduces frequency-domain adaptive style recalibration into prototype construction, which effectively decouples content-style representations and learns optimal style parameters for robust domain-invariant prototypes.</li>
                    
                    <li>Designs a context-aware dual-level prototype alignment method that extracts and fuses domain-invariant prototypes from different levels of both the encoder and decoder to achieve finer-grained representation alignment.</li>
                    
                    <li>Aims to enhance model robustness by preventing the accumulation of domain-specific style discrepancies throughout the network's layers.</li>
                    
                    <li>Extensive experiments conducted on two public datasets demonstrate that FedBCS achieves remarkable performance in medical image segmentation.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>FedBCS leverages two primary technical innovations: 1) Frequency-domain adaptive style recalibration, which is integrated into the prototype construction process to decouple content from style representations and learn optimal, robust style parameters. 2) A context-aware dual-level prototype alignment method that extracts domain-invariant prototypes from both the encoder and decoder at various network layers, fusing them with contextual information to achieve fine-grained and comprehensive representation alignment across diverse data domains.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed FedBCS method significantly improves performance in federated medical image segmentation by effectively mitigating feature heterogeneity and domain-specific biases. Experiments on two public datasets validate its remarkable accuracy and robustness compared to existing approaches.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By improving the robustness and accuracy of federated medical image segmentation models, this work can lead to more reliable and universally applicable AI-assisted diagnostic tools across hospitals with varying imaging equipment and protocols. This enables collaborative development of powerful models for critical tasks like tumor detection, organ segmentation, or lesion identification, potentially leading to more consistent, precise, and equitable patient care globally.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract implicitly highlights limitations of *existing* methods, specifically 'Incomplete Contextual Representation Learning' (due to focus on final-layer features) and 'Layerwise Style Bias Accumulation' in intermediate layers, which FedBCS is designed to overcome. The abstract does not explicitly state limitations of FedBCS itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging Diagnostics</span>
                    
                    <span class="tag">Pathology (if applicable to broader image types)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Federated Learning</span>
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Feature Heterogeneity</span>
                    
                    <span class="tag tag-keyword">Prototype Alignment</span>
                    
                    <span class="tag tag-keyword">Style Recalibration</span>
                    
                    <span class="tag tag-keyword">Domain Invariance</span>
                    
                    <span class="tag tag-keyword">Multi-level Features</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Federated learning enables multiple medical institutions to train a global model without sharing data, yet feature heterogeneity from diverse scanners or protocols remains a major challenge. Many existing works attempt to address this issue by leveraging model representations (e.g., mean feature vectors) to correct local training; however, they often face two key limitations: 1) Incomplete Contextual Representation Learning: Current approaches primarily focus on final-layer features, overlooking critical multi-level cues and thus diluting essential context for accurate segmentation. 2) Layerwise Style Bias Accumulation: Although utilizing representations can partially align global features, these methods neglect domain-specific biases within intermediate layers, allowing style discrepancies to build up and reduce model robustness. To address these challenges, we propose FedBCS to bridge feature representation gaps via domain-invariant contextual prototypes alignment. Specifically, we introduce a frequency-domain adaptive style recalibration into prototype construction that not only decouples content-style representations but also learns optimal style parameters, enabling more robust domain-invariant prototypes. Furthermore, we design a context-aware dual-level prototype alignment method that extracts domain-invariant prototypes from different layers of both encoder and decoder and fuses them with contextual information for finer-grained representation alignment. Extensive experiments on two public datasets demonstrate that our method exhibits remarkable performance.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted at AAAI-26</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>