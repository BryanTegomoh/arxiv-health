<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quantifying Articulatory Coordination as a Biomarker for Schizophrenia - Health AI Hub</title>
    <meta name="description" content="This paper introduces an interpretable AI framework that quantifies vocal tract coordination using articulatory speech features, specifically eigenspectra diffe">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Quantifying Articulatory Coordination as a Biomarker for Schizophrenia</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03084v1" target="_blank">2511.03084v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Gowtham Premananth, Carol Espy-Wilson
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.AS, cs.LG, eess.SP
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03084v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03084v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces an interpretable AI framework that quantifies vocal tract coordination using articulatory speech features, specifically eigenspectra difference plots and a Weighted Sum with Exponential Decay (WSED) score. The WSED scores effectively distinguish complex from simpler coordination patterns and correlate significantly with both overall BPRS severity and the balance between positive and negative symptoms in schizophrenia, offering a transparent and severity-sensitive biomarker.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a novel, objective, and interpretable method to assess schizophrenia severity and symptom profiles (positive vs. negative) through speech analysis. It moves beyond subjective clinical observations, offering a quantitative biomarker that can aid in early diagnosis, personalized treatment planning, and monitoring therapeutic efficacy.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research presents an interpretable AI-driven framework that utilizes articulatory speech features and computational methods (eigenspectra difference plots, WSED) to quantify vocal tract coordination. This serves as a severity-sensitive biomarker for schizophrenia, with the goal of advancing clinically interpretable speech-based assessment and diagnostic tools for the disorder.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical need for interpretable and severity-sensitive diagnostic/monitoring tools for schizophrenia, overcoming current AI limitations in clinical adoption.</li>
                    
                    <li>Proposes an interpretable framework that leverages articulatory speech features to objectively quantify vocal tract coordination patterns.</li>
                    
                    <li>Utilizes eigenspectra difference plots to effectively distinguish complex from simpler articulatory coordination patterns.</li>
                    
                    <li>Introduces a Weighted Sum with Exponential Decay (WSED) scoring mechanism, which reliably separated these coordination groups with minimal ambiguity.</li>
                    
                    <li>WSED scores demonstrated a significant correlation with overall BPRS (Brief Psychiatric Rating Scale) severity, indicating its potential as a quantitative measure of disease burden.</li>
                    
                    <li>Crucially, WSED scores also reflected the balance between positive and negative symptoms, showing more complex coordination in subjects with pronounced positive symptoms and the opposite trend for stronger negative symptoms.</li>
                    
                    <li>The approach offers a transparent, severity-sensitive, and clinically interpretable speech-based biomarker for schizophrenia assessment and monitoring.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study developed an interpretable AI framework utilizing articulatory speech features to quantify vocal tract coordination. It employed eigenspectra difference plots to visualize and distinguish complex versus simpler coordination patterns. A Weighted Sum with Exponential Decay (WSED) score was then computed from these features to provide a quantitative measure of coordination. These WSED scores were subsequently correlated with established clinical measures, specifically overall BPRS (Brief Psychiatric Rating Scale) severity and the balance of positive and negative symptoms in individuals with schizophrenia.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>['Eigenspectra plots effectively distinguished between complex and simpler vocal tract coordination patterns.', 'WSED scores reliably separated groups based on coordination complexity, with minimal ambiguity (confined to a narrow range near zero).', 'WSED scores showed a significant correlation with overall BPRS severity in subjects with schizophrenia.', 'The scores also correlated with the balance of positive and negative symptoms: more complex vocal tract coordination was associated with pronounced positive symptoms, while a trend towards simpler coordination was observed with stronger negative symptoms.']</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research holds significant clinical impact by providing an objective, transparent, and quantitative biomarker for schizophrenia, reducing reliance on subjective clinical assessments. It can enable severity-sensitive monitoring of the disorder, potentially guiding more personalized and timely interventions. The ability to differentiate between positive and negative symptom profiles through speech analysis could lead to more targeted pharmacological or psychotherapeutic treatments, ultimately improving patient outcomes and quality of life.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the study (e.g., sample size, generalizability, specific patient demographics, or cross-linguistic validation).</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests that this approach advances the potential for clinically interpretable speech-based assessment tools, implying future work in validation within larger and more diverse cohorts, refining the framework for broader clinical applicability, and exploring its utility in monitoring treatment response or predicting disease trajectory in schizophrenia and potentially other neuropsychiatric conditions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Neuroscience (Cognitive/Motor Control)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Schizophrenia</span>
                    
                    <span class="tag tag-keyword">Biomarker</span>
                    
                    <span class="tag tag-keyword">Articulatory speech features</span>
                    
                    <span class="tag tag-keyword">Vocal tract coordination</span>
                    
                    <span class="tag tag-keyword">Interpretability</span>
                    
                    <span class="tag tag-keyword">AI in healthcare</span>
                    
                    <span class="tag tag-keyword">Symptom severity</span>
                    
                    <span class="tag tag-keyword">Psychiatric assessment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Advances in artificial intelligence (AI) and deep learning have improved
diagnostic capabilities in healthcare, yet limited interpretability continues
to hinder clinical adoption. Schizophrenia, a complex disorder with diverse
symptoms including disorganized speech and social withdrawal, demands tools
that capture symptom severity and provide clinically meaningful insights beyond
binary diagnosis. Here, we present an interpretable framework that leverages
articulatory speech features through eigenspectra difference plots and a
weighted sum with exponential decay (WSED) to quantify vocal tract
coordination. Eigenspectra plots effectively distinguished complex from simpler
coordination patterns, and WSED scores reliably separated these groups, with
ambiguity confined to a narrow range near zero. Importantly, WSED scores
correlated not only with overall BPRS severity but also with the balance
between positive and negative symptoms, reflecting more complex coordination in
subjects with pronounced positive symptoms and the opposite trend for stronger
negative symptoms. This approach offers a transparent, severity-sensitive
biomarker for schizophrenia, advancing the potential for clinically
interpretable speech-based assessment tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Submitted to ICASSP 2026</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>