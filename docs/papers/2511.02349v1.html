<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M3PD Dataset: Dual-view Photoplethysmography (PPG) Using Front-and-rear Cameras of Smartphones in Lab and Clinical Settings - Health AI Hub</title>
    <meta name="description" content="This paper introduces the M3PD dataset, the first publicly available dual-view mobile photoplethysmography (PPG) dataset, which captures synchronized facial and">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>M3PD Dataset: Dual-view Photoplethysmography (PPG) Using Front-and-rear Cameras of Smartphones in Lab and Clinical Settings</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.02349v1" target="_blank">2511.02349v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jiankai Tang, Tao Zhang, Jia Li, Yiru Zhang, Mingyu Zhang, Kegang Wang, Yuming Hao, Bolin Wang, Haiyang Li, Xingyao Wang, Yuanchun Shi, Yuntao Wang, Sichong Qian
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.02349v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.02349v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the M3PD dataset, the first publicly available dual-view mobile photoplethysmography (PPG) dataset, which captures synchronized facial and fingertip videos from 60 participants (including 47 cardiovascular patients) using smartphone front and rear cameras. Building on this dataset, the authors propose F3Mamba, a novel model fusing these dual views through Mamba-based temporal modeling, achieving a 21.9-30.2% reduction in heart-rate error and improved robustness over single-view baselines.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for advancing portable physiological monitoring, offering a more accessible, non-invasive, and reliable method for early detection and continuous management of cardiovascular disease, especially by mitigating current limitations that require specialized equipment or impractical patient postures.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper introduces F3Mamba, an AI model that fuses facial and fingertip photoplethysmography (PPG) views captured by smartphone cameras using Mamba-based temporal modeling. This AI application aims to significantly reduce heart-rate error and improve the robustness of smartphone-based physiological monitoring, making it more reliable for clinical and real-world health assessment, particularly for cardiovascular patients.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical limitations of current video-PPG (vPPG), including susceptibility to motion artifacts, lighting variations, single-view constraints, and a lack of open datasets for cardiovascular patients.</li>
                    
                    <li>Introduces M3PD, the first publicly available dual-view mobile PPG dataset, featuring synchronized facial and fingertip videos.</li>
                    
                    <li>Data in M3PD is captured simultaneously using both front and rear cameras of smartphones, providing a unique dual-perspective for analysis.</li>
                    
                    <li>The dataset includes recordings from 60 participants, crucially comprising 47 individuals diagnosed with cardiovascular diseases, enhancing its clinical relevance.</li>
                    
                    <li>Proposes F3Mamba, a novel machine learning model that fuses the facial and fingertip PPG views using Mamba-based temporal modeling.</li>
                    
                    <li>F3Mamba demonstrated significant performance improvement, reducing heart-rate error by 21.9% to 30.2% compared to existing single-view baseline methods.</li>
                    
                    <li>The proposed model also improved robustness, enhancing the reliability of heart-rate measurement in challenging real-world monitoring scenarios.</li>
                    
                    <li>The M3PD dataset and F3Mamba code are made publicly available, fostering further research and development in this domain.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved creating the M3PD dataset by concurrently capturing synchronized facial and fingertip videos from 60 participants, including 47 cardiovascular patients, using the front and rear cameras of smartphones. Subsequently, a novel model named F3Mamba was developed. This model employs Mamba-based temporal modeling to effectively fuse the data from these dual facial and fingertip views, and its performance was evaluated against established single-view baseline approaches.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The F3Mamba model significantly improved heart-rate measurement accuracy, achieving a 21.9% to 30.2% reduction in error when compared to existing single-view PPG baselines. Furthermore, the model demonstrated enhanced robustness, making it more reliable for use in complex and challenging real-world monitoring environments.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to transform cardiovascular monitoring by enabling highly accurate and robust heart rate tracking using readily available smartphones, even for patients. This could facilitate more widespread early detection, continuous remote patient monitoring, and improved management of cardiovascular conditions, thereby increasing accessibility to vital physiological data outside traditional clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *existing* video-PPG methods (e.g., susceptibility to motion artifacts, lighting variations, single-view constraints, and a lack of open datasets for cardiovascular patients) which the M3PD dataset and F3Mamba model are designed to overcome. It does not explicitly state specific limitations or caveats pertaining to the M3PD dataset or the F3Mamba model itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The public release of the M3PD dataset, as the first dual-view mobile PPG dataset, along with the F3Mamba code, implicitly encourages future research. This includes developing new algorithms leveraging dual-view data, validating cross-device accuracy, and further improving robust physiological monitoring, particularly in diverse clinical populations and varied real-world conditions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                    <span class="tag">Remote patient monitoring</span>
                    
                    <span class="tag">Preventive medicine</span>
                    
                    <span class="tag">Digital health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Photoplethysmography</span>
                    
                    <span class="tag tag-keyword">Video-PPG</span>
                    
                    <span class="tag tag-keyword">Smartphone health</span>
                    
                    <span class="tag tag-keyword">Dual-view sensing</span>
                    
                    <span class="tag tag-keyword">Mamba model</span>
                    
                    <span class="tag tag-keyword">Cardiovascular disease</span>
                    
                    <span class="tag tag-keyword">Heart rate monitoring</span>
                    
                    <span class="tag tag-keyword">Open dataset</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Portable physiological monitoring is essential for early detection and
management of cardiovascular disease, but current methods often require
specialized equipment that limits accessibility or impose impractical postures
that patients cannot maintain. Video-based photoplethysmography on smartphones
offers a convenient noninvasive alternative, yet it still faces reliability
challenges caused by motion artifacts, lighting variations, and single-view
constraints. Few studies have demonstrated reliable application to
cardiovascular patients, and no widely used open datasets exist for
cross-device accuracy. To address these limitations, we introduce the M3PD
dataset, the first publicly available dual-view mobile photoplethysmography
dataset, comprising synchronized facial and fingertip videos captured
simultaneously via front and rear smartphone cameras from 60 participants
(including 47 cardiovascular patients). Building on this dual-view setting, we
further propose F3Mamba, which fuses the facial and fingertip views through
Mamba-based temporal modeling. The model reduces heart-rate error by 21.9 to
30.2 percent over existing single-view baselines while improving robustness in
challenging real-world scenarios. Data and code:
https://github.com/Health-HCI-Group/F3Mamba.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>