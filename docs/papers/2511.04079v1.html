<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods - Health AI Hub</title>
    <meta name="description" content="This paper presents a novel transformer-based model significantly enhancing the automated de-identification of radiology reports by leveraging large-scale, dive">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.04079v1" target="_blank">2511.04079v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Eva Prakash, Maayane Attias, Pierre Chambon, Justin Xu, Steven Truong, Jean-Benoit Delbrouck, Tessa Cook, Curtis Langlotz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.04079v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.04079v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a novel transformer-based model significantly enhancing the automated de-identification of radiology reports by leveraging large-scale, diverse training data and incorporating an 'AGE' PHI category. The model achieves superior performance (F1 scores up to 0.996) for Protected Health Information (PHI) detection, outperforming both prior academic models and leading commercial cloud vendor systems. This work establishes a new benchmark for secure and accurate clinical text processing.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is vital for accelerating medical discovery and AI development by enabling the secure and privacy-compliant sharing of vast amounts of clinical text data, such as radiology reports, which are rich sources of protected health information (PHI) but crucial for secondary uses like research and model training.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automated de-identification of Protected Health Information (PHI) from clinical text, specifically radiology reports, using transformer-based natural language processing models. This enables the creation of privacy-preserving medical datasets, which are essential for developing and validating other medical AI tools (e.g., diagnostic assistants, predictive analytics) and conducting medical research on real-world patient data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Developed and fine-tuned a state-of-the-art transformer-based model for token-level PHI de-identification in radiology reports.</li>
                    
                    <li>Utilized extensive, multimodal radiology corpora from Stanford (chest X-ray, chest CT, abdomen/pelvis CT, brain MR) for large-scale training.</li>
                    
                    <li>Introduced an additional PHI category, 'AGE', into the model architecture for more comprehensive de-identification.</li>
                    
                    <li>Achieved high F1 scores of 0.996 on the Stanford dataset and 0.973 on the University of Pennsylvania (Penn) dataset, surpassing or matching previous academic state-of-the-art.</li>
                    
                    <li>Significantly outperformed all commercial cloud vendor systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).</li>
                    
                    <li>Demonstrated the stability and utility of synthetic PHI generation ('hide-in-plain-sight' method) with consistent detectability (F1: 0.959).</li>
                    
                    <li>The large-scale, multimodal training approach improved cross-institutional generalization and model robustness.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study enhanced a transformer-based PHI de-identification pipeline by fine-tuning it on two large, manually annotated radiology corpora from Stanford, encompassing chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports. An 'AGE' category was added to the PHI architecture. Model performance was evaluated on token-level PHI detection using precision, recall, and F1 scores on test sets from Stanford and the University of Pennsylvania. Performance was also rigorously benchmarked against commercial cloud vendor systems, and the stability of a 'hide-in-plain-sight' synthetic PHI generation method was assessed.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The model achieved F1 scores of 0.996 on the Stanford dataset and 0.973 on the Penn dataset, outperforming or maintaining the previous state-of-the-art. It significantly surpassed all commercial vendor systems on synthetic Penn reports (0.960 F1 vs. 0.632-0.754 F1). Synthetic PHI evaluation confirmed consistent detectability (0.959 F1), validating its utility. The large-scale, multimodal training was found to improve cross-institutional generalization and robustness.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This advanced de-identification model offers a highly accurate and efficient solution for removing PHI from sensitive clinical documents like radiology reports. This will facilitate safer and faster sharing of medical data for research, AI algorithm development, and quality improvement initiatives, reducing the privacy risks associated with data sharing and compliance burdens, while promoting data-driven healthcare innovation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions, but implicitly, continued development of such robust de-identification models will support broader applications in clinical NLP and data privacy.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Clinical Research</span>
                    
                    <span class="tag">Data Privacy</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Radiology Reports</span>
                    
                    <span class="tag tag-keyword">De-identification</span>
                    
                    <span class="tag tag-keyword">Protected Health Information (PHI)</span>
                    
                    <span class="tag tag-keyword">Transformers</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Benchmarking</span>
                    
                    <span class="tag tag-keyword">Clinical Text</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>In submission to JAMIA</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>