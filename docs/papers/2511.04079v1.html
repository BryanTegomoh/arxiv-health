<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods - Health AI Hub</title>
    <meta name="description" content="This paper presents a transformer-based model significantly improving automated de-identification of radiology reports by leveraging large-scale, multimodal tra">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.04079v1" target="_blank">2511.04079v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Eva Prakash, Maayane Attias, Pierre Chambon, Justin Xu, Steven Truong, Jean-Benoit Delbrouck, Tessa Cook, Curtis Langlotz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.04079v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.04079v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a transformer-based model significantly improving automated de-identification of radiology reports by leveraging large-scale, multimodal training data and introducing an AGE PHI category. The model achieves high F1 scores on institutional datasets and notably outperforms commercial cloud vendor systems, establishing a new benchmark for secure clinical text processing. This advancement enhances the ability to share and utilize sensitive patient data for research and AI development while maintaining privacy.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critical for enabling secure and compliant sharing and secondary use of vast amounts of sensitive patient data contained in radiology reports. It directly addresses HIPAA compliance, facilitating advancements in medical research, artificial intelligence model development, and quality improvement initiatives without compromising patient privacy.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automated de-identification of Protected Health Information (PHI) from clinical text, specifically radiology reports, using transformer-based models. This facilitates the secure use of medical data for research, analytics, and the training of other medical AI models by ensuring patient privacy.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A state-of-the-art transformer-based model was fine-tuned on two large, diverse radiology corpora from Stanford University, covering chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports.</li>
                    
                    <li>An additional Protected Health Information (PHI) category, AGE, was incorporated into the model's architecture to enhance de-identification completeness.</li>
                    
                    <li>The model achieved high overall F1 scores for token-level PHI detection: 0.996 on the Stanford dataset and 0.973 on the University of Pennsylvania (Penn) dataset, outperforming or maintaining the previous academic state-of-the-art.</li>
                    
                    <li>Stability of synthetic PHI generation was validated using a "hide-in-plain-sight" method, showing consistent detectability with an overall F1 of 0.959 across 50 independently de-identified Penn datasets.</li>
                    
                    <li>The proposed model significantly outperformed all commercial cloud vendor de-identification systems on synthetic Penn reports, achieving an overall F1 of 0.960 compared to vendor scores ranging from 0.632 to 0.754.</li>
                    
                    <li>Large-scale, multimodal training was crucial for improving cross-institutional generalization and robustness of the de-identification process.</li>
                    
                    <li>The synthetic PHI generation method demonstrated potential for preserving data utility for research and development while ensuring patient privacy.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study enhanced a transformer-based PHI de-identification pipeline by fine-tuning it on large, manually annotated radiology corpora (chest X-ray/CT, abdomen/pelvis CT, brain MR) from Stanford University. It introduced a new 'AGE' PHI category and evaluated token-level PHI detection using precision, recall, and F1 scores on test sets from Stanford and Penn. Performance stability was assessed via synthetic PHI generated by a "hide-in-plain-sight" method, and the model was benchmarked against commercial cloud vendor systems.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The developed transformer model achieved superior PHI detection performance with F1 scores of 0.996 (Stanford) and 0.973 (Penn), surpassing prior academic state-of-the-art. It demonstrated robust and consistent detection of synthetic PHI (overall F1 0.959). Crucially, the model significantly outperformed all tested commercial cloud vendor de-identification systems (F1 0.960 vs. 0.632-0.754) on cross-institutional data, highlighting improved generalization and robustness through large-scale, multimodal training.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This advancement provides a highly accurate and robust automated solution for de-identifying clinical free-text data, particularly radiology reports. It facilitates safer and more efficient access to real-world patient data for research, AI model training, and healthcare quality improvement, reducing manual effort and accelerating the translation of data-driven insights into clinical practice while ensuring stringent adherence to patient privacy regulations.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly detail any limitations or caveats of the proposed method or study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly outline future research directions, though the establishment of a "new benchmark" implies a foundation for ongoing advancements in secure clinical text processing and potential expansion to other clinical domains or even more diverse data modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                    <span class="tag">Clinical Research</span>
                    
                    <span class="tag">Data Privacy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Radiology reports</span>
                    
                    <span class="tag tag-keyword">De-identification</span>
                    
                    <span class="tag tag-keyword">Protected Health Information</span>
                    
                    <span class="tag tag-keyword">Transformer models</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Benchmarking</span>
                    
                    <span class="tag tag-keyword">Clinical text</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>In submission to JAMIA</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>