<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models - Health AI Hub</title>
    <meta name="description" content="ShapeX introduces a novel post-hoc explanation framework for time series classification models, addressing the limitations of existing methods that overlook the">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20084v1" target="_blank">2510.20084v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Bosong Huang, Ming Jin, Yuxuan Liang, Johan Barthelemy, Debo Cheng, Qingsong Wen, Chenghao Liu, Shirui Pan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20084v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20084v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">ShapeX introduces a novel post-hoc explanation framework for time series classification models, addressing the limitations of existing methods that overlook the fundamental role of key shapelets. By segmenting time series into shapelet-driven components and applying Shapley values, ShapeX provides explanations that reveal causal relationships rather than mere correlations. Experimental results validate its superior performance in identifying relevant subsequences with enhanced precision and causal fidelity on both synthetic and real-world datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>In high-stakes medical applications, understanding *why* a time series model (e.g., for disease diagnosis from ECG or EEG) makes a particular prediction is crucial for clinician trust, adoption, and patient safety. ShapeX's ability to provide causally faithful explanations based on identifiable physiological patterns (shapelets) directly supports clinical validation and responsible AI deployment in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research provides a framework (ShapeX) for developing explainable AI (XAI) models specifically for time series data in healthcare. It would enable medical professionals to understand why a machine learning model made a particular prediction regarding a patient's condition based on their time-series physiological data, thereby enhancing trust, facilitating clinical adoption, and potentially leading to more accurate and reliable medical interventions. This is crucial for medical AI applications that involve pattern recognition in patient data over time.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing post-hoc time series explanation (PHTSE) methods primarily focus on timestep-level feature attribution, failing to recognize that classification outcomes are predominantly driven by key subsequences (shapelets).</li>
                    
                    <li>ShapeX is an innovative framework that segments time series into meaningful, shapelet-driven segments and employs Shapley values to assess their saliency for classification explanations.</li>
                    
                    <li>The core of ShapeX is the Shapelet Describe-and-Detect (SDD) framework, designed to effectively learn a diverse and essential set of shapelets for classification tasks.</li>
                    
                    <li>ShapeX is demonstrated to produce explanations that uncover causal relationships, distinguishing itself from correlation-based methods due to the inherent atomicity properties of shapelets.</li>
                    
                    <li>Experimental evaluations on both synthetic and real-world datasets show that ShapeX outperforms existing explanation methods.</li>
                    
                    <li>The framework significantly enhances the precision and causal fidelity of time series explanations by more accurately identifying the most relevant subsequences.</li>
                    
                    <li>The research underscores the critical need for transparent and trustworthy explanations in high-stakes applications such as healthcare and finance.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ShapeX operates by first segmenting time series into 'shapelet-driven segments.' This segmentation relies on the Shapelet Describe-and-Detect (SDD) framework, which is responsible for learning a diverse set of shapelets essential for the underlying classification task. Subsequently, Shapley values are employed to quantify the saliency or contribution of these identified shapelet-driven segments to the final classification outcome, thereby generating explanations that reveal causal relationships due to the atomicity of shapelets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>ShapeX consistently outperforms existing time series explanation methods by significantly enhancing both the precision and causal fidelity of explanations. It achieves this by accurately identifying the most relevant subsequences (shapelets) that truly drive classification decisions, rather than relying on less interpretable, timestep-level attributions. This leads to more reliable and interpretable insights into model behavior.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>ShapeX has the potential to profoundly impact the deployment and trustworthiness of AI in clinical settings. By offering clear, causally-linked explanations of model predictions based on specific physiological patterns (shapelets), clinicians can better understand, validate, and confidently integrate AI tools into diagnostic and prognostic workflows. This increased transparency can lead to improved clinical decision-making, earlier interventions, enhanced patient safety, and accelerated regulatory approval and adoption of AI technologies in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the ShapeX framework itself. It primarily highlights the limitations of *existing* post-hoc time series explanation methods, which ShapeX aims to overcome.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention any specific future research directions for the ShapeX framework.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Cardiology (ECG/PPG analysis)</span>
                    
                    <span class="tag">Neurology (EEG analysis, seizure detection)</span>
                    
                    <span class="tag">Critical Care Monitoring</span>
                    
                    <span class="tag">Remote Patient Monitoring</span>
                    
                    <span class="tag">Disease Progression Modeling</span>
                    
                    <span class="tag">Diabetic Retinopathy Detection</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Time series classification</span>
                    
                    <span class="tag tag-keyword">Post hoc explanations</span>
                    
                    <span class="tag tag-keyword">Shapelets</span>
                    
                    <span class="tag tag-keyword">Shapley values</span>
                    
                    <span class="tag tag-keyword">Explainable AI (XAI)</span>
                    
                    <span class="tag tag-keyword">Causality</span>
                    
                    <span class="tag tag-keyword">Feature attribution</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Explaining time series classification models is crucial, particularly in
high-stakes applications such as healthcare and finance, where transparency and
trust play a critical role. Although numerous time series classification
methods have identified key subsequences, known as shapelets, as core features
for achieving state-of-the-art performance and validating their pivotal role in
classification outcomes, existing post-hoc time series explanation (PHTSE)
methods primarily focus on timestep-level feature attribution. These
explanation methods overlook the fundamental prior that classification outcomes
are predominantly driven by key shapelets. To bridge this gap, we present
ShapeX, an innovative framework that segments time series into meaningful
shapelet-driven segments and employs Shapley values to assess their saliency.
At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,
which effectively learns a diverse set of shapelets essential for
classification. We further demonstrate that ShapeX produces explanations which
reveal causal relationships instead of just correlations, owing to the
atomicity properties of shapelets. Experimental results on both synthetic and
real-world datasets demonstrate that ShapeX outperforms existing methods in
identifying the most relevant subsequences, enhancing both the precision and
causal fidelity of time series explanations.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>