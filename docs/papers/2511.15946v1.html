<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automated Interpretable 2D Video Extraction from 3D Echocardiography - Health AI Hub</title>
    <meta name="description" content="This paper introduces an automated deep learning-based method to extract standard 2D echocardiography views from complex 3D cardiac ultrasound volumes. The appr">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Automated Interpretable 2D Video Extraction from 3D Echocardiography</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15946v1" target="_blank">2511.15946v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Milos Vukadinovic, Hirotaka Ieki, Yuki Sahasi, David Ouyang, Bryan He
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15946v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15946v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces an automated deep learning-based method to extract standard 2D echocardiography views from complex 3D cardiac ultrasound volumes. The approach allows physicians to interpret comprehensive 3D data in their familiar 2D format, preserving critical diagnostic features and spatial calibration. Validation confirmed high accuracy in view identification and utility for AI-driven abnormality detection and measurement.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This method bridges the gap between advanced 3D echocardiography acquisition and conventional 2D interpretation workflows, potentially making 3D ultrasound more clinically accessible, efficient, and standardized. It facilitates the integration of AI tools by converting 3D data into a widely understood 2D format familiar to clinicians.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using deep learning (a view classifier) and anatomical heuristics to automatically extract standard 2D echocardiography videos from 3D cardiac ultrasound volumes. This allows physicians to interpret complex 3D data in a familiar, clinically validated 2D format, streamlining acquisition, improving assessment, and aiding in the detection of cardiac abnormalities and generation of clinical-grade anatomical measurements using existing AI echocardiography models (EchoPrime, PanEcho, EchoNet-Measurement).</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenge of interpreting complex 3D cardiac anatomy using traditional, standardized 2D echocardiography views.</li>
                    
                    <li>Proposes an automated pipeline that combines a deep learning view classifier with downstream heuristics based on anatomical landmarks and cardiologist-provided rules.</li>
                    
                    <li>Successfully reconstructs standard 2D echocardiography views from 3D ultrasound volumes, aiming to streamline acquisition and improve off-axis feature assessment.</li>
                    
                    <li>Achieved 96% accuracy in blinded evaluation by three cardiologists across 1,600 videos sourced from two different hospitals.</li>
                    
                    <li>Validated the utility of the extracted 2D videos for detecting cardiac abnormalities using established AI echocardiography models (EchoPrime and PanEcho).</li>
                    
                    <li>Demonstrated the capability of the extracted 2D videos to generate clinical-grade measurements of cardiac anatomy using the EchoNet-Measurement model.</li>
                    
                    <li>Confirms that the extracted 2D videos preserve both spatial calibration and essential diagnostic features from the original 3D volumes.</li>
                    
                    <li>The authors open-sourced their code and a dataset of 29 3D echocardiography videos to foster further research.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The method employs a deep learning view classifier to initially identify potential standard 2D views within a 3D echocardiography volume. This is followed by a series of downstream heuristics, which utilize anatomical landmarks and expert rules defined by cardiologists, to accurately reconstruct and select the final standard 2D echocardiography videos.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The automated extraction process demonstrated high performance, achieving 96% accuracy in identifying standard 2D views when evaluated by cardiologists. Crucially, the extracted 2D videos were shown to preserve both spatial calibration and diagnostic features, enabling accurate detection of cardiac abnormalities by AI models and precise generation of clinical measurements.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This innovation has the potential to significantly improve the efficiency, standardization, and reproducibility of cardiac ultrasound examinations. By automating the extraction of familiar 2D views from 3D data, it can reduce operator variability, streamline image acquisition, facilitate wider adoption of 3D echocardiography, and enable seamless integration of AI-powered diagnostic and measurement tools into routine clinical workflows.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. Implicitly, the generalizability might be influenced by the specifics of the deep learning model training data or the specific AI models used for downstream validation. The publicly released dataset (29 videos) is small compared to the internal validation set, which could be a hurdle for external researchers.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. Potential avenues could include expanding the training and validation datasets to increase generalizability across diverse patient populations and scanner types, investigating real-time extraction for immediate clinical feedback during 3D acquisition, and exploring the utility of this approach for other organs or medical imaging modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Cardiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Diagnostic Ultrasound</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">3D echocardiography</span>
                    
                    <span class="tag tag-keyword">2D view extraction</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Cardiac ultrasound</span>
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Image interpretation</span>
                    
                    <span class="tag tag-keyword">Automated diagnosis</span>
                    
                    <span class="tag tag-keyword">Echocardiography</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Although the heart has complex three-dimensional (3D) anatomy, conventional medical imaging with cardiac ultrasound relies on a series of 2D videos showing individual cardiac structures. 3D echocardiography is a developing modality that now offers adequate image quality for clinical use, with potential to streamline acquisition and improve assessment of off-axis features. We propose an automated method to select standard 2D views from 3D cardiac ultrasound volumes, allowing physicians to interpret the data in their usual format while benefiting from the speed and usability of 3D scanning. Applying a deep learning view classifier and downstream heuristics based on anatomical landmarks together with heuristics provided by cardiologists, we reconstruct standard echocardiography views. This approach was validated by three cardiologists in blinded evaluation (96\% accuracy in 1,600 videos from 2 hospitals). The downstream 2D videos were also validated in their ability to detect cardiac abnormalities using AI echocardiography models (EchoPrime and PanEcho) as well as ability to generate clinical-grade measurements of cardiac anatomy (EchoNet-Measurement). We demonstrated that the extracted 2D videos preserve spatial calibration and diagnostic features, allowing clinicians to obtain accurate real-world interpretations from 3D volumes. We release the code and a dataset of 29 3D echocardiography videos https://github.com/echonet/3d-echo .</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>12 pages, 5 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>