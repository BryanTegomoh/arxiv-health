<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ProPL: Universal Semi-Supervised Ultrasound Image Segmentation via Prompt-Guided Pseudo-Labeling - Health AI Hub</title>
    <meta name="description" content="Existing ultrasound image segmentation methods are often highly specialized for specific anatomical structures, limiting their broad applicability in clinical s">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ProPL: Universal Semi-Supervised Ultrasound Image Segmentation via Prompt-Guided Pseudo-Labeling</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15057v1" target="_blank">2511.15057v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-19
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yaxiong Chen, Qicong Wang, Chunlei Li, Jingliang Hu, Yilei Shi, Shengwu Xiong, Xiao Xiang Zhu, Lichao Mou
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15057v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15057v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Existing ultrasound image segmentation methods are often highly specialized for specific anatomical structures, limiting their broad applicability in clinical settings. ProPL introduces a pioneering universal semi-supervised framework that addresses multiple organs and segmentation tasks simultaneously, leveraging both labeled and unlabeled data. It achieves this through prompt-guided dual decoders and an uncertainty-driven pseudo-label calibration module, outperforming state-of-the-art methods and establishing a new benchmark.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine as it addresses a critical bottleneck in the clinical deployment of AI for ultrasound: the need for numerous specialized models. A universal segmentation framework could significantly streamline clinical workflows, making AI more accessible and efficient for diagnostic imaging across a wide range of anatomical structures and pathologies.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to develop a universal semi-supervised model for automated segmentation of ultrasound images across various organs and tasks. This aims to improve the efficiency, accuracy, and consistency of medical image interpretation in clinical settings, aiding diagnosis, treatment planning, and monitoring by reducing reliance on specialized, task-specific models and leveraging both labeled and unlabeled data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Pioneering Universal Semi-Supervised Segmentation**: ProPL is the first framework specifically designed for universal semi-supervised ultrasound image segmentation, overcoming the limitations of specialized models.</li>
                    
                    <li>**Multi-Organ and Multi-Task Capability**: The framework can handle segmentation across various organs and diverse segmentation tasks within a unified model.</li>
                    
                    <li>**Prompt-Guided Dual Decoders**: Utilizes a shared vision encoder combined with prompt-guided dual decoders, enabling flexible adaptation to different tasks via a prompting-upon-decoding mechanism.</li>
                    
                    <li>**Uncertainty-Driven Pseudo-Label Calibration (UPLC)**: Incorporates a UPLC module to ensure reliable self-training by calibrating pseudo-labels, enhancing the utility of unlabeled data.</li>
                    
                    <li>**Comprehensive Dataset Introduction**: The authors introduce a new, comprehensive ultrasound dataset spanning 5 organs and 8 distinct segmentation tasks to facilitate research in this domain.</li>
                    
                    <li>**State-of-the-Art Performance**: ProPL demonstrates superior performance against existing state-of-the-art methods across various evaluation metrics.</li>
                    
                    <li>**New Benchmark Established**: The framework sets a new benchmark for universal ultrasound image segmentation, indicating significant progress in the field.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ProPL employs a deep learning architecture featuring a shared vision encoder coupled with prompt-guided dual decoders. It integrates a 'prompting-upon-decoding' mechanism to facilitate flexible task adaptation. For semi-supervised learning, it utilizes an 'uncertainty-driven pseudo-label calibration (UPLC)' module to perform reliable self-training by leveraging unlabeled data.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>ProPL significantly outperforms existing state-of-the-art methods on a comprehensive set of metrics for universal ultrasound image segmentation. It successfully demonstrates the feasibility and effectiveness of a single model to address multiple organ and segmentation tasks, establishing a new benchmark in this emerging area.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The clinical impact of ProPL is substantial: it could enable the deployment of a single, adaptable AI model in sonography departments, reducing the need to develop and manage multiple specialized models for different organs or tasks. This could lead to increased efficiency in image analysis, more consistent diagnostic assistance, and accelerate the integration of AI into diverse clinical ultrasound applications, ultimately benefiting patient care through faster and potentially more accurate diagnoses.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the ProPL framework or its experimental setup.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions, beyond establishing a new benchmark and dataset to facilitate further research in this new direction.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Sonography</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Anatomy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Ultrasound Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Semi-Supervised Learning</span>
                    
                    <span class="tag tag-keyword">Prompt Learning</span>
                    
                    <span class="tag tag-keyword">Universal Segmentation</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Pseudo-Labeling</span>
                    
                    <span class="tag tag-keyword">Multi-Task Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Existing approaches for the problem of ultrasound image segmentation, whether supervised or semi-supervised, are typically specialized for specific anatomical structures or tasks, limiting their practical utility in clinical settings. In this paper, we pioneer the task of universal semi-supervised ultrasound image segmentation and propose ProPL, a framework that can handle multiple organs and segmentation tasks while leveraging both labeled and unlabeled data. At its core, ProPL employs a shared vision encoder coupled with prompt-guided dual decoders, enabling flexible task adaptation through a prompting-upon-decoding mechanism and reliable self-training via an uncertainty-driven pseudo-label calibration (UPLC) module. To facilitate research in this direction, we introduce a comprehensive ultrasound dataset spanning 5 organs and 8 segmentation tasks. Extensive experiments demonstrate that ProPL outperforms state-of-the-art methods across various metrics, establishing a new benchmark for universal ultrasound image segmentation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>AAAI 2026</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>