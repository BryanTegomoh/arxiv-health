<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening - Health AI Hub</title>
    <meta name="description" content="NutriScreener is a novel retrieval-augmented, multi-pose graph attention network that leverages CLIP-based visual embeddings and class-boosted knowledge retriev">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16566v1" target="_blank">2511.16566v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Misaal Khan, Mayank Vatsa, Kuldeep Singh, Richa Singh
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16566v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16566v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">NutriScreener is a novel retrieval-augmented, multi-pose graph attention network that leverages CLIP-based visual embeddings and class-boosted knowledge retrieval for robust child malnutrition detection and anthropometric prediction from images. It achieves high recall (0.79) and AUC (0.82) with significantly lower anthropometric RMSEs, earning high clinical ratings for accuracy and efficiency, making it a scalable solution for early intervention in low-resource settings.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This technology offers a scalable, accurate, and early detection method for child malnutrition, directly addressing the limitations of existing laborious and poorly scalable screening methods, thereby enabling timely medical and nutritional interventions, especially critical in resource-constrained environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>NutriScreener is an AI model that utilizes retrieval-augmented multi-pose graph attention networks with CLIP-based visual embeddings to enable robust malnutrition detection and anthropometric prediction from children's images. Its application is to provide a scalable and accurate solution for early malnutrition screening and intervention, particularly in low-resource healthcare environments, enhancing diagnostic efficiency and accessibility.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Introduces NutriScreener, a retrieval-augmented, multi-pose Graph Attention Network (GAT) for child malnutrition screening.</li>
                    
                    <li>Combines CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to enhance detection and prediction from images.</li>
                    
                    <li>Designed to simultaneously address malnutrition detection and anthropometric prediction, improving generalizability and handling class imbalance.</li>
                    
                    <li>Achieved strong performance metrics: 0.79 recall, 0.82 AUC for malnutrition detection, and significantly lower anthropometric RMSEs.</li>
                    
                    <li>Demonstrated significant improvements in cross-dataset evaluations, with up to 25% recall gain and up to 3.5 cm RMSE reduction using demographically matched knowledge bases.</li>
                    
                    <li>Received high clinical ratings from doctors (4.3/5 for accuracy, 4.6/5 for efficiency), confirming its readiness for deployment in low-resource settings.</li>
                    
                    <li>Trained on 2,141 children from AnthroVision and validated on diverse datasets including ARAN and an in-house CampusPose dataset.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>NutriScreener employs a retrieval-augmented, multi-pose Graph Attention Network (GAT). It integrates CLIP (Contrastive Language-Image Pre-training) for generating robust visual embeddings, a class-boosted knowledge retrieval system to incorporate contextual information, and multi-pose analysis for inferring malnutrition status and predicting anthropometric measurements from children's images. The system was trained on a dataset of 2,141 children from AnthroVision and evaluated on diverse, cross-continent populations including ARAN and a proprietary CampusPose dataset.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>{'anthropometric_prediction': 'Significantly lower Root Mean Square Errors (RMSEs)', 'clinical_study_ratings': {'accuracy': '4.3/5', 'efficiency': '4.6/5'}, 'cross_dataset_performance_gains': {'recall_gain': 'up to 25%', 'rmse_reduction': 'up to 3.5 cm'}, 'malnutrition_detection_metrics': {'auc': 0.82, 'recall': 0.79}, 'overall_reliability': 'Demonstrates reliable measurement in unconstrained pediatric settings.'}</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>NutriScreener provides a highly scalable and accurate tool for the early identification of child malnutrition, which is crucial for timely intervention and improved health outcomes. Its high ratings from doctors for accuracy and efficiency confirm its practical readiness for deployment, potentially revolutionizing large-scale screening programs in low-resource environments by overcoming current logistical challenges and facilitating rapid diagnostic assessment.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the NutriScreener system or the clinical study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pediatrics</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Nutrition</span>
                    
                    <span class="tag">Global Health</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">child malnutrition</span>
                    
                    <span class="tag tag-keyword">anthropometry</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">graph attention network</span>
                    
                    <span class="tag tag-keyword">computer vision</span>
                    
                    <span class="tag tag-keyword">retrieval-augmented</span>
                    
                    <span class="tag tag-keyword">low-resource settings</span>
                    
                    <span class="tag tag-keyword">early detection</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Child malnutrition remains a global crisis, yet existing screening methods are laborious and poorly scalable, hindering early intervention. In this work, we present NutriScreener, a retrieval-augmented, multi-pose graph attention network that combines CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to enable robust malnutrition detection and anthropometric prediction from children's images, simultaneously addressing generalizability and class imbalance. In a clinical study, doctors rated it 4.3/5 for accuracy and 4.6/5 for efficiency, confirming its deployment readiness in low-resource settings. Trained and tested on 2,141 children from AnthroVision and additionally evaluated on diverse cross-continent populations, including ARAN and an in-house collected CampusPose dataset, it achieves 0.79 recall, 0.82 AUC, and significantly lower anthropometric RMSEs, demonstrating reliable measurement in unconstrained pediatric settings. Cross-dataset results show up to 25% recall gain and up to 3.5 cm RMSE reduction using demographically matched knowledge bases. NutriScreener offers a scalable and accurate solution for early malnutrition detection in low-resource environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted in AAAI 2026 Special Track on AI for Social Impact</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>