<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening - Health AI Hub</title>
    <meta name="description" content="NutriScreener introduces a novel retrieval-augmented multi-pose graph attention network designed for robust child malnutrition detection and anthropometric pred">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>NutriScreener: Retrieval-Augmented Multi-Pose Graph Attention Network for Malnourishment Screening</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16566v1" target="_blank">2511.16566v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Misaal Khan, Mayank Vatsa, Kuldeep Singh, Richa Singh
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16566v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16566v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">NutriScreener introduces a novel retrieval-augmented multi-pose graph attention network designed for robust child malnutrition detection and anthropometric prediction from images. By integrating CLIP-based visual embeddings, knowledge retrieval, and context awareness, the system achieves high accuracy and scalability, addressing generalizability and class imbalance. Clinically validated and showing strong performance across diverse populations, it offers a promising solution for early intervention in low-resource settings.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a highly scalable, accurate, and efficient automated tool for early detection of child malnutrition and anthropometric assessment. This is critical for enabling timely medical and nutritional interventions, improving child health outcomes, and mitigating the global burden of malnutrition, especially in underserved populations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>NutriScreener is a medical AI application that utilizes computer vision (retrieval-augmented multi-pose graph attention network) to analyze images of children for the purpose of detecting malnutrition and predicting anthropometric measurements. This serves as an automated, scalable, and efficient screening tool for early diagnosis and intervention, particularly valuable in resource-limited healthcare settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the global crisis of child malnutrition by overcoming the limitations of laborious and poorly scalable existing screening methods.</li>
                    
                    <li>Presents NutriScreener, a novel retrieval-augmented multi-pose graph attention network architecture.</li>
                    
                    <li>Combines CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to enable robust malnutrition detection and anthropometric prediction.</li>
                    
                    <li>Demonstrated high clinical utility, with doctors rating it 4.3/5 for accuracy and 4.6/5 for efficiency, confirming deployment readiness in low-resource settings.</li>
                    
                    <li>Achieved strong quantitative performance: 0.79 recall and 0.82 AUC for malnutrition detection, and significantly lower anthropometric RMSEs.</li>
                    
                    <li>Trained and evaluated on large, diverse datasets including AnthroVision (2,141 children), ARAN, and CampusPose, showing reliable measurement in unconstrained pediatric settings.</li>
                    
                    <li>Showed further performance gains (up to 25% recall, 3.5 cm RMSE reduction) through the use of demographically matched knowledge bases.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>NutriScreener employs a retrieval-augmented multi-pose graph attention network. The system utilizes CLIP-based visual embeddings for feature extraction from children's images, integrates class-boosted knowledge retrieval to enhance decision-making, and incorporates context awareness to improve robustness. This architecture facilitates both the detection of malnutrition and the prediction of anthropometric measurements, specifically designed to address generalizability and class imbalance issues.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Clinical validation by doctors yielded high ratings: 4.3/5 for accuracy and 4.6/5 for efficiency. The system achieved 0.79 recall and 0.82 AUC for malnutrition detection, alongside significantly lower Root Mean Square Errors (RMSEs) for anthropometric predictions. Performance was reliable across diverse datasets and unconstrained pediatric settings. Furthermore, using demographically matched knowledge bases led to substantial improvements, with up to a 25% recall gain and up to a 3.5 cm reduction in anthropometric RMSEs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>NutriScreener offers a transformative solution for child malnutrition screening, enabling early and accurate detection through a scalable, automated method. Its deployment readiness in low-resource settings means it can significantly reduce the burden on healthcare professionals, improve access to screening, and facilitate timely interventions, thereby improving global child health and survival rates. The ability to predict anthropometric measurements from images can streamline clinical assessments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *existing* screening methods (laborious, poorly scalable) which NutriScreener aims to overcome, rather than stating specific limitations of NutriScreener itself. No explicit limitations of the proposed system are mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pediatrics</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Nutrition</span>
                    
                    <span class="tag">Global Health</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Child Malnutrition</span>
                    
                    <span class="tag tag-keyword">Anthropometric Prediction</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Graph Attention Network</span>
                    
                    <span class="tag tag-keyword">Retrieval-Augmented AI</span>
                    
                    <span class="tag tag-keyword">Low-Resource Settings</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                    <span class="tag tag-keyword">Digital Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Child malnutrition remains a global crisis, yet existing screening methods are laborious and poorly scalable, hindering early intervention. In this work, we present NutriScreener, a retrieval-augmented, multi-pose graph attention network that combines CLIP-based visual embeddings, class-boosted knowledge retrieval, and context awareness to enable robust malnutrition detection and anthropometric prediction from children's images, simultaneously addressing generalizability and class imbalance. In a clinical study, doctors rated it 4.3/5 for accuracy and 4.6/5 for efficiency, confirming its deployment readiness in low-resource settings. Trained and tested on 2,141 children from AnthroVision and additionally evaluated on diverse cross-continent populations, including ARAN and an in-house collected CampusPose dataset, it achieves 0.79 recall, 0.82 AUC, and significantly lower anthropometric RMSEs, demonstrating reliable measurement in unconstrained pediatric settings. Cross-dataset results show up to 25% recall gain and up to 3.5 cm RMSE reduction using demographically matched knowledge bases. NutriScreener offers a scalable and accurate solution for early malnutrition detection in low-resource environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted in AAAI 2026 Special Track on AI for Social Impact</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>