<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs - Health AI Hub</title>
    <meta name="description" content="This paper introduces FAITH, a novel framework that leverages medical knowledge graphs (KGs) for automated factuality assessment of large language model (LLM) r">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.12817v1" target="_blank">2511.12817v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-16
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shasha Zhou, Mingyu Huang, Jack Cole, Charles Britton, Ming Yin, Jan Wolber, Ke Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.12817v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.12817v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces FAITH, a novel framework that leverages medical knowledge graphs (KGs) for automated factuality assessment of large language model (LLM) responses in healthcare, addressing the critical need for rigorous verification in high-stakes medical settings. FAITH decomposes LLM responses into atomic claims, links them to a medical KG, and scores them based on evidence paths, demonstrating significantly higher correlations with clinician judgments, robustness to textual variance, and the ability to distinguish LLMs of varying capabilities. Its inherent explainability further aids in understanding and mitigating LLM limitations, positioning KGs as a prominent direction for reliable LLM deployment in medicine.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for safely integrating Large Language Models into healthcare by providing an automated, verifiable method to ensure the factual accuracy of their medical outputs. It directly addresses the risk of erroneous information in clinical contexts, which could lead to incorrect diagnoses, treatment plans, or patient harm.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Automated fact-checking and validation of Large Language Model (LLM) responses for safe and reliable deployment in healthcare settings, improving the trustworthiness of AI-driven medical information and tools.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical need for rigorous verification and validation of LLM responses before deployment in high-stakes healthcare environments due to potential harm.</li>
                    
                    <li>Proposes a novel approach using medical knowledge graphs (KGs) for automated factuality evaluation of LLM-generated medical responses.</li>
                    
                    <li>Introduces FAITH, a framework designed to systematically probe KG-based evaluation by decomposing LLM responses into atomic claims, linking them to a medical KG, and scoring based on evidence paths, notably operating without reference answers.</li>
                    
                    <li>Experimental results show that KG-grounded evaluation achieves considerably higher correlations with subjective clinician judgments regarding factuality compared to other evaluation methods.</li>
                    
                    <li>The FAITH framework effectively distinguishes LLMs with varying capabilities and demonstrates robustness to textual variances in their outputs.</li>
                    
                    <li>The inherent explainability of FAITH's scoring mechanism helps users understand the rationale behind factuality assessments and can aid in identifying and mitigating current LLM limitations.</li>
                    
                    <li>Concludes that leveraging KGs represents a prominent and viable direction for automated factuality assessment in healthcare, despite acknowledging existing limitations.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper introduces FAITH, a framework for automated factuality evaluation operating without reference answers. It functions by: 1) **Decomposing** LLM-generated responses into atomic claims. 2) **Linking** these claims to entities and relationships within a comprehensive medical knowledge graph (KG). 3) **Scoring** the claims based on the existence and structure of evidence paths found within the KG. Experiments involved applying FAITH to diverse medical tasks and validating its performance through comparison with human subjective evaluations provided by clinicians.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The KG-grounded evaluation achieved considerably higher correlations with clinician judgments regarding the factuality of LLM responses. The FAITH framework was effective at distinguishing LLMs with varying levels of accuracy and capabilities. Furthermore, the method proved robust to different textual phrasings and variances in LLM outputs. The inherent explainability of its scoring mechanism was identified as a significant benefit, aiding in user comprehension and mitigation of LLM limitations.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work has the potential to significantly enhance the safety and reliability of LLMs in healthcare by providing a scalable, automated mechanism for factual verification. It can prevent the dissemination of inaccurate medical information, thereby reducing clinical errors and improving patient outcomes. By offering explainable feedback, it can also foster greater trust among clinicians in AI tools and guide developers in building more robust and factually sound medical LLMs for applications ranging from clinical decision support to medical information synthesis.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract explicitly notes that "while limitations exist" for the proposed KG-based approach. Specific limitations are not detailed, but they could potentially include the completeness, currency, or granularity of the underlying medical knowledge graphs, challenges in accurately decomposing complex or ambiguous medical claims, or the computational cost associated with large-scale KG querying.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper concludes that leveraging knowledge graphs is a "prominent direction for automated factuality assessment in healthcare." This suggests future research will likely focus on addressing the identified limitations, potentially through developing more comprehensive and dynamic KGs, refining claim decomposition and linking algorithms, and exploring real-world clinical integration and scalability of the FAITH framework.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">General Medicine</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Medical Information Retrieval</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Automated Fact-Checking</span>
                    
                    <span class="tag tag-keyword">Medical LLMs</span>
                    
                    <span class="tag tag-keyword">Knowledge Graphs (KGs)</span>
                    
                    <span class="tag tag-keyword">Factuality Evaluation</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                    <span class="tag tag-keyword">Clinical Verification</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Explainable AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted as a conference paper at AAAI'26</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>