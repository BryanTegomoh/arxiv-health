<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images - Health AI Hub</title>
    <meta name="description" content="This paper introduces NuClass, a novel deep learning framework designed to overcome limitations in cell annotation from histopathology images by integrating mul">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.13586v1" target="_blank">2511.13586v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-17
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yinuo Xu, Yan Cui, Mingyao Li, Zhi Huang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.13586v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.13586v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces NuClass, a novel deep learning framework designed to overcome limitations in cell annotation from histopathology images by integrating multi-scale information. NuClass combines detailed nuclear morphology with broader microenvironmental context using an adaptive, uncertainty-aware fusion mechanism. Evaluated on a new, high-quality spatial transcriptomics-derived dataset, NuClass achieves significantly improved performance, enabling robust and interpretable cell-level phenotype prediction.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and fine-grained identification of cell types and subtypes in histopathology images is fundamental for advancing the computational understanding of human diseases, enabling more precise diagnoses, prognoses, and the development of targeted therapies.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development of a robust deep learning framework (NuClass) for automated, fine-grained cell annotation and phenotyping in histopathology images. This can assist pathologists in diagnosing diseases, understanding disease progression, identifying specific cell populations relevant to prognosis or treatment response, and potentially accelerating drug discovery and translational research by providing more accurate and detailed cellular insights from tissue samples.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing tile-based cell annotation models struggle to incorporate broader tissue context and are limited by coarse, unevenly distributed human annotations.</li>
                    
                    <li>NuClass is a pathologist-workflow-inspired framework for cell-wise multi-scale integration, combining a 'Path local' (224x224 pixel crops for nuclear morphology) and a 'Path global' (1024x1024 pixel neighborhood for microenvironmental context).</li>
                    
                    <li>A learnable gating module adaptively balances local detail and contextual cues, while an uncertainty-guided objective promotes complementary learning by directing the global path to focus on regions where the local path is uncertain.</li>
                    
                    <li>Interpretability is enhanced through the provision of calibrated confidence estimates and Grad-CAM visualizations.</li>
                    
                    <li>To address annotation scarcity, a novel marker-guided dataset was constructed from Xenium spatial transcriptomics, providing single-cell resolution labels for over two million cells across eight organs and 16 distinct classes.</li>
                    
                    <li>NuClass achieved up to 96% F1 score for its best-performing class when evaluated on three fully held-out cohorts, significantly outperforming strong baseline models.</li>
                    
                    <li>The findings demonstrate that multi-scale, uncertainty-aware fusion effectively bridges the gap between slide-level pathological foundation models and reliable, fine-grained cell-level phenotype prediction.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>NuClass employs a deep learning architecture with two main processing streams: 'Path local' for 224x224 pixel crops focusing on nuclear morphology, and 'Path global' for 1024x1024 pixel neighborhoods capturing microenvironmental context. These streams are integrated via a learnable gating module that adaptively weighs their contributions. An uncertainty-guided objective function is used to encourage complementary learning, prioritizing global context where local information is ambiguous. For interpretability, calibrated confidence estimates and Grad-CAM visualizations are generated. The model was trained and evaluated on a custom-built, marker-guided dataset derived from Xenium spatial transcriptomics, offering single-cell resolution labels for over two million cells across 8 organs and 16 classes.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>NuClass demonstrated superior performance in cell annotation, achieving an F1 score of up to 96% for its best-performing class. This result significantly surpassed strong baseline models when evaluated on three independent, fully held-out cohorts. The study concludes that multi-scale, uncertainty-aware fusion is a highly effective strategy for bridging the gap between high-level pathological models and precise, cell-level phenotype predictions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>NuClass offers a robust and interpretable tool for precise cell type and subtype identification in clinical histopathology. This can lead to more accurate and standardized diagnoses, deeper insights into disease mechanisms (e.g., tumor microenvironment characterization), and the identification of new biomarkers or therapeutic targets. Its ability to provide reliable, cell-level phenotype predictions could directly inform personalized medicine approaches and improve patient management.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights the limitations of existing methods, specifically their inability to incorporate broader tissue context and the scarcity of high-quality, fine-grained, subtype-level human annotations. NuClass directly addresses these challenges, but the abstract does not explicitly state limitations *of the NuClass framework itself*.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work implies a future direction where the robust cell-level phenotype predictions achieved by NuClass can be integrated with or leveraged by slide-level pathological foundation models. This would allow for a more comprehensive and granular understanding of whole slide images, potentially leading to more advanced computational pathology applications and a deeper computational understanding of disease.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Immunology</span>
                    
                    <span class="tag">Histology</span>
                    
                    <span class="tag">Diagnostic Medicine</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Cell Annotation</span>
                    
                    <span class="tag tag-keyword">Multi-scale Integration</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Spatial Transcriptomics</span>
                    
                    <span class="tag tag-keyword">Nuclear Morphology</span>
                    
                    <span class="tag tag-keyword">Microenvironment</span>
                    
                    <span class="tag tag-keyword">Uncertainty-aware Fusion</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>