<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Relational Graph Perceiver (RGP), a novel graph transformer architecture designed to effectively integrate long-range temporal and str">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.04557v1" target="_blank">2511.04557v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Divyansha Lachi, Mahmoud Mohammadi, Joe Meyer, Vinam Arora, Tom Palczewski, Eva L. Dyer
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.04557v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.04557v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Relational Graph Perceiver (RGP), a novel graph transformer architecture designed to effectively integrate long-range temporal and structural dependencies in complex relational data, particularly in domains like healthcare. RGP employs a temporal subgraph sampler and a cross-attention-based latent bottleneck to build global context across diverse entities, alongside a flexible decoder for multi-task learning. It achieves state-of-the-art performance on various benchmarks, offering a general and scalable solution for relational deep learning with diverse predictive tasks.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>In healthcare, patient-provider interactions and the evolution of patient conditions are inherently temporal and relational. This model is crucial for better understanding disease progression, predicting clinical outcomes, and optimizing interventions by integrating complex, time-dependent data from diverse sources like electronic health records, which existing models struggle with.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The Relational Graph Perceiver (RGP), a graph transformer architecture, can be applied in healthcare to model and predict outcomes from complex, time-evolving relational data such as patient-provider interactions. This includes tasks like predicting disease progression, identifying at-risk patients, optimizing treatment pathways, analyzing healthcare resource utilization based on patient flow and interactions, and supporting multi-task predictions for various clinical or operational outcomes within healthcare systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical gaps in existing graph models which primarily focus on spatial structure, treat temporal information merely as a filtering constraint, and are typically designed for single-task prediction.</li>
                    
                    <li>Proposes a novel temporal subgraph sampler that enhances global context by retrieving nodes beyond the immediate neighborhood to capture long-range, temporally relevant relationships.</li>
                    
                    <li>Introduces the Relational Graph Perceiver (RGP), a graph transformer architecture specifically designed for relational deep learning.</li>
                    
                    <li>RGP leverages a cross-attention-based latent bottleneck to efficiently integrate information from both structural and temporal contexts, consolidating signals from different node and edge types into a common latent space for global context building.</li>
                    
                    <li>Incorporates a flexible cross-attention decoder that supports joint learning across multiple predictive tasks, even with disjoint label spaces, within a single model.</li>
                    
                    <li>Delivers state-of-the-art performance across established benchmarks including RelBench, SALT, and CTU datasets.</li>
                    
                    <li>Offers a general, scalable, and multi-task capable solution for complex relational deep learning problems in domains like healthcare, finance, and e-commerce.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves two main components: first, a temporal subgraph sampler that extends context retrieval beyond immediate node neighborhoods to capture temporally relevant long-range relationships. Second, the Relational Graph Perceiver (RGP) architecture, a graph transformer that utilizes a cross-attention-based latent bottleneck to efficiently integrate diverse structural and temporal contexts and consolidate signals from various node and edge types into a shared latent space. RGP also features a flexible cross-attention decoder that enables joint learning across multiple predictive tasks, even when they have disjoint label spaces.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The Relational Graph Perceiver (RGP) achieves state-of-the-art performance across multiple benchmarks, including RelBench, SALT, and CTU. This demonstrates its superior ability to effectively integrate complex temporal and structural information for diverse predictive tasks, offering a general and scalable framework for relational deep learning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to significantly enhance the accuracy and comprehensiveness of predictive models in clinical settings. By effectively leveraging the rich, temporal, and relational data embedded in Electronic Health Records (EHRs), RGP could enable more precise disease progression modeling, earlier identification of patients at risk for adverse events, and better-informed, personalized treatment recommendations. Its multi-task learning capability could also streamline the development of comprehensive clinical decision support systems that can simultaneously address various prediction needs within a single model.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly detailed in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly detailed in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Decision Support Systems</span>
                    
                    <span class="tag">Electronic Health Record (EHR) Analysis</span>
                    
                    <span class="tag">Predictive Analytics in Healthcare</span>
                    
                    <span class="tag">Patient Trajectory Modeling</span>
                    
                    <span class="tag">Personalized Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Graph Transformers</span>
                    
                    <span class="tag tag-keyword">Relational Deep Learning</span>
                    
                    <span class="tag tag-keyword">Temporal Graphs</span>
                    
                    <span class="tag tag-keyword">Multi-task Learning</span>
                    
                    <span class="tag tag-keyword">Latent Bottleneck</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                    <span class="tag tag-keyword">Graph Neural Networks</span>
                    
                    <span class="tag tag-keyword">State-of-the-art</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">In domains such as healthcare, finance, and e-commerce, the temporal dynamics
of relational data emerge from complex interactions-such as those between
patients and providers, or users and products across diverse categories. To be
broadly useful, models operating on these data must integrate long-range
spatial and temporal dependencies across diverse types of entities, while also
supporting multiple predictive tasks. However, existing graph models for
relational data primarily focus on spatial structure, treating temporal
information merely as a filtering constraint to exclude future events rather
than a modeling signal, and are typically designed for single-task prediction.
To address these gaps, we introduce a temporal subgraph sampler that enhances
global context by retrieving nodes beyond the immediate neighborhood to capture
temporally relevant relationships. In addition, we propose the Relational Graph
Perceiver (RGP), a graph transformer architecture for relational deep learning
that leverages a cross-attention-based latent bottleneck to efficiently
integrate information from both structural and temporal contexts. This latent
bottleneck integrates signals from different node and edge types into a common
latent space, enabling the model to build global context across the entire
relational system. RGP also incorporates a flexible cross-attention decoder
that supports joint learning across tasks with disjoint label spaces within a
single model. Experiments on RelBench, SALT, and CTU show that RGP delivers
state-of-the-art performance, offering a general and scalable solution for
relational deep learning with support for diverse predictive tasks.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>