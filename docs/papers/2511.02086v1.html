<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Markerless Augmented Reality Registration for Surgical Guidance: A Multi-Anatomy Clinical Accuracy Study - Health AI Hub</title>
    <meta name="description" content="This paper develops and clinically evaluates a novel depth-only, markerless augmented reality (AR) registration pipeline using a head-mounted display (HMD) for ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Markerless Augmented Reality Registration for Surgical Guidance: A Multi-Anatomy Clinical Accuracy Study</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.02086v1" target="_blank">2511.02086v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yue Yang, Fabian Necker, Christoph Leuze, Michelle Chen, Andrey Finegersh, Jake Lee, Vasu Divi, Bruce Daniel, Brian Hargreaves, Jie Ying Wu, Fred M Baik
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.02086v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.02086v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper develops and clinically evaluates a novel depth-only, markerless augmented reality (AR) registration pipeline using a head-mounted display (HMD) for surgical guidance on small or low-curvature anatomies. The system achieved a median intraoperative registration error of approximately 3-4 mm across feet, ear, and lower leg, approaching typical clinical thresholds for moderate-risk surgical tasks without the need for fiducials.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research provides a significant step towards practical, non-invasive surgical guidance by enabling accurate AR registration without cumbersome fiducial markers, potentially simplifying surgical workflows and improving precision in complex reconstructive procedures.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes an Augmented Reality (AR) registration pipeline for surgical guidance. This system leverages computer vision techniques (e.g., depth-only markerless registration, 3D model alignment using global and local registration) to accurately overlay virtual anatomical data onto a patient's real anatomy in real-time. While 'AI' is not explicitly mentioned, these advanced computer vision and registration algorithms often incorporate or are foundational to AI/machine learning methods for robust performance in complex clinical environments, qualifying it as a medical AI application focused on enhancing surgical precision and navigation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A depth-only, markerless AR registration pipeline was developed for HoloLens 2, aligning AHAT depth data to CT-derived skin meshes through depth-bias correction, human-in-the-loop initialization, and global/local registration.</li>
                    
                    <li>Preclinical validation using AR-tracked tools on leg and foot models demonstrated high accuracy, with median absolute differences of 0.78 mm (leg) and 0.80 mm (feet) between AR-traced and CT ground truth distances.</li>
                    
                    <li>Clinical accuracy was assessed in seven intraoperative trials (feet, ear, lower leg) during fibula free-flap harvest and mandibular reconstruction surgeries, collecting over 500 data points per trial.</li>
                    
                    <li>The overall clinical per-point error had a median of 3.9 mm, with anatomy-specific medians of 3.2 mm (feet), 4.3 mm (ear), and 5.3 mm (lower leg).</li>
                    
                    <li>Error coverage within 5 mm was high: 92-95% for feet, 84-90% for ear, and 72-86% for the lower leg. Accuracy on feet was significantly better than the lower leg (Delta median ~1.1 mm; p < 0.001).</li>
                    
                    <li>The inclusion of human-guided initialization combined with global-to-local registration proved crucial for achieving accurate alignment on anatomies with limited curvature or small size.</li>
                    
                    <li>The achieved accuracy of approximately 3-4 mm median error suggests the system's clinical readiness for moderate-risk surgical tasks, offering a fiducial-less alternative to existing guidance systems.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized a HoloLens 2 HMD to develop a depth-only, markerless AR registration pipeline. This pipeline aligned AHAT (Articulated HAnd Tracking) depth data with CT-derived skin meshes via sequential steps: depth-bias correction, a brief human-in-the-loop initialization, followed by global and local registration. Preclinical validation involved comparing AR-traced "skin-to-bone" distances to CT ground truth on leg and foot models. Clinical validation included seven intraoperative trials across different anatomies (feet, ear, lower leg) during fibula free-flap harvest and mandibular reconstruction surgeries, collecting extensive per-point error data.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Preclinical validation demonstrated sub-millimeter accuracy (median |Delta d| 0.78-0.80 mm, RMSE 0.97-1.20 mm). Clinically, the overall median per-point registration error was 3.9 mm. Anatomy-specific median errors were 3.2 mm for feet, 4.3 mm for the ear, and 5.3 mm for the lower leg. The system achieved a 5 mm error coverage ranging from 72% to 95%, depending on the anatomy. Accuracy was significantly better for feet compared to the lower leg (p < 0.001).</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This markerless AR registration system offers a highly practical solution for surgical guidance, eliminating the need for fiducials and thereby reducing pre-operative preparation time and potential patient discomfort. Its ~3-4 mm median accuracy, particularly in live surgical settings, is clinically acceptable for moderate-risk procedures, enhancing precision in reconstructive surgeries like fibula free-flap and mandibular reconstruction, and potentially broadening the application of AR in surgery.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While achieving significant accuracy for moderate-risk tasks, the system's median error (up to 5.3 mm for the lower leg) might not meet the stringent sub-millimeter requirements for all high-precision surgical interventions. The pipeline requires brief human-in-the-loop initialization, indicating it is not fully autonomous. The study focused on small or low-curvature anatomies; performance on larger or more complex anatomical structures is not detailed.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The conclusion of "improving the clinical readiness of markerless AR guidance" suggests future work could focus on further enhancing accuracy to meet higher precision demands, expanding validation to a wider range of anatomies and surgical procedures, and optimizing the human-in-the-loop initialization to further streamline the surgical workflow.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Plastic and Reconstructive Surgery</span>
                    
                    <span class="tag">Maxillofacial Surgery</span>
                    
                    <span class="tag">Orthopedic Surgery</span>
                    
                    <span class="tag">Otolaryngology (ENT)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Augmented Reality</span>
                    
                    <span class="tag tag-keyword">Surgical Guidance</span>
                    
                    <span class="tag tag-keyword">Markerless Registration</span>
                    
                    <span class="tag tag-keyword">HoloLens 2</span>
                    
                    <span class="tag tag-keyword">Depth Sensing</span>
                    
                    <span class="tag tag-keyword">Clinical Accuracy</span>
                    
                    <span class="tag tag-keyword">Fibula Free-Flap</span>
                    
                    <span class="tag tag-keyword">Mandibular Reconstruction</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Purpose: In this paper, we develop and clinically evaluate a depth-only,
markerless augmented reality (AR) registration pipeline on a head-mounted
display, and assess accuracy across small or low-curvature anatomies in
real-life operative settings. Methods: On HoloLens 2, we align Articulated HAnd
Tracking (AHAT) depth to Computed Tomography (CT)-derived skin meshes via (i)
depth-bias correction, (ii) brief human-in-the-loop initialization, (iii)
global and local registration. We validated the surface-tracing error metric by
comparing "skin-to-bone" relative distances to CT ground truth on leg and foot
models, using an AR-tracked tool. We then performed seven intraoperative target
trials (feet x2, ear x3, leg x2) during the initial stage of fibula free-flap
harvest and mandibular reconstruction surgery, and collected 500+ data per
trial. Results: Preclinical validation showed tight agreement between AR-traced
and CT distances (leg: median |Delta d| 0.78 mm, RMSE 0.97 mm; feet: 0.80 mm,
1.20 mm). Clinically, per-point error had a median of 3.9 mm. Median errors by
anatomy were 3.2 mm (feet), 4.3 mm (ear), and 5.3 mm (lower leg), with 5 mm
coverage 92-95%, 84-90%, and 72-86%, respectively. Feet vs. lower leg differed
significantly (Delta median ~1.1 mm; p < 0.001). Conclusion: A depth-only,
markerless AR pipeline on HMDs achieved ~3-4 mm median error across feet, ear,
and lower leg in live surgical settings without fiducials, approaching typical
clinical error thresholds for moderate-risk tasks. Human-guided initialization
plus global-to-local registration enabled accurate alignment on small or
low-curvature targets, improving the clinical readiness of markerless AR
guidance.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>