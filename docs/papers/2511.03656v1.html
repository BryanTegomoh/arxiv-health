<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation - Health AI Hub</title>
    <meta name="description" content="ChiMDQA introduces a novel Chinese Multi-Document Question Answering Dataset designed for various downstream NLP applications, encompassing six diverse domains ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03656v1" target="_blank">2511.03656v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">ChiMDQA introduces a novel Chinese Multi-Document Question Answering Dataset designed for various downstream NLP applications, encompassing six diverse domains including medical treatment. This dataset features 6,068 rigorously curated, high-quality QA pairs derived from long-form documents, further classified into ten fine-grained categories. It aims to provide a robust foundation for advancing Chinese QA, document comprehension, and knowledge extraction systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This dataset directly addresses the critical need for high-quality Chinese QA data in the medical domain, enabling the development of advanced NLP models capable of understanding and extracting complex information from medical texts. It is instrumental for building intelligent systems that can process and answer queries based on Chinese medical literature and clinical notes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The ChiMDQA dataset, specifically designed to include medical treatment documents, provides a crucial resource for developing and evaluating advanced Chinese natural language processing models in healthcare. These models can power AI applications such as intelligent question-answering systems for clinicians (e.g., retrieving information from medical guidelines or patient records), automated knowledge extraction from medical literature, enhancing medical education, and improving patient understanding of their conditions or treatment plans through conversational AI.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Presentation of ChiMDQA, a new Chinese Multi-Document Question Answering Dataset tailored for business scenarios.</li>
                    
                    <li>The dataset spans six prevalent domains: academic, education, finance, law, medical treatment, and news, ensuring broad applicability.</li>
                    
                    <li>Comprises 6,068 high-quality question-answer (QA) pairs meticulously curated from long-form documents.</li>
                    
                    <li>QA pairs are categorized into ten fine-grained types, facilitating comprehensive evaluation of NLP models.</li>
                    
                    <li>Construction involved meticulous document screening and a systematic question-design methodology to guarantee diversity and quality.</li>
                    
                    <li>Applicable to critical NLP tasks such as document comprehension, knowledge extraction, and intelligent QA system development.</li>
                    
                    <li>Offers a foundational resource for future research and practical applications in Chinese natural language processing, particularly in QA.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The ChiMDQA dataset was constructed through a rigorous process involving meticulous document screening to select long-form content from six distinct domains. A systematic question-design methodology was then employed to create 6,068 high-quality question-answer pairs, which were subsequently classified into ten fine-grained categories to enable detailed evaluation of NLP systems.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful creation and robust characteristics of the ChiMDQA dataset: a high-quality, multi-domain Chinese Multi-Document QA resource. It features 6,068 question-answer pairs derived from long-form documents, explicitly includes a medical treatment domain, and incorporates a fine-grained evaluation system, establishing a new benchmark for Chinese QA research.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This dataset can significantly enhance the development of intelligent QA systems for clinical use, allowing healthcare professionals to quickly retrieve precise information from vast amounts of Chinese medical literature, patient records, or clinical guidelines. It can support decision-making, improve diagnostic accuracy, facilitate medical education, and streamline knowledge extraction for research purposes, ultimately improving patient care efficiency and quality.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the ChiMDQA dataset itself. However, common implicit limitations for such new resources may include the scale of the dataset relative to the immense volume of real-world medical data, potential biases inherent in the document selection or question generation process, and the ongoing challenge of achieving perfect semantic understanding in complex Chinese medical texts.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The ChiMDQA dataset is intended to serve as a substantial foundation for future research in Chinese QA, specifically encouraging advancements in document comprehension, knowledge extraction techniques, and the development of more sophisticated intelligent QA systems. It also paves the way for practical applications across various industries, with significant potential in the medical treatment sector.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Treatment</span>
                    
                    <span class="tag">Healthcare Informatics</span>
                    
                    <span class="tag">Clinical Natural Language Processing</span>
                    
                    <span class="tag">Medical Knowledge Management</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Chinese NLP</span>
                    
                    <span class="tag tag-keyword">Question Answering</span>
                    
                    <span class="tag tag-keyword">Multi-Document QA</span>
                    
                    <span class="tag tag-keyword">Medical Treatment</span>
                    
                    <span class="tag tag-keyword">Document Comprehension</span>
                    
                    <span class="tag tag-keyword">Knowledge Extraction</span>
                    
                    <span class="tag tag-keyword">Fine-grained Evaluation</span>
                    
                    <span class="tag tag-keyword">Dataset</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>13 pages, 6 tables, 4 figures, accepted by ICANN 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>