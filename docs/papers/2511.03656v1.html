<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation - Health AI Hub</title>
    <meta name="description" content="This paper introduces ChiMDQA, a novel Chinese Multi-Document Question Answering Dataset comprising 6,068 rigorously curated, high-quality QA pairs across six p">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03656v1" target="_blank">2511.03656v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ChiMDQA, a novel Chinese Multi-Document Question Answering Dataset comprising 6,068 rigorously curated, high-quality QA pairs across six prevalent domains, including medical treatment. Designed with a fine-grained evaluation system and systematic construction, the dataset aims to support advanced NLP tasks like document comprehension and knowledge extraction, laying a crucial foundation for future Chinese QA research and practical applications.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>The ChiMDQA dataset includes 'medical treatment' as a core domain, making it highly relevant for advancing NLP capabilities in Chinese healthcare. It provides a vital resource for training and evaluating models designed to understand and answer questions from complex medical texts in Chinese.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The ChiMDQA dataset can be used to train and evaluate AI models for developing intelligent question-answering systems specifically for the medical treatment domain in Chinese. This could include applications like assisting healthcare professionals in retrieving information from medical literature or patient records, answering patient queries based on medical documents, or extracting structured knowledge from clinical notes and research papers for various healthcare applications.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Introduction of ChiMDQA**: Presents a new Chinese Multi-Document Question Answering Dataset to meet the increasing demand for high-quality Chinese QA resources.</li>
                    
                    <li>**Multi-domain Coverage**: Encompasses long-form documents from six distinct fields: academic, education, finance, law, medical treatment, and news, providing broad applicability.</li>
                    
                    <li>**Scale and Quality**: Contains 6,068 meticulously curated, high-quality question-answer (QA) pairs, ensuring reliability for downstream tasks.</li>
                    
                    <li>**Fine-grained Evaluation System**: QA pairs are categorized into ten fine-grained types, enabling more nuanced and comprehensive model evaluation.</li>
                    
                    <li>**Robust Construction Methodology**: Dataset quality and diversity are guaranteed through meticulous document screening and a systematic question-design approach.</li>
                    
                    <li>**Broad NLP Applicability**: Designed to be applicable to various Natural Language Processing tasks, including document comprehension, knowledge extraction, and the development of intelligent QA systems.</li>
                    
                    <li>**Foundation for Future Research**: Aims to provide a substantial foundation for future research and practical applications in Chinese Question Answering across its diverse domains.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The ChiMDQA dataset was constructed through a methodology centered on meticulous document screening from six distinct fields and a systematic question-design process. This approach focused on curating 6,068 high-quality question-answer pairs, which were then classified into ten fine-grained categories, ensuring both diversity and quality for various NLP tasks.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful creation and detailed characterization of the ChiMDQA dataset. This includes its comprehensive coverage across six critical domains (notably medical treatment), its substantial size of 6,068 rigorously curated QA pairs, the implementation of a fine-grained evaluation system with ten categories, and a robust construction methodology that guarantees data quality and diversity for advanced Chinese NLP applications.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The direct inclusion of a 'medical treatment' domain within ChiMDQA offers significant potential clinical and practical impact. It can drive the development of more accurate and intelligent Chinese medical question-answering systems, which could aid clinicians in information retrieval, support clinical decision-making, enhance patient education, and facilitate automated knowledge extraction from vast amounts of Chinese medical literature and electronic health records.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the ChiMDQA dataset or the methodologies employed in its construction. It primarily focuses on the dataset's strengths and comprehensive nature.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper positions ChiMDQA as a 'substantial foundation for future research and practical applications in Chinese QA,' specifically mentioning its utility for tasks such as document comprehension, knowledge extraction, and the development of intelligent QA systems across its diverse domains, including medical treatment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Treatment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Chinese NLP</span>
                    
                    <span class="tag tag-keyword">Question Answering</span>
                    
                    <span class="tag tag-keyword">Multi-Document QA</span>
                    
                    <span class="tag tag-keyword">Dataset</span>
                    
                    <span class="tag tag-keyword">Medical Treatment</span>
                    
                    <span class="tag tag-keyword">Knowledge Extraction</span>
                    
                    <span class="tag tag-keyword">Document Comprehension</span>
                    
                    <span class="tag tag-keyword">Fine-grained Evaluation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>13 pages, 6 tables, 4 figures, accepted by ICANN 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>