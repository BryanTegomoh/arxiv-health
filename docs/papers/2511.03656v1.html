<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation - Health AI Hub</title>
    <meta name="description" content="This paper introduces ChiMDQA, a novel Chinese Multi-Document Question Answering Dataset designed to meet the growing demand for high-quality NLP resources in v">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03656v1" target="_blank">2511.03656v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jing Gao, Shutiao Luo, Yumeng Liu, Yuanming Li, Hongji Zeng
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03656v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03656v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ChiMDQA, a novel Chinese Multi-Document Question Answering Dataset designed to meet the growing demand for high-quality NLP resources in various domains, including medical treatment. It comprises 6,068 rigorously curated QA pairs from long-form documents across six distinct fields, categorized into ten fine-grained types, serving as a robust foundation for document comprehension, knowledge extraction, and intelligent QA system development.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>ChiMDQA explicitly includes 'medical treatment' as one of its core domains, making it highly relevant for training and evaluating natural language processing models on complex Chinese medical texts. This resource can significantly advance the ability of AI systems to understand and answer questions in the healthcare sector, which is critical for supporting medical professionals and informing patients.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The ChiMDQA dataset can be utilized to train and evaluate AI models for intelligent question-answering systems, document comprehension, and knowledge extraction within the medical treatment domain. This could lead to applications such as AI-powered diagnostic support tools, medical information retrieval systems for professionals or patients, medical education platforms, or automated analysis of medical literature in Chinese.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Dataset Introduction**: Presents ChiMDQA, a new Chinese Multi-Document Question Answering Dataset addressing the lack of high-quality Chinese QA resources.</li>
                    
                    <li>**Multi-Domain Focus**: Specifically designed for prevalent business scenarios across six distinct domains: academic, education, finance, law, medical treatment, and news.</li>
                    
                    <li>**Comprehensive Scale**: Contains 6,068 rigorously curated, high-quality question-answer (QA) pairs sourced from long-form documents.</li>
                    
                    <li>**Fine-grained Categorization**: QA pairs are further classified into ten fine-grained categories, enabling more nuanced evaluation and model training.</li>
                    
                    <li>**Rigorous Construction**: Dataset quality and diversity are ensured through meticulous document screening and a systematic question-design methodology.</li>
                    
                    <li>**Broad Applicability**: Applicable to various NLP tasks, including document comprehension, knowledge extraction, and the development of intelligent QA systems.</li>
                    
                    <li>**Foundation for Future Research**: Offers a substantial foundation for future research and practical applications in Chinese Question Answering, with code and data publicly available.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The ChiMDQA dataset was constructed through a process involving meticulous document screening to select long-form documents from six distinct domains. A systematic question-design methodology was then applied to create 6,068 high-quality question-answer pairs. These QA pairs were subsequently classified into ten fine-grained categories to ensure diversity and applicability for various NLP tasks.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful creation and characterization of ChiMDQA, a novel, large-scale, and high-quality Chinese Multi-Document QA dataset. This dataset features 6,068 QA pairs, covers six diverse domains including medical treatment, and incorporates a ten-category fine-grained evaluation system, setting a new standard for Chinese NLP resources.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This dataset can significantly impact clinical practice by enabling the development of more accurate and robust intelligent QA systems for Chinese medical information. Such systems could assist healthcare professionals in quickly extracting critical information from medical records, research papers, or clinical guidelines, thereby improving diagnostic accuracy, treatment planning, and overall efficiency. It could also empower patients by providing more accessible and understandable answers to their health-related questions in Chinese.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the ChiMDQA dataset or the construction methodology. Further details on data coverage, potential biases, or specific challenges encountered during curation would likely be found in the full paper.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The dataset is presented as a substantial foundation for future research and practical applications in Chinese QA. This implies future work will involve training and evaluating advanced NLP models (e.g., large language models) on ChiMDQA, exploring its utility in specific domain applications (like medical information extraction), and potentially expanding the dataset or refining its fine-grained evaluation system.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Treatment</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Medical Education</span>
                    
                    <span class="tag">Patient Information Systems</span>
                    
                    <span class="tag">Medical Literature Review</span>
                    
                    <span class="tag">Health Information Retrieval</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Chinese NLP</span>
                    
                    <span class="tag tag-keyword">QA Dataset</span>
                    
                    <span class="tag tag-keyword">Multi-Document QA</span>
                    
                    <span class="tag tag-keyword">Medical Treatment</span>
                    
                    <span class="tag tag-keyword">Knowledge Extraction</span>
                    
                    <span class="tag tag-keyword">Fine-grained Evaluation</span>
                    
                    <span class="tag tag-keyword">Document Comprehension</span>
                    
                    <span class="tag tag-keyword">Chinese Healthcare AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>13 pages, 6 tables, 4 figures, accepted by ICANN 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>