<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives - Health AI Hub</title>
    <meta name="description" content="This study directly compared state-of-the-art Large Language Models (LLMs), specifically Gemini Pro, against mental health professionals in diagnosing Borderlin">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.20298v1" target="_blank">2512.20298v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Karolina Dro≈ºd≈º, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI, cs.CY, cs.HC
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.20298v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.20298v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study directly compared state-of-the-art Large Language Models (LLMs), specifically Gemini Pro, against mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders using Polish first-person narratives. While LLMs demonstrated higher overall diagnostic accuracy and proficiency in identifying BPD, they severely underdiagnosed NPD, highlighting significant reliability and bias issues despite their competence in interpreting complex qualitative clinical data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for understanding the capabilities and limitations of AI in psychiatric diagnosis and self-assessment, directly informing the safe and ethical integration of LLMs into mental healthcare. It highlights the potential for diagnostic inaccuracies and biases, particularly concerning specific personality disorders, which can have significant consequences for patient care and therapeutic approaches.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research evaluates Large Language Models (LLMs) for their capability to assist in or perform psychiatric diagnosis of personality disorders (BPD, NPD) by interpreting complex, first-person patient narratives. It compares LLM performance against human mental health professionals, identifying both the strengths and critical limitations (e.g., bias, underdiagnosis) of AI in a diagnostic clinical context. This has direct implications for developing AI tools for psychiatric assessment, self-assessment, or as diagnostic aids for clinicians.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study represents the first direct comparison of LLMs (Gemini Pro) against human mental health professionals for diagnosing BPD and NPD.</li>
                    
                    <li>Diagnostic data consisted of Polish-language first-person autobiographical accounts from patients.</li>
                    
                    <li>Gemini Pro models achieved a significantly higher overall diagnostic accuracy (65.48%) compared to human professionals (43.57%).</li>
                    
                    <li>Both LLMs (F1=83.4) and human experts (F1=80.0) demonstrated high efficacy in diagnosing Borderline Personality Disorder (BPD).</li>
                    
                    <li>LLMs severely underdiagnosed Narcissistic Personality Disorder (NPD) (F1=6.7) compared to human experts (F1=50.0), attributed to a reluctance towards the 'value-laden term "narcissism"'.</li>
                    
                    <li>Qualitatively, LLMs provided confident, elaborate justifications focused on patterns and formal categories, while human experts were more concise and cautious, emphasizing the patient's sense of self and temporal experience.</li>
                    
                    <li>The findings indicate LLMs are competent at interpreting complex clinical data but are subject to critical reliability and bias issues, particularly with emotionally charged or socially stigmatized diagnoses.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed a direct comparative evaluation between state-of-the-art Large Language Models (Gemini Pro) and human mental health professionals. The task involved diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders using a dataset of Polish-language first-person autobiographical patient narratives. Performance was quantitatively assessed via overall diagnostic accuracy and F1-scores for individual disorders, complemented by a qualitative analysis of the diagnostic justifications provided by both LLMs and humans.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Gemini Pro LLMs surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). Both LLMs (F1=83.4) and human experts (F1=80.0) excelled at identifying BPD. However, LLMs severely underdiagnosed NPD (F1=6.7) compared to human experts (F1=50.0), attributed to a reluctance towards the 'value-laden term "narcissism"'. Qualitatively, LLMs offered confident, elaborate, pattern- and category-focused justifications, contrasting with human experts' concise, cautious, patient-centric reasoning emphasizing self and temporal experience.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While LLMs demonstrate potential for enhancing diagnostic accuracy in mental health, their identified biases, especially with diagnoses like NPD, pose significant clinical risks. Integrating LLMs into psychiatric assessment requires robust bias mitigation strategies and human oversight to prevent misdiagnosis, ensure ethical care, and avoid perpetuating stigma. The findings suggest that LLMs should not be universally trusted for all psychiatric conditions without specific, nuanced validation for each.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The primary limitations noted are the 'critical reliability and bias issues' of LLMs, specifically their severe underdiagnosis of Narcissistic Personality Disorder (NPD). This underdiagnosis is linked to a potential 'reluctance toward the value-laden term "narcissism"', indicating a susceptibility to social biases or ethical constraints programmed into the models.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research should focus on developing strategies to mitigate biases in LLMs, particularly when dealing with value-laden or stigmatized psychiatric diagnostic terms, to improve their reliability and ethical deployment. Further investigation into how LLMs' 'pattern-focused' reasoning can be integrated with or complement human experts' 'patient's sense of self and temporal experience' reasoning could lead to more holistic AI-assisted diagnostic tools.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Clinical Psychology</span>
                    
                    <span class="tag">Mental Health</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Computational Psychiatry</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">Personality Disorders</span>
                    
                    <span class="tag tag-keyword">Psychiatric Diagnosis</span>
                    
                    <span class="tag tag-keyword">Borderline Personality Disorder</span>
                    
                    <span class="tag tag-keyword">Narcissistic Personality Disorder</span>
                    
                    <span class="tag tag-keyword">Artificial Intelligence</span>
                    
                    <span class="tag tag-keyword">Bias</span>
                    
                    <span class="tag tag-keyword">Mental Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term "narcissism." Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>