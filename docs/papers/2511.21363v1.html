<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Directed Prediction Change (DPC) metric, a novel approach for efficiently and deterministically assessing the fidelity of local featur">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.21363v1" target="_blank">2511.21363v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-26
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kevin Iselborn, David Dembinsky, Adriano Lucieri, Andreas Dengel
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.21363v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.21363v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Directed Prediction Change (DPC) metric, a novel approach for efficiently and deterministically assessing the fidelity of local feature attribution methods to their underlying machine learning models. DPC modifies the existing Prediction Change metric by incorporating the direction of both perturbation and attribution, achieving an almost tenfold speedup and eliminating randomness compared to Monte Carlo-based metrics like local Infidelity, while measuring the same property.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>In high-stakes medical settings, faithful and trustworthy AI explanations are critical for clinical decision-making and regulatory approval. DPC provides a faster, deterministic, and reliable method to assess whether an explanation truly reflects an AI model's internal decision process, which is essential for ensuring patient safety and building trust in AI-powered healthcare tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research directly contributes to Explainable AI (XAI) in health. It proposes a more efficient and trustworthy method for evaluating the fidelity of explanations generated by AI models, which is crucial for applications such as medical diagnostics (e.g., skin lesion analysis). This allows clinicians and regulators to better understand and trust how AI models arrive at their predictions, facilitating responsible deployment of AI in high-stakes healthcare environments.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing fidelity metrics, such as Infidelity, rely on computationally intensive Monte Carlo approximation and introduce uncertainty through random sampling.</li>
                    
                    <li>The proposed Directed Prediction Change (DPC) metric is a modification of the Prediction Change (PC) metric, specifically within the Guided Perturbation Experiment framework.</li>
                    
                    <li>DPC incorporates the explicit direction of both the applied feature perturbation and the feature attribution itself, allowing for deterministic computation.</li>
                    
                    <li>This directional approach leads to an almost tenfold speedup in fidelity assessment and completely eliminates the randomness associated with Monte Carlo methods.</li>
                    
                    <li>DPC provides a deterministic, trustworthy, and reproducible evaluation procedure that measures the same critical fidelity property as local Infidelity.</li>
                    
                    <li>The metric was rigorously evaluated across 4,744 distinct explanations, using two datasets (skin lesion images and financial tabular data), two black-box models, and seven different explanation algorithms with varying hyperparameters.</li>
                    
                    <li>The results demonstrate that DPC, in conjunction with PC, enables a holistic, computationally efficient, and reliable evaluation of both baseline-oriented and local feature attribution methods.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper proposes the Directed Prediction Change (DPC) metric by modifying the Prediction Change (PC) metric within the Guided Perturbation Experiment. This modification involves explicitly incorporating the direction of the perturbation applied to input features and the direction of the feature attribution itself. This directional guidance allows DPC to be computed deterministically, avoiding the need for Monte Carlo approximations. The method's effectiveness was validated by applying it to explanations from seven different algorithms, evaluated on two black-box models using a skin lesion image dataset and a financial tabular dataset, across a wide range of hyperparameters.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The DPC metric achieves an almost tenfold speedup in assessing the fidelity of local feature attribution methods compared to traditional Monte Carlo-based approaches like local Infidelity. Crucially, it eliminates the randomness and uncertainty inherent in previous methods, providing a deterministic and reproducible fidelity score that measures the same property. This enables a more efficient and trustworthy evaluation of XAI methods, as demonstrated by extensive testing across diverse datasets, models, and explanation algorithms.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By providing a rapid, deterministic, and trustworthy method for evaluating the fidelity of AI explanations, DPC directly contributes to the development and deployment of safer and more reliable AI in healthcare. Clinicians and regulators can have increased confidence that the explanations offered by AI systems accurately reflect the model's reasoning, facilitating better-informed clinical decisions, improving patient outcomes, and streamlining regulatory compliance for medical AI applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed DPC method itself. Its primary focus is on highlighting the advancements and benefits DPC offers over existing fidelity assessment techniques.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for the DPC metric or its applications.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Dermatology</span>
                    
                    <span class="tag">Medical Diagnostics (general)</span>
                    
                    <span class="tag">Clinical Decision Support Systems</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Fidelity Assessment</span>
                    
                    <span class="tag tag-keyword">Local Feature Attribution</span>
                    
                    <span class="tag tag-keyword">Explainable AI (XAI)</span>
                    
                    <span class="tag tag-keyword">Directed Prediction Change (DPC)</span>
                    
                    <span class="tag tag-keyword">Trustworthy AI</span>
                    
                    <span class="tag tag-keyword">Deterministic Evaluation</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Skin Lesions</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>