<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking - Health AI Hub</title>
    <meta name="description" content="This paper introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method for Retrieval Augmented Generation (RAG) systems that enhances factu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05012v1" target="_blank">2512.05012v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Francielle Vargas, Daniel Pedronette
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05012v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05012v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method for Retrieval Augmented Generation (RAG) systems that enhances factuality and transparency. CER fine-unes embeddings with contrastive learning and generates token-level attribution rationales, explicitly aligning retrieval with evidential reasoning. Evaluated on clinical trial reports, the method demonstrates improved retrieval accuracy, mitigates hallucinations, and provides transparent, reliable evidence-based retrieval critical for safety-critical domains.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This method is highly relevant to medicine by improving the trustworthiness and safety of AI systems, such as RAG, when processing critical medical information like clinical trial data. By reducing 'hallucinations' (incorrect or fabricated information) and ensuring transparent, evidence-based retrieval, it directly supports more accurate and reliable decision-making in healthcare, a domain where errors can have severe consequences.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI method (Self-Explaining Contrastive Evidence Re-ranking - CER) is designed to improve the reliability, factuality, and transparency of Retrieval Augmented Generation (RAG) systems. In a health context, this means RAG systems applied to medical literature (like clinical trial reports) can provide more accurate, evidence-backed, and auditable information. This is crucial for applications such as assisting medical researchers, supporting clinical decision-making, extracting insights for drug discovery, and generating trustworthy health information, by reducing the risk of misinformation (hallucinations) and increasing the explainability of the AI's output.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Introduces Self-Explaining Contrastive Evidence Re-Ranking (CER) to improve factuality and transparency in RAG systems.</li>
                    
                    <li>Utilizes contrastive learning to fine-tune embeddings, explicitly structuring retrieval around factual evidence.</li>
                    
                    <li>Generates token-level attribution rationales for each retrieved passage, offering granular transparency into the evidence.</li>
                    
                    <li>Employs a subjectivity-based criterion for automatic hard negative selection, which pushes subjective or misleading explanations apart from factual ones in the embedding space.</li>
                    
                    <li>Creates an embedding space specifically optimized for evidential reasoning by pulling factual rationales closer.</li>
                    
                    <li>Initial experimental results on clinical trial reports show an improvement in retrieval accuracy.</li>
                    
                    <li>Significantly mitigates the potential for hallucinations in RAG systems and enhances reliability, especially in safety-critical medical contexts.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The Self-Explaining Contrastive Evidence Re-Ranking (CER) method restructures retrieval by fine-tuning embeddings using contrastive learning. It generates token-level attribution rationales for each retrieved passage, indicating the factual evidence. Hard negatives are automatically selected based on a subjectivity-based criterion, which then forces the model during training to pull factual rationales closer together in the embedding space while pushing subjective or misleading explanations further apart. This process creates an embedding space explicitly aligned with evidential reasoning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Initial experimental results from evaluation on clinical trial reports demonstrate that CER improves retrieval accuracy. Crucially, it mitigates the potential for hallucinations in RAG systems, providing transparent and evidence-based retrieval. This significantly enhances the reliability of RAG systems, particularly in safety-critical domains.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>CER has the potential to profoundly impact clinical practice by making AI-powered information retrieval more reliable and trustworthy. In clinical settings, where RAG systems might be used to summarize patient records, synthesize evidence for treatment guidelines, or interpret clinical trial results, CER's ability to prevent hallucinations and provide transparent, evidence-based rationales can directly lead to safer and more informed clinical decisions, ultimately improving patient outcomes and reducing medical errors.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract notes this is an "extended abstract" and reports "initial experimental results," implying the work is preliminary and potentially not fully exhaustive. Specific detailed limitations or a broader scope of evaluation are not elaborated within the abstract itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly stated in the abstract. However, given that it's an "extended abstract" with "initial experimental results," future directions would likely involve more extensive evaluation across diverse medical datasets, exploration of different safety-critical medical applications, and potentially integration into real-world clinical RAG systems for further validation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Trials</span>
                    
                    <span class="tag">Evidence-Based Medicine</span>
                    
                    <span class="tag">AI in Healthcare</span>
                    
                    <span class="tag">Medical Decision Support Systems</span>
                    
                    <span class="tag">Pharmacovigilance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">RAG</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Evidence Re-ranking</span>
                    
                    <span class="tag tag-keyword">Factuality</span>
                    
                    <span class="tag tag-keyword">Hallucination Mitigation</span>
                    
                    <span class="tag tag-keyword">Transparency</span>
                    
                    <span class="tag tag-keyword">Clinical Trials</span>
                    
                    <span class="tag tag-keyword">Safety-Critical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>This work was presented as a poster at the Applied Social Media Lab during the 2025 Synthesizer & Open Showcase at the Berkman Klein Center for Internet & Society at Harvard University</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>