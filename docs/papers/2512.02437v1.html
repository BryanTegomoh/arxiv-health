<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LightHCG: a Lightweight yet powerful HSIC Disentanglement based Causal Glaucoma Detection Model framework - Health AI Hub</title>
    <meta name="description" content="This research introduces LightHCG, a novel and extremely lightweight Convolutional VAE-based model designed for causal glaucoma detection, addressing limitation">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>LightHCG: a Lightweight yet powerful HSIC Disentanglement based Causal Glaucoma Detection Model framework</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.02437v1" target="_blank">2512.02437v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-02
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Daeyoung Kim
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.02437v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.02437v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This research introduces LightHCG, a novel and extremely lightweight Convolutional VAE-based model designed for causal glaucoma detection, addressing limitations of existing AI approaches. By employing HSIC-based latent space disentanglement and Graph Autoencoders, LightHCG learns true causal relationships among glaucoma-related physical factors in the optic nerve. This results in superior classification performance, a significant reduction in model parameters (93-99% less weights), and enhanced capabilities for AI-driven intervention analysis and clinical simulations.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant as it offers a more robust, interpretable, and efficient AI solution for early glaucoma detection, a leading cause of irreversible blindness. By explicitly modeling causality, LightHCG can move beyond simple correlation to provide insights into disease mechanisms, potentially enabling more targeted interventions and personalized treatment strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes the development of 'LightHCG,' a lightweight and causal representation-driven AI model designed for automated glaucoma detection from retinal fundus images or OCT scans. This model aims to enhance diagnostic accuracy, reduce computational resources, and improve the reliability of AI for medical diagnosis, potentially enabling AI-driven intervention analysis and clinical simulations for glaucoma management.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Identifies and addresses key limitations of current AI-driven glaucoma detection models, including reliability issues, excessive parameter usage, potential for spurious correlations, and restricted application to intervention analysis or clinical simulations.</li>
                    
                    <li>Proposes LightHCG, a novel causal representation-driven model based on a Convolutional Variational Autoencoder (VAE) for latent glaucoma representation.</li>
                    
                    <li>Utilizes HSIC (Hilbert-Schmidt Independence Criterion) for latent space disentanglement, aiming to isolate independent causal factors relevant to glaucoma progression.</li>
                    
                    <li>Incorporates Graph Autoencoders for unsupervised causal representation learning, specifically designed to model true causal relationships among physical factors within the optic nerve region.</li>
                    
                    <li>Achieves higher performance in classifying glaucoma compared to existing advanced vision models like InceptionV3, MobileNetV2, and VGG16.</li>
                    
                    <li>Demonstrates significant efficiency, operating with 93-99% fewer computational weights, making it an extremely lightweight solution.</li>
                    
                    <li>Enhances the potential for AI-driven intervention analysis and clinical simulations, providing a more actionable tool beyond mere detection.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>LightHCG is built upon a Convolutional Variational Autoencoder (VAE) framework to learn latent representations of glaucoma from medical images (likely retinal fundus images or OCT). Its core methodology involves HSIC-based latent space disentanglement to ensure the learned latent factors are independent and represent true causal variables. Additionally, it employs Graph Autoencoders for unsupervised causal representation learning, enabling the model to explicitly infer and represent the causal relationships among glaucoma-related physical factors within the optic nerve region.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings indicate that LightHCG achieves higher performance in classifying glaucoma. Crucially, it does so with a dramatically reduced model size, utilizing 93-99% less weights compared to established advanced vision models such as InceptionV3, MobileNetV2, and VGG16. Furthermore, its causal representation learning capabilities significantly enhance the possibility of AI-driven intervention analysis and clinical simulations.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>LightHCG's lightweight design makes it highly deployable in various clinical settings, including those with limited computational resources, and potentially on edge devices for real-time analysis. Its focus on causal representations can provide clinicians with a deeper understanding of glaucoma pathology, facilitating more accurate diagnoses, individualized treatment planning, and effective monitoring of disease progression. The enhanced ability for intervention analysis and clinical simulations could lead to predictive modeling for treatment outcomes and personalized risk assessment for patients.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any specific limitations or caveats of the LightHCG model itself. It primarily focuses on the limitations of *existing* AI models that LightHCG aims to overcome.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract implies that LightHCG significantly enhances the possibility of AI-driven intervention analysis and clinical simulations, suggesting these as immediate and impactful applications of the developed framework. While not explicitly stated as 'future research directions,' these capabilities represent key areas for further exploration and deployment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Neuro-ophthalmology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Preventive Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Glaucoma Detection</span>
                    
                    <span class="tag tag-keyword">Causal Representation Learning</span>
                    
                    <span class="tag tag-keyword">HSIC Disentanglement</span>
                    
                    <span class="tag tag-keyword">Convolutional VAE</span>
                    
                    <span class="tag tag-keyword">Graph Autoencoder</span>
                    
                    <span class="tag tag-keyword">Lightweight AI</span>
                    
                    <span class="tag tag-keyword">Retinal Fundus Images</span>
                    
                    <span class="tag tag-keyword">Optic Nerve Damage</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">As a representative optic degenerative condition, glaucoma has been a threat to millions due to its irreversibility and severe impact on human vision fields. Mainly characterized by dimmed and blurred visions, or peripheral vision loss, glaucoma is well known to occur due to damages in the optic nerve from increased intraocular pressure (IOP) or neovascularization within the retina. Traditionally, most glaucoma related works and clinical diagnosis focused on detecting these damages in the optic nerve by using patient data from perimetry tests, optic papilla inspections and tonometer-based IOP measurements. Recently, with advancements in computer vision AI models, such as VGG16 or Vision Transformers (ViT), AI-automatized glaucoma detection and optic cup segmentation based on retinal fundus images or OCT recently exhibited significant performance in aiding conventional diagnosis with high performance. However, current AI-driven glaucoma detection approaches still have significant room for improvement in terms of reliability, excessive parameter usage, possibility of spurious correlation within detection, and limitations in applications to intervention analysis or clinical simulations. Thus, this research introduced a novel causal representation driven glaucoma detection model: LightHCG, an extremely lightweight Convolutional VAE-based latent glaucoma representation model that can consider the true causality among glaucoma-related physical factors within the optic nerve region. Using HSIC-based latent space disentanglement and Graph Autoencoder based unsupervised causal representation learning, LightHCG not only exhibits higher performance in classifying glaucoma with 93~99% less weights, but also enhances the possibility of AI-driven intervention analysis, compared to existing advanced vision models such as InceptionV3, MobileNetV2 or VGG16.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>