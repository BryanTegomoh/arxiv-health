<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Monitoring Deployed AI Systems in Health Care - Health AI Hub</title>
    <meta name="description" content="This paper presents a novel framework for the post-deployment monitoring of artificial intelligence (AI) systems in health care, crucial for ensuring their safe">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Monitoring Deployed AI Systems in Health Care</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.09048v1" target="_blank">2512.09048v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-09
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Timothy Keyes, Alison Callahan, Abby S. Pandya, Nerissa Ambers, Juan M. Banda, Miguel Fuentes, Carlene Lugtu, Pranav Masariya, Srikar Nallan, Connor O'Brien, Thomas Wang, Emily Alsentzer, Jonathan H. Chen, Dev Dash, Matthew A. Eisenberg, Patricia Garcia, Nikesh Kotecha, Anurang Revri, Michael A. Pfeffer, Nigam H. Shah, Sneha S. Jain
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> q-bio.OT, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.09048v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.09048v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a novel framework for the post-deployment monitoring of artificial intelligence (AI) systems in health care, crucial for ensuring their safety, quality, and sustained benefit. Organized around principles of system integrity, performance, and impact, this framework provides practical guidance for creating monitoring plans that facilitate informed governance decisions regarding AI system updates, modifications, or decommissioning. The framework is actively utilized at Stanford Health Care, demonstrating its real-world applicability.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This framework directly addresses critical issues of patient safety, quality of care, and clinical efficacy in AI-driven healthcare. By systematically monitoring deployed AI, it helps prevent adverse events, maintain diagnostic and therapeutic accuracy, and ensures that AI systems continue to deliver value to patients and clinicians over time, aligning with the ethical and regulatory demands of clinical practice.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper focuses on the post-deployment monitoring and governance of AI systems used in clinical practice and healthcare operations, ensuring their continued safety, performance, and positive impact on patient care and clinical workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Motivation for Monitoring**: Post-deployment monitoring of AI systems in healthcare is essential for safety, quality, sustained benefit, and informing governance decisions (update, modify, decommission).</li>
                    
                    <li>**Framework Development**: A monitoring framework was developed, grounded in the mandate to take specific actions when AI systems fail to behave as intended.</li>
                    
                    <li>**Three Core Principles**: The framework is structured around system integrity (uptime, error detection, IT ecosystem changes), performance (accuracy in face of changing input data/practices), and impact (value to clinicians/patients).</li>
                    
                    <li>**Practical Guidance**: Provides practical guidance for creating detailed monitoring plans, including specifying metrics, review schedules, responsible parties, and concrete follow-up actions for both traditional and generative AI.</li>
                    
                    <li>**Real-World Implementation**: The framework is actively deployed and used at Stanford Health Care, serving as a practical template for other health systems.</li>
                    
                    <li>**Identified Challenges**: Implementation challenges include the significant effort and cost for resource-limited health systems, and difficulties integrating data-driven monitoring into complex organizations with often conflicting priorities.</li>
                    
                    <li>**Action-Oriented Approach**: The entire framework emphasizes an action-oriented approach, ensuring that monitoring leads directly to decisions and interventions.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed a conceptual framework for AI monitoring, explicitly 'grounded in the mandate to take specific actions' based on deviations from intended behavior. This framework was then practically implemented and is actively used at Stanford Health Care, indicating an applied research approach with real-world validation and continuous refinement based on operational experience with both traditional and generative AI systems.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is the successful development and practical implementation of a comprehensive, action-oriented framework for post-deployment AI monitoring in healthcare. This framework, structured by system integrity, performance, and impact principles, provides a clear template for health systems to proactively manage AI risks and ensure sustained benefit. Its active use at Stanford Health Care validates its utility.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework offers a standardized, actionable approach for health systems to enhance patient safety by proactively identifying and mitigating AI failures or degradations. It improves the reliability and trustworthiness of AI-assisted clinical decisions, streamlines governance over AI lifecycles, and enables data-driven decisions on whether to update, modify, or decommission AI tools, ultimately fostering a safer and more effective digital health environment.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper notes significant challenges, including the substantial effort and cost required for comprehensive monitoring, which may be prohibitive for health systems with limited resources. Additionally, integrating data-driven monitoring practices into complex healthcare organizations where conflicting priorities and varied definitions of success often exist presents a considerable difficulty.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Implicit future directions include developing more resource-efficient monitoring strategies for health systems with budget constraints, as well as researching effective methods to seamlessly integrate robust data-driven monitoring into complex organizational structures. Further validation and adaptation of the framework across diverse clinical settings and for an expanding array of AI applications (including more advanced generative AI) would also be beneficial.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical AI</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                    <span class="tag">Patient Safety</span>
                    
                    <span class="tag">Quality Improvement</span>
                    
                    <span class="tag">Health Systems Management</span>
                    
                    <span class="tag">Digital Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">AI monitoring</span>
                    
                    <span class="tag tag-keyword">healthcare AI</span>
                    
                    <span class="tag tag-keyword">post-deployment</span>
                    
                    <span class="tag tag-keyword">system integrity</span>
                    
                    <span class="tag tag-keyword">performance monitoring</span>
                    
                    <span class="tag tag-keyword">impact assessment</span>
                    
                    <span class="tag tag-keyword">patient safety</span>
                    
                    <span class="tag tag-keyword">clinical governance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Post-deployment monitoring of artificial intelligence (AI) systems in health care is essential to ensure their safety, quality, and sustained benefit-and to support governance decisions about which systems to update, modify, or decommission. Motivated by these needs, we developed a framework for monitoring deployed AI systems grounded in the mandate to take specific actions when they fail to behave as intended. This framework, which is now actively used at Stanford Health Care, is organized around three complementary principles: system integrity, performance, and impact. System integrity monitoring focuses on maximizing system uptime, detecting runtime errors, and identifying when changes to the surrounding IT ecosystem have unintended effects. Performance monitoring focuses on maintaining accurate system behavior in the face of changing health care practices (and thus input data) over time. Impact monitoring assesses whether a deployed system continues to have value in the form of benefit to clinicians and patients. Drawing on examples of deployed AI systems at our academic medical center, we provide practical guidance for creating monitoring plans based on these principles that specify which metrics to measure, when those metrics should be reviewed, who is responsible for acting when metrics change, and what concrete follow-up actions should be taken-for both traditional and generative AI. We also discuss challenges to implementing this framework, including the effort and cost of monitoring for health systems with limited resources and the difficulty of incorporating data-driven monitoring practices into complex organizations where conflicting priorities and definitions of success often coexist. This framework offers a practical template and starting point for health systems seeking to ensure that AI deployments remain safe and effective over time.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>36 pages, 3 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>