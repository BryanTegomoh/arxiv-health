<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders - Health AI Hub</title>
    <meta name="description" content="Generative AI systems pose significant and often subtle risks to individuals vulnerable to eating disorders, as existing safeguards frequently overlook critical">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04843v1" target="_blank">2512.04843v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Amy Winecoff, Kevin Klyman
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.HC, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04843v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04843v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Generative AI systems pose significant and often subtle risks to individuals vulnerable to eating disorders, as existing safeguards frequently overlook critical clinical cues. This study employed expert interviews to develop a seven-category taxonomy of these risks, illustrating how interactions with AI can exacerbate clinical features of eating disorders. The findings provide a framework for enhancing risk assessment, safeguard design, and expert-guided evaluation practices for AI technologies.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically important for understanding and mitigating the mental health risks associated with generative AI, particularly for a vulnerable population like individuals with or at risk of eating disorders. It provides a structured, clinically-informed framework to identify subtle yet significant harms that current AI safety protocols may overlook.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research analyzes the potential negative impacts and risks of general-purpose generative AI systems on individuals vulnerable to eating disorders, providing a framework for risk assessment and safeguard design in the context of mental health and medical conditions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing generative AI safeguards are inadequate, failing to address subtle but clinically significant risks for individuals vulnerable to eating disorders.</li>
                    
                    <li>The research involved semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders.</li>
                    
                    <li>An abductive qualitative analysis was utilized to develop an 'expert-guided taxonomy of generative AI risks' specifically for eating disorders.</li>
                    
                    <li>The taxonomy delineates seven categories of risk: generalized health advice, encouraging disordered behaviors, symptom concealment, creating thinspiration, reinforcing negative self-beliefs, promoting excessive body focus, and perpetuating narrow views about eating disorders.</li>
                    
                    <li>The study demonstrates how specific user interactions with generative AI can intersect with and intensify clinical features characteristic of eating disorders.</li>
                    
                    <li>Implications include the need for advanced approaches to generative AI risk assessment in the context of mental health.</li>
                    
                    <li>The work advocates for the design of more robust, clinically informed AI safeguards and the implementation of participatory evaluation practices involving domain experts.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study conducted semi-structured interviews with 15 experts, including clinicians, researchers, and advocates specializing in eating disorders. The data collected from these interviews was then subjected to an abductive qualitative analysis to develop the expert-guided taxonomy of generative AI risks.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The main finding is an 'expert-guided taxonomy of generative AI risks' for eating disorders, categorized into seven areas: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. These categories highlight how AI interactions can exacerbate the clinical features of eating disorders.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research offers a crucial framework for clinicians and AI developers to identify, assess, and mitigate the specific risks posed by generative AI to individuals with eating disorders. It directly informs the development of more clinically sensitive and effective AI safeguards, better risk assessment protocols, and participatory evaluation methods involving domain experts, thereby enhancing patient safety and ethical AI deployment in mental health contexts.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper implies future directions by discussing the need for developing concrete approaches for AI risk assessment, designing more sophisticated and clinically aware safeguards, and integrating participatory evaluation practices that actively involve eating disorder domain experts in AI development and deployment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Eating Disorders</span>
                    
                    <span class="tag">Mental Health</span>
                    
                    <span class="tag">Clinical Psychology</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Digital Psychiatry</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">generative AI</span>
                    
                    <span class="tag tag-keyword">eating disorders</span>
                    
                    <span class="tag tag-keyword">AI risks</span>
                    
                    <span class="tag tag-keyword">mental health</span>
                    
                    <span class="tag tag-keyword">qualitative research</span>
                    
                    <span class="tag tag-keyword">clinical psychology</span>
                    
                    <span class="tag tag-keyword">AI safeguards</span>
                    
                    <span class="tag tag-keyword">digital health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>