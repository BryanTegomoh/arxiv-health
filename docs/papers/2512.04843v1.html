<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders - Health AI Hub</title>
    <meta name="description" content="This paper investigates the serious risks generative AI systems pose to individuals vulnerable to eating disorders, noting that existing safeguards are inadequa">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04843v1" target="_blank">2512.04843v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Amy Winecoff, Kevin Klyman
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.HC, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04843v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04843v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper investigates the serious risks generative AI systems pose to individuals vulnerable to eating disorders, noting that existing safeguards are inadequate as they overlook subtle but clinically significant cues. Through semi-structured interviews with 15 eating disorder experts and abductive qualitative analysis, the authors developed a seven-category taxonomy of AI-related risks to understand how specific user interactions intersect with clinical features of eating disorders.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for mental health and preventative medicine by precisely identifying AI-driven harms that can exacerbate eating disorders, thus informing the development of safer digital environments and better clinical guidance for vulnerable populations. It bridges the gap between AI technology and clinical understanding of eating disorder pathology.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper analyzes the potential negative impacts and risks of general-purpose generative AI systems on individuals vulnerable to eating disorders. This research is critical for informing the design of safeguards, risk assessment frameworks, and responsible development practices for AI tools that may interact with users in health-sensitive contexts, thereby contributing to the safe and ethical application of AI in healthcare and mental health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Generative AI presents significant, often overlooked, risks for individuals vulnerable to eating disorders due to insufficient current safeguards that miss subtle clinical cues.</li>
                    
                    <li>The study employed semi-structured interviews with 15 multidisciplinary experts (clinicians, researchers, advocates) specializing in eating disorders.</li>
                    
                    <li>An abductive qualitative analysis approach was utilized to systematically develop an expert-guided taxonomy of generative AI risks.</li>
                    
                    <li>A seven-category taxonomy of risks was developed: providing generalized health advice, encouraging disordered behaviors, supporting symptom concealment, creating thinspiration, reinforcing negative self-beliefs, promoting excessive focus on the body, and perpetuating narrow views about eating disorders.</li>
                    
                    <li>Findings illustrate how specific user interactions with AI systems can amplify risks by intersecting with core clinical features and vulnerabilities characteristic of eating disorders.</li>
                    
                    <li>The research highlights the critical need for improved risk assessment frameworks and novel safeguard designs tailored to the nuanced psychological and behavioral aspects of eating disorders.</li>
                    
                    <li>The paper emphasizes the importance of participatory evaluation practices, integrating continuous input from domain experts into the development and ongoing assessment of AI systems to ensure clinical safety.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study conducted semi-structured interviews with 15 experts in eating disorders (comprising clinicians, researchers, and advocates). The qualitative data gathered from these interviews was subsequently analyzed using an abductive approach to systematically identify and categorize specific risks posed by generative AI.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is an expert-guided taxonomy of generative AI risks for individuals vulnerable to eating disorders, categorized into seven distinct areas: (1) providing generalized health advice, (2) encouraging disordered behaviors, (3) supporting symptom concealment, (4) creating thinspiration, (5) reinforcing negative self-beliefs, (6) promoting excessive focus on the body, and (7) perpetuating narrow views about eating disorders. These categories demonstrate how user interactions with AI can intersect with and intensify the clinical features of eating disorders, thereby increasing risk.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This taxonomy provides clinicians, researchers, and AI developers with a structured and clinically informed framework to identify and understand the specific ways generative AI can harm individuals with eating disorders. It will directly inform the creation of more effective, clinically sensitive safeguards, enhance risk assessment protocols for AI tools, and guide the development of ethical AI in mental health, potentially leading to improved patient safety and better-targeted interventions in digital mental health spaces.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the study.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work implies future directions in developing precise and clinically-informed risk assessment frameworks for generative AI, designing robust and nuanced AI safeguards, and implementing participatory evaluation practices that integrate continuous input from eating disorder domain experts throughout the AI development and deployment lifecycle.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Eating Disorders</span>
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Clinical Psychology</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Mental Health Technology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">eating disorders</span>
                    
                    <span class="tag tag-keyword">generative AI</span>
                    
                    <span class="tag tag-keyword">AI risks</span>
                    
                    <span class="tag tag-keyword">mental health</span>
                    
                    <span class="tag tag-keyword">qualitative research</span>
                    
                    <span class="tag tag-keyword">clinical psychology</span>
                    
                    <span class="tag tag-keyword">digital health</span>
                    
                    <span class="tag tag-keyword">safeguard design</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>