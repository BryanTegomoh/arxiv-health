<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders - Health AI Hub</title>
    <meta name="description" content="This paper establishes an expert-guided taxonomy of generative AI risks for individuals vulnerable to eating disorders (EDs), highlighting how current safeguard">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04843v1" target="_blank">2512.04843v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Amy Winecoff, Kevin Klyman
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.HC, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04843v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04843v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper establishes an expert-guided taxonomy of generative AI risks for individuals vulnerable to eating disorders (EDs), highlighting how current safeguards are insufficient for subtle clinical cues. Through qualitative analysis of interviews with ED specialists, the research identifies seven critical risk categories, demonstrating how AI interactions can exacerbate ED features and intensify user harm.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for mental health and digital medicine as it systematically identifies serious, unaddressed risks posed by generative AI to individuals vulnerable to eating disorders. Understanding these risks is vital for developing clinically informed safeguards that protect patient well-being and prevent the exacerbation of severe psychiatric conditions through digital interactions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research analyzes the potential negative impacts and risks of generative AI systems when interacting with individuals suffering from or vulnerable to eating disorders. While not an 'application' in the sense of a positive therapeutic tool, it examines how AI, when used by or presented to individuals, can influence health outcomes in a medical context, thus directly falling under the purview of AI in health/medicine.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study utilized semi-structured interviews with 15 multidisciplinary experts (clinicians, researchers, advocates) specializing in eating disorders.</li>
                    
                    <li>An abductive qualitative analysis approach was employed to synthesize expert insights into a structured risk framework.</li>
                    
                    <li>A comprehensive taxonomy of generative AI risks was developed, comprising seven distinct categories directly relevant to eating disorder pathology and vulnerability.</li>
                    
                    <li>The identified risk categories include providing generalized health advice, encouraging disordered behaviors, supporting symptom concealment, creating thinspiration, reinforcing negative self-beliefs, promoting excessive focus on the body, and perpetuating narrow views about eating disorders.</li>
                    
                    <li>The research demonstrates a critical intersection where specific user interactions with generative AI systems can directly intensify clinical features and risks associated with eating disorders.</li>
                    
                    <li>Key implications include informing robust risk assessment methodologies, designing more clinically sensitive AI safeguards, and advocating for participatory evaluation practices involving domain experts.</li>
                    
                    <li>The findings underscore the limitations of existing AI safeguards in recognizing and mitigating subtle, but clinically significant, cues pertinent to eating disorder vulnerability.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed semi-structured interviews with 15 experts (clinicians, researchers, advocates) specializing in eating disorders. Data gathered from these interviews were subjected to abductive qualitative analysis to develop the expert-guided taxonomy of generative AI risks.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is an expert-guided, 7-category taxonomy of generative AI risks for eating disorders: (1) generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. These findings highlight how specific AI-user interactions intersect with clinical features of EDs to intensify risk.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a foundational framework for clinicians and developers to understand the nuanced risks of generative AI for ED patients. It can inform the development of more clinically relevant AI risk assessment tools, guide the design of proactive and effective safeguards that address specific ED vulnerabilities, and promote the integration of expert knowledge into AI evaluation, ultimately contributing to safer digital environments for vulnerable populations.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of this study (e.g., sample size, generalizability of expert opinions). However, it implicitly points to the limitation of existing AI safeguards in overlooking subtle, clinically significant cues relevant to eating disorders.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future work should focus on implementing the identified risk categories into practical approaches for AI risk assessment, designing novel safeguard mechanisms that are responsive to clinically subtle cues, and establishing participatory evaluation practices involving domain experts to continuously assess and improve the safety and ethical deployment of generative AI in sensitive health contexts.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Mental Health</span>
                    
                    <span class="tag">Eating Disorder Treatment</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Clinical Psychology</span>
                    
                    <span class="tag">Public Health</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Generative AI</span>
                    
                    <span class="tag tag-keyword">Eating Disorders</span>
                    
                    <span class="tag tag-keyword">AI Risks</span>
                    
                    <span class="tag tag-keyword">Clinical Safeguards</span>
                    
                    <span class="tag tag-keyword">Mental Health Technology</span>
                    
                    <span class="tag tag-keyword">Qualitative Research</span>
                    
                    <span class="tag tag-keyword">Digital Ethics</span>
                    
                    <span class="tag tag-keyword">Patient Safety</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>