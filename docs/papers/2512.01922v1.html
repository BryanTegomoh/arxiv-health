<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding - Health AI Hub</title>
    <meta name="description" content="Med-VCD introduces a novel sparse visual-contrastive decoding method to mitigate hallucinations in medical Large Vision Language Models (LVLMs). By employing an">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.01922v1" target="_blank">2512.01922v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-01
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zahra Mahdavi, Zahra Khodakaramimaghsoud, Hooman Khaloo, Sina Bakhshandeh Taleshani, Erfan Hashemi, Javad Mirzapour Kaleybar, Omid Nejati Manzari
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.01922v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.01922v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Med-VCD introduces a novel sparse visual-contrastive decoding method to mitigate hallucinations in medical Large Vision Language Models (LVLMs). By employing an efficient token-sparsification strategy, it selectively reinforces visually informed tokens, leading to substantial improvements in factual and hallucination accuracy across diverse medical tasks without the time overhead of previous solutions.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically important for improving the reliability and safety of AI in clinical settings. Mitigating hallucinations in medical LVLMs directly addresses a major barrier to their adoption, ensuring that AI-generated content for diagnoses, prognoses, and treatment planning is factual and trustworthy, thereby enhancing patient care and reducing medical errors.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper aims to improve the reliability and accuracy of Large Vision-Language Models (LVLMs) specifically used in healthcare for tasks such as medical visual question answering and medical imaging report generation. By mitigating 'hallucination', it enhances the trustworthiness and safety of AI systems that assist in medical diagnosis, interpretation of medical images, and generation of clinical reports, thereby directly impacting patient care and clinical workflows.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Medical LVLMs, despite their utility in healthcare (e.g., VQA, report generation), are highly susceptible to hallucinations (plausible but incorrect outputs).</li>
                    
                    <li>Existing hallucination mitigation techniques from the natural image domain are often computationally intensive (secondary decoding, rollback) and may introduce modality misalignment in medical contexts.</li>
                    
                    <li>Med-VCD proposes a sparse visual-contrastive decoding method specifically tailored for medical LVLMs, designed to avoid the time overhead of prior approaches.</li>
                    
                    <li>A core innovation is a novel token-sparsification strategy that dynamically identifies and selects visually informed tokens, thereby trimming redundancy while preserving critical visual context.</li>
                    
                    <li>This on-the-fly selection balances efficiency with reliability, ensuring that the generated text is strongly grounded in visual evidence.</li>
                    
                    <li>Evaluations were conducted on eight medical datasets, encompassing ophthalmology, radiology, and pathology, across tasks including visual question answering, report generation, and dedicated hallucination benchmarks.</li>
                    
                    <li>Med-VCD achieved an average increase of 13% in factual accuracy and a 6% improvement in hallucination accuracy compared to baseline medical LVLMs.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Med-VCD utilizes a sparse visual-contrastive decoding approach. Its central mechanism is a novel token-sparsification strategy that operates by selecting visually informed tokens dynamically during the decoding process. This strategy effectively prunes redundant information while retaining essential visual context, thereby reinforcing visual evidence and mitigating hallucinations without requiring computationally expensive secondary decoding or rollback procedures.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Med-VCD significantly boosts the performance of medical LVLMs, demonstrating an average 13% increase in factual accuracy and a 6% improvement in hallucination accuracy. These results were consistent across eight diverse medical datasets and various tasks, including visual question answering and report generation in ophthalmology, radiology, and pathology domains.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By drastically reducing hallucinations, Med-VCD can lead to more dependable medical imaging reports, more accurate AI-driven responses to clinical queries, and more reliable diagnostic support tools. This enhanced trustworthiness can accelerate the integration of AI into clinical workflows, improve diagnostic precision, inform treatment strategies, and ultimately contribute to better patient outcomes and increased clinician confidence in AI aids.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of existing hallucination mitigation methods (slowness, domain-specificity, misalignment) which Med-VCD aims to overcome. It does not explicitly detail any specific limitations or caveats of Med-VCD itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly outline future research directions for Med-VCD or related work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">ophthalmology</span>
                    
                    <span class="tag">radiology</span>
                    
                    <span class="tag">pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical LVLMs</span>
                    
                    <span class="tag tag-keyword">hallucination mitigation</span>
                    
                    <span class="tag tag-keyword">visual-contrastive decoding</span>
                    
                    <span class="tag tag-keyword">token sparsification</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">factual accuracy</span>
                    
                    <span class="tag tag-keyword">visual question answering</span>
                    
                    <span class="tag tag-keyword">report generation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large vision-language models (LVLMs) are now central to healthcare applications such as medical visual question answering and imaging report generation. Yet, these models remain vulnerable to hallucination outputs that appear plausible but are in fact incorrect. In the natural image domain, several decoding strategies have been proposed to mitigate hallucinations by reinforcing visual evidence, but most rely on secondary decoding or rollback procedures that substantially slow inference. Moreover, existing solutions are often domain-specific and may introduce misalignment between modalities or between generated and ground-truth content. We introduce Med-VCD, a sparse visual-contrastive decoding method that mitigates hallucinations in medical LVLMs without the time overhead of secondary decoding. Med-VCD incorporates a novel token-sparsification strategy that selects visually informed tokens on the fly, trimming redundancy while retaining critical visual context and thus balancing efficiency with reliability. Evaluations on eight medical datasets, spanning ophthalmology, radiology, and pathology tasks in visual question answering, report generation, and dedicated hallucination benchmarks, show that Med-VCD raises factual accuracy by an average of 13\% and improves hallucination accuracy by 6\% relative to baseline medical LVLMs.</p>
            </section>

            

            
            <section class="paper-section">
                <h2>Journal Reference</h2>
                <p>Computers in Biology and Medicine (2026)</p>
            </section>
            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>