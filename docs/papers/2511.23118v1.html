<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine learning for violence prediction: a systematic review and critical appraisal - Health AI Hub</title>
    <meta name="description" content="This systematic review critically appraises machine learning (ML) models developed for violence prediction, synthesizing data from 38 studies on 40 models. It r">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Machine learning for violence prediction: a systematic review and critical appraisal</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.23118v1" target="_blank">2511.23118v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-28
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Stefaniya Kozhevnikova, Denis Yukhnenko, Giulio Scola, Seena Fazel
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> stat.ME, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.23118v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.23118v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This systematic review critically appraises machine learning (ML) models developed for violence prediction, synthesizing data from 38 studies on 40 models. It reveals that while discrimination (AUC 0.68-0.99) is often reported, crucial aspects like calibration and external validation are largely neglected, and most studies suffer from high risk of bias. The paper concludes that current black-box ML models have limited clinical utility due to methodological flaws but offer promise for identifying high-risk individuals, outlining five key recommendations for future, more robust development.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate violence prediction is crucial for patient safety, public health, and guiding interventions in psychiatric, forensic, and correctional settings to prevent harm and facilitate targeted clinical management.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research reviews and appraises machine learning models used for predicting violent behavior, which is a critical application in mental healthcare for risk assessment, patient management, and public safety. It evaluates the current and potential use of AI/ML for identifying individuals at high risk of violence within clinical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A systematic review identified 38 studies reporting the development and/or validation of 40 machine learning models for predicting various forms of violent behavior.</li>
                    
                    <li>Model discrimination performance, primarily reported by Area Under the Curve (AUC), ranged widely from 0.68 to 0.99, indicating varying levels of predictive accuracy.</li>
                    
                    <li>Critical performance metrics like calibration were reported in only 8 studies, and external validation in a mere 3, highlighting significant gaps in assessing model generalizability and reliability.</li>
                    
                    <li>A substantial majority (31 out of 38) of the reviewed studies were found to have a high risk of bias, particularly in the analysis domain, severely impacting the trustworthiness of their findings.</li>
                    
                    <li>The overall clinical utility of existing violence prediction models is deemed poor due to high risks of overfitting from small samples, inadequate transparent reporting, and limited generalizability.</li>
                    
                    <li>Despite current limitations in clinical applicability, black-box ML models are recognized for their potential in identifying individuals at high risk of violence.</li>
                    
                    <li>Five key recommendations are proposed for future violence prediction modeling: enhancing methodological quality, selective use of black-box algorithms, incorporating dynamic predictions, developing explainable AI (XAI), and applying causal ML approaches.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors conducted a systematic search across nine bibliographic databases and Google Scholar (up to September 2025) for studies on ML methods for violence prediction. They synthesized results by summarizing discrimination (e.g., AUC) and calibration performance, and appraised study quality by assessing risk of bias and clinical utility.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The review identified 38 studies developing/validating 40 ML models. Most reported AUC (range 0.68-0.99), but calibration was reported by only eight studies, and external validation by three. 31 studies had a high risk of bias (mainly analysis-related), while only three had low risk. The overall clinical utility is poor due to overfitting, lack of transparent reporting, and low generalizability.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>Currently, black-box ML models for violence prediction have limited direct applicability in clinical settings due to their poor methodological quality, lack of validation, and generalizability issues. However, with significant methodological improvements, they hold promise for more effectively identifying high-risk individuals, which could inform stratified interventions and risk management strategies in forensic and mental health services.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The systematic review highlighted significant limitations within the studies reviewed, including high risks of overfitting due to small sample sizes, lack of transparent reporting of methods and results (especially calibration and external validation), and consequently, poor generalizability of the models. A high prevalence of bias, particularly in the analysis domain, further undermines the validity of current findings.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>['Ensure rigorous methodological quality (e.g., following reporting guidelines) and foster interdisciplinary collaborations in model development.', 'Use black-box algorithms judiciously, reserving them for highly complex data where simpler models are inadequate.', 'Incorporate dynamic prediction models that allow for continuous risk monitoring and adaptation.', 'Develop more trustworthy and interpretable algorithms using explainable artificial intelligence (XAI) methods to provide clinical insights.', 'Apply causal machine learning approaches where appropriate to better understand the underlying mechanisms of violence risk.']</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Forensic Psychiatry</span>
                    
                    <span class="tag">Mental Health</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Psychology</span>
                    
                    <span class="tag">Risk Assessment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Machine learning</span>
                    
                    <span class="tag tag-keyword">violence prediction</span>
                    
                    <span class="tag tag-keyword">systematic review</span>
                    
                    <span class="tag tag-keyword">AUC</span>
                    
                    <span class="tag tag-keyword">risk of bias</span>
                    
                    <span class="tag tag-keyword">clinical utility</span>
                    
                    <span class="tag tag-keyword">explainable AI</span>
                    
                    <span class="tag tag-keyword">causal machine learning</span>
                    
                    <span class="tag tag-keyword">forensic psychiatry</span>
                    
                    <span class="tag tag-keyword">risk assessment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Purpose To conduct a systematic review of machine learning models for predicting violent behaviour by synthesising and appraising their validity, usefulness, and performance.
  Methods We systematically searched nine bibliographic databases and Google Scholar up to September 2025 for development and/or validation studies on machine learning methods for predicting all forms of violent behaviour. We synthesised the results by summarising discrimination and calibration performance statistics and evaluated study quality by examining risk of bias and clinical utility.
  Results We identified 38 studies reporting the development and validation of 40 models. Most studies reported Area Under the Curve (AUC) as the discrimination statistic with a range of 0.68-0.99. Only eight studies reported calibration performance, and three studies reported external validation. 31 studies had a high risk of bias, mainly in the analysis domain, and three studies had low risk of bias. The overall clinical utility of violence prediction models is poor, as indicated by risks of overfitting due to small samples, lack of transparent reporting, and low generalisability.
  Conclusion Although black box machine learning models currently have limited applicability in clinical settings, they may show promise for identifying high-risk individuals. We recommend five key considerations for violence prediction modelling: (i) ensuring methodological quality (e.g. following guidelines) and interdisciplinary collaborations; (ii) using black box algorithms only for highly complex data; (iii) incorporating dynamic predictions to allow for risk monitoring; (iv) developing more trustworthy algorithms using explainable methods; and (v) applying causal machine learning approaches where appropriate.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>