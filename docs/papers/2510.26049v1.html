<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation - Health AI Hub</title>
    <meta name="description" content="FlexICL introduces a novel and flexible in-context learning (ICL) framework for highly efficient segmentation of bony regions in pediatric elbow and wrist ultra">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26049v1" target="_blank">2510.26049v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yuyue Zhou, Jessica Knight, Shrimanti Ghosh, Banafshe Felfeliyan, Jacob L. Jaremko, Abhilash R. Hareendranathan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26049v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26049v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">FlexICL introduces a novel and flexible in-context learning (ICL) framework for highly efficient segmentation of bony regions in pediatric elbow and wrist ultrasound (US) images. It significantly reduces the need for expert annotations, requiring only 5% of training images, while robustly outperforming state-of-the-art ICL and conventional deep learning models by 1-27% Dice coefficient across multiple datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Automatic segmentation of musculoskeletal structures in ultrasound improves diagnostic accuracy and treatment planning for common pediatric elbow and wrist fractures. This framework allows lightly trained users to confidently perform exams and identify subtle cortical defects (fractures), addressing the current reliance on time-consuming and costly expert interpretations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is a deep learning framework (FlexICL) for medical image segmentation. Specifically, it uses in-context learning to segment bony regions in ultrasound images of the elbow and wrist, aiming to detect fractures. This AI tool provides real-time feedback and highlights key structures, thereby improving diagnostic accuracy for fractures, assisting medical professionals (especially those lightly trained) in performing ultrasound exams, and facilitating treatment planning. It's an AI solution designed to make medical imaging diagnostics more efficient and accessible.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of scarce pixel-wise expert annotations in medical imaging, particularly for pediatric elbow and wrist fracture ultrasound segmentation.</li>
                    
                    <li>Proposes FlexICL, a novel visual In-Context Learning (ICL) framework designed for intra-video segmentation, where only a small subset of frames requires expert annotation.</li>
                    
                    <li>Introduces innovative image concatenation techniques and integrates multiple augmentation strategies to significantly enhance model performance with limited labeled data.</li>
                    
                    <li>Achieves robust segmentation of bony regions in US images while utilizing only 5% of the total training data for annotation.</li>
                    
                    <li>Demonstrates superior performance, outperforming state-of-the-art visual ICL models (Painter, MAE-VQGAN) and conventional deep learning segmentation models (U-Net, TransUNet) by 1-27% Dice coefficient.</li>
                    
                    <li>Validated across four diverse wrist and elbow US datasets, encompassing 1,252 US sweeps, showcasing its generalizability and efficacy.</li>
                    
                    <li>Highlights the potential of FlexICL as an efficient and scalable solution for US image segmentation, particularly well-suited for medical imaging scenarios where labeled data is sparse and costly.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>FlexICL is a visual In-Context Learning (ICL) framework applied to an intra-video segmentation setting. It systematically investigates various image concatenation techniques and training strategies for visual ICL, introducing novel methods to improve performance with limited labeled data. The framework also integrates multiple augmentation strategies to enhance segmentation robustness. The core idea is to train a model that can segment unseen frames by learning from a small, expert-annotated subset of frames within the same video.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>FlexICL significantly enhances model performance by requiring only 5% of the training images for annotation. It achieves robust segmentation performance across four diverse wrist and elbow US datasets, outperforming state-of-the-art visual ICL models (Painter, MAE-VQGAN) and conventional segmentation models (U-Net, TransUNet) by 1-27% Dice coefficient on 1,252 US sweeps.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides an efficient and scalable solution for US image segmentation, reducing the burden of expert annotation in clinical settings. It can enable real-time feedback and highlight key structures for less experienced clinicians, improving diagnostic confidence and accuracy for pediatric elbow and wrist fractures. This ultimately could lead to earlier and more appropriate treatment planning, improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract mentions these are "initial results," suggesting further validation, broader generalization studies, or perhaps clinical trials might be needed. No explicit methodological limitations or specific shortcomings of the FlexICL framework itself are detailed within the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated as future research, the phrase "initial results highlight the potential" implies that future work could involve extending FlexICL to other anatomical regions, pathologies, or validating its performance in diverse clinical environments and larger datasets.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pediatric Orthopedics</span>
                    
                    <span class="tag">Diagnostic Radiology</span>
                    
                    <span class="tag">Emergency Medicine</span>
                    
                    <span class="tag">Musculoskeletal Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Ultrasound Segmentation</span>
                    
                    <span class="tag tag-keyword">In-Context Learning (ICL)</span>
                    
                    <span class="tag tag-keyword">Pediatric Fractures</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Bony Region Segmentation</span>
                    
                    <span class="tag tag-keyword">Data Efficiency</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Musculoskeletal Ultrasound</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Elbow and wrist fractures are the most common fractures in pediatric
populations. Automatic segmentation of musculoskeletal structures in ultrasound
(US) can improve diagnostic accuracy and treatment planning. Fractures appear
as cortical defects but require expert interpretation. Deep learning (DL) can
provide real-time feedback and highlight key structures, helping lightly
trained users perform exams more confidently. However, pixel-wise expert
annotations for training remain time-consuming and costly. To address this
challenge, we propose FlexICL, a novel and flexible in-context learning (ICL)
framework for segmenting bony regions in US images. We apply it to an
intra-video segmentation setting, where experts annotate only a small subset of
frames, and the model segments unseen frames. We systematically investigate
various image concatenation techniques and training strategies for visual ICL
and introduce novel concatenation methods that significantly enhance model
performance with limited labeled data. By integrating multiple augmentation
strategies, FlexICL achieves robust segmentation performance across four wrist
and elbow US datasets while requiring only 5% of the training images. It
outperforms state-of-the-art visual ICL models like Painter, MAE-VQGAN, and
conventional segmentation models like U-Net and TransUNet by 1-27% Dice
coefficient on 1,252 US sweeps. These initial results highlight the potential
of FlexICL as an efficient and scalable solution for US image segmentation well
suited for medical imaging use cases where labeled data is scarce.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>