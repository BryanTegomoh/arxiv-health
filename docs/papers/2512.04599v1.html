<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel zero-shot pipeline for malicious image analysis that simultaneously detects harmful content, identifies specific illicit elements,">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04599v1" target="_blank">2512.04599v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-04
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Sheng Hang, Chaoxiang He, Hongsheng Hu, Hanqing Hu, Bin Benjamin Zhu, Shi-Feng Sun, Dawu Gu, Shuo Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04599v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04599v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel zero-shot pipeline for malicious image analysis that simultaneously detects harmful content, identifies specific illicit elements, and localizes them with pixel-accurate masks in a single pass. The method achieves high recall and precision on a newly annotated dataset spanning drug, sexual, violent, and extremist content, demonstrating significant robustness against adversarial attacks and offering a practical, explainable tool for fine-grained content moderation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for public health and safety by providing an advanced tool for automatically identifying and localizing specific harmful content, particularly images related to illicit drugs. This capability can prevent exposure to triggering materials for individuals in recovery, aid in combating illegal online drug activities, and support mental health initiatives aimed at protecting vulnerable populations from various forms of online harm.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This AI system provides a practical tool for fine-grained, explainable moderation of malicious images. Specifically for health and biosecurity, it can be applied to automatically identify and localize objects related to illicit drug manufacturing/distribution (e.g., specific chemicals, equipment, substances), or elements within extremist content that signal biothreats (e.g., biological agents, weapon designs, specific hazardous materials). This capability enhances intelligence gathering, prevention strategies, and content moderation platforms vital for public safety and health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A zero-shot, one-pass pipeline is proposed for detecting harmful content, identifying critical elements, and localizing them with pixel-accurate masks.</li>
                    
                    <li>The system utilizes a foundation segmentation model (SAM) to generate candidate object masks, which are refined into independent regions.</li>
                    
                    <li>A vision-language model (VLM) scores each region's malicious relevance using open-vocabulary prompts, with scores weighted for a consolidated malicious object map.</li>
                    
                    <li>An ensemble across multiple segmenters is employed to harden the pipeline against adaptive adversarial attacks targeting single segmentation methods.</li>
                    
                    <li>Evaluated on a new 790-image dataset (covering drug, sexual, violent, extremist content), the method achieved 85.8% element-level recall, 78.1% precision, and a 92.1% segment-success rate.</li>
                    
                    <li>The proposed approach significantly outperforms direct zero-shot VLM localization, achieving 27.4% higher recall at comparable precision.</li>
                    
                    <li>Demonstrates high robustness against PGD adversarial perturbations, with precision and recall decreasing by no more than 10%, and processes images rapidly (in seconds).</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The pipeline integrates a foundation segmentation model (SAM) to generate initial object masks, which are subsequently refined into distinct regions. A vision-language model (VLM) then evaluates the malicious relevance of each region using open-vocabulary prompts, assigning scores that are weighted in a fusion step to produce a consolidated malicious object map. To enhance resilience against targeted attacks, an ensemble of multiple segmentation methods is utilized.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The method achieved an 85.8% element-level recall, 78.1% precision, and a 92.1% segment-success rate on a newly-annotated 790-image dataset. It significantly outperformed direct zero-shot VLM localization, boasting a 27.4% higher recall at comparable precision. Furthermore, the system demonstrated high robustness against PGD adversarial perturbations, with precision and recall decreases of less than 10%.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology offers a practical and explainable solution for rapidly identifying and localizing harmful content online, particularly crucial for detecting imagery associated with illicit drugs. Its ability to pinpoint specific elements can support public health interventions by enabling faster removal of content promoting drug use, protecting individuals in recovery from relapse triggers, and assisting law enforcement in digital investigations related to illegal substances. The fine-grained localization allows for more targeted moderation and potentially informs educational efforts.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the method's strengths and robustness, noting its resilience against specific adaptive attacks. It does not explicitly detail any inherent limitations of the proposed pipeline itself within the provided text.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for the proposed method.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Addiction Medicine</span>
                    
                    <span class="tag">Mental Health</span>
                    
                    <span class="tag">Digital Forensics (Health-related crime)</span>
                    
                    <span class="tag">Child Protection</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">malicious image detection</span>
                    
                    <span class="tag tag-keyword">vision-language models</span>
                    
                    <span class="tag tag-keyword">semantic segmentation</span>
                    
                    <span class="tag tag-keyword">zero-shot learning</span>
                    
                    <span class="tag tag-keyword">content moderation</span>
                    
                    <span class="tag tag-keyword">adversarial robustness</span>
                    
                    <span class="tag tag-keyword">public health</span>
                    
                    <span class="tag tag-keyword">drug content</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Detecting illicit visual content demands more than image-level NSFW flags; moderators must also know what objects make an image illegal and where those objects occur. We introduce a zero-shot pipeline that simultaneously (i) detects if an image contains harmful content, (ii) identifies each critical element involved, and (iii) localizes those elements with pixel-accurate masks - all in one pass. The system first applies foundation segmentation model (SAM) to generate candidate object masks and refines them into larger independent regions. Each region is scored for malicious relevance by a vision-language model using open-vocabulary prompts; these scores weight a fusion step that produces a consolidated malicious object map. An ensemble across multiple segmenters hardens the pipeline against adaptive attacks that target any single segmentation method. Evaluated on a newly-annotated 790-image dataset spanning drug, sexual, violent and extremist content, our method attains 85.8% element-level recall, 78.1% precision and a 92.1% segment-success rate - exceeding direct zero-shot VLM localization by 27.4% recall at comparable precision. Against PGD adversarial perturbations crafted to break SAM and VLM, our method's precision and recall decreased by no more than 10%, demonstrating high robustness against attacks. The full pipeline processes an image in seconds, plugs seamlessly into existing VLM workflows, and constitutes the first practical tool for fine-grained, explainable malicious-image moderation.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>