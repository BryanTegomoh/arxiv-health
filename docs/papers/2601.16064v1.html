<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces Phi-SegNet, a novel CNN-based architecture designed to enhance medical image segmentation by explicitly integrating phase-aware informatio">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.16064v1" target="_blank">2601.16064v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-22
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shams Nafisa Ali, Taufiq Hasan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.16064v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.16064v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Phi-SegNet, a novel CNN-based architecture designed to enhance medical image segmentation by explicitly integrating phase-aware information at both architectural and optimization levels. By leveraging frequency-domain representations, Phi-SegNet addresses the crucial challenge of generalization across diverse imaging modalities and anatomical structures. The model consistently achieves state-of-the-art performance and exhibits robust cross-dataset generalization, underscoring the potential of spectral priors for fine-grained object localization in medical imaging.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Improved generalization in medical image segmentation is paramount for deploying AI models reliably across various clinical settings, scanners, and patient populations without extensive re-training. This advancement can lead to more accurate and automated diagnostic support, precise surgical planning, and efficient quantitative analysis across diverse medical imaging modalities, directly impacting patient care and clinical workflows.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI model (Phi-SegNet) for medical image segmentation. This application directly supports computer-aided diagnosis (CAD), treatment planning (e.g., radiation therapy, surgical planning), and quantitative analysis in healthcare. By accurately segmenting anatomical structures, abnormalities, or lesions in various medical scans, the AI can assist clinicians in disease detection, monitoring progression, and guiding interventions, thereby improving patient outcomes and healthcare efficiency.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of robust generalization in medical image segmentation across diverse modalities and anatomies, a limitation of existing deep learning architectures.</li>
                    
                    <li>Proposes Phi-SegNet, a CNN-based framework that uniquely incorporates phase-aware information to capture rich structural and textural cues, which are often overlooked in spatial-only encoding methods.</li>
                    
                    <li>Integrates Bi-Feature Mask Former (BFMF) modules within the encoder to reduce semantic gaps by blending neighboring features and Reverse Fourier Attention (RFA) blocks in the decoder to refine outputs using phase-regularized features.</li>
                    
                    <li>Employs a dedicated phase-aware loss function, aligning features with structural priors and forming a closed feedback loop to emphasize boundary precision at the supervision level.</li>
                    
                    <li>Evaluated on five public datasets (X-ray, US, histopathology, MRI, colonoscopy), demonstrating consistent state-of-the-art performance with average relative improvements of 1.54% IoU and 0.98% F1-score.</li>
                    
                    <li>Exhibits robust and superior performance in cross-dataset generalization scenarios, highlighting its adaptability and modality-agnostic design for unseen data within known domains.</li>
                    
                    <li>Demonstrates the significant potential of leveraging spectral (frequency-domain) priors in both feature representation and supervision for developing generalized segmentation frameworks capable of fine-grained object localization.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Phi-SegNet is a CNN-based architecture that integrates phase-aware information at both architectural and optimization levels. It utilizes Bi-Feature Mask Former (BFMF) modules to blend neighboring encoder features, reducing semantic gaps. Reverse Fourier Attention (RFA) blocks are incorporated to refine decoder outputs using phase-regularized features. A dedicated phase-aware loss function is used during optimization to align features with structural priors, ensuring a closed feedback loop that emphasizes boundary precision.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Phi-SegNet consistently achieved state-of-the-art performance across five diverse medical imaging datasets, showing an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score compared to the next best-performing model. Crucially, it also demonstrated robust and superior performance in cross-dataset generalization scenarios involving unseen datasets from known domains, validating its adaptability and modality-agnostic design.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced generalization capabilities of Phi-SegNet mean that trained models could be more readily applied to new patients, different hospital environments, or varying scanner types without significant degradation in performance or the need for extensive re-annotation and re-training. This translates to increased efficiency in clinical workflows, more consistent and accurate automated analyses (e.g., tumor segmentation, organ delineation), reduced inter-observer variability, and potentially faster diagnoses and treatment planning, supporting a broader adoption of AI in routine clinical practice.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights limitations of *existing architectures* by overlooking frequency-domain representations. It does not explicitly state specific limitations or caveats of the proposed Phi-SegNet model or its current evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The findings are noted to "pave the way for generalized segmentation frameworks that excel in fine-grained object localization," suggesting future research directions will likely involve further exploration and application of spectral priors to enhance generalization and precision in medical image segmentation across an even wider array of challenging clinical scenarios and imaging types.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">X-ray imaging</span>
                    
                    <span class="tag">Ultrasound (US) imaging</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="tag">Colonoscopy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Phase-Aware</span>
                    
                    <span class="tag tag-keyword">Frequency Domain</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">Spectral Priors</span>
                    
                    <span class="tag tag-keyword">Fine-Grained Localization</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>10 pages, 7 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>