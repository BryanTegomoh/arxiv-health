<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="Phi-SegNet introduces a CNN-based architecture that integrates phase-aware information at both architectural and optimization levels to enhance medical image se">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.16064v1" target="_blank">2601.16064v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-22
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shams Nafisa Ali, Taufiq Hasan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.16064v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.16064v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Phi-SegNet introduces a CNN-based architecture that integrates phase-aware information at both architectural and optimization levels to enhance medical image segmentation. By leveraging Bi-Feature Mask Former modules, Reverse Fourier Attention blocks, and a dedicated phase-aware loss, it emphasizes boundary precision and improves generalization across diverse imaging modalities. The model achieved state-of-the-art performance on five public datasets and demonstrated robust cross-dataset generalization, highlighting the potential of spectral priors for fine-grained object localization.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances automated medical image segmentation by improving accuracy and generalization across diverse imaging modalities, which is critical for precise disease diagnosis, treatment planning, and surgical guidance. Enhanced segmentation leads to more reliable quantitative analysis and objective assessment of pathologies, directly impacting patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development of a robust and generalized deep learning framework (Phi-SegNet) for segmenting anatomical structures, lesions, or other regions of interest in diverse medical images. This can lead to more accurate, automated, and efficient tools for diagnosis, disease detection (e.g., tumors, polyps), surgical planning, and monitoring of various conditions across different medical specialties, ultimately improving patient care.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of achieving robust generalization in medical image segmentation across diverse modalities and anatomical structures.</li>
                    
                    <li>Proposes Phi-SegNet, a CNN-based architecture that integrates phase-aware information from the frequency domain at both architectural and optimization levels.</li>
                    
                    <li>Incorporates Bi-Feature Mask Former (BFMF) modules to blend neighboring encoder features, reducing semantic gaps, and Reverse Fourier Attention (RFA) blocks to refine decoder outputs using phase-regularized features.</li>
                    
                    <li>Utilizes a novel phase-aware loss function to align features with structural priors, forming a closed feedback loop that specifically emphasizes and enhances boundary precision in segmentations.</li>
                    
                    <li>Evaluated on a comprehensive set of five public datasets spanning various medical imaging modalities: X-ray, Ultrasound (US), histopathology, MRI, and colonoscopy.</li>
                    
                    <li>Achieved consistent state-of-the-art performance, demonstrating average relative improvements of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model.</li>
                    
                    <li>Exhibits robust and superior performance in cross-dataset generalization scenarios, indicating its adaptability and modality-agnostic design crucial for real-world clinical deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Phi-SegNet is a CNN-based deep learning architecture that incorporates phase-aware information. Its architecture includes Bi-Feature Mask Former (BFMF) modules for blending neighboring encoder features and Reverse Fourier Attention (RFA) blocks for refining decoder outputs using phase-regularized features. The optimization process is guided by a dedicated phase-aware loss that aligns features with structural priors to emphasize boundary precision. The model was rigorously evaluated on five public medical imaging datasets and tested for cross-dataset generalization capabilities.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Phi-SegNet consistently achieved state-of-the-art performance across five diverse medical imaging datasets, with average relative improvements of 1.54% in IoU and 0.98% in F1-score over competing models. Crucially, it demonstrated robust and superior performance in cross-dataset generalization, highlighting its adaptability and modality-agnostic design. These findings underscore the effectiveness of integrating spectral priors for fine-grained object localization and generalized segmentation.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The superior accuracy and generalization demonstrated by Phi-SegNet have direct clinical impact by enabling more reliable and automated medical image analysis, potentially reducing diagnostic errors and inter-observer variability. Its modality-agnostic nature allows for broader application across various clinical imaging types, supporting more precise tumor delineation, organ segmentation, and pathology detection, which are fundamental for improved treatment planning, surgical navigation, and patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly mention any specific limitations of the proposed Phi-SegNet architecture or the study methodology.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract implicitly suggests future research by highlighting the potential of leveraging spectral priors in both feature representation and supervision, thereby paving the way for further development of generalized segmentation frameworks that excel in fine-grained object localization. Specific, concrete future research directions are not detailed.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">X-ray</span>
                    
                    <span class="tag">Ultrasound (US)</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">MRI</span>
                    
                    <span class="tag">Colonoscopy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical image segmentation</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">phase-aware</span>
                    
                    <span class="tag tag-keyword">frequency domain</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">generalization</span>
                    
                    <span class="tag tag-keyword">Fourier Attention</span>
                    
                    <span class="tag tag-keyword">boundary precision</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>10 pages, 7 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>