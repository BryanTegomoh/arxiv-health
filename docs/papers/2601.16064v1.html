<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="Phi-SegNet is a novel CNN-based architecture that enhances medical image segmentation by integrating phase-aware frequency-domain information at both architectu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.16064v1" target="_blank">2601.16064v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-22
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shams Nafisa Ali, Taufiq Hasan
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.16064v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.16064v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Phi-SegNet is a novel CNN-based architecture that enhances medical image segmentation by integrating phase-aware frequency-domain information at both architectural and optimization levels, addressing limitations in robust generalization. It leverages specialized modules and a phase-aware loss to improve structural and boundary precision. Evaluated across five diverse medical imaging modalities, Phi-SegNet achieved state-of-the-art performance and demonstrated robust cross-dataset generalization, highlighting the potential of spectral priors for fine-grained object localization.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Robust and generalized medical image segmentation is fundamental for accurate diagnosis, precise treatment planning, and effective disease monitoring. Phi-SegNet's ability to maintain high performance across varied imaging modalities and generalize to unseen data directly enhances the reliability and applicability of AI in diverse clinical settings, improving the consistency and accuracy of medical image analysis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Phi-SegNet is a deep learning (AI) architecture designed to enhance the accuracy and generalization capabilities of medical image segmentation. This directly contributes to medical AI applications such as automated lesion detection, organ segmentation for treatment planning (e.g., radiotherapy), quantitative analysis of tissue morphology in histopathology, and improved diagnostic support systems across various medical imaging modalities.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge of achieving robust generalization in medical image segmentation across diverse modalities and anatomical structures.</li>
                    
                    <li>Proposes Phi-SegNet, a CNN-based architecture that uniquely integrates phase-aware information from the frequency domain at both architectural and optimization levels.</li>
                    
                    <li>Incorporates Bi-Feature Mask Former (BFMF) modules within the encoder to blend neighboring features, thereby reducing semantic gaps in feature representation.</li>
                    
                    <li>Employs Reverse Fourier Attention (RFA) blocks in the decoder to refine outputs through the application of phase-regularized features.</li>
                    
                    <li>Introduces a dedicated phase-aware loss function that aligns learned features with structural priors, forming a closed feedback loop to emphasize boundary precision.</li>
                    
                    <li>Achieved state-of-the-art performance across five public datasets (X-ray, US, histopathology, MRI, colonoscopy), showing an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score.</li>
                    
                    <li>Demonstrated robust and superior performance in cross-dataset generalization scenarios involving unseen datasets, underscoring its adaptability and modality-agnostic design.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Phi-SegNet is a CNN-based architecture that integrates phase-aware information from the frequency domain. Its design includes Bi-Feature Mask Former (BFMF) modules in the encoder to blend adjacent features and mitigate semantic gaps. In the decoder, Reverse Fourier Attention (RFA) blocks refine outputs by leveraging phase-regularized features. A critical component is a novel phase-aware loss function that optimizes features by aligning them with structural priors, establishing a feedback mechanism that prioritizes fine-grained object localization and boundary accuracy.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Phi-SegNet consistently achieved state-of-the-art performance, demonstrating an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model across five diverse medical imaging datasets. Crucially, the model exhibited robust and superior performance in cross-dataset generalization, indicating its strong adaptability and modality-agnostic design when applied to unseen data from known domains.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The enhanced accuracy and robust generalization of Phi-SegNet across multiple medical imaging modalities can significantly improve the precision and reliability of automated medical image analysis. This allows for more consistent and accurate disease detection, tumor segmentation, anatomical structure identification, and quantitative assessment, which can lead to better diagnostic insights, more effective treatment planning, and more objective monitoring of patient conditions in a wide array of clinical applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of existing deep learning architectures (overlooking frequency-domain representations) that Phi-SegNet aims to address, rather than explicitly noting limitations of the proposed Phi-SegNet model itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests that leveraging spectral priors in both feature representation and supervision holds significant potential. This paves the way for future research focused on further developing and exploring these frequency-domain integration techniques to create even more generalized and robust segmentation frameworks, particularly those excelling in fine-grained object localization across an even broader spectrum of medical imaging challenges.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">X-ray</span>
                    
                    <span class="tag">Ultrasound (US)</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Magnetic Resonance Imaging (MRI)</span>
                    
                    <span class="tag">Colonoscopy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical image segmentation</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">frequency domain</span>
                    
                    <span class="tag tag-keyword">phase-aware</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">generalization</span>
                    
                    <span class="tag tag-keyword">state-of-the-art</span>
                    
                    <span class="tag tag-keyword">multi-modal</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>10 pages, 7 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>