<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision - Health AI Hub</title>
    <meta name="description" content="DisentangleFormer is a novel Vision Transformer architecture that addresses the fundamental limitation of entangled spatial and channel representations in multi">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04314v1" target="_blank">2512.04314v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jiashu Liao, Pietro Li√≤, Marc de Kamps, Duygu Sarikaya
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04314v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04314v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DisentangleFormer is a novel Vision Transformer architecture that addresses the fundamental limitation of entangled spatial and channel representations in multi-channel vision tasks by introducing principled spatial-channel decoupling. It achieves state-of-the-art performance on various hyperspectral and infrared pathology datasets while significantly reducing computational costs.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine, particularly in pathology, as it offers a robust method for analyzing multi-channel infrared pathology images, where distinct biophysical or biochemical cues are vital for accurate disease characterization and diagnosis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The DisentangleFormer can be applied as an AI tool for enhanced analysis of multi-channel medical images, particularly in infrared pathology. It could power automated systems for disease detection, tissue classification, tumor identification, or monitoring of treatment responses by effectively extracting and interpreting complex spatial and spectral information from biopsy slides or in-vivo imaging, thereby assisting pathologists and clinicians in making more accurate and efficient diagnoses.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Standard Vision Transformers' self-attention mechanism jointly processes spatial and channel dimensions, leading to entangled representations that hinder independent modeling of structural and semantic dependencies.</li>
                    
                    <li>DisentangleFormer proposes a robust multi-channel vision representation through principled spatial-channel decoupling, motivated by information-theoretic principles for decorrelated representation learning.</li>
                    
                    <li>The architecture integrates three core components: (1) Parallel Disentanglement for independent processing of spatial-token and channel-token streams, (2) Squeezed Token Enhancer for adaptive dynamic fusion of streams, and (3) Multi-Scale FFN to capture local context.</li>
                    
                    <li>This design enables independent modeling of structural and semantic cues, minimizing redundancy between spatial and channel information, which is crucial for data like hyperspectral imaging where channels carry distinct biophysical/biochemical cues.</li>
                    
                    <li>Achieved state-of-the-art performance on hyperspectral benchmarks including Indian Pine, Pavia University, Houston, and the large-scale BigEarthNet dataset.</li>
                    
                    <li>Demonstrated superior performance on an infrared pathology dataset, directly addressing a critical medical imaging application.</li>
                    
                    <li>Maintains competitive accuracy on ImageNet while providing significant computational efficiency, reducing FLOPs by 17.8%.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DisentangleFormer employs a parallel design to independently process spatial-token and channel-token streams, facilitating decorrelated feature learning. It incorporates a Squeezed Token Enhancer for adaptive, dynamic fusion of these spatial and channel streams. Additionally, a Multi-Scale Feed-Forward Network (FFN) is utilized to capture multi-scale local contextual information, complementing the global attention mechanisms.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>DisentangleFormer consistently achieves state-of-the-art performance on various hyperspectral benchmarks and, significantly, on an infrared pathology dataset. It also demonstrates competitive accuracy on the ImageNet dataset while reducing computational costs by 17.8% in FLOPs, proving both effectiveness and efficiency.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By enabling a more precise and robust analysis of multi-channel infrared pathology images, DisentangleFormer has the potential to significantly improve diagnostic accuracy for diseases. This could lead to earlier and more reliable disease detection, better prognostication, and the ability to differentiate subtle biophysical or biochemical markers crucial for personalized treatment strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of DisentangleFormer itself. It highlights the 'fundamental limitation' of existing Vision Transformers (entangled spatial-channel processing) as the problem DisentangleFormer addresses.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>No specific future research directions are mentioned in the abstract beyond the code being made publicly available upon acceptance.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Infrared Pathology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Biochemical Sensing</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Vision Transformers</span>
                    
                    <span class="tag tag-keyword">Spatial-Channel Decoupling</span>
                    
                    <span class="tag tag-keyword">Hyperspectral Imaging</span>
                    
                    <span class="tag tag-keyword">Infrared Pathology</span>
                    
                    <span class="tag tag-keyword">Multi-Channel Vision</span>
                    
                    <span class="tag tag-keyword">Disentangled Representation</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Vision Transformers face a fundamental limitation: standard self-attention jointly processes spatial and channel dimensions, leading to entangled representations that prevent independent modeling of structural and semantic dependencies. This problem is especially pronounced in hyperspectral imaging, from satellite hyperspectral remote sensing to infrared pathology imaging, where channels capture distinct biophysical or biochemical cues. We propose DisentangleFormer, an architecture that achieves robust multi-channel vision representation through principled spatial-channel decoupling. Motivated by information-theoretic principles of decorrelated representation learning, our parallel design enables independent modeling of structural and semantic cues while minimizing redundancy between spatial and channel streams. Our design integrates three core components: (1) Parallel Disentanglement: Independently processes spatial-token and channel-token streams, enabling decorrelated feature learning across spatial and spectral dimensions, (2) Squeezed Token Enhancer: An adaptive calibration module that dynamically fuses spatial and channel streams, and (3) Multi-Scale FFN: complementing global attention with multi-scale local context to capture fine-grained structural and semantic dependencies. Extensive experiments on hyperspectral benchmarks demonstrate that DisentangleFormer achieves state-of-the-art performance, consistently outperforming existing models on Indian Pine, Pavia University, and Houston, the large-scale BigEarthNet remote sensing dataset, as well as an infrared pathology dataset. Moreover, it retains competitive accuracy on ImageNet while reducing computational cost by 17.8% in FLOPs. The code will be made publicly available upon acceptance.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>