<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision - Health AI Hub</title>
    <meta name="description" content="DisentangleFormer addresses a fundamental limitation of Vision Transformers by introducing a novel architecture for spatial-channel decoupling, allowing indepen">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04314v1" target="_blank">2512.04314v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jiashu Liao, Pietro Li√≤, Marc de Kamps, Duygu Sarikaya
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04314v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04314v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">DisentangleFormer addresses a fundamental limitation of Vision Transformers by introducing a novel architecture for spatial-channel decoupling, allowing independent modeling of structural and semantic dependencies in multi-channel data. This approach achieves state-of-the-art performance across various hyperspectral datasets, including critical applications in infrared pathology imaging, while simultaneously improving computational efficiency.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine, particularly in pathology and diagnostic imaging, as it provides a robust and efficient method for analyzing complex multi-channel medical data like infrared pathology images, promising enhanced diagnostic accuracy and faster analysis.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The DisentangleFormer architecture, by disentangling spatial and channel information, can be applied to enhance the analysis of multi-channel medical images, such as those from infrared pathology or other hyperspectral medical imaging modalities. This could lead to improved accuracy in disease detection, tissue classification, tumor grading, and understanding of biochemical changes in biological samples, thereby aiding in more precise and efficient medical diagnosis and research.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Standard Vision Transformers entangle spatial and channel dimensions, hindering independent modeling of structural (spatial) and semantic (channel) dependencies, a problem especially pronounced in multi-channel data like hyperspectral imaging.</li>
                    
                    <li>DisentangleFormer proposes a principled spatial-channel decoupling mechanism, featuring 'Parallel Disentanglement' that independently processes spatial-token and channel-token streams to achieve decorrelated feature learning.</li>
                    
                    <li>The architecture integrates a 'Squeezed Token Enhancer,' an adaptive calibration module designed for dynamic fusion of the spatial and channel information streams.</li>
                    
                    <li>A 'Multi-Scale FFN' component complements global attention by capturing multi-scale local context, thereby enhancing the modeling of fine-grained structural and semantic dependencies.</li>
                    
                    <li>The model achieves state-of-the-art performance on major hyperspectral benchmarks (Indian Pine, Pavia University, Houston) and the large-scale BigEarthNet remote sensing dataset.</li>
                    
                    <li>Crucially for medical applications, DisentangleFormer demonstrates superior performance on an infrared pathology dataset, indicating its strong potential for diagnostic image analysis.</li>
                    
                    <li>Beyond performance gains, the architecture also retains competitive accuracy on ImageNet while achieving a significant 17.8% reduction in computational cost (FLOPs).</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>DisentangleFormer is a novel Vision Transformer architecture engineered for robust multi-channel vision representation through principled spatial-channel decoupling. Its design incorporates three core components: (1) **Parallel Disentanglement**, which processes spatial-token and channel-token streams independently to facilitate decorrelated feature learning across spatial and spectral dimensions; (2) **Squeezed Token Enhancer**, an adaptive calibration module that dynamically fuses the independently processed spatial and channel streams; and (3) **Multi-Scale FFN**, which complements global attention mechanisms by integrating multi-scale local context to capture fine-grained structural and semantic dependencies.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>DisentangleFormer achieves state-of-the-art performance across numerous hyperspectral benchmarks, including Indian Pine, Pavia University, and Houston, as well as the large-scale BigEarthNet dataset. Significantly, it consistently outperforms existing models on an infrared pathology dataset, underscoring its utility in medical contexts. Additionally, the model maintains competitive accuracy on the ImageNet dataset while reducing computational cost by 17.8% in FLOPs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>In clinical pathology, DisentangleFormer could substantially enhance the accuracy and efficiency of analyzing multi-channel infrared pathology images, potentially leading to earlier and more precise disease diagnosis, improved characterization of tissue pathologies, and more informed treatment decisions. The notable reduction in computational cost could also accelerate image processing in clinical laboratories, making advanced AI-powered diagnostic tools more practical and accessible for routine use.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily focuses on the advantages and performance of DisentangleFormer without explicitly stating specific limitations of the proposed model itself. It rather frames the problem that DisentangleFormer solves as a limitation of standard Vision Transformers.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract mentions that the code will be made publicly available upon acceptance, implying a direction towards broader community adoption and potential collaborative development. However, it does not explicitly outline specific future research directions for the model's further development or expanded applications.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Vision Transformers</span>
                    
                    <span class="tag tag-keyword">Hyperspectral Imaging</span>
                    
                    <span class="tag tag-keyword">Spatial-Channel Decoupling</span>
                    
                    <span class="tag tag-keyword">Infrared Pathology</span>
                    
                    <span class="tag tag-keyword">Multi-channel Vision</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Diagnostic AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Vision Transformers face a fundamental limitation: standard self-attention jointly processes spatial and channel dimensions, leading to entangled representations that prevent independent modeling of structural and semantic dependencies. This problem is especially pronounced in hyperspectral imaging, from satellite hyperspectral remote sensing to infrared pathology imaging, where channels capture distinct biophysical or biochemical cues. We propose DisentangleFormer, an architecture that achieves robust multi-channel vision representation through principled spatial-channel decoupling. Motivated by information-theoretic principles of decorrelated representation learning, our parallel design enables independent modeling of structural and semantic cues while minimizing redundancy between spatial and channel streams. Our design integrates three core components: (1) Parallel Disentanglement: Independently processes spatial-token and channel-token streams, enabling decorrelated feature learning across spatial and spectral dimensions, (2) Squeezed Token Enhancer: An adaptive calibration module that dynamically fuses spatial and channel streams, and (3) Multi-Scale FFN: complementing global attention with multi-scale local context to capture fine-grained structural and semantic dependencies. Extensive experiments on hyperspectral benchmarks demonstrate that DisentangleFormer achieves state-of-the-art performance, consistently outperforming existing models on Indian Pine, Pavia University, and Houston, the large-scale BigEarthNet remote sensing dataset, as well as an infrared pathology dataset. Moreover, it retains competitive accuracy on ImageNet while reducing computational cost by 17.8% in FLOPs. The code will be made publicly available upon acceptance.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>