<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities - Health AI Hub</title>
    <meta name="description" content="MedROV is introduced as the first real-time open-vocabulary object detection (OVOD) model specifically for medical imaging, addressing the limitations of tradit">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20650v1" target="_blank">2511.20650v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedROV is introduced as the first real-time open-vocabulary object detection (OVOD) model specifically for medical imaging, addressing the limitations of traditional closed-set detectors and data scarcity. It achieves this by curating a large multi-modality dataset (Omnis), employing a pseudo-labeling strategy, and integrating knowledge from a pre-trained foundation model, resulting in significant performance improvements and real-time operation at 70 FPS.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This innovation is highly relevant for medical diagnosis and research, as it enables the real-time detection of both known and novel pathological structures or anomalies across various imaging modalities without the need for prior explicit training for every new object, significantly broadening diagnostic capabilities.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedROV applies advanced AI (Open-Vocabulary Object Detection, foundation models, contrastive learning) to medical imaging to enable real-time, generalized detection of anatomical structures and pathologies. This AI application can significantly enhance diagnostic capabilities by identifying not only known conditions but also novel or rare findings in various imaging modalities. Its real-time performance (70 FPS) makes it suitable for integration into clinical settings for faster and more accurate image analysis, potentially improving patient outcomes and healthcare efficiency.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**First Real-Time Medical OVOD:** MedROV is presented as the pioneering real-time Open-Vocabulary Object Detection model for diverse medical imaging, tackling the challenges of limited medical OVOD datasets and closed-set detection. </li>
                    
                    <li>**Omnis Dataset Curation:** A large-scale dataset named "Omnis" was specifically curated, comprising 600,000 detection samples spanning nine different medical imaging modalities to facilitate robust open-vocabulary learning.</li>
                    
                    <li>**Pseudo-labeling Strategy:** A novel pseudo-labeling strategy was implemented to effectively manage and integrate missing annotations common in multi-source medical datasets, thereby maximizing data utility.</li>
                    
                    <li>**Foundation Model Integration:** MedROV enhances its generalization capabilities by incorporating knowledge from large pre-trained foundation models, allowing it to detect both known and previously unseen structures.</li>
                    
                    <li>**Contrastive and Cross-Modal Learning:** The model leverages contrastive learning and cross-modal representations to establish strong text-image alignments, which are crucial for identifying objects with novel labels.</li>
                    
                    <li>**State-of-the-Art Performance:** MedROV achieved an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model for medical image detection and surpassed closed-set detectors by more than 3 mAP50.</li>
                    
                    <li>**Real-Time Operation:** The model demonstrates high efficiency by running at 70 Frames Per Second (FPS), making it suitable for practical, real-time clinical applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MedROV's methodology centers on developing an open-vocabulary object detection model. Key steps include the curation of a large-scale, multi-modal dataset (Omnis) with 600K samples, and the implementation of a pseudo-labeling strategy to handle incomplete annotations from diverse sources. The model integrates knowledge from a pre-trained foundation model to enhance generalization and employs contrastive learning with cross-modal representations to align textual and image features, enabling the detection of both previously observed and novel objects.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedROV significantly outperformed existing methods, demonstrating an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model for medical image detection. It also surpassed traditional closed-set detectors by more than 3 mAP50. Crucially, it achieves this high performance in real-time, operating at an efficient rate of 70 FPS.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedROV has the potential to transform medical diagnostics by enabling the rapid and accurate identification of a broader spectrum of abnormalities, including novel diseases or subtle findings, across diverse medical imaging types. This could lead to earlier and more precise diagnoses, reduce the manual annotation burden for clinicians when new conditions arise, and ultimately improve patient care and outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations specific to MedROV. However, it implicitly addresses inherent challenges in medical OVOD, such as "dataset scarcity and weak text-image alignment," which remain significant hurdles. The reliance on a pseudo-labeling strategy, while effective, might introduce complexities or potential biases if the initial incomplete annotations are of varying quality across the diverse, multi-source dataset.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Medical Diagnostics</span>
                    
                    <span class="tag">Medical Imaging Analysis</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Open-Vocabulary Object Detection</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Real-Time Detection</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Multi-modal Data</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Computer Vision</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>