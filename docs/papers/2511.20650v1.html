<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities - Health AI Hub</title>
    <meta name="description" content="MedROV introduces the first real-time, open-vocabulary object detection (OVOD) model for medical imaging, addressing the limitations of traditional closed-set d">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20650v1" target="_blank">2511.20650v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedROV introduces the first real-time, open-vocabulary object detection (OVOD) model for medical imaging, addressing the limitations of traditional closed-set detectors and the scarcity of OVOD-specific medical datasets. By curating a large multi-modal dataset (Omnis), employing pseudo-labeling, and leveraging pre-trained foundation models, MedROV achieves significant performance gains (40 mAP50 over SOTA foundation model, >3 mAP50 over closed-set) at 70 FPS, setting a new benchmark for medical detection. This enables the detection of both known and novel medical structures across diverse imaging modalities.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances medical diagnostics by enabling AI models to detect unexpected or novel findings in real-time across various imaging types, which is crucial for comprehensive patient assessment and proactive disease management beyond predefined categories. It allows AI to adapt to evolving medical knowledge and rare disease presentations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedROV is an AI model designed to automatically detect objects (e.g., diseases, lesions, anatomical landmarks) in various medical imaging modalities (e.g., X-ray, CT, MRI, ultrasound). Its open-vocabulary nature means it can identify novel structures or conditions not seen during training, enhancing diagnostic capabilities. Its real-time performance (70 FPS) suggests potential for integration into clinical workflows to assist radiologists and clinicians in faster, more accurate diagnosis, screening, and treatment planning, especially for challenging or rare conditions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>MedROV is presented as the first real-time open-vocabulary object detection (OVOD) model specifically designed for diverse medical imaging modalities.</li>
                    
                    <li>It addresses the critical limitations of traditional closed-set medical object detectors, which cannot identify novel or previously unseen labels, a challenge exacerbated by dataset scarcity and weak text-image alignment.</li>
                    
                    <li>A new large-scale dataset, Omnis, comprising 600K detection samples across nine medical imaging modalities, was curated to facilitate open-vocabulary learning.</li>
                    
                    <li>The methodology incorporates a pseudo-labeling strategy to effectively manage missing annotations within multi-source datasets and enhances generalization by integrating knowledge from large pre-trained foundation models.</li>
                    
                    <li>MedROV utilizes contrastive learning and cross-modal representations to enable robust detection of both known and novel anatomical structures or pathologies.</li>
                    
                    <li>Experimental results demonstrate an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model for medical image detection and surpasses closed-set detectors by more than 3 mAP50.</li>
                    
                    <li>The model operates at a real-time speed of 70 Frames Per Second (FPS), establishing a new performance and efficiency benchmark in medical image analysis.</li>
                    
                    <li>Source code, the Omnis dataset, and trained model are openly available for further research and development.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves curating a large-scale, multi-modal medical imaging dataset called Omnis (600K samples across 9 modalities) to specifically enable open-vocabulary learning. A pseudo-labeling strategy is employed to handle missing annotations from multi-source datasets. The MedROV model integrates knowledge from a large pre-trained foundation model and leverages contrastive learning coupled with cross-modal representations to effectively detect both known and previously unseen medical structures.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedROV achieves an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model for medical image detection and surpasses traditional closed-set detectors by more than 3 mAP50. Crucially, it performs these detections at a real-time inference speed of 70 FPS, setting a new benchmark for medical detection tasks.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedROV's real-time, open-vocabulary detection capability can significantly enhance clinical workflows by assisting radiologists and clinicians in rapidly identifying a broader spectrum of abnormalities, including novel or rare conditions, across diverse imaging modalities. This could lead to earlier and more accurate diagnoses, improved screening efficiency, reduced diagnostic errors, and more informed clinical decision-making, ultimately benefiting patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the general challenges of open-vocabulary object detection in medical imaging (dataset scarcity and weak text-image alignment) that MedROV aims to overcome. It does not explicitly state specific limitations of the MedROV model itself within the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated as future directions within the abstract, the authors' provision of the source code, dataset, and trained model on GitHub encourages further research, validation in diverse clinical settings, and potential extensions of MedROV to even more medical imaging modalities or specific diagnostic tasks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">General Medical Image Analysis</span>
                    
                    <span class="tag">Computer-Aided Diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Open-vocabulary detection</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">real-time</span>
                    
                    <span class="tag tag-keyword">foundation models</span>
                    
                    <span class="tag tag-keyword">contrastive learning</span>
                    
                    <span class="tag tag-keyword">pseudo-labeling</span>
                    
                    <span class="tag tag-keyword">object detection</span>
                    
                    <span class="tag tag-keyword">multi-modal</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>