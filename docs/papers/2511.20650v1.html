<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities - Health AI Hub</title>
    <meta name="description" content="MedROV introduces the first real-time open-vocabulary object detection (OVOD) model specifically for diverse medical imaging, addressing the limitations of trad">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20650v1" target="_blank">2511.20650v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedROV introduces the first real-time open-vocabulary object detection (OVOD) model specifically for diverse medical imaging, addressing the limitations of traditional closed-set detectors in identifying novel structures. It achieves this by curating a large-scale multi-modal dataset, employing a pseudo-labeling strategy, and integrating knowledge from foundation models via contrastive learning, resulting in significant performance gains and real-time inference speed. MedROV sets a new benchmark for medical detection by outperforming state-of-the-art models in both accuracy and speed for detecting known and novel pathologies.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances medical diagnostics by enabling AI systems to detect a broader range of abnormalities, including novel or rare conditions not explicitly seen during training, across various imaging types. This capability can lead to earlier and more accurate diagnoses, especially for challenging cases or emerging diseases.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedROV applies open-vocabulary object detection (OVOD) AI to medical images across diverse modalities. Its application is to detect and identify known and previously unseen anatomical structures, anomalies, or pathologies in real-time. This capability can significantly enhance diagnostic accuracy and speed, assist clinicians in identifying rare conditions, improve screening programs, and support personalized treatment planning by providing comprehensive and flexible image analysis capabilities beyond closed-set models.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>MedROV is presented as the first real-time open-vocabulary object detection model designed for diverse medical imaging modalities, overcoming the closed-set limitations of traditional detectors.</li>
                    
                    <li>A large-scale dataset named "Omnis" was curated, containing 600K detection samples across nine different medical imaging modalities, which is crucial for enabling open-vocabulary learning.</li>
                    
                    <li>A pseudo-labeling strategy was developed to effectively handle and leverage multi-source datasets with missing annotations, addressing common data scarcity challenges in medical imaging.</li>
                    
                    <li>The model incorporates knowledge from a large pre-trained foundation model and utilizes contrastive learning with cross-modal representations to enhance generalization to both known and novel medical structures.</li>
                    
                    <li>MedROV achieved an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model for medical image detection.</li>
                    
                    <li>It surpassed traditional closed-set medical detectors by more than 3 mAP50, demonstrating superior adaptability to unseen object classes.</li>
                    
                    <li>The model operates at a high frame rate of 70 FPS, establishing a new benchmark for real-time performance in medical object detection tasks.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MedROV's methodology involves curating a large, multi-modal medical imaging dataset (Omnis, 600K samples across 9 modalities). It employs a pseudo-labeling strategy to generate missing annotations from multi-source datasets. The model integrates knowledge from a large pre-trained foundation model and leverages contrastive learning with cross-modal representations to enable open-vocabulary detection, allowing it to generalize and detect both familiar and novel medical structures.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedROV significantly advanced the state-of-the-art in medical object detection, achieving an average absolute improvement of 40 mAP50 over the previous best foundation model. It also outperformed closed-set detectors by more than 3 mAP50 and demonstrated real-time performance at 70 FPS, establishing a new benchmark for both accuracy and speed in detecting known and novel medical structures.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedROV has the potential to revolutionize clinical workflows by providing highly accurate, real-time detection of medical abnormalities across diverse imaging modalities. Its ability to identify novel or rare pathologies without prior explicit training can aid clinicians in early diagnosis, reduce diagnostic errors, and improve patient outcomes, particularly in complex or under-researched conditions. The real-time capability allows for immediate integration into diagnostic processes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the MedROV model itself, though it mentions the general challenges of 'dataset scarcity and weak text-image alignment' in the field which MedROV aims to address.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic imaging</span>
                    
                    <span class="tag">Pathology (microscopy)</span>
                    
                    <span class="tag">Computer-aided diagnosis (CAD)</span>
                    
                    <span class="tag">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Open-vocabulary detection</span>
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Real-time AI</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Object detection</span>
                    
                    <span class="tag tag-keyword">Foundation models</span>
                    
                    <span class="tag tag-keyword">Contrastive learning</span>
                    
                    <span class="tag tag-keyword">Pseudo-labeling</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>