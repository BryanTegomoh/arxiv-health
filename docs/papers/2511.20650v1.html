<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities - Health AI Hub</title>
    <meta name="description" content="MedROV introduces the first real-time open-vocabulary object detection (OVOD) model for diverse medical imaging, addressing the limitations of traditional close">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20650v1" target="_blank">2511.20650v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Tooba Tehreem Sheikh, Jean Lahoud, Rao Muhammad Anwer, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20650v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20650v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedROV introduces the first real-time open-vocabulary object detection (OVOD) model for diverse medical imaging, addressing the limitations of traditional closed-set detectors that cannot identify novel labels. By curating a large-scale dataset, Omnis, employing pseudo-labeling, and leveraging knowledge from foundation models with contrastive learning, MedROV achieves significant performance gains and real-time inference, setting a new benchmark in medical detection.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This innovation is highly relevant to medicine as it enables AI systems to detect previously unseen or 'novel' anatomical structures, pathologies, or medical devices in imaging, greatly expanding diagnostic capabilities beyond predefined categories and improving adaptability in evolving clinical scenarios.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedROV is an AI model that applies open-vocabulary object detection to medical images. It enables real-time identification of anatomical structures, lesions, or other clinically relevant features, including those that may be novel or not explicitly trained on. This application can significantly enhance diagnostic accuracy, streamline image analysis workflows, and provide comprehensive insights in various medical imaging modalities, assisting clinicians in making faster and more informed decisions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical limitation of closed-set object detection in medical imaging, which cannot detect objects of novel labels.</li>
                    
                    <li>Introduces MedROV, the first real-time open-vocabulary detection model specifically designed for medical imaging.</li>
                    
                    <li>Curates Omnis, a large-scale dataset comprising 600K detection samples across nine diverse medical imaging modalities, to enable open-vocabulary learning.</li>
                    
                    <li>Implements a pseudo-labeling strategy to effectively handle missing annotations from multi-source datasets within Omnis.</li>
                    
                    <li>Enhances generalization and learning efficiency by incorporating knowledge from a large pre-trained foundation model, combined with contrastive learning and cross-modal representations.</li>
                    
                    <li>Achieves an average absolute improvement of 40 mAP50 over previous state-of-the-art foundation models for medical image detection.</li>
                    
                    <li>Surpasses traditional closed-set detectors by more than 3 mAP50 while maintaining a real-time inference speed of 70 FPS.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MedROV's methodology centers on open-vocabulary learning for medical imaging. It involves curating the Omnis dataset (600K samples, 9 modalities) and employing a pseudo-labeling strategy to manage incomplete annotations. The model integrates knowledge from a large pre-trained foundation model and leverages contrastive learning with cross-modal representations to detect both known and novel structures effectively.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>MedROV significantly outperforms existing models, demonstrating an average absolute improvement of 40 mAP50 over the previous state-of-the-art foundation model and more than 3 mAP50 over closed-set detectors. Crucially, it achieves this high performance at a real-time speed of 70 FPS, setting a new benchmark for medical detection.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedROV has the potential to significantly enhance clinical workflows by enabling real-time detection of a broader range of findings, including those not previously explicitly trained for. This could lead to faster and more accurate diagnoses, improved disease monitoring, and enhanced adaptability of AI tools in diverse and evolving clinical contexts, ultimately supporting better patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations specific to MedROV itself, but highlights 'dataset scarcity and weak text-image alignment' as general challenges in the field of OVOD in medical imaging that MedROV aims to address.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for MedROV.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Diagnostic Radiology</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                    <span class="tag">Pathology Detection</span>
                    
                    <span class="tag">Anatomical Structure Identification</span>
                    
                    <span class="tag">Diverse Imaging Modalities (e.g., X-ray, CT, MRI, Ultrasound, etc.)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Open-Vocabulary Detection</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Real-Time</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Contrastive Learning</span>
                    
                    <span class="tag tag-keyword">Object Detection</span>
                    
                    <span class="tag tag-keyword">Pseudo-labeling</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Traditional object detection models in medical imaging operate within a closed-set paradigm, limiting their ability to detect objects of novel labels. Open-vocabulary object detection (OVOD) addresses this limitation but remains underexplored in medical imaging due to dataset scarcity and weak text-image alignment. To bridge this gap, we introduce MedROV, the first Real-time Open Vocabulary detection model for medical imaging. To enable open-vocabulary learning, we curate a large-scale dataset, Omnis, with 600K detection samples across nine imaging modalities and introduce a pseudo-labeling strategy to handle missing annotations from multi-source datasets. Additionally, we enhance generalization by incorporating knowledge from a large pre-trained foundation model. By leveraging contrastive learning and cross-modal representations, MedROV effectively detects both known and novel structures. Experimental results demonstrate that MedROV outperforms the previous state-of-the-art foundation model for medical image detection with an average absolute improvement of 40 mAP50, and surpasses closed-set detectors by more than 3 mAP50, while running at 70 FPS, setting a new benchmark in medical detection. Our source code, dataset, and trained model are available at https://github.com/toobatehreem/MedROV.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>