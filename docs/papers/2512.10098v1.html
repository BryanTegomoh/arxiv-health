<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis - Health AI Hub</title>
    <meta name="description" content="MedXAI is a novel retrieval-augmented and self-verifying framework that integrates deep vision models with clinician-derived expert knowledge to enhance medical">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.10098v1" target="_blank">2512.10098v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Midhat Urooj, Ayan Banerjee, Farhat Shaikh, Kuntal Thakur, Sandeep Gupta
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.10098v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.10098v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedXAI is a novel retrieval-augmented and self-verifying framework that integrates deep vision models with clinician-derived expert knowledge to enhance medical image analysis. It addresses key deep learning limitations such as poor generalization under domain shifts and rare-class bias, while providing human-understandable, clinically aligned explanations by localizing diagnostic features. The framework demonstrates superior performance in accuracy and interpretability, particularly for rare diseases and cross-domain applications.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing AI's role in medical diagnosis by improving accuracy, ensuring reliability under varying clinical conditions, and providing transparent, clinician-understandable explanations. This enables more confident and effective diagnostic decision-making, particularly for complex or rare diseases where current AI struggles.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>MedXAI is an AI framework designed to enhance the accuracy, interpretability, and robustness of deep learning models for medical image analysis and diagnosis. It aims to overcome challenges like domain shifts and rare-class bias by incorporating expert clinical knowledge, providing explainable AI solutions suitable for real-world clinical deployment in areas such as seizure localization and diabetic retinopathy grading.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>MedXAI integrates deep vision models with clinician-derived expert knowledge to improve generalization and reduce rare-class bias in medical AI.</li>
                    
                    <li>It provides intrinsic, human-understandable explanations by localizing relevant diagnostic features, diverging from technical post-hoc methods.</li>
                    
                    <li>The framework was evaluated on two challenging, heterogeneous tasks: Seizure Onset Zone localization from fMRI and Diabetic Retinopathy grading.</li>
                    
                    <li>Experiments on ten multicenter datasets showed a 3% improvement in cross-domain generalization and a 10% F1 score improvement for rare classes.</li>
                    
                    <li>MedXAI substantially outperformed strong deep learning baselines across various performance metrics.</li>
                    
                    <li>Ablation studies confirmed that the symbolic components derived from expert knowledge act as effective clinical priors and regularizers, enhancing robustness under distribution shifts.</li>
                    
                    <li>The framework delivers clinically aligned explanations alongside superior in-domain and cross-domain performance, especially for rare pathologies in multimodal medical AI.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MedXAI is a unified, expert knowledge-based framework that couples deep vision models with clinician-derived symbolic expert knowledge. This integration is designed to guide the model's learning process and provide intrinsic explanations by directly localizing diagnostically relevant features, rather than relying on external post-hoc interpretability techniques like Saliency Maps or LIME.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The MedXAI framework consistently achieved a 3% improvement in cross-domain generalization and a significant 10% F1 score improvement for rare classes, substantially outperforming deep learning baselines. Ablation studies confirmed that the integrated symbolic components effectively function as clinical priors and regularizers, leading to enhanced robustness and improved performance, particularly under distribution shifts.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedXAI has the potential to significantly enhance diagnostic accuracy and reliability in clinical practice, especially for challenging and rare medical conditions. By providing human-understandable, clinically aligned explanations, it can increase trust and adoption among medical professionals, facilitating more precise and timely patient care and potentially reducing diagnostic errors in safety-critical environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the MedXAI framework or the study conducted.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions for MedXAI.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Epilepsy</span>
                    
                    <span class="tag">Diabetes</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                    <span class="tag tag-keyword">Explainable AI (XAI)</span>
                    
                    <span class="tag tag-keyword">Domain Shift</span>
                    
                    <span class="tag tag-keyword">Rare Disease Diagnosis</span>
                    
                    <span class="tag tag-keyword">Knowledge-Guided</span>
                    
                    <span class="tag tag-keyword">fMRI</span>
                    
                    <span class="tag tag-keyword">Diabetic Retinopathy</span>
                    
                    <span class="tag tag-keyword">Clinical Priors</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>https://cmsworkshops.com/Asilomar2025/Papers/Uploads/FinalPapers/Original/1527/20251130102314_899554_1527.pdf</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>