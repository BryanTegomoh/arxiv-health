<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations - Health AI Hub</title>
    <meta name="description" content="This paper introduces MEDIQA-OE 2025, the inaugural shared task focused on extracting actionable medical orders from doctor-patient consultations, a critical st">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26974v1" target="_blank">2510.26974v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jean-Philippe Corbeil, Asma Ben Abacha, Jerome Tremblay, Phillip Swazinna, Akila Jeeson Daniel, Miguel Del-Agua, Francois Beaulieu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26974v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26974v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MEDIQA-OE 2025, the inaugural shared task focused on extracting actionable medical orders from doctor-patient consultations, a critical step towards automating clinical documentation. Six participating teams explored diverse methodologies, including both closed- and open-weight large language models, to address the challenge of converting spoken interactions into structured Electronic Health Record (EHR) entries. The paper details the task, dataset, final leaderboard, and the innovative solutions developed by the participants.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Automating medical order extraction directly addresses clinician burnout by reducing manual documentation time, thereby allowing more focus on patient care. This technology is crucial for enhancing the efficiency and accuracy of Electronic Health Records, ensuring timely and appropriate patient management.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves developing and evaluating Natural Language Processing (NLP) models, particularly Large Language Models (LLMs), to automatically identify and extract structured medical orders from unstructured doctor-patient consultation dialogues. The goal is to automate and streamline the creation of medical orders, thereby improving the efficiency of clinical documentation and data input into EHRs, which directly impacts clinician burden and patient care.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Identifies a significant unmet need in clinical documentation: converting doctor-patient conversations into actionable medical orders for EHRs.</li>
                    
                    <li>Introduces MEDIQA-OE 2025, the first shared task specifically addressing medical order extraction from clinical dialogues.</li>
                    
                    <li>Aims to substantially reduce the documentation burden on clinicians and directly improve downstream patient care by automating this process.</li>
                    
                    <li>Six teams participated, experimenting with a broad spectrum of natural language processing approaches, including various Large Language Models (LLMs).</li>
                    
                    <li>Participant solutions leveraged both commercially available (closed-weight) and publicly accessible (open-weight) LLMs.</li>
                    
                    <li>The paper provides an overview of the MEDIQA-OE task, the dataset utilized, the final ranking of participating teams, and a description of their technical solutions.</li>
                    
                    <li>The initiative highlights the potential for advanced NLP and AI to bridge the gap between spoken clinical interactions and structured medical records.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper *describes* a shared task. The methodologies *employed by participants* involved a broad range of natural language processing (NLP) approaches, particularly leveraging both closed-source (e.g., proprietary) and open-source Large Language Models (LLMs) to extract structured medical orders from conversational data. The paper presents the task definition, dataset characteristics, and a comparative analysis of these participant-developed solutions.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding from the abstract is the successful execution of the first-ever MEDIQA-OE shared task, demonstrating that six teams were able to participate and explore a broad range of approaches, including both closed- and open-weight LLMs, for medical order extraction. While specific performance metrics are not detailed in the abstract, the participation and diverse methodologies indicate active and promising research in this challenging domain.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has significant potential to revolutionize clinical workflows by drastically reducing the time clinicians spend on documentation, freeing them to engage more directly with patients. Accurate and automated extraction of medical orders can enhance patient safety by minimizing transcription errors, ensure timely execution of care plans, and improve the overall efficiency and data integrity within Electronic Health Records.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract for this overview paper does not explicitly state limitations of the task or the participant solutions. It primarily introduces the task and its scope.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract, but the introduction of a shared task implicitly sets the stage for continuous research and development. Future directions would likely include improving the accuracy and robustness of extraction models, handling diverse clinical dialogue styles, integrating these solutions into real-world EHR systems, and exploring multimodal approaches.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Health Information Management</span>
                    
                    <span class="tag">Medical Natural Language Processing</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">EHR Systems</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Order Extraction</span>
                    
                    <span class="tag tag-keyword">Doctor-Patient Consultations</span>
                    
                    <span class="tag tag-keyword">Clinical Documentation</span>
                    
                    <span class="tag tag-keyword">Electronic Health Records (EHR)</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Shared Task</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>