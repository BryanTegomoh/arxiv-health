<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery - Health AI Hub</title>
    <meta name="description" content="This paper introduces US-X Complete, a novel multi-modal deep learning method designed to overcome ultrasound's inherent limitation in visualizing complete vert">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15600v1" target="_blank">2511.15600v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-19
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Miruna-Alexandra Gafencu, Yordanka Velikova, Nassir Navab, Mohammad Farid Azampour
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15600v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15600v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces US-X Complete, a novel multi-modal deep learning method designed to overcome ultrasound's inherent limitation in visualizing complete vertebral anatomy due to acoustic shadowing. By leveraging complementary morphological information from a single X-ray image and 3D partial ultrasound data, the method significantly improves vertebral reconstruction, providing a more accurate and complete volumetric lumbar spine visualization without requiring preoperative CT registration.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This method significantly enhances intraoperative guidance for spinal procedures by providing a complete, accurate 3D view of vertebral anatomy using radiation-free ultrasound, supplemented by a single X-ray, thereby reducing reliance on higher-radiation preoperative scans like CT and potentially improving patient safety and outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is a multi-modal deep learning system that enhances 3D ultrasound imaging of the spine for intraoperative guidance. By integrating complementary information from a single X-ray image, the AI completes occluded anatomical structures, providing a more accurate and complete volumetric visualization of the lumbar spine. This aims to improve surgical precision and reduce the need for pre-operative CT registration in spinal procedures.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses ultrasound's limitation in spinal imaging, specifically the inability to visualize complete vertebral anatomy (e.g., vertebral bodies) due to acoustic shadowing.</li>
                    
                    <li>Proposes US-X Complete, a novel multi-modal deep learning approach that integrates 3D ultrasound data with information from a single 2D X-ray image.</li>
                    
                    <li>Utilizes a unique training data generation strategy: simulated 2D lateral vertebral X-ray views and 3D partial vertebral representations mimicking ultrasound's limited visibility.</li>
                    
                    <li>Demonstrates significant improvements in vertebral reconstruction accuracy (p < 0.001) compared to state-of-the-art 3D ultrasound vertebral completion methods.</li>
                    
                    <li>Enables accurate, complete volumetric lumbar spine visualization directly overlaid on the ultrasound scan, eliminating the need for preoperative registration with modalities like CT.</li>
                    
                    <li>The method performs phantom studies as an initial validation step towards future clinical translation, showcasing its potential for practical application.</li>
                    
                    <li>Preserves the key strengths of ultrasound (radiation-free, real-time, cost-effective) while mitigating its primary limitation of incomplete anatomical visualization.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a novel multi-modal deep learning approach that integrates 3D ultrasound data with complementary information from a single 2D X-ray image. It utilizes synthetically generated paired training data, comprising simulated 2D lateral vertebral X-ray views and 3D partial vertebral representations mimicking ultrasound occlusions, to learn and complete missing anatomical structures. The deep learning model is trained to leverage morphological information from both modalities to achieve accurate 3D shape recovery.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings indicate a statistically significant improvement (p < 0.001) in vertebral reconstruction accuracy compared to existing 3D ultrasound completion methods. The system successfully provides a more accurate and complete volumetric visualization of the lumbar spine, which can be directly overlaid on ultrasound scans without the need for registration with preoperative modalities such as computed tomography.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The clinical impact includes enabling more precise and safer intraoperative guidance for spinal procedures by offering a comprehensive 3D visualization of the spine without the need for high-radiation preoperative CT scans. This approach preserves the real-time, cost-effective, and radiation-free benefits of ultrasound while overcoming its primary limitation, potentially leading to improved patient outcomes, reduced procedure times, and lower healthcare costs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The current work is presented as an 'initial step to future clinical translation,' indicating that the method has been validated primarily through phantom studies. Further validation in human clinical trials, including robustness across diverse patient anatomies and pathologies, is implicitly a current limitation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The authors explicitly state that phantom studies are an 'initial step to future clinical translation,' strongly implying that future work will involve validating the method in clinical settings with human subjects to assess its real-world efficacy, robustness, and generalizability.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Spine Surgery</span>
                    
                    <span class="tag">Neurosurgery</span>
                    
                    <span class="tag">Orthopedic Surgery</span>
                    
                    <span class="tag">Interventional Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Ultrasound</span>
                    
                    <span class="tag tag-keyword">X-ray</span>
                    
                    <span class="tag tag-keyword">Multi-modal imaging</span>
                    
                    <span class="tag tag-keyword">Deep learning</span>
                    
                    <span class="tag tag-keyword">Vertebral reconstruction</span>
                    
                    <span class="tag tag-keyword">Spinal procedures</span>
                    
                    <span class="tag tag-keyword">Anatomical completion</span>
                    
                    <span class="tag tag-keyword">Acoustic shadowing</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Ultrasound offers a radiation-free, cost-effective solution for real-time visualization of spinal landmarks, paraspinal soft tissues and neurovascular structures, making it valuable for intraoperative guidance during spinal procedures. However, ultrasound suffers from inherent limitations in visualizing complete vertebral anatomy, in particular vertebral bodies, due to acoustic shadowing effects caused by bone. In this work, we present a novel multi-modal deep learning method for completing occluded anatomical structures in 3D ultrasound by leveraging complementary information from a single X-ray image. To enable training, we generate paired training data consisting of: (1) 2D lateral vertebral views that simulate X-ray scans, and (2) 3D partial vertebrae representations that mimic the limited visibility and occlusions encountered during ultrasound spine imaging. Our method integrates morphological information from both imaging modalities and demonstrates significant improvements in vertebral reconstruction (p < 0.001) compared to state of art in 3D ultrasound vertebral completion. We perform phantom studies as an initial step to future clinical translation, and achieve a more accurate, complete volumetric lumbar spine visualization overlayed on the ultrasound scan without the need for registration with preoperative modalities such as computed tomography. This demonstrates that integrating a single X-ray projection mitigates ultrasound's key limitation while preserving its strengths as the primary imaging modality. Code and data can be found at https://github.com/miruna20/US-X-Complete</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted at the Workshop on Shape in Medical Imaging at MICCAI 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>