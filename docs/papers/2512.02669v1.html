<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAND Challenge: Four Approaches for Dysartria Severity Classification - Health AI Hub</title>
    <meta name="description" content="This paper investigates four distinct modeling approaches‚ÄîViT-OF, 1D-CNN, BiLSTM-OF, and Hierarchical XGBoost‚Äîfor classifying dysarthria severity into five clas">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>SAND Challenge: Four Approaches for Dysartria Severity Classification</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.02669v1" target="_blank">2512.02669v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-02
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Gauri Deshpande, Harish Battula, Ashish Panda, Sunil Kumar Kopparapu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.SD, cs.AI, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.02669v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.02669v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper investigates four distinct modeling approaches‚ÄîViT-OF, 1D-CNN, BiLSTM-OF, and Hierarchical XGBoost‚Äîfor classifying dysarthria severity into five classes using a common speech dataset. While the feature-engineered Hierarchical XGBoost ensemble achieved the highest macro-F1 score of 0.86, deep learning models also demonstrated competitive performance (0.70 macro-F1), offering complementary perspectives for automated speech analysis in neurodegenerative diseases.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critical for developing objective, automated tools to assess and monitor dysarthria severity, a common symptom in various neurodegenerative diseases. Such tools can significantly aid in early diagnosis, tracking disease progression, and personalizing therapeutic interventions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research applies various AI/machine learning models (Vision Transformers, CNNs, BiLSTMs, XGBoost ensembles) to classify the severity of dysarthria. This provides an AI-powered diagnostic and monitoring tool that can objectively assess a patient's speech impairment, aiding clinicians in diagnosing neurodegenerative diseases, tracking disease progression, and evaluating the effectiveness of treatments or therapies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The study addresses a five-class dysarthria severity classification task using a common dataset of speech recordings from the SAND challenge.</li>
                    
                    <li>Four distinct modeling approaches were evaluated: ViT-OF (Vision Transformer on spectrograms), a 1D-CNN ensemble, a BiLSTM-OF ensemble, and a Hierarchical XGBoost ensemble.</li>
                    
                    <li>The Hierarchical XGBoost model uniquely leveraged a two-stage learning framework combining glottal and formant speech features.</li>
                    
                    <li>Performance was assessed on a validation set comprising 53 speakers, using the macro-F1 score as the primary evaluation metric.</li>
                    
                    <li>The Hierarchical XGBoost ensemble achieved the highest macro-F1 score of 0.86, demonstrating superior performance among the tested methods.</li>
                    
                    <li>The deep learning models (ViT-OF, 1D-CNN, BiLSTM-OF) exhibited competitive macro-F1 scores, all around 0.70.</li>
                    
                    <li>The findings suggest that both sophisticated feature engineering with traditional machine learning and deep learning approaches offer valuable, potentially complementary insights for dysarthria severity classification.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study utilized a common dataset of speech recordings for a five-class dysarthria severity classification task. Four distinct models were developed and evaluated: (1) ViT-OF, applying a Vision Transformer to spectrogram images; (2) a 1D-CNN approach, employing an ensemble of eight 1-D CNNs with majority-vote fusion; (3) a BiLSTM-OF approach, using an ensemble of nine BiLSTM models with majority-vote fusion; and (4) a Hierarchical XGBoost ensemble, which combined glottal and formant features within a two-stage learning framework. All models were compared based on their macro-F1 scores on a validation set of 53 speakers.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The Hierarchical XGBoost ensemble, leveraging a two-stage learning framework on glottal and formant features, achieved the highest performance with a macro-F1 score of 0.86. The deep learning models (ViT-OF, 1D-CNN, BiLSTM-OF) also demonstrated competitive macro-F1 scores of approximately 0.70. This indicates that while advanced feature engineering coupled with traditional machine learning can yield superior results for this specific task, deep learning approaches offer robust alternatives and distinct analytical perspectives.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work contributes to the development of objective, quantitative measures for dysarthria severity, reducing reliance on subjective clinical assessment. It has the potential to enhance the accuracy and consistency of diagnosis, facilitate monitoring of disease progression in neurodegenerative conditions, and support personalized rehabilitation strategies for patients with speech impairments by providing an automated, consistent evaluation tool.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The evaluation was performed on a relatively small validation set of 53 speakers, which might limit the generalizability of the findings to a broader population. The abstract does not detail the performance per individual severity class, which could be important for fine-grained clinical utility, nor does it discuss the computational complexity or real-time applicability of the proposed models.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated, the mention of 'complementary insights' suggests future research could focus on developing hybrid ensemble strategies that combine the strengths of feature-engineered models (like XGBoost) with deep learning architectures to potentially achieve higher accuracy and robustness. Expanding the dataset size and diversity, along with investigating the interpretability of deep learning models, would also be valuable next steps for clinical deployment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Speech-Language Pathology</span>
                    
                    <span class="tag">Neuroscience</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Dysarthria Classification</span>
                    
                    <span class="tag tag-keyword">Speech Analysis</span>
                    
                    <span class="tag tag-keyword">Neurodegenerative Diseases</span>
                    
                    <span class="tag tag-keyword">XGBoost</span>
                    
                    <span class="tag tag-keyword">Deep Learning</span>
                    
                    <span class="tag tag-keyword">Vision Transformer</span>
                    
                    <span class="tag tag-keyword">BiLSTM</span>
                    
                    <span class="tag tag-keyword">Severity Assessment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">This paper presents a unified study of four distinct modeling approaches for classifying dysarthria severity in the Speech Analysis for Neurodegenerative Diseases (SAND) challenge. All models tackle the same five class classification task using a common dataset of speech recordings. We investigate: (1) a ViT-OF method leveraging a Vision Transformer on spectrogram images, (2) a 1D-CNN approach using eight 1-D CNN's with majority-vote fusion, (3) a BiLSTM-OF approach using nine BiLSTM models with majority vote fusion, and (4) a Hierarchical XGBoost ensemble that combines glottal and formant features through a two stage learning framework. Each method is described, and their performances on a validation set of 53 speakers are compared. Results show that while the feature-engineered XGBoost ensemble achieves the highest macro-F1 (0.86), the deep learning models (ViT, CNN, BiLSTM) attain competitive F1-scores (0.70) and offer complementary insights into the problem.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>7 pages, 5 figures</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>