<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation - Health AI Hub</title>
    <meta name="description" content="HBFormer addresses the critical limitation of existing Vision Transformers in medical image segmentation, specifically their struggle to fuse local details with">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.03597v1" target="_blank">2512.03597v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fuchen Zheng, Xinyi Chen, Weixuan Li, Quanjun Li, Junhua Zhou, Xiaojiao Guo, Xuhang Chen, Chi-Man Pun, Shoujun Zhou
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.03597v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.03597v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">HBFormer addresses the critical limitation of existing Vision Transformers in medical image segmentation, specifically their struggle to fuse local details with global context, which is particularly detrimental for microtumors and miniature organs. This novel Hybrid-Bridge Transformer combines a U-shaped architecture with a Swin Transformer backbone and introduces a Multi-Scale Feature Fusion (MFF) decoder, designed with attention modules and specialized convolutions, to effectively integrate multi-scale and global contextual information. The architecture achieves state-of-the-art performance on challenging medical image segmentation datasets, demonstrating superior capabilities for microtumor and miniature organ segmentation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and precise segmentation of microtumors and miniature organs is paramount for early disease detection, precise diagnosis, personalized treatment planning (e.g., radiation oncology, surgical guidance), and monitoring therapeutic response in various clinical settings, directly impacting patient prognosis and care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>HBFormer is an AI model (Hybrid-Bridge Transformer) designed for automated and highly precise segmentation of microtumors and miniature organs from medical images. This application aims to improve the accuracy and efficiency of clinical diagnostics, potentially leading to earlier disease detection (e.g., cancer) and more effective treatment planning in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** Current Vision Transformers, including Swin Transformers, struggle with localized attention mechanisms that fail to effectively fuse local details with global context, hindering accurate segmentation of microtumors and miniature organs.</li>
                    
                    <li>**Novel Architecture:** Proposes HBFormer, a Hybrid-Bridge Transformer, integrating a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction.</li>
                    
                    <li>**Core Innovation - Multi-Scale Feature Fusion (MFF) Decoder:** Introduces a novel 'Bridge' mechanism embodied by the MFF decoder, which is architecturally distinct from conventional symmetric designs.</li>
                    
                    <li>**MFF Decoder Mechanism:** The MFF decoder is engineered to fuse multi-scale features from the encoder with crucial global contextual information.</li>
                    
                    <li>**Component Design:** Achieves feature fusion through a synergistic combination of channel and spatial attention modules, constructed from a series of dilated and depth-wise convolutions.</li>
                    
                    <li>**Enhanced Capabilities:** These components explicitly capture long-range dependencies and refine object boundaries with exceptional precision, crucial for fine-grained segmentation.</li>
                    
                    <li>**State-of-the-Art Performance:** Comprehensive experiments demonstrate HBFormer achieves state-of-the-art results on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>HBFormer employs a Hybrid-Bridge Transformer architecture built upon a U-shaped encoder-decoder framework with a Swin Transformer backbone for hierarchical feature extraction. Its primary innovation is the Multi-Scale Feature Fusion (MFF) decoder, which serves as a 'bridge'. This MFF decoder integrates multi-scale features from the encoder with global contextual information via a synergistic combination of channel and spatial attention modules. These attention modules are constructed using dilated and depth-wise convolutions, specifically designed to capture long-range dependencies and refine object boundaries.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>HBFormer consistently achieves state-of-the-art results on challenging medical image segmentation datasets, including benchmarks for multi-organ, liver tumor, and bladder tumor segmentation. This demonstrates its outstanding capabilities, particularly in the precise segmentation of microtumors and miniature organs.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The superior segmentation precision offered by HBFormer for microtumors and miniature organs can significantly enhance clinical workflows by enabling earlier and more accurate disease detection, precise delineation of targets for radiation therapy, improved surgical planning by defining exact tumor margins, and more reliable assessment of treatment efficacy, leading to improved patient outcomes and more informed clinical decision-making.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights limitations of existing Vision Transformers regarding their struggle to fuse local details with global context. It does not explicitly state any inherent limitations or caveats regarding the proposed HBFormer architecture itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for HBFormer.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Urology</span>
                    
                    <span class="tag">Gastroenterology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Vision Transformer</span>
                    
                    <span class="tag tag-keyword">Microtumor Segmentation</span>
                    
                    <span class="tag tag-keyword">Miniature Organ Segmentation</span>
                    
                    <span class="tag tag-keyword">Hybrid-Bridge Transformer</span>
                    
                    <span class="tag tag-keyword">Multi-Scale Feature Fusion</span>
                    
                    <span class="tag tag-keyword">Attention Mechanisms</span>
                    
                    <span class="tag tag-keyword">Dilated Convolutions</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical image segmentation is a cornerstone of modern clinical diagnostics. While Vision Transformers that leverage shifted window-based self-attention have established new benchmarks in this field, they are often hampered by a critical limitation: their localized attention mechanism struggles to effectively fuse local details with global context. This deficiency is particularly detrimental to challenging tasks such as the segmentation of microtumors and miniature organs, where both fine-grained boundary definition and broad contextual understanding are paramount. To address this gap, we propose HBFormer, a novel Hybrid-Bridge Transformer architecture. The 'Hybrid' design of HBFormer synergizes a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction. The core innovation lies in its 'Bridge' mechanism, a sophisticated nexus for multi-scale feature integration. This bridge is architecturally embodied by our novel Multi-Scale Feature Fusion (MFF) decoder. Departing from conventional symmetric designs, the MFF decoder is engineered to fuse multi-scale features from the encoder with global contextual information. It achieves this through a synergistic combination of channel and spatial attention modules, which are constructed from a series of dilated and depth-wise convolutions. These components work in concert to create a powerful feature bridge that explicitly captures long-range dependencies and refines object boundaries with exceptional precision. Comprehensive experiments on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks, demonstrate that HBFormer achieves state-of-the-art results, showcasing its outstanding capabilities in microtumor and miniature organ segmentation. Code and models are available at: https://github.com/lzeeorno/HBFormer.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>6 pages, 4 figures, 3 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>