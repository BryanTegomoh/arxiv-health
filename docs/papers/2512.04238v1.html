<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces AdversarialAnatomyBench, the first benchmark specifically designed to test vision-language models (VLMs) on naturally occurring rare anato">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04238v1" target="_blank">2512.04238v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Leon Mayer, Piotr Kalinowski, Caroline Ebersbach, Marcel Knopp, Tim R√§dsch, Evangelia Christodoulou, Annika Reinke, Fiona R. Kolbinger, Lena Maier-Hein
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04238v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04238v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces AdversarialAnatomyBench, the first benchmark specifically designed to test vision-language models (VLMs) on naturally occurring rare anatomical variants across various imaging modalities. The study reveals a critical weakness: state-of-the-art VLMs, including top performers like GPT-5 and Gemini 2.5 Pro, experience a drastic performance drop (from 74% to 29% mean accuracy) when confronted with atypical anatomy compared to typical presentations, with current mitigation strategies proving ineffective.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for medical AI safety and efficacy, demonstrating that current VLMs are unreliable in identifying or interpreting rare but real anatomical variations, which could lead to critical diagnostic errors or missed pathologies in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research directly informs the development and evaluation of AI systems used for interpreting medical images, assisting with diagnosis, and potentially guiding clinical decision-making. By identifying weaknesses in VLMs when encountering rare anatomical variants, it aims to improve the robustness and reliability of medical AI applications, ensuring they can perform accurately across a wide spectrum of patient presentations, thus enhancing patient safety and diagnostic precision.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Introduction of AdversarialAnatomyBench**: A novel benchmark comprising naturally occurring rare anatomical variants from diverse imaging modalities and anatomical regions.</li>
                    
                    <li>**Definition of Natural Adversarial Anatomy**: These variants violate learned priors about 'typical' human anatomy, presenting a unique challenge for VLMs.</li>
                    
                    <li>**Benchmarking of 22 State-of-the-Art VLMs**: The study rigorously tested a wide array of current VLMs, including leading commercial and open-source models, on basic medical perception tasks.</li>
                    
                    <li>**Significant Performance Degradation**: Mean accuracy for VLMs plummeted from 74% on typical anatomy to a mere 29% on atypical anatomy, highlighting a severe generalization gap.</li>
                    
                    <li>**Failure of Top Models**: Even the highest-performing models (GPT-5, Gemini 2.5 Pro, Llama 4 Maverick) exhibited substantial performance drops, ranging from 41% to 51% on rare variants.</li>
                    
                    <li>**Anatomical Bias in Errors**: Model errors consistently mirrored expected anatomical biases, suggesting VLMs rely heavily on common anatomical patterns.</li>
                    
                    <li>**Ineffectiveness of Mitigation Strategies**: Neither model scaling (larger models) nor interventions like bias-aware prompting or test-time reasoning were able to resolve the observed performance issues.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved creating AdversarialAnatomyBench, a curated dataset of naturally occurring rare anatomical variants across various imaging modalities. This benchmark was then used to evaluate the performance of 22 state-of-the-art vision-language models on basic medical perception tasks, comparing their accuracy on 'typical' versus 'atypical' anatomical presentations. Experiments also investigated the impact of model scaling and intervention techniques like prompting and test-time reasoning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>['A dramatic drop in VLM accuracy from 74% on typical anatomy to 29% on atypical anatomy for basic medical perception tasks.', 'Best-performing models (GPT-5, Gemini 2.5 Pro, Llama 4 Maverick) suffered significant performance decreases of 41-51% when encountering rare anatomical variants.', 'Observed model errors were closely aligned with expected anatomical biases, indicating a reliance on prevalent anatomical priors.', 'Neither increased model scale nor specialized interventions (bias-aware prompting, test-time reasoning) effectively mitigated the generalization issues on rare anatomical presentations.']</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings have profound clinical impact, highlighting a significant patient safety concern. VLMs integrated into clinical workflows could misinterpret or completely fail to recognize rare but clinically significant anatomical variants, leading to misdiagnoses, delayed treatment, or incorrect surgical planning. This necessitates rigorous testing against such 'natural adversarial' cases before widespread clinical deployment and emphasizes the need for bias mitigation in medical AI to ensure equitable and safe patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The study identifies a critical and previously unquantified limitation in current VLMs: their poor generalization to rare anatomical presentations. It also implicitly highlights the limitation of existing benchmarks, which primarily assess performance on common anatomical presentations and fail to capture these crucial challenges.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper posits that AdversarialAnatomyBench provides a foundational tool for systematically measuring and, importantly, mitigating anatomical bias in multimodal medical AI systems. This implies future research will focus on developing and evaluating new model architectures, training methodologies, or fine-tuning approaches specifically designed to improve VLM robustness and generalization to rare anatomical variants.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Vision-language models</span>
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                    <span class="tag tag-keyword">Rare anatomical variants</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                    <span class="tag tag-keyword">Anatomical bias</span>
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Adversarial examples</span>
                    
                    <span class="tag tag-keyword">Clinical workflows</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Vision-language models are increasingly integrated into clinical workflows. However, existing benchmarks primarily assess performance on common anatomical presentations and fail to capture the challenges posed by rare variants. To address this gap, we introduce AdversarialAnatomyBench, the first benchmark comprising naturally occurring rare anatomical variants across diverse imaging modalities and anatomical regions. We call such variants that violate learned priors about "typical" human anatomy natural adversarial anatomy. Benchmarking 22 state-of-the-art VLMs with AdversarialAnatomyBench yielded three key insights. First, when queried with basic medical perception tasks, mean accuracy dropped from 74% on typical to 29% on atypical anatomy. Even the best-performing models, GPT-5, Gemini 2.5 Pro, and Llama 4 Maverick, showed performance drops of 41-51%. Second, model errors closely mirrored expected anatomical biases. Third, neither model scaling nor interventions, including bias-aware prompting and test-time reasoning, resolved these issues. These findings highlight a critical and previously unquantified limitation in current VLM: their poor generalization to rare anatomical presentations. AdversarialAnatomyBench provides a foundation for systematically measuring and mitigating anatomical bias in multimodal medical AI systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>