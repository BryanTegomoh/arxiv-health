<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models - Health AI Hub</title>
    <meta name="description" content="This paper introduces AdversarialAnatomyBench, the first benchmark dataset comprising naturally occurring rare anatomical variants across various medical imagin">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.04238v1" target="_blank">2512.04238v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-03
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Leon Mayer, Piotr Kalinowski, Caroline Ebersbach, Marcel Knopp, Tim R√§dsch, Evangelia Christodoulou, Annika Reinke, Fiona R. Kolbinger, Lena Maier-Hein
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.04238v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.04238v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces AdversarialAnatomyBench, the first benchmark dataset comprising naturally occurring rare anatomical variants across various medical imaging modalities, to evaluate the robustness of Vision-Language Models (VLMs). Benchmarking 22 state-of-the-art VLMs revealed a drastic accuracy drop from 74% on typical to 29% on atypical anatomy, with leading models also showing significant performance degradation, highlighting a critical generalization weakness. The findings emphasize that current VLMs struggle with uncommon medical presentations, posing substantial risks for their integration into clinical workflows.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically important for patient safety and the responsible integration of AI in healthcare. It reveals that VLMs, if deployed clinically without addressing these weaknesses, could misinterpret or completely miss rare but crucial anatomical findings, potentially leading to incorrect diagnoses, delayed treatments, or adverse patient outcomes for individuals with atypical presentations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research is entirely focused on the application of AI (specifically Vision-Language Models) in health and medicine. It evaluates the robustness and reliability of AI systems for medical perception tasks, such as interpreting medical images and identifying anatomical features or anomalies. The findings are critical for the development and deployment of medical AI applications in areas like diagnostic assistance, automated image analysis, and clinical decision support systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current medical VLM benchmarks primarily assess performance on common anatomical presentations, failing to capture challenges posed by rare variants.</li>
                    
                    <li>The paper introduces AdversarialAnatomyBench, a novel benchmark dataset of naturally occurring rare anatomical variants, dubbed 'natural adversarial anatomy,' spanning diverse imaging modalities and regions.</li>
                    
                    <li>Benchmarking 22 state-of-the-art VLMs demonstrated a significant mean accuracy drop from 74% on typical anatomy to 29% on atypical anatomy for basic medical perception tasks.</li>
                    
                    <li>Even the best-performing models (GPT-5, Gemini 2.5 Pro, Llama 4 Maverick) experienced substantial performance drops of 41-51% when encountering rare anatomical variants.</li>
                    
                    <li>Model errors were found to closely mirror expected anatomical biases, indicating a reliance on learned 'typical' anatomical priors.</li>
                    
                    <li>Neither model scaling nor advanced interventions like bias-aware prompting or test-time reasoning effectively resolved these issues.</li>
                    
                    <li>The study quantifies a critical and previously unaddressed limitation of VLMs: their poor generalization capabilities to rare anatomical presentations.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved creating AdversarialAnatomyBench, a new benchmark dataset curated with naturally occurring rare anatomical variants across various medical imaging modalities and anatomical regions. This benchmark was then used to evaluate the performance of 22 state-of-the-art Vision-Language Models (VLMs) on basic medical perception tasks. The evaluation compared VLM accuracy on typical versus atypical anatomical presentations and analyzed the nature of errors. Additionally, the researchers investigated whether model scaling or interventions like bias-aware prompting and test-time reasoning could mitigate the observed performance drops.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>1. **Significant Performance Degradation:** Vision-language models exhibited a drastic decline in accuracy, from a mean of 74% on typical anatomical presentations to only 29% on rare, atypical anatomy. Top-tier models experienced severe performance drops of 41-51%. 2. **Anatomical Bias in Errors:** Model errors were consistent with expected anatomical biases, suggesting VLMs strongly prioritize learned common anatomical patterns. 3. **Ineffectiveness of Mitigation Strategies:** Attempts to improve performance through increased model scaling or advanced interventions such as bias-aware prompting and test-time reasoning proved unsuccessful in addressing these generalization issues.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings have profound clinical impact, highlighting a major barrier to the safe and effective deployment of VLMs in clinical practice. The demonstrated failure of VLMs to reliably interpret rare anatomical variants means they are currently unfit for autonomous decision-making in diverse patient populations. This necessitates stringent validation, continuous human oversight, and specialized training data focused on atypical cases to prevent misdiagnosis and ensure equitable, high-quality care for all patients, particularly those with uncommon conditions.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper identifies a critical and previously unquantified limitation of current Vision-Language Models: their profound inability to generalize robustly to rare anatomical presentations. This intrinsic weakness is not resolved by increasing model scale or implementing advanced prompting/reasoning techniques. It also implicitly highlights a limitation of existing VLM benchmarks, which are inadequate for assessing real-world clinical performance due to their focus on common anatomical presentations.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The AdversarialAnatomyBench provides a crucial foundation for systematically measuring, quantifying, and mitigating anatomical bias in multimodal medical AI systems. This opens avenues for future research to develop more robust VLM architectures, novel training methodologies, and bias-aware learning algorithms specifically designed to improve generalization to rare anatomical variants, thereby enhancing the reliability and safety of medical AI in diverse clinical scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical AI</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Vision-language models (VLMs)</span>
                    
                    <span class="tag tag-keyword">Adversarial examples</span>
                    
                    <span class="tag tag-keyword">Anatomical variants</span>
                    
                    <span class="tag tag-keyword">Medical imaging</span>
                    
                    <span class="tag tag-keyword">Generalization</span>
                    
                    <span class="tag tag-keyword">AI bias</span>
                    
                    <span class="tag tag-keyword">Clinical workflows</span>
                    
                    <span class="tag tag-keyword">Benchmarking</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Vision-language models are increasingly integrated into clinical workflows. However, existing benchmarks primarily assess performance on common anatomical presentations and fail to capture the challenges posed by rare variants. To address this gap, we introduce AdversarialAnatomyBench, the first benchmark comprising naturally occurring rare anatomical variants across diverse imaging modalities and anatomical regions. We call such variants that violate learned priors about "typical" human anatomy natural adversarial anatomy. Benchmarking 22 state-of-the-art VLMs with AdversarialAnatomyBench yielded three key insights. First, when queried with basic medical perception tasks, mean accuracy dropped from 74% on typical to 29% on atypical anatomy. Even the best-performing models, GPT-5, Gemini 2.5 Pro, and Llama 4 Maverick, showed performance drops of 41-51%. Second, model errors closely mirrored expected anatomical biases. Third, neither model scaling nor interventions, including bias-aware prompting and test-time reasoning, resolved these issues. These findings highlight a critical and previously unquantified limitation in current VLM: their poor generalization to rare anatomical presentations. AdversarialAnatomyBench provides a foundation for systematically measuring and mitigating anatomical bias in multimodal medical AI systems.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>