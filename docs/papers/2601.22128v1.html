<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR - Health AI Hub</title>
    <meta name="description" content="This paper introduces SMB-Structure, a novel 'world model' paradigm for longitudinal EHR that addresses the limitations of next-word-prediction LLMs in capturin">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.22128v1" target="_blank">2601.22128v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-29
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Irsyad Adam, Zekai Chen, David Laprade, Shaun Porwal, David Laub, Erik Reinertsen, Arda Pekis, Kevin Brown
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI, cs.CE, q-bio.QM
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.22128v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.22128v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SMB-Structure, a novel 'world model' paradigm for longitudinal EHR that addresses the limitations of next-word-prediction LLMs in capturing dynamic patient trajectories. By integrating a Joint-Embedding Prediction Architecture (JEPA) with next-token prediction (SFT), SMB-Structure learns embeddings that explicitly encode future patient states and disease dynamics from initial representations. Validated on large oncology and pulmonary embolism cohorts, the model demonstrates superior capture of disease dynamics and competitive performance on complex tasks characterized by high patient heterogeneity.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This approach is crucial for precision medicine as it enables more accurate prediction of disease progression, patient response to interventions, and personalized risk assessment by truly understanding the dynamic nature of health trajectories rather than merely summarizing past events.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes a novel AI paradigm for training 'world models' on structured EHR data to simulate patient dynamics rather than just predict tokens. This aims to create more accurate and dynamic representations of patient health trajectories, enabling better prediction of future patient states, understanding of disease progression, and ultimately enhancing clinical decision-making, risk stratification, and personalized treatment planning by providing deeper insights into how patient conditions evolve over time and under interventions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Critiques existing LLMs for EHR, stating they treat patients as static documents rather than dynamic systems whose trajectories evolve over time and interventions.</li>
                    
                    <li>Introduces SMB-Structure, a novel 'world model' paradigm specifically designed for longitudinal structured Electronic Health Records (EHR).</li>
                    
                    <li>The model architecture combines a Joint-Embedding Prediction Architecture (JEPA) with next-token prediction (SFT) to simulate patient dynamics.</li>
                    
                    <li>JEPA is designed to predict future patient states in latent space based solely on the initial patient representation, forcing the model to proactively encode trajectory dynamics before future states are observed.</li>
                    
                    <li>Validated across two large-scale clinical cohorts: 23,319 oncology patients from Memorial Sloan Kettering (323,000+ patient-years) and 19,402 pulmonary embolism patients from INSPECT.</li>
                    
                    <li>Evaluation utilized a linear probe applied at multiple points along the disease trajectory to assess the learned embeddings' ability to capture evolving disease states.</li>
                    
                    <li>Key finding: SMB-Structure learns embeddings that significantly better capture disease dynamics compared to traditional autoregressive next-token prediction baselines, achieving competitive performance on complex tasks with high patient heterogeneity.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>SMB-Structure utilizes a novel world model training paradigm combining a Joint-Embedding Prediction Architecture (JEPA) with next-token prediction (SFT). SFT reconstructs future patient states in token space, while JEPA predicts these futures in a latent space using only the initial patient representation, thereby enforcing the encoding of trajectory dynamics. The model was trained and validated on large-scale structured EHR datasets from Memorial Sloan Kettering (oncology) and INSPECT (pulmonary embolism), with evaluation performed via linear probes at multiple points along disease trajectories.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The model successfully learns embeddings that capture intricate disease dynamics, outperforming autoregressive baselines in this aspect. It achieves competitive performance on complex clinical tasks, particularly those involving high patient heterogeneity, by encoding future patient states and trajectories preemptively.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This model could significantly advance precision medicine by enabling earlier and more accurate prediction of disease progression, personalized risk stratification, and optimized timing of interventions. By simulating dynamic patient trajectories, it provides a more robust foundation for clinical decision support systems and the development of tailored treatment plans, especially for complex and heterogeneous diseases.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed model or methodology.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Pulmonary Embolism</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">longitudinal EHR</span>
                    
                    <span class="tag tag-keyword">world model</span>
                    
                    <span class="tag tag-keyword">patient trajectory</span>
                    
                    <span class="tag tag-keyword">disease dynamics</span>
                    
                    <span class="tag tag-keyword">JEPA</span>
                    
                    <span class="tag tag-keyword">SFT</span>
                    
                    <span class="tag tag-keyword">clinical foundation models</span>
                    
                    <span class="tag tag-keyword">oncology</span>
                    
                    <span class="tag tag-keyword">pulmonary embolism</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>