<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR - Health AI Hub</title>
    <meta name="description" content="This paper introduces SMB-Structure, a novel 'world model' paradigm for structured Electronic Health Records (EHR) designed to simulate patient dynamics rather ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.22128v1" target="_blank">2601.22128v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-29
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Irsyad Adam, Zekai Chen, David Laprade, Shaun Porwal, David Laub, Erik Reinertsen, Arda Pekis, Kevin Brown
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI, cs.CE, q-bio.QM
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.22128v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.22128v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces SMB-Structure, a novel 'world model' paradigm for structured Electronic Health Records (EHR) designed to simulate patient dynamics rather than merely summarizing them as static documents. It combines a Joint-Embedding Prediction Architecture (JEPA) with next-token prediction (SFT) to learn embeddings that capture complex disease trajectories. Validated across oncology and pulmonary embolism cohorts, the model demonstrates superior capture of disease dynamics compared to autoregressive baselines, achieving competitive performance on heterogeneous patient tasks.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing clinical AI by developing models that understand and predict the dynamic evolution of patient health, rather than just summarizing static data. It enables more accurate forecasting of disease progression, personalized risk assessment, and proactive intervention strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development of advanced models (SMB-Structure, a world model) that can learn and simulate complex patient trajectories and disease dynamics from structured EHR data. This can lead to improved predictive analytics for patient outcomes, personalized treatment recommendations, early detection of adverse events, and more robust clinical decision support by understanding how a patient's state evolves over time.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Critiques existing Large Language Models (LLMs) in clinical settings for treating patients as static documents via next-word-prediction, failing to model them as dynamical systems evolving under interventions and time.</li>
                    
                    <li>Introduces SMB-Structure, a 'world model' specifically designed for structured EHR data, aiming to simulate patient trajectories and dynamics.</li>
                    
                    <li>Proposes a novel training paradigm that grounds a Joint-Embedding Prediction Architecture (JEPA) with next-token prediction (SFT).</li>
                    
                    <li>JEPA component predicts future patient states in a latent space solely from the initial patient representation, forcing the model to encode entire disease dynamics proactively.</li>
                    
                    <li>SFT component grounds the model by reconstructing future patient states in the token space, linking latent predictions to concrete EHR data.</li>
                    
                    <li>Validated across two large-scale real-world cohorts: Memorial Sloan Kettering (23,319 oncology patients) and INSPECT (19,402 pulmonary embolism patients).</li>
                    
                    <li>Demonstrates that SMB-Structure learns embeddings that capture disease dynamics not recoverable by traditional autoregressive baselines, achieving competitive performance on complex tasks characterized by high patient heterogeneity.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study develops SMB-Structure, a world model for structured EHR data. Its training paradigm integrates two components: a Joint-Embedding Prediction Architecture (JEPA), which predicts future patient states in a latent embedding space from an initial patient representation, and next-token prediction (Supervised Fine-Tuning - SFT), which reconstructs future patient states in the token space. Model performance was evaluated using linear probes on the learned embeddings at various points along disease trajectories and compared against autoregressive baselines across large oncology and pulmonary embolism patient cohorts.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>SMB-Structure's novel training paradigm successfully learns embeddings that capture intricate disease dynamics, a capability notably absent in traditional autoregressive baselines. The model achieved competitive performance on complex tasks even with high patient heterogeneity, effectively modeling patients as dynamic systems evolving over time and interventions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This paradigm offers a significant step towards developing more robust and clinically useful AI models capable of simulating patient health trajectories. It has the potential to improve prognostication, enable more personalized treatment planning, facilitate early identification of adverse events, and support proactive clinical decision-making, particularly in managing complex, chronic, or rapidly evolving conditions like cancer and pulmonary embolism.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the proposed SMB-Structure model itself. However, it implicitly highlights the limitations of prior work, specifically that current LLMs (even clinical foundation models) treat patients as static documents through next-word-prediction, failing to model their true dynamical nature.</p>
            </section>
            

            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Pulmonary Embolism</span>
                    
                    <span class="tag">Computational Medicine</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Predictive Analytics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Longitudinal EHR</span>
                    
                    <span class="tag tag-keyword">World Model</span>
                    
                    <span class="tag tag-keyword">Disease Dynamics</span>
                    
                    <span class="tag tag-keyword">Joint-Embedding Prediction Architecture (JEPA)</span>
                    
                    <span class="tag tag-keyword">Next-token prediction</span>
                    
                    <span class="tag tag-keyword">Clinical Foundation Models</span>
                    
                    <span class="tag tag-keyword">Structured EHR</span>
                    
                    <span class="tag tag-keyword">Patient Trajectory</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>