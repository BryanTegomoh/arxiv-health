<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers - Health AI Hub</title>
    <meta name="description" content="This paper introduces a vision transformer-based approach for real-time inference of thin liquid film thickness profiles directly from interference patterns, ad">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from Interference Patterns Using Vision Transformers</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.25157v1" target="_blank">2510.25157v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-29
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Gautam A. Viruthagiri, Arnuv Tandon, Gerald G. Fuller, Vinny Chandran Suja
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.25157v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.25157v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a vision transformer-based approach for real-time inference of thin liquid film thickness profiles directly from interference patterns, addressing the computational and noise sensitivity issues of traditional methods. Trained on a hybrid dataset of synthetic and experimental tear film data, the model leverages long-range spatial correlations to resolve phase ambiguities and reconstruct temporally coherent profiles in a single pass. It demonstrates state-of-the-art performance on noisy, rapidly-evolving films, enabling automated, consistent thickness reconstruction at real-time speeds for clinical applications like dry eye disease diagnosis.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances the non-invasive measurement of liquid film thickness, particularly tear films in ophthalmology, by providing a real-time, automated, and robust diagnostic tool. This is critical for improving the diagnosis and continuous monitoring of ocular surface conditions like dry eye disease.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research applies a vision transformer-based deep learning model to automate and accelerate the reconstruction of thin liquid film thickness profiles from interference patterns. This enables real-time, consistent monitoring and non-invasive diagnosis of pre-lens ocular tear films for conditions such as dry eye disease, overcoming limitations of traditional manual or computationally intensive methods in a clinical context.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Traditional thin film interferometry for thickness measurement is hindered by an ill-posed inverse problem, computational intensity, noise sensitivity, and reliance on manual expert analysis, making it impractical for real-time diagnostics.</li>
                    
                    <li>A novel vision transformer (ViT)-based approach is presented for real-time, direct inference of thin liquid film thickness profiles from isolated interferograms.</li>
                    
                    <li>The ViT model is trained on a hybrid dataset combining physiologically-relevant synthetic data with experimental tear film data.</li>
                    
                    <li>It leverages long-range spatial correlations to effectively resolve phase ambiguities and reconstruct temporally coherent thickness profiles in a single forward pass, even from dynamic in vivo and ex vivo interferograms.</li>
                    
                    <li>The network achieves state-of-the-art performance on noisy, rapidly-evolving films with motion artifacts, overcoming limitations of conventional phase-unwrapping and iterative fitting methods.</li>
                    
                    <li>The data-driven approach enables automated, consistent thickness reconstruction at real-time speeds on consumer hardware.</li>
                    
                    <li>This innovation opens possibilities for continuous monitoring of pre-lens ocular tear films and non-invasive diagnosis of conditions such as dry eye disease.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employs a vision transformer (ViT) architecture, which is trained on a hybrid dataset comprising both physiologically-relevant synthetic and experimental tear film interferogram data. This model is designed to infer thin liquid film thickness profiles directly from isolated interferograms in a single forward pass, leveraging long-range spatial correlations to resolve phase ambiguities and reconstruct temporally coherent profiles.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The vision transformer model demonstrates state-of-the-art performance in reconstructing thin liquid film thickness profiles, even when dealing with noisy, rapidly-evolving films and motion artifacts. It successfully overcomes the computational intensity, noise sensitivity, and manual analysis requirements inherent in conventional phase-unwrapping and iterative fitting methods, providing automated and consistent reconstructions at real-time speeds on consumer hardware.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology enables automated, consistent, and real-time measurement of pre-lens ocular tear film thickness profiles using accessible consumer hardware. This capability is transformative for continuous monitoring of ocular surface health and provides an efficient, non-invasive diagnostic tool for conditions like dry eye disease, reducing reliance on time-consuming manual analysis and expert interpretation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper highlights that traditional thin film interferometry methods are computationally intensive, highly sensitive to imaging noise and ambient artifacts, ill-posed due to phase periodicity, and require manual expert analysis, rendering them impractical for real-time clinical diagnostics. The proposed Vision Transformer method specifically aims to overcome these prior limitations.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly detailing future research directions for the model itself, the paper suggests that the proposed real-time inference capability 'opens new possibilities' for continuous monitoring of pre-lens ocular tear films and facilitates non-invasive diagnosis of conditions such as dry eye disease, implying future work would focus on broader clinical deployment and integration.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Optometry</span>
                    
                    <span class="tag">Ocular Surface Disease</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">vision transformer</span>
                    
                    <span class="tag tag-keyword">thin film interferometry</span>
                    
                    <span class="tag tag-keyword">tear film thickness</span>
                    
                    <span class="tag tag-keyword">real-time inference</span>
                    
                    <span class="tag tag-keyword">dry eye disease</span>
                    
                    <span class="tag tag-keyword">ophthalmology</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">phase unwrapping</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Thin film interferometry is a powerful technique for non-invasively measuring
liquid film thickness with applications in ophthalmology, but its clinical
translation is hindered by the challenges in reconstructing thickness profiles
from interference patterns - an ill-posed inverse problem complicated by phase
periodicity, imaging noise and ambient artifacts. Traditional reconstruction
methods are either computationally intensive, sensitive to noise, or require
manual expert analysis, which is impractical for real-time diagnostics. To
address this challenge, here we present a vision transformer-based approach for
real-time inference of thin liquid film thickness profiles directly from
isolated interferograms. Trained on a hybrid dataset combining
physiologically-relevant synthetic and experimental tear film data, our model
leverages long-range spatial correlations to resolve phase ambiguities and
reconstruct temporally coherent thickness profiles in a single forward pass
from dynamic interferograms acquired in vivo and ex vivo. The network
demonstrates state-of-the-art performance on noisy, rapidly-evolving films with
motion artifacts, overcoming limitations of conventional phase-unwrapping and
iterative fitting methods. Our data-driven approach enables automated,
consistent thickness reconstruction at real-time speeds on consumer hardware,
opening new possibilities for continuous monitoring of pre-lens ocular tear
films and non-invasive diagnosis of conditions such as the dry eye disease.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>6 pages, 2 figures, will be updated</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>