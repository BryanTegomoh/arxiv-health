<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach - Health AI Hub</title>
    <meta name="description" content="This paper introduces Fairness-Aware Survival Modeling (FASM) to address algorithmic bias in machine learning models used in healthcare, particularly focusing o">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">← Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20629v1" target="_blank">2510.20629v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mingxuan Liu, Yilin Ning, Haoyuan Wang, Chuan Hong, Matthew Engelhard, Danielle S. Bitterman, William G. La Cava, Nan Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20629v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20629v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces Fairness-Aware Survival Modeling (FASM) to address algorithmic bias in machine learning models used in healthcare, particularly focusing on disparities in cross-group risk rankings within survival analysis. Applied to breast cancer prognosis using SEER data, FASM substantially improves fairness and mitigates misranking across patient groups, while preserving discrimination performance comparable to fairness-unaware models. The approach demonstrates stable fairness improvements over a 10-year horizon, especially in the mid-term follow-up.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for medical equity as it directly confronts how AI/ML models can perpetuate or amplify health disparities. By ensuring fairness in survival predictions, FASM can prevent biased clinical decision-making, promote equitable care, and challenge biological essentialism reinforced by misranked risk assessments.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper develops a Fairness-Aware Survival Modeling (FASM) approach for mitigating algorithmic bias in machine learning models used for predicting patient survival and risk ranking (e.g., breast cancer prognosis). This directly applies AI to improve the fairness and equity of clinical decision-making and patient care.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Machine learning integration into healthcare can amplify structural inequities and social biases inherent in clinical data, particularly in complex survival analysis due to censoring and time dynamics.</li>
                    
                    <li>Existing algorithmic fairness approaches often overlook critical disparities in cross-group risk rankings, such as high-risk Black patients being ranked below lower-risk White patients.</li>
                    
                    <li>The proposed Fairness-Aware Survival Modeling (FASM) is designed to mitigate algorithmic bias concerning both intra-group and cross-group risk rankings over time.</li>
                    
                    <li>FASM was evaluated using breast cancer prognosis as a representative case, applying the method to data from the SEER (Surveillance, Epidemiology, and End Results) database.</li>
                    
                    <li>Results indicate that FASM substantially improves fairness compared to fairness-unaware survival models.</li>
                    
                    <li>FASM maintains discrimination performance at a level comparable to traditional, fairness-unaware survival models.</li>
                    
                    <li>Time-stratified evaluations demonstrated that FASM sustains stable fairness over a 10-year follow-up period, with the most significant improvements observed during the mid-term.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes Fairness-Aware Survival Modeling (FASM), a novel machine learning approach specifically designed to mitigate algorithmic bias in survival predictions by addressing disparities in both intra-group and cross-group risk rankings across time. FASM was applied to breast cancer prognosis data extracted from the SEER database and evaluated against fairness-unaware survival models using time-stratified metrics over a 10-year follow-up.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>['FASM substantially improves fairness in survival predictions for breast cancer prognosis.', 'FASM preserves discrimination performance, ensuring it remains comparable to existing fairness-unaware survival models.', 'The fairness improvements achieved by FASM are stable and consistent over a 10-year follow-up horizon, with peak improvements noted during the mid-term of the follow-up period.', 'The approach effectively mitigates cross-group misranking, such as the potential for high-risk minority patients to be ranked below lower-risk majority patients.']</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>FASM has the potential to significantly improve the equity and trustworthiness of clinical decision-making by enabling the development of survival models that provide fair and unbiased risk predictions across diverse patient populations. This can lead to more equitable treatment recommendations, resource allocation, and a reduction in health disparities, ultimately advancing fairness as a core principle in clinical care for conditions like breast cancer.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats of the FASM approach or its evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Health Informatics</span>
                    
                    <span class="tag">Prognosis Modeling</span>
                    
                    <span class="tag">Medical Ethics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">fairness</span>
                    
                    <span class="tag tag-keyword">survival analysis</span>
                    
                    <span class="tag tag-keyword">algorithmic bias</span>
                    
                    <span class="tag tag-keyword">healthcare equity</span>
                    
                    <span class="tag tag-keyword">breast cancer prognosis</span>
                    
                    <span class="tag tag-keyword">risk ranking</span>
                    
                    <span class="tag tag-keyword">machine learning</span>
                    
                    <span class="tag tag-keyword">SEER data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">As machine learning models become increasingly integrated into healthcare,
structural inequities and social biases embedded in clinical data can be
perpetuated or even amplified by data-driven models. In survival analysis,
censoring and time dynamics can further add complexity to fair model
development. Additionally, algorithmic fairness approaches often overlook
disparities in cross-group rankings, e.g., high-risk Black patients may be
ranked below lower-risk White patients who do not experience the event of
mortality. Such misranking can reinforce biological essentialism and undermine
equitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed
to mitigate algorithmic bias regarding both intra-group and cross-group risk
rankings over time. Using breast cancer prognosis as a representative case and
applying FASM to SEER breast cancer data, we show that FASM substantially
improves fairness while preserving discrimination performance comparable to
fairness-unaware survival models. Time-stratified evaluations show that FASM
maintains stable fairness over a 10-year horizon, with the greatest
improvements observed during the mid-term of follow-up. Our approach enables
the development of survival models that prioritize both accuracy and equity in
clinical decision-making, advancing fairness as a core principle in clinical
care.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">← Back to all papers</a></p>
    </footer>
</body>
</html>