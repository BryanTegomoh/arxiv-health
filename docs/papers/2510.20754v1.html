<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology - Health AI Hub</title>
    <meta name="description" content="This paper introduces ACS-SegNet, a novel attention-based dual-encoder segmentation network that integrates Convolutional Neural Networks (CNNs) and Vision Tran">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">← Back to all papers</a>
            </nav>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.20754v1" target="_blank">2510.20754v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-23
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Nima Torbati, Anastasia Meshcheryakova, Ramona Woitek, Diana Mechtcheriakova, Amirreza Mahbod
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.20754v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.20754v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces ACS-SegNet, a novel attention-based dual-encoder segmentation network that integrates Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for semantic tissue segmentation in histopathological images. The model demonstrates superior performance on two publicly available datasets, GCPS and PUMA, consistently outperforming state-of-the-art and baseline methods with high μIoU and μDice scores.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Automated and highly accurate tissue segmentation is paramount in computational pathology for precise identification and quantification of various tissue types, which directly impacts the diagnosis, grading, and prognosis of diseases like cancer, thereby improving diagnostic efficiency and consistency for pathologists.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to develop a more accurate and robust deep learning model (ACS-SegNet) for automated semantic tissue segmentation in histopathological images. This technology directly supports computer-aided diagnosis (CAD) of various diseases, potentially improving diagnostic efficiency, consistency, and accuracy for pathologists, especially in identifying and quantifying disease-related tissues in biopsy samples.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed**: Enhancing the accuracy and automation of semantic tissue segmentation in histopathological images, crucial for computer-aided diagnosis.</li>
                    
                    <li>**Proposed Solution**: ACS-SegNet, a novel attention-based segmentation network that leverages the complementary strengths of CNNs and Vision Transformers.</li>
                    
                    <li>**Architectural Innovation**: Features a unified dual-encoder model that performs attention-driven feature fusion of representations extracted from both CNN and ViT branches.</li>
                    
                    <li>**Performance Metrics**: Evaluation was conducted using mean Intersection over Union (μIoU) and mean Dice coefficient (μDice) scores.</li>
                    
                    <li>**Results on GCPS Dataset**: Achieved robust performance with 76.79% μIoU and 86.87% μDice scores.</li>
                    
                    <li>**Results on PUMA Dataset**: Demonstrated strong segmentation capabilities with 64.93% μIoU and 76.60% μDice scores.</li>
                    
                    <li>**Competitive Advantage**: Consistently outperformed existing state-of-the-art deep learning models and baseline benchmarks across both evaluated datasets.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study proposes ACS-SegNet, an attention-based segmentation network designed for histopathological images. This architecture employs a unified dual-encoder system, integrating both Convolutional Neural Networks (CNNs) for local feature extraction and Vision Transformers (ViTs) for capturing global context. Features from these distinct branches are then combined through an attention-driven fusion mechanism before being processed by a decoder to generate semantic segmentation masks. The model's performance was rigorously evaluated on two publicly available datasets, GCPS and PUMA, using standard metrics such as μIoU and μDice, and compared against established state-of-the-art and baseline segmentation models.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>ACS-SegNet demonstrated superior semantic segmentation performance, achieving μIoU/μDice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset. These results indicate that the proposed attention-driven CNN-ViT fusion approach significantly outperforms current state-of-the-art and baseline methods for tissue segmentation in histopathology.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This advanced segmentation method offers the potential for significant clinical impact by enhancing the precision, consistency, and efficiency of quantitative histopathological analysis. It can aid pathologists in more accurately identifying and characterizing tissue regions, facilitating improved disease diagnosis, grading, and treatment planning, while potentially reducing inter-observer variability and workload.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly noted in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly noted in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Computational Pathology</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Diagnostic Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">histopathology</span>
                    
                    <span class="tag tag-keyword">semantic segmentation</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">convolutional neural networks</span>
                    
                    <span class="tag tag-keyword">vision transformers</span>
                    
                    <span class="tag tag-keyword">attention mechanism</span>
                    
                    <span class="tag tag-keyword">medical image analysis</span>
                    
                    <span class="tag tag-keyword">computer-aided diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated histopathological image analysis plays a vital role in
computer-aided diagnosis of various diseases. Among developed algorithms, deep
learning-based approaches have demonstrated excellent performance in multiple
tasks, including semantic tissue segmentation in histological images. In this
study, we propose a novel approach based on attention-driven feature fusion of
convolutional neural networks (CNNs) and vision transformers (ViTs) within a
unified dual-encoder model to improve semantic segmentation performance.
Evaluation on two publicly available datasets showed that our model achieved
{\mu}IoU/{\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and
64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline
benchmarks. The implementation of our method is publicly available in a GitHub
repository: https://github.com/NimaTorbati/ACS-SegNet</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>5 pages</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">← Back to all papers</a></p>
    </footer>
</body>
</html>