<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation - Health AI Hub</title>
    <meta name="description" content="CURE addresses the critical issues of inaccurate visual grounding and factual inconsistencies in AI-generated radiology reports by introducing an error-aware cu">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15408v1" target="_blank">2601.15408v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Pablo Messina, Andr√©s Villa, Juan Le√≥n Alc√°zar, Karen S√°nchez, Carlos Hinojosa, Denis Parra, √Ålvaro Soto, Bernard Ghanem
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15408v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15408v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">CURE addresses the critical issues of inaccurate visual grounding and factual inconsistencies in AI-generated radiology reports by introducing an error-aware curriculum learning framework. It fine-tunes a multimodal instructional model across multiple tasks, dynamically emphasizing challenging samples to significantly improve grounding accuracy, overall report quality, and substantially reduce hallucinations, all without requiring additional data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and reliable radiology report generation is paramount for timely and correct patient diagnosis, treatment planning, and monitoring. Misaligned findings or hallucinations in AI-generated reports could lead to diagnostic errors, suboptimal patient care, and increased medical liability, making CURE's improvements in grounding and factual consistency directly relevant to clinical safety and efficacy.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops an AI framework (CURE) designed to automate and improve the generation of radiology reports. By enhancing the accuracy, visual grounding, and factual consistency of these AI-generated reports, it aims to provide more reliable diagnostic support, streamline clinical workflows for radiologists, and potentially contribute to better patient outcomes by reducing errors in medical documentation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed**: Existing medical vision-language models for radiology report generation often suffer from poor visual grounding (misaligning text with images) and factual inconsistencies (hallucinations), leading to unreliable reports.</li>
                    
                    <li>**Proposed Solution (CURE)**: CURE (Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation) is an error-aware curriculum learning framework designed to enhance grounding and report quality.</li>
                    
                    <li>**Methodology**: It fine-tunes a pre-existing multimodal instructional model on three specific tasks: phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets.</li>
                    
                    <li>**Dynamic Curriculum Learning**: CURE employs a dynamic sampling strategy that adjusts based on the model's performance, prioritizing harder samples to improve both spatial and textual alignment between images and generated text.</li>
                    
                    <li>**Significant Grounding Improvement**: The framework achieves a notable improvement in grounding accuracy, demonstrated by a +0.37 IoU (Intersection over Union) score.</li>
                    
                    <li>**Enhanced Report Quality & Reliability**: CURE boosts overall report quality by +0.188 CXRFEScore and, critically, reduces factual hallucinations by 18.6%, leading to more reliable clinical outputs.</li>
                    
                    <li>**Data Efficiency**: The approach is highlighted as data-efficient, improving performance without requiring the collection or annotation of new training data.</li>
                    
                    <li>**Open-Source Availability**: Code and model weights are publicly available, promoting reproducibility and further research.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>CURE employs an error-aware curriculum learning framework to fine-tune a pre-existing multimodal instructional model. It utilizes a multi-task training approach, simultaneously optimizing for phrase grounding, grounded report generation, and anatomy-grounded report generation on public datasets. The core of its curriculum learning involves dynamically adjusting the sampling of training data, emphasizing harder or more error-prone samples based on the model's real-time performance to enhance spatial and textual alignment.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The study demonstrates that CURE significantly improves grounding accuracy by +0.37 IoU. It also boosts the quality of generated radiology reports, as measured by a +0.188 CXRFEScore, and substantially reduces factual hallucinations by 18.6%. These improvements are achieved without the need for additional data, highlighting the framework's data efficiency.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By enhancing the accuracy of visual grounding and drastically reducing hallucinations, CURE can lead to more reliable and trustworthy AI-generated radiology reports. This directly translates to improved diagnostic confidence for clinicians, potentially faster report turnaround times, and a reduced risk of misdiagnosis due to AI errors. This advancement could support radiologists by pre-populating reports with higher fidelity, allowing them to focus on critical analysis and patient-specific nuances, thereby improving overall patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any specific limitations or caveats of the CURE framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Clinical Diagnosis</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">radiology report generation</span>
                    
                    <span class="tag tag-keyword">visual grounding</span>
                    
                    <span class="tag tag-keyword">curriculum learning</span>
                    
                    <span class="tag tag-keyword">multimodal AI</span>
                    
                    <span class="tag tag-keyword">hallucination reduction</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">vision-language models</span>
                    
                    <span class="tag tag-keyword">anatomy grounding</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>31 pages, 7 figures, submitted to CVPR 2026 (under review)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>