<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation - Health AI Hub</title>
    <meta name="description" content="CURE introduces an error-aware curriculum learning framework to enhance the reliability and accuracy of automated radiology report generation. It addresses comm">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15408v1" target="_blank">2601.15408v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Pablo Messina, Andr√©s Villa, Juan Le√≥n Alc√°zar, Karen S√°nchez, Carlos Hinojosa, Denis Parra, √Ålvaro Soto, Bernard Ghanem
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15408v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15408v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">CURE introduces an error-aware curriculum learning framework to enhance the reliability and accuracy of automated radiology report generation. It addresses common issues like inaccurate visual grounding and factual inconsistency by fine-tuning a multimodal instructional model across multiple tasks. The method achieves significant improvements in grounding accuracy, report quality, and reduces hallucinations without requiring additional data.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate visual grounding and factual consistency in radiology reports are paramount for correct diagnosis, treatment planning, and patient safety. CURE's improvements directly enhance the reliability of automated reports, thus supporting clinical decision-making and potentially reducing diagnostic errors.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the automation and enhancement of radiology report generation. By developing a curriculum-guided multi-task training framework, CURE aims to create more accurate, factually consistent, and reliable reports from medical images, thereby assisting radiologists, improving diagnostic workflows, and potentially contributing to better patient outcomes through more precise medical documentation.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses critical challenges in medical vision-language models: inaccurate visual grounding and factual inconsistency in radiology report generation.</li>
                    
                    <li>Introduces CURE (Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation), an error-aware curriculum learning framework.</li>
                    
                    <li>CURE fine-tunes a multimodal instructional model on public datasets, without needing additional data, to improve report quality.</li>
                    
                    <li>Employs multi-task training encompassing phrase grounding, grounded report generation, and anatomy-grounded report generation.</li>
                    
                    <li>Dynamically adjusts training sample emphasis based on model performance, prioritizing harder samples to improve spatial and textual alignment.</li>
                    
                    <li>Achieves substantial performance gains: +0.37 IoU in grounding accuracy, +0.188 CXRFEScore in report quality, and an 18.6% reduction in hallucinations.</li>
                    
                    <li>Presents a data-efficient approach for developing more reliable and accurately grounded medical AI models.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>CURE employs an error-aware curriculum learning strategy to fine-tune a pre-existing multimodal instructional model. The training process leverages public datasets and is structured around three interconnected tasks: phrase grounding (linking textual findings to specific image regions), grounded report generation (generating reports with explicit visual evidence), and anatomy-grounded report generation (ensuring findings are correctly localized to anatomical structures). A key aspect is the dynamic adjustment of training sample selection, where samples that the model struggles with (harder samples) are prioritized based on its performance, aiming to improve spatial and textual alignment.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The CURE framework demonstrates significant improvements across key metrics: grounding accuracy improved by +0.37 IoU (Intersection over Union), overall report quality increased by +0.188 CXRFEScore, and the rate of factual hallucinations in generated reports was reduced by 18.6%. These enhancements highlight CURE's ability to produce more reliable and well-grounded medical reports efficiently, without requiring additional data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By delivering more accurate and factually consistent radiology reports with strong visual grounding, CURE can profoundly impact clinical practice. It can lead to improved diagnostic efficiency, reduced workload for radiologists by automating preliminary report generation, and minimize the risk of misinterpretation or errors in patient records, ultimately contributing to higher quality patient care and more precise treatment pathways.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the CURE framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical vision-language models</span>
                    
                    <span class="tag tag-keyword">radiology reports</span>
                    
                    <span class="tag tag-keyword">visual grounding</span>
                    
                    <span class="tag tag-keyword">curriculum learning</span>
                    
                    <span class="tag tag-keyword">multi-task training</span>
                    
                    <span class="tag tag-keyword">hallucination reduction</span>
                    
                    <span class="tag tag-keyword">AI in medicine</span>
                    
                    <span class="tag tag-keyword">diagnostic imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>31 pages, 7 figures, submitted to CVPR 2026 (under review)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>