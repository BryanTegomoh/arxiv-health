<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RT-Focuser: A Real-Time Lightweight Model for Edge-side Image Deblurring - Health AI Hub</title>
    <meta name="description" content="RT-Focuser is a novel lightweight U-shaped deep learning model designed for real-time image deblurring, specifically targeting edge devices. It effectively miti">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>RT-Focuser: A Real-Time Lightweight Model for Edge-side Image Deblurring</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.21975v1" target="_blank">2512.21975v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-26
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhuoyu Wu, Wenhui Ou, Qiawei Zheng, Jiayan Yang, Quanjun Wang, Wenqi Fang, Zheng Wang, Yongkui Yang, Heshan Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.21975v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.21975v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">RT-Focuser is a novel lightweight U-shaped deep learning model designed for real-time image deblurring, specifically targeting edge devices. It effectively mitigates motion blur, which degrades image quality in real-time applications like medical imaging, by utilizing specialized blocks for edge-aware feature extraction, encoder integration, and progressive decoder refinement. The model achieves high accuracy and exceptional speed with minimal computational resources, demonstrating strong potential for edge deployment.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Motion blur in medical images can obscure vital diagnostic features, leading to misinterpretations, delayed diagnoses, or compromised procedural guidance. RT-Focuser's ability to perform real-time, high-quality deblurring on lightweight, edge devices can significantly enhance the clarity and reliability of images from portable diagnostic tools, endoscopes, and intraoperative imaging systems, thereby improving diagnostic accuracy and operational efficiency in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The RT-Focuser model, being an AI-powered image deblurring technique, can be applied in various health settings to enhance the clarity and quality of medical images. This would improve the accuracy of diagnoses (e.g., clearer CT/MRI scans, ultrasound images, endoscopic videos), aid in real-time surgical guidance by correcting motion blur, and improve the interpretability of microscopic images for pathology, ultimately leading to better clinical decision-making and patient outcomes, especially on edge devices like mobile diagnostic tools or integrated systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of motion blur in real-time applications, including autonomous driving, UAV perception, and medical imaging, which severely degrades image quality.</li>
                    
                    <li>Introduces RT-Focuser, a lightweight U-shaped network meticulously designed for efficient and real-time image deblurring on edge devices.</li>
                    
                    <li>Employs three key architectural components: a Lightweight Deblurring Block (LD) for efficient edge-aware feature extraction, a Multi-Level Integrated Aggregation module (MLIA) for robust encoder feature integration, and a Cross-source Fusion Block (X-Fuse) for progressive decoder refinement.</li>
                    
                    <li>Achieves a high image quality benchmark of 30.67 dB PSNR while maintaining an extremely compact design with only 5.85 million parameters and 15.76 GMACs.</li>
                    
                    <li>Demonstrates outstanding real-time processing capabilities, running at 6ms per frame (exceeding 140 FPS) on both GPU and mobile platforms.</li>
                    
                    <li>The model is trained effectively on a single blurred input, streamlining its application.</li>
                    
                    <li>Highlights significant potential for practical deployment on edge computing devices due to its blend of high accuracy, minimal resource consumption, and rapid processing speed.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The RT-Focuser is a lightweight U-shaped convolutional neural network architecture. Its design incorporates three specialized modules: the Lightweight Deblurring Block (LD) for efficient edge-aware feature extraction, the Multi-Level Integrated Aggregation module (MLIA) to enhance encoder feature integration, and the Cross-source Fusion Block (X-Fuse) for progressive refinement within the decoder. The model is trained using a single blurred input image.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>RT-Focuser achieves a peak signal-to-noise ratio (PSNR) of 30.67 dB, demonstrating high deblurring quality. It is exceptionally efficient, utilizing only 5.85 million parameters and 15.76 GMACs. Performance on real-time processing is strong, with an inference time of 6 milliseconds per frame, equating to over 140 frames per second (FPS) on both GPU and mobile platforms.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The real-time, lightweight deblurring capabilities of RT-Focuser can have a profound impact in clinical settings by enabling clearer visualization of anatomical structures and pathologies from mobile or point-of-care medical devices. This can lead to quicker and more confident diagnoses, reduce the need for repeat imaging due to motion artifact, and improve precision during image-guided procedures. Its edge deployment potential makes it ideal for enhancing image quality in portable ultrasound, endoscopy, and other bedside imaging scenarios, particularly in remote areas or emergency medicine where immediate, high-quality images are crucial.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations regarding the model's generalizability to various blur types or specific medical imaging modalities beyond its general mention, nor does it detail potential challenges in real-world clinical deployment or specific hardware constraints beyond being 'lightweight' and 'edge-side'.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly suggest future research directions, such as evaluating performance across a wider range of medical imaging modalities, integrating with specific clinical workflows, or exploring robustness to diverse environmental factors.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">diagnostic imaging</span>
                    
                    <span class="tag">interventional radiology</span>
                    
                    <span class="tag">ultrasound imaging</span>
                    
                    <span class="tag">endoscopy</span>
                    
                    <span class="tag">mobile health</span>
                    
                    <span class="tag">telemedicine</span>
                    
                    <span class="tag">surgical guidance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">image deblurring</span>
                    
                    <span class="tag tag-keyword">real-time processing</span>
                    
                    <span class="tag tag-keyword">lightweight model</span>
                    
                    <span class="tag tag-keyword">edge computing</span>
                    
                    <span class="tag tag-keyword">motion blur</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">U-shaped network</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Motion blur caused by camera or object movement severely degrades image quality and poses challenges for real-time applications such as autonomous driving, UAV perception, and medical imaging. In this paper, a lightweight U-shaped network tailored for real-time deblurring is presented and named RT-Focuser. To balance speed and accuracy, we design three key components: Lightweight Deblurring Block (LD) for edge-aware feature extraction, Multi-Level Integrated Aggregation module (MLIA) for encoder integration, and Cross-source Fusion Block (X-Fuse) for progressive decoder refinement. Trained on a single blurred input, RT-Focuser achieves 30.67 dB PSNR with only 5.85M parameters and 15.76 GMACs. It runs 6ms per frame on GPU and mobile, exceeds 140 FPS on both, showing strong potential for deployment on the edge. The official code and usage are available on: https://github.com/ReaganWu/RT-Focuser.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>2 pages, 2 figures, this paper already accepted by IEEE ICTA 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>