<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts - Health AI Hub</title>
    <meta name="description" content="This paper systematically evaluated 12 large language models (LLMs) as potential pediatricians using a novel framework called PEDIASBench, tailored for real-wor">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.13381v1" target="_blank">2511.13381v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-17
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Siyu Zhu, Mouxiao Bian, Yue Xie, Yongyu Tang, Zhikang Yu, Tianbin Li, Pengcheng Chen, Bing Han, Jie Xu, Xiaoyan Dong
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.13381v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.13381v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper systematically evaluated 12 large language models (LLMs) as potential pediatricians using a novel framework called PEDIASBench, tailored for real-world clinical contexts. While LLMs demonstrated strong foundational knowledge, they exhibited significant limitations in complex reasoning, dynamic diagnosis adaptation, and humanistic sensitivity. The findings suggest current LLMs cannot independently perform pediatric care but hold promise for supportive roles in healthcare.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medical AI and healthcare innovation as it rigorously assesses the current capabilities and critical limitations of LLMs in a sensitive and complex specialty like pediatrics, directly informing their safe and effective integration into clinical practice.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper evaluates Large Language Models (LLMs) for their potential as pediatricians, focusing on their use in clinical decision support, medical education, and patient communication. It assesses their ability to apply medical knowledge, perform dynamic diagnosis and treatment, and adhere to pediatric medical safety and ethics standards within a healthcare setting.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A systematic evaluation framework, PEDIASBench, was developed to assess LLMs in realistic pediatric clinical environments across three dimensions: basic knowledge, dynamic diagnosis/treatment, and medical safety/ethics.</li>
                    
                    <li>Twelve representative LLMs (e.g., GPT-4o, Qwen, DeepSeek-V3) were evaluated across 19 pediatric subspecialties and 211 prototypical diseases.</li>
                    
                    <li>State-of-the-art models like Qwen3-235B-A22B achieved over 90% accuracy on licensing-level foundational knowledge but experienced a ~15% performance decline with increased task complexity, indicating limitations in complex and integrative reasoning.</li>
                    
                    <li>In dynamic diagnosis scenarios, most models struggled to adapt to real-time patient changes, although DeepSeek-R1 scored highest in case reasoning (mean 0.58).</li>
                    
                    <li>Qwen2.5-72B performed best on pediatric medical ethics and safety tasks (92.05% accuracy), but humanistic sensitivity remained limited across all evaluated models.</li>
                    
                    <li>The study concluded that current pediatric LLMs are constrained by insufficient dynamic decision-making and underdeveloped humanistic care, making them unsuitable for independent pediatric practice.</li>
                    
                    <li>Future development should prioritize multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and foster human-AI collaboration for improved clinical utility.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study employed PEDIASBench, a systematic evaluation framework, to assess LLMs. This framework is centered on a knowledge-system approach and simulates realistic clinical environments. It evaluates LLMs across three dimensions: application of basic medical knowledge (including licensing-level questions and complex reasoning), dynamic diagnosis and treatment capability (assessing adaptation to real-time patient changes), and pediatric medical safety and medical ethics. Twelve representative LLMs were tested across 19 pediatric subspecialties and 211 prototypical diseases.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Foundational knowledge performance was strong, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level pediatric questions. However, performance dropped by approximately 15% when task complexity increased, revealing weaknesses in complex and integrative reasoning. In dynamic diagnosis and treatment, most models struggled to adapt to real-time patient changes, though DeepSeek-R1 showed the highest mean case reasoning score (0.58). While Qwen2.5-72B demonstrated strong accuracy (92.05%) in pediatric medical safety and ethics, overall humanistic sensitivity in LLMs was limited.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>While current LLMs cannot independently perform pediatric care due to limitations in dynamic decision-making and humanistic care, they show significant promise for roles in decision support, medical education, and patient communication. This research provides a crucial roadmap for integrating AI safely and effectively into pediatric healthcare, paving the way for a collaborative intelligent system where LLMs augment human clinicians rather than replacing them.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Current LLMs are constrained by their limited dynamic decision-making capabilities, struggling to adapt to real-time patient changes, and possess underdeveloped humanistic care and sensitivity. They also exhibit limitations in complex and integrative reasoning tasks, despite strong foundational knowledge.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future development should focus on multimodal integration (e.g., incorporating imaging and physiological data), implementing a robust clinical feedback-model iteration loop for continuous learning, and enhancing the safety, interpretability, and overall human-AI collaboration to build a trustworthy intelligent pediatric healthcare system.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pediatrics</span>
                    
                    <span class="tag">Clinical Medicine</span>
                    
                    <span class="tag">Medical Ethics</span>
                    
                    <span class="tag">Diagnostic Reasoning</span>
                    
                    <span class="tag">Treatment Planning</span>
                    
                    <span class="tag">Medical Education</span>
                    
                    <span class="tag">Patient Communication</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Large Language Models</span>
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">Pediatrics</span>
                    
                    <span class="tag tag-keyword">Clinical Evaluation</span>
                    
                    <span class="tag tag-keyword">PEDIASBench</span>
                    
                    <span class="tag tag-keyword">AI in Medicine</span>
                    
                    <span class="tag tag-keyword">Medical Ethics</span>
                    
                    <span class="tag tag-keyword">Dynamic Diagnosis</span>
                    
                    <span class="tag tag-keyword">Decision Support</span>
                    
                    <span class="tag tag-keyword">Human-AI Collaboration</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>