<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media - Health AI Hub</title>
    <meta name="description" content="This paper introduces a unified multiclass machine learning framework to detect ten distinct mental health and cyberbullying categories from social media data. ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20001v1" target="_blank">2511.20001v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Edward Ajayi, Martha Kachweka, Mawuli Deku, Emily Aiken
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.SI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20001v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20001v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a unified multiclass machine learning framework to detect ten distinct mental health and cyberbullying categories from social media data. Utilizing a rigorous "split-then-balance" pipeline and fine-tuning transformer models, the study identified the domain-adapted MentalBERT as the top performer, achieving 0.92 accuracy and 0.76 Macro F1. The system is designed as an explainable, human-in-the-loop screening aid for moderators, not a diagnostic tool.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly medically relevant as it provides a scalable, interpretable machine learning tool capable of early identification of individuals exhibiting signs of mental health distress or experiencing cyberbullying in digital environments, potentially enabling timely intervention and support.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This AI application uses machine learning (specifically transformer models like MentalBERT) to analyze social media data (Twitter, Reddit) for the early detection and screening of various mental health conditions and cyberbullying instances. It is designed as a 'Social Media Screener' to aid moderators or potentially healthcare professionals in identifying individuals at risk, supporting preventative or early intervention efforts in mental health.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A unified multiclass classification framework was developed to detect ten distinct mental health and cyberbullying categories from Twitter and Reddit data.</li>
                    
                    <li>A rigorous "split-then-balance" pipeline was implemented to train on balanced data while evaluating on a realistic, held-out imbalanced test set.</li>
                    
                    <li>Comprehensive evaluation compared traditional lexical models, hybrid approaches, and end-to-end fine-tuned transformers, finding fine-tuning critical for performance.</li>
                    
                    <li>The domain-adapted MentalBERT emerged as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, outperforming generic transformer models and a zero-shot LLM baseline.</li>
                    
                    <li>The system is framed as a human-in-the-loop screening aid for moderators, explicitly not a diagnostic tool, and is grounded in a comprehensive ethical analysis.</li>
                    
                    <li>A hybrid SHAPLLM explainability framework was introduced, alongside a prototype dashboard ("Social Media Screener") for practical integration of model predictions and explanations.</li>
                    
                    <li>The research highlights the critical future need for multi-label, clinically-validated datasets at the intersection of online safety and computational mental health.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved curating social media datasets from Twitter and Reddit. A "split-then-balance" pipeline was used to preprocess data for training (balanced) and evaluation (realistic imbalanced test set). A comprehensive comparative analysis was performed on traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformer models, including the domain-adapted MentalBERT. Model performance was measured using accuracy and Macro F1 score. Additionally, a hybrid SHAPLLM explainability framework was developed, and a prototype dashboard ("Social Media Screener") was built to integrate predictions and explanations.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>End-to-end fine-tuning was found to be critical for achieving high performance in detecting mental health conditions and cyberbullying. The domain-adapted MentalBERT model significantly outperformed other evaluated models, including its generic counterpart and a zero-shot LLM baseline, achieving an accuracy of 0.92 and a Macro F1 score of 0.76. The research successfully developed an interpretable system framed as a screening aid, capable of providing explainable predictions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology holds significant potential as a screening aid for mental health professionals, community support workers, and platform moderators. It could facilitate early identification of individuals at risk of mental health conditions or cyberbullying, enabling targeted outreach, resource allocation, and timely intervention. The integrated explainability (SHAPLLM) and prototype dashboard enhance its utility by providing actionable insights, supporting human-in-the-loop decision-making, and potentially improving patient safety and well-being in digital spaces.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The paper implicitly highlights a limitation by emphasizing the future need for "multi-label, clinically-validated datasets." This suggests that the current datasets, while curated, may lack the granularity of multi-label annotations or full clinical validation, which could impact the system's ability to detect co-occurring conditions or its direct applicability in a formal clinical diagnostic context. The system is also explicitly defined as a screening aid, not a diagnostic tool, indicating its inherent limitations for medical diagnosis.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future research should focus on developing and utilizing multi-label, clinically-validated datasets to enhance the system's ability to detect complex, co-occurring mental health conditions. Further exploration of generalizable approaches across diverse social media platforms and integration with real-world clinical workflows for validation and impact assessment are also crucial.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Clinical Psychology</span>
                    
                    <span class="tag">Adolescent Health</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Preventive Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Mental Health Detection</span>
                    
                    <span class="tag tag-keyword">Cyberbullying</span>
                    
                    <span class="tag tag-keyword">Social Media Analysis</span>
                    
                    <span class="tag tag-keyword">Transformer Models</span>
                    
                    <span class="tag tag-keyword">MentalBERT</span>
                    
                    <span class="tag tag-keyword">Explainable AI</span>
                    
                    <span class="tag tag-keyword">Multiclass Classification</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted for Oral Presentation at the AAAI-26 Bridge Program on AI for Medicine and Healthcare (AIMedHealth). To appear in Proceedings of Machine Learning Research (PMLR)</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>