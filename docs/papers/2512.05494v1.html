<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel Transformer decoder framework designed to overcome limitations in capturing edge details, local textures, and spatial continuity i">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Decoding with Structured Awareness: Integrating Directional, Frequency-Spatial, and Structural Attention for Medical Image Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05494v1" target="_blank">2512.05494v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fan Zhang, Zhiwei Gu, Hua Wang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05494v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05494v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel Transformer decoder framework designed to overcome limitations in capturing edge details, local textures, and spatial continuity in medical image segmentation. It integrates three specialized modules‚ÄîAdaptive Cross-Fusion Attention (ACFA), Triple Feature Fusion Attention (TFFA), and Structural-aware Multi-scale Masking Module (SMMM)‚Äîto enhance feature representation and interaction. The framework significantly improves segmentation accuracy and generalization, particularly for high-precision tasks like tumor segmentation and organ boundary extraction.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine as it directly addresses crucial challenges in automated medical image analysis, enhancing the precision required for accurate diagnosis, surgical planning, and treatment monitoring, particularly for identifying tumors and delineating organ boundaries.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research provides an AI-driven solution for automated and highly accurate segmentation of anatomical structures and pathological findings (e.g., tumors) in medical images. Such an application directly supports clinical decision-making, improves diagnostic efficiency, aids in surgical planning, and facilitates disease monitoring, thereby enhancing overall healthcare delivery and patient outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>A novel decoder framework is proposed to address Transformer decoder shortcomings in medical image segmentation, focusing on improving edge detail capture, local texture recognition, and spatial continuity modeling.</li>
                    
                    <li>The Adaptive Cross-Fusion Attention (ACFA) module integrates channel feature enhancement with spatial attention, incorporating learnable guidance in planar, horizontal, and vertical directions to boost responsiveness to key regions and structural orientations.</li>
                    
                    <li>The Triple Feature Fusion Attention (TFFA) module fuses features from Spatial, Fourier, and Wavelet domains, achieving a joint frequency-spatial representation that strengthens global dependency and structural modeling while preserving crucial local information like edges and textures.</li>
                    
                    <li>The Structural-aware Multi-scale Masking Module (SMMM) optimizes skip connections between the encoder and decoder by leveraging multi-scale context and structural saliency filtering, reducing feature redundancy and enhancing semantic interaction quality.</li>
                    
                    <li>The synergistic operation of these three modules is designed to be particularly effective in complex and blurred boundary scenarios common in medical imaging.</li>
                    
                    <li>Experimental results demonstrate that the framework significantly enhances performance in high-precision tasks such as tumor segmentation and organ boundary extraction.</li>
                    
                    <li>The framework provides improved segmentation accuracy and model generalization, offering an efficient and practical solution for medical image segmentation.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper introduces a novel deep learning decoder framework based on Transformer architecture principles. It integrates three core modules: the Adaptive Cross-Fusion Attention (ACFA) module for directional and spatial attention, the Triple Feature Fusion Attention (TFFA) module for joint frequency-spatial feature representation using Spatial, Fourier, and Wavelet domains, and the Structural-aware Multi-scale Masking Module (SMMM) for optimizing encoder-decoder skip connections through structural saliency filtering and multi-scale context.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed decoder framework significantly enhances performance in medical image segmentation tasks, especially high-precision applications like tumor and organ boundary extraction. It achieves improved segmentation accuracy and model generalization by effectively capturing edge details, local textures, and spatial continuity, particularly beneficial in complex and blurred medical imaging scenarios.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework has the potential for substantial clinical impact by providing more accurate and reliable automated segmentation of medical images. This could lead to earlier and more precise disease diagnosis, improved accuracy in surgical planning, more consistent treatment monitoring, and reduced reliance on time-consuming manual segmentation, ultimately enhancing patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions for this work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Anatomy</span>
                    
                    <span class="tag">Surgical Planning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical image segmentation</span>
                    
                    <span class="tag tag-keyword">Transformer decoder</span>
                    
                    <span class="tag tag-keyword">attention mechanisms</span>
                    
                    <span class="tag tag-keyword">frequency-spatial analysis</span>
                    
                    <span class="tag tag-keyword">multi-scale features</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">tumor segmentation</span>
                    
                    <span class="tag tag-keyword">organ boundary extraction</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">To address the limitations of Transformer decoders in capturing edge details, recognizing local textures and modeling spatial continuity, this paper proposes a novel decoder framework specifically designed for medical image segmentation, comprising three core modules. First, the Adaptive Cross-Fusion Attention (ACFA) module integrates channel feature enhancement with spatial attention mechanisms and introduces learnable guidance in three directions (planar, horizontal, and vertical) to enhance responsiveness to key regions and structural orientations. Second, the Triple Feature Fusion Attention (TFFA) module fuses features from Spatial, Fourier and Wavelet domains, achieving joint frequency-spatial representation that strengthens global dependency and structural modeling while preserving local information such as edges and textures, making it particularly effective in complex and blurred boundary scenarios. Finally, the Structural-aware Multi-scale Masking Module (SMMM) optimizes the skip connections between encoder and decoder by leveraging multi-scale context and structural saliency filtering, effectively reducing feature redundancy and improving semantic interaction quality. Working synergistically, these modules not only address the shortcomings of traditional decoders but also significantly enhance performance in high-precision tasks such as tumor segmentation and organ boundary extraction, improving both segmentation accuracy and model generalization. Experimental results demonstrate that this framework provides an efficient and practical solution for medical image segmentation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to AAAI 2026</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>