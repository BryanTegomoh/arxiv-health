<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework - Health AI Hub</title>
    <meta name="description" content="This paper presents a Retrieval-Augmented Generation (RAG) based medical question-answering (QA) system designed to address challenges of factual accuracy and h">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05863v1" target="_blank">2512.05863v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Tasnimul Hassan, Md Faisal Karim, Haziq Jeelani, Elham Behnam, Robert Green, Fayeq Jeelani Syed
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05863v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05863v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a Retrieval-Augmented Generation (RAG) based medical question-answering (QA) system designed to address challenges of factual accuracy and hallucinations in LLMs for clinical use. By fine-tuning open-source LLMs (LLaMA-2 and Falcon) with LoRA and grounding answers in retrieved medical literature, the system significantly improves accuracy and reduces unsupported content, demonstrating potential for reliable biomedical QA applications. The fine-tuned LLaMA-2 model achieved 71.8% accuracy on PubMedQA, a substantial improvement over its 55.4% zero-shot baseline.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine as it addresses fundamental limitations of AI in healthcare, particularly the need for factual accuracy and trustworthiness. By mitigating hallucinations and providing verifiable sources, it paves the way for safer and more reliable AI-driven tools in clinical practice and medical education.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops and evaluates an AI-powered medical question-answering system. It leverages large language models (LLMs) combined with a Retrieval-Augmented Generation (RAG) framework to provide accurate and evidence-grounded answers to medical questions, drawing from medical literature. The application is designed to support clinical decision-making, information retrieval for healthcare professionals, and general biomedical knowledge access by mitigating common LLM issues like hallucinations in a medical context.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The research tackles the critical issues of factual accuracy and hallucinations when applying Large Language Models (LLMs) directly to the medical domain.</li>
                    
                    <li>A Retrieval-Augmented Generation (RAG) framework is utilized, combining domain-specific knowledge retrieval with open-source LLMs (LLaMA-2 and Falcon) for medical QA.</li>
                    
                    <li>Low-Rank Adaptation (LoRA) was employed for efficient fine-tuning of the chosen LLMs, enabling domain specialization.</li>
                    
                    <li>The system grounds generated answers in retrieved relevant medical literature, which is shown to improve factual correctness and significantly reduce hallucinations.</li>
                    
                    <li>Evaluated on benchmark datasets (PubMedQA and MedMCQA), retrieval augmentation demonstrably improves answer accuracy compared to LLMs used in isolation.</li>
                    
                    <li>The fine-tuned LLaMA-2 model achieved a 71.8% accuracy on PubMedQA, substantially outperforming its 55.4% zero-shot baseline and providing transparency through source references.</li>
                    
                    <li>Grounding answers in retrieved evidence was shown to reduce unsupported content (hallucinations) by approximately 60%.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved developing a RAG-based medical QA system. Two state-of-the-art open LLMs, LLaMA-2 and Falcon, were fine-tuned using Low-Rank Adaptation (LoRA) for domain-specific knowledge. The core mechanism involves retrieving relevant medical literature to 'ground' the LLM's generated answers, aiming to enhance factual correctness and reduce hallucination. The system's performance was evaluated against benchmark datasets, PubMedQA and MedMCQA, comparing accuracy of RAG-augmented, fine-tuned models against zero-shot baselines and LLMs without retrieval.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings include a substantial improvement in medical QA accuracy through retrieval augmentation; the fine-tuned LLaMA-2 model achieved 71.8% accuracy on PubMedQA, a significant increase from its 55.4% zero-shot baseline. Furthermore, grounding answers in retrieved evidence was shown to reduce unsupported content (hallucinations) by approximately 60%, while also providing critical transparency through source references.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The potential clinical impact is significant, enabling the development of more reliable and trustworthy medical QA systems for diverse applications such as clinical decision support, medical education, and patient information dissemination. By ensuring factual accuracy, minimizing hallucinations, and offering verifiable sources, this approach fosters greater confidence in AI-generated medical information, ultimately contributing to better patient outcomes and more efficient healthcare delivery.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the methodology or findings.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The results highlight the potential for RAG-augmented open-source LLMs in reliable biomedical QA, pointing towards practical applications within clinical informatics. This suggests future work could focus on further development, validation, and deployment of such systems in real-world clinical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Biomedical Research</span>
                    
                    <span class="tag">Medical Education</span>
                    
                    <span class="tag">Decision Support Systems</span>
                    
                    <span class="tag">Patient Information</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical QA</span>
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">RAG</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                    <span class="tag tag-keyword">LLaMA-2</span>
                    
                    <span class="tag tag-keyword">Hallucination</span>
                    
                    <span class="tag tag-keyword">Factual Accuracy</span>
                    
                    <span class="tag tag-keyword">Clinical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>