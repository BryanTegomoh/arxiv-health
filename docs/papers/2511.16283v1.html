<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering - Health AI Hub</title>
    <meta name="description" content="This paper introduces MuISQA, a new benchmark designed to evaluate Retrieval-Augmented Generation (RAG) systems on complex scientific questions that entail mult">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.16283v1" target="_blank">2511.16283v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-20
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Zhiyuan Li, Haisheng Yu, Guangchuan Guo, Nan Zhou, Jiajun Zhang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.90 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.16283v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.16283v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MuISQA, a new benchmark designed to evaluate Retrieval-Augmented Generation (RAG) systems on complex scientific questions that entail multiple intents and require heterogeneous evidence. To address the limitations of conventional single-intent RAG systems, the authors propose an intent-aware retrieval framework that leverages Large Language Models (LLMs) to decompose questions into intent-specific queries. The framework retrieves supporting evidence for each intent, aggregates, and re-ranks it using Reciprocal Rank Fusion (RRF), demonstrating superior performance in retrieval accuracy and evidence coverage compared to conventional approaches.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine and health as it directly addresses the challenge of accurately and comprehensively answering complex biomedical questions, such as identifying gene mutations and linking them to specific diseases, which require synthesizing information from diverse and often fragmented sources.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research contributes to the development of advanced AI systems for scientific question answering in the biomedical domain. Potential applications include assisting researchers in identifying gene-disease relationships, aiding in drug discovery by synthesizing information from diverse sources, supporting clinical decision-making by providing comprehensive evidence for complex cases (e.g., rare genetic disorders), and enhancing knowledge retrieval for medical professionals and patients.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Conventional RAG systems are limited by their single-intent orientation, leading to incomplete evidence coverage for complex scientific questions requiring multi-hop reasoning and diverse sources.</li>
                    
                    <li>The MuISQA benchmark is introduced to specifically evaluate RAG systems' capacity for heterogeneous evidence coverage across sub-questions within multi-intent scientific queries.</li>
                    
                    <li>An intent-aware retrieval framework is proposed, utilizing LLMs to first hypothesize potential answers and then decompose them into distinct, intent-specific queries.</li>
                    
                    <li>The framework retrieves supporting passages for each underlying intent, ensuring a comprehensive collection of diverse evidence.</li>
                    
                    <li>Retrieved fragments are subsequently aggregated and re-ranked using Reciprocal Rank Fusion (RRF) to optimally balance evidence coverage across different intents while minimizing redundancy.</li>
                    
                    <li>Experimental results on both the MuISQA benchmark and other general RAG datasets confirm that the proposed method consistently outperforms conventional RAG approaches.</li>
                    
                    <li>The improvements are particularly notable in enhanced retrieval accuracy and more comprehensive evidence coverage, addressing a critical need in scientific question answering.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves an intent-aware retrieval framework. This framework employs LLMs to first hypothesize potential answers, which are then decomposed into multiple intent-specific queries. For each decomposed intent, supporting passages are retrieved. These retrieved fragments are then aggregated and re-ranked using Reciprocal Rank Fusion (RRF) to achieve balanced coverage across diverse intents and reduce redundancy.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The proposed multi-intent retrieval framework consistently and significantly outperforms conventional RAG approaches. This superior performance is evident in both increased retrieval accuracy and markedly improved evidence coverage, particularly for complex scientific questions requiring heterogeneous information, as validated on the MuISQA benchmark and other general RAG datasets.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The ability to accurately and comprehensively answer complex, multi-faceted medical questions can significantly impact clinical practice and biomedical research. It can lead to more robust clinical decision support systems, enabling healthcare professionals to quickly access all relevant evidence for complex patient cases (e.g., linking specific genetic profiles to disease prognoses or optimal drug therapies). For researchers, it accelerates the synthesis of vast amounts of scientific literature, fostering new discoveries and advancements in fields like precision medicine by ensuring all related aspects of a query are considered.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *conventional* Retrieval-Augmented Generation (RAG) systems (i.e., being single-intent oriented and leading to incomplete evidence). It does not explicitly state specific limitations or caveats of the proposed MuISQA framework itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions for the MuISQA framework or the intent-aware retrieval approach.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Genomics</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Biomedical Research</span>
                    
                    <span class="tag">Pharmacogenomics</span>
                    
                    <span class="tag">Disease Diagnostics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multi-intent Question Answering</span>
                    
                    <span class="tag tag-keyword">Retrieval-Augmented Generation (RAG)</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Scientific Question Answering</span>
                    
                    <span class="tag tag-keyword">Evidence Coverage</span>
                    
                    <span class="tag tag-keyword">Reciprocal Rank Fusion (RRF)</span>
                    
                    <span class="tag tag-keyword">Biomedical Information Retrieval</span>
                    
                    <span class="tag tag-keyword">Precision Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>15 pages</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>