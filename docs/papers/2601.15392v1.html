<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation - Health AI Hub</title>
    <meta name="description" content="GeMM-GAN is a novel multimodal Generative Adversarial Network designed to synthesize realistic and biologically coherent gene expression profiles. It addresses ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15392v1" target="_blank">2601.15392v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Francesca Pia Panaccione, Carlo Sgaravatti, Pietro Pinoli
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI, cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15392v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15392v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">GeMM-GAN is a novel multimodal Generative Adversarial Network designed to synthesize realistic and biologically coherent gene expression profiles. It addresses the challenges of privacy regulations and high costs associated with real gene expression data by conditioning its generation on readily available histopathology images and clinical metadata. The framework demonstrates superior performance, generating functionally meaningful profiles that improve downstream disease type prediction by over 11% compared to current state-of-the-art generative models.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research offers a critical solution for generating synthetic gene expression data, effectively bypassing strict privacy regulations and reducing the substantial costs associated with laboratory experiments. It facilitates broader biomedical research, model development, and data sharing in genomics and precision medicine, accelerating the discovery of biomarkers and therapeutic targets.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>GeMM-GAN is a medical AI application designed to generate synthetic yet biologically coherent gene expression profiles from routinely collected medical images (histopathology) and clinical descriptions. This capability helps overcome limitations in medical research by circumventing stringent privacy regulations and reducing the high cost of laboratory experiments for gene expression profiling. The generated data can be used to augment datasets, facilitate research without direct access to sensitive patient genomic data, and improve the accuracy of downstream AI models for disease type prediction, contributing to more robust diagnostic and prognostic tools in healthcare.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed**: Tackles the limitations of gene expression data collection, primarily due to stringent privacy regulations and costly laboratory experiments.</li>
                    
                    <li>**Novel Model Introduction**: Presents GeMM-GAN, a new Generative Adversarial Network specifically engineered for multimodal data integration.</li>
                    
                    <li>**Multimodal Conditioning**: The generative process is conditioned on two distinct and routinely collected modalities: histopathology tissue slides (image data) and clinical metadata (textual descriptions).</li>
                    
                    <li>**Advanced Architecture**: Employs a Transformer Encoder to process image patches and incorporates a Cross Attention mechanism to effectively integrate features from image patches and text tokens, producing a comprehensive conditioning vector.</li>
                    
                    <li>**Biologically Realistic Output**: Designed to synthesize gene expression profiles that are not only realistic but also biologically coherent.</li>
                    
                    <li>**Performance Evaluation**: The approach is rigorously evaluated using the TCGA dataset, demonstrating superior performance over existing standard generative models.</li>
                    
                    <li>**Improved Downstream Prediction**: Achieves a significant improvement of more than 11% in accuracy on downstream disease type prediction tasks, surpassing current state-of-the-art generative models.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>GeMM-GAN operates as a conditional Generative Adversarial Network. It processes histopathology tissue slides by first extracting image patches, which are then encoded using a Transformer Encoder. Clinical descriptions are tokenized to represent textual information. A critical component is the Cross Attention mechanism, which enables the integration of features from both the image patches and the text tokens, producing a unified 'conditioning vector.' This multimodal conditioning vector subsequently guides the generative model (the generator component of the GAN) to synthesize realistic and biologically coherent gene expression profiles. The entire framework is trained and validated on the TCGA dataset.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings indicate that GeMM-GAN successfully synthesizes realistic and biologically coherent gene expression profiles by leveraging multimodal input (histopathology images and clinical metadata). The framework significantly outperforms standard generative models in the quality and functional meaningfulness of the generated data. Crucially, the synthetic gene expression profiles generated by GeMM-GAN lead to an improvement of over 11% in accuracy for downstream disease type prediction tasks when compared to state-of-the-art generative models.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>GeMM-GAN has the potential to profoundly impact clinical research and practice by providing an ethical, cost-effective, and scalable method for generating large, diverse datasets of gene expression profiles. This can accelerate biomarker discovery, facilitate the development and validation of diagnostic tools, enhance personalized treatment strategies, and enable robust training of AI models for disease prediction, particularly in contexts where real patient data is scarce or sensitive, all without compromising patient privacy or incurring high experimental costs.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations or caveats regarding the GeMM-GAN model or its evaluation.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state specific future research directions for GeMM-GAN.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Genomics</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Biomedical Research</span>
                    
                    <span class="tag">Bioinformatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Generative Adversarial Network</span>
                    
                    <span class="tag tag-keyword">Gene Expression</span>
                    
                    <span class="tag tag-keyword">Histopathology Images</span>
                    
                    <span class="tag tag-keyword">Clinical Metadata</span>
                    
                    <span class="tag tag-keyword">Multimodal Learning</span>
                    
                    <span class="tag tag-keyword">Transformer Encoder</span>
                    
                    <span class="tag tag-keyword">Cross Attention</span>
                    
                    <span class="tag tag-keyword">Synthetic Data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>12 pages, 2 figures. Published at Image Analysis and Processing - ICIAP 2025 Workshops</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>