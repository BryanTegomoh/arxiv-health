<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation - Health AI Hub</title>
    <meta name="description" content="GeMM-GAN is a novel Multimodal Generative Adversarial Network designed to synthesize realistic gene expression profiles. It addresses the challenges of costly a">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2601.15392v1" target="_blank">2601.15392v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2026-01-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Francesca Pia Panaccione, Carlo Sgaravatti, Pietro Pinoli
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.AI, cs.CV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2601.15392v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2601.15392v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">GeMM-GAN is a novel Multimodal Generative Adversarial Network designed to synthesize realistic gene expression profiles. It addresses the challenges of costly and privacy-sensitive gene expression data collection by conditioning its generation on readily available histopathology images and clinical metadata. The model produces biologically coherent profiles, significantly improving downstream disease type prediction accuracy by over 11% compared to current state-of-the-art generative models.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for medical and health fields as it offers a solution to the significant hurdles of accessing and utilizing gene expression data in research. By enabling the synthesis of realistic gene expression profiles from more readily available clinical images and text, it can accelerate biomarker discovery, drug development, and personalized medicine research while circumventing privacy concerns and high laboratory costs.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI model (GeMM-GAN) serves as an application to generate synthetic but realistic gene expression profiles from routinely collected medical images (histopathology) and clinical descriptions. This addresses the scarcity, cost, and privacy issues associated with real gene expression data. The generated data can then be utilized to improve the accuracy of disease type prediction, thereby assisting in medical diagnosis, understanding disease mechanisms, and accelerating biomedical research by providing rich, integrated data for analysis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitations of gene expression data (privacy regulations, costly experiments) by generating synthetic profiles from routinely collected clinical data.</li>
                    
                    <li>Utilizes a multimodal conditioning approach, taking both histopathology tissue slides (images) and clinical metadata (text) as inputs.</li>
                    
                    <li>Employs a Transformer Encoder to process image patches and a Cross Attention mechanism to integrate image and text information.</li>
                    
                    <li>Generates a unified conditioning vector from the multimodal inputs to guide the generative process of synthesizing gene expression profiles.</li>
                    
                    <li>The model is designed to produce biologically coherent and functionally meaningful synthetic gene expression profiles.</li>
                    
                    <li>Evaluated on the TCGA dataset, GeMM-GAN demonstrates superior performance compared to standard generative models.</li>
                    
                    <li>Achieves a significant improvement, exceeding 11% in accuracy, for downstream disease type prediction when using the generated gene expression profiles.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>GeMM-GAN is a Generative Adversarial Network (GAN) framework. It integrates multimodal data by first employing a Transformer Encoder to process patches from histopathology images. This visual information is then combined with text tokens from clinical descriptions using a Cross Attention mechanism. The output of this multimodal integration is a compact conditioning vector, which subsequently guides the generative model to synthesize realistic and biologically coherent gene expression profiles.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that GeMM-GAN successfully generates realistic and functionally meaningful gene expression profiles conditioned on multimodal inputs (histopathology images and clinical descriptions). This framework significantly outperforms standard generative models, leading to an over 11% improvement in accuracy on downstream disease type prediction compared to current state-of-the-art generative models.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This technology has the potential to transform biomedical research by providing an alternative, cost-effective, and privacy-preserving method to access gene expression-like data. Clinically, it could facilitate the development of AI models for more accurate disease diagnosis, prognosis, and therapeutic stratification without the need for direct, expensive, and invasive gene sequencing. This could accelerate personalized medicine initiatives and biomarker discovery, especially in cancer research.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                    <span class="tag">Bioinformatics</span>
                    
                    <span class="tag">Genomics</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Gene expression</span>
                    
                    <span class="tag tag-keyword">Generative Adversarial Network (GAN)</span>
                    
                    <span class="tag tag-keyword">Multimodal learning</span>
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Clinical metadata</span>
                    
                    <span class="tag tag-keyword">Transformer Encoder</span>
                    
                    <span class="tag tag-keyword">Cross Attention</span>
                    
                    <span class="tag tag-keyword">TCGA</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>12 pages, 2 figures. Published at Image Analysis and Processing - ICIAP 2025 Workshops</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>