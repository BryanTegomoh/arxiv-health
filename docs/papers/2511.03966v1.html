<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis - Health AI Hub</title>
    <meta name="description" content="This paper addresses the critical need for effective data unlearning mechanisms in Cognitive Diagnosis (CD) models to protect student privacy and comply with 'r">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.03966v1" target="_blank">2511.03966v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-06
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mingliang Hou, Yinuo Wang, Teng Guo, Zitao Liu, Wenzhou Dou, Jiaqi Zheng, Renqiang Luo, Mi Tian, Weiqi Luo
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.80 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.03966v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.03966v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper addresses the critical need for effective data unlearning mechanisms in Cognitive Diagnosis (CD) models to protect student privacy and comply with 'right to be forgotten' requests. It introduces a novel algorithm, Hierarchical Importance-guided Forgetting (HIF), which leverages the unique layer-wise characteristics of parameter importance in CD models. HIF significantly outperforms existing baselines, offering the first effective solution for deploying high-performance, privacy-preserving AI systems in cognitive assessment.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Cognitive diagnosis models, while presented in an educational context here, have direct applications in medicine for assessing patient cognitive function (e.g., in neurology, psychiatry, rehabilitation). The ability to unlearn specific patient data is paramount for ensuring patient privacy, adhering to strict health data regulations (like HIPAA/GDPR), and fostering trust in AI-powered clinical tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research enables the development and deployment of high-performance, privacy-preserving AI systems for clinical cognitive assessment, diagnosis of cognitive impairments, and personalized treatment planning. It ensures that AI models used in healthcare for cognitive diagnosis can effectively respond to patient data removal requests ('right to be forgotten'), enhancing data protection and ethical AI practices in medicine.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Identification:** Existing Cognitive Diagnosis (CD) models lack effective data unlearning mechanisms, making them unable to comply with user privacy requests like the 'right to be forgotten' due to their unique heterogeneous structure.</li>
                    
                    <li>**Ineffectiveness of General Methods:** General-purpose unlearning algorithms are suboptimal for CD models, struggling to balance unlearning completeness, model utility, and efficiency.</li>
                    
                    <li>**Novel Solution (HIF):** The paper proposes Hierarchical Importance-guided Forgetting (HIF), the first systematic algorithm specifically designed for data unlearning in CD models.</li>
                    
                    <li>**Core Methodology - Hierarchical Importance:** HIF's key insight is the distinct layer-wise nature of parameter importance in CD models, which it leverages to precisely identify parameters associated with specific unlearned data.</li>
                    
                    <li>**Innovative Mechanism - Smoothing:** HIF employs an innovative smoothing mechanism that combines both individual and layer-level importance measures, enabling more accurate distinction of parameters for targeted unlearning.</li>
                    
                    <li>**Superior Performance:** Experimental evaluations on three real-world datasets demonstrate that HIF significantly outperforms baseline unlearning algorithms across key metrics (completeness, utility, efficiency).</li>
                    
                    <li>**Enabling Privacy-Preserving AI:** HIF provides the first practical solution for CD models to effectively respond to user data removal requests, paving the way for the deployment of high-performance, privacy-preserving AI systems in cognitive assessment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The paper introduces Hierarchical Importance-guided Forgetting (HIF), an algorithm tailored for unlearning in Cognitive Diagnosis (CD) models. HIF exploits the layer-wise characteristics of parameter importance within these models. It utilizes an innovative smoothing mechanism that integrates both individual and layer-level importance to accurately distinguish and modify model parameters associated with the specific data targeted for unlearning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>HIF demonstrably and significantly outperforms existing general-purpose data unlearning algorithms on three real-world datasets across crucial metrics, achieving a superior balance of unlearning completeness, model utility, and efficiency. This establishes HIF as the first effective solution for CD models to robustly handle user data removal requests, thereby enabling truly privacy-preserving AI systems in cognitive assessment.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a crucial technical foundation for developing and deploying ethical, privacy-preserving AI systems in clinical cognitive assessment. It allows healthcare organizations to comply with patient 'right to be forgotten' requests and data privacy regulations (e.g., HIPAA, GDPR) without compromising the diagnostic utility of AI models. This capability fosters greater patient trust and facilitates the wider adoption of AI in sensitive medical applications like tracking cognitive decline, assessing treatment efficacy, or personalized rehabilitation.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While not explicitly stated in the abstract, potential limitations could include the computational complexity of applying HIF to extremely large-scale CD models with massive parameter counts or the absolute guarantee of 'complete' unlearning in highly entangled deep learning architectures. The generalizability of 'layer-wise importance' might also need further exploration across a broader range of CD model types beyond those implicitly studied.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>Future work could involve investigating the scalability of HIF to even larger and more complex cognitive assessment models, exploring its integration with other privacy-enhancing technologies like differential privacy or federated learning for enhanced data protection, and rigorously validating its effectiveness with actual patient data in diverse clinical settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Neuropsychology</span>
                    
                    <span class="tag">Psychiatry</span>
                    
                    <span class="tag">Neurology</span>
                    
                    <span class="tag">Rehabilitation Medicine</span>
                    
                    <span class="tag">Geriatrics</span>
                    
                    <span class="tag">Medical Education</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Cognitive Diagnosis</span>
                    
                    <span class="tag tag-keyword">Data Unlearning</span>
                    
                    <span class="tag tag-keyword">Privacy Preservation</span>
                    
                    <span class="tag tag-keyword">Right to be Forgotten</span>
                    
                    <span class="tag tag-keyword">Hierarchical Forgetting</span>
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">AI in Healthcare</span>
                    
                    <span class="tag tag-keyword">Patient Privacy</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>