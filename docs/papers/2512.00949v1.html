<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Modal AI for Remote Patient Monitoring in Cancer Care - Health AI Hub</title>
    <meta name="description" content="This paper presents a multi-modal AI framework for remote patient monitoring (RPM) in cancer care, aiming to bridge the gap of unmonitored side effects between ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Multi-Modal AI for Remote Patient Monitoring in Cancer Care</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.00949v1" target="_blank">2512.00949v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Yansong Liu, Ronnie Stafford, Pramit Khetrapal, Huriye Kocadag, Gra√ßa Carvalho, Patricia de Winter, Maryam Imran, Amelia Snook, Adamos Hadjivasiliou, D. Vijay Anand, Weining Lin, John Kelly, Yukun Zhou, Ivana Drobnjak
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.00949v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.00949v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper presents a multi-modal AI framework for remote patient monitoring (RPM) in cancer care, aiming to bridge the gap of unmonitored side effects between clinic visits. Developed and prospectively trialed on 84 patients, the system integrates diverse data from the HALO-X platform, achieving 83.9% accuracy (AUROC=0.70) in forecasting adverse events. The findings establish the feasibility of AI-powered RPM for proactive patient support in oncology.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant as it offers a robust solution to a significant unmet need in oncology: proactive monitoring of treatment-related side effects between clinic visits. By enabling early detection and intervention, it has the potential to improve patient safety, reduce morbidity, enhance quality of life, and optimize resource utilization in cancer care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Development and prospective trial of a multi-modal AI model that integrates data from wearable sensors, daily surveys, and clinical events to forecast the continuous risk of future adverse events in cancer patients undergoing systemic therapy, enabling early warnings and proactive patient support.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical gap in cancer care by providing continuous monitoring for patients undergoing systemic therapy, aiming to mitigate risks of unmonitored side effects.</li>
                    
                    <li>Developed a multi-modal AI framework for Remote Patient Monitoring (RPM) that integrates various data streams from the HALO-X platform, including demographics, wearable sensors, daily surveys, and clinical events.</li>
                    
                    <li>Conducted a large observational trial, collecting over 2.1 million data points (6,080 patient-days) from 84 cancer patients.</li>
                    
                    <li>The multi-modal AI model was specifically adapted to handle the asynchronous and incomplete nature of real-world RPM data, continuously forecasting the risk of future adverse events.</li>
                    
                    <li>Achieved a predictive accuracy of 83.9% with an Area Under the Receiver Operating Characteristic (AUROC) curve of 0.70 for forecasting adverse events.</li>
                    
                    <li>Identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features for adverse events.</li>
                    
                    <li>A case study demonstrated the model's capability to provide early warnings by outputting escalating risk profiles prior to the actual occurrence of an adverse event.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>An observational trial was conducted using the HALO-X platform to collect multi-modal data (demographics, wearable sensor data, daily surveys, clinical events) from 84 cancer patients. A multi-modal AI model was developed and adapted to address the asynchronous and incomplete nature of real-world RPM data, tasked with forecasting a continuous risk of future adverse events. The model's performance was evaluated using accuracy and AUROC.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The multi-modal AI model achieved an accuracy of 83.9% (AUROC=0.70) in forecasting future adverse events. Key predictive features identified were previous treatments, wellness check-ins, and daily maximum heart rate. A case study demonstrated the model's ability to provide early warnings through escalating risk profiles, thereby establishing the feasibility of multi-modal AI RPM in cancer care.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This system holds significant clinical potential for providing proactive patient support in oncology. It could enable early intervention for emerging adverse events, potentially preventing severe complications, reducing unplanned hospitalizations, and improving overall patient outcomes and quality of life during systemic cancer therapy. It offers a paradigm shift towards more preventative and personalized cancer care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly list limitations of the study itself. However, the AUROC of 0.70, while indicating fair discrimination, suggests room for improvement in predictive power. The generalizability of findings from a cohort of 84 patients, although noted as one of the largest of its kind, might still be a consideration for broader application.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work establishes the feasibility of multi-modal AI RPM for cancer care and 'offers a path toward more proactive patient support.' This implies future work will focus on further refinement, validation in larger and more diverse cohorts, and integration into clinical workflows to realize its full potential for proactive patient management.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Telemedicine</span>
                    
                    <span class="tag">Palliative Care</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multi-modal AI</span>
                    
                    <span class="tag tag-keyword">Remote Patient Monitoring (RPM)</span>
                    
                    <span class="tag tag-keyword">Cancer Care</span>
                    
                    <span class="tag tag-keyword">Adverse Events</span>
                    
                    <span class="tag tag-keyword">Wearable Sensors</span>
                    
                    <span class="tag tag-keyword">Machine Learning</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Predictive Analytics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop)</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>