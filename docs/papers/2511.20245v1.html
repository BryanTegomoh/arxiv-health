<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers - Health AI Hub</title>
    <meta name="description" content="HistoSpeckle-Net is a novel deep learning architecture designed for high-fidelity reconstruction of complex medical images (OrganAMNIST) from multimode fiber (M">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20245v1" target="_blank">2511.20245v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jawaria Maqbool, M. Imran Cheema
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, physics.optics
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20245v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20245v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">HistoSpeckle-Net is a novel deep learning architecture designed for high-fidelity reconstruction of complex medical images (OrganAMNIST) from multimode fiber (MMF) speckle patterns. It introduces a distribution-aware learning strategy, utilizing histogram-based mutual information loss and multiscale Structural Similarity Index Measure (SSIM) loss, enabling robust and data-efficient performance. This approach significantly outperforms baseline models, even with limited training data and under fiber perturbations, bringing MMF imaging closer to practical clinical deployment.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant to medicine by advancing multimode fiber imaging, a technology critical for minimally invasive procedures and diagnostics. It enables accurate reconstruction of complex anatomical features from fiber-optic data under real-world clinical constraints, such as limited data and physical fiber perturbations.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>HistoSpeckle-Net is an AI application that uses deep learning to reconstruct high-fidelity medical images of organs from speckle patterns transmitted through multimode fibers. This technology could enable advanced minimally invasive endoscopic imaging for diagnostic purposes in clinical environments, allowing for the visualization of internal anatomical structures that are difficult to image otherwise, even under challenging conditions like fiber bending or limited data.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed**: Current deep learning methods for MMF imaging are limited by simpler datasets, high data intensity requirements, and lack of consideration for speckle/image statistics, hindering applicability to complex medical tasks.</li>
                    
                    <li>**Novel Architecture**: Introduces HistoSpeckle-Net, a deep learning model specifically designed for high-fidelity reconstruction of structurally rich medical images from MMF speckles.</li>
                    
                    <li>**Clinically Relevant Dataset Generation**: An optical setup utilizing a spatial light modulator (SLM) and MMF was developed to generate speckle patterns from OrganAMNIST images, creating a practical dataset for training.</li>
                    
                    <li>**Distribution-Aware Learning Strategy**: Incorporates a histogram-based mutual information (MI) loss, calculated via a histogram computation unit, to enhance model robustness and reduce reliance on large datasets by ensuring statistical alignment.</li>
                    
                    <li>**Multiscale Structural Fidelity**: Features a unique Three-Scale Feature Refinement Module that enables multiscale Structural Similarity Index Measure (SSIM) loss computation, thereby improving the structural fidelity of reconstructions.</li>
                    
                    <li>**Superior Performance**: HistoSpeckle-Net achieves higher reconstruction fidelity on the complex OrganAMNIST dataset compared to baseline models like U-Net and Pix2Pix.</li>
                    
                    <li>**Robustness and Data Efficiency**: Demonstrates superior performance even with limited training samples and across varying fiber bending conditions, effectively reconstructing complex anatomical features under perturbed environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors established an optical setup involving a laser, a spatial light modulator (SLM) to encode OrganAMNIST images, and a multimode fiber (MMF) to generate output speckle patterns. This system created a synthetic but clinically relevant dataset. HistoSpeckle-Net, a deep learning architecture, was then developed and trained on these speckle-image pairs. Its core innovations include a histogram computation unit for calculating smooth marginal and joint histograms, which are used to derive a histogram-based mutual information (MI) loss for statistical alignment. Additionally, a Three-Scale Feature Refinement Module facilitates the computation of a multiscale Structural Similarity Index Measure (SSIM) loss to ensure high structural fidelity. Performance was evaluated against U-Net and Pix2Pix baselines on the OrganAMNIST dataset under various conditions, including limited data and fiber bending.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>HistoSpeckle-Net significantly outperforms baseline deep learning models (U-Net, Pix2Pix) in reconstructing complex OrganAMNIST images from MMF speckles, achieving higher fidelity. Its unique combination of mutual information loss for statistical alignment and multiscale SSIM loss for structural fidelity allows it to operate effectively with limited training data and maintain superior performance even under physical perturbations like fiber bending. This demonstrates its capability to accurately reconstruct intricate anatomical features under challenging conditions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work represents a significant step towards the practical clinical deployment of multimode fiber imaging. By enabling robust, high-fidelity reconstruction of complex anatomical features with reduced data requirements and resilience to fiber perturbations, HistoSpeckle-Net addresses key challenges for real-world applications in minimally invasive diagnostics, endoscopy, and surgical guidance, potentially leading to more advanced and reliable medical imaging tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of existing MMF imaging methods (simpler datasets, data-intensive) that HistoSpeckle-Net aims to overcome. It does not explicitly state specific limitations or drawbacks of the HistoSpeckle-Net model itself.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper concludes by stating that HistoSpeckle-Net "brings MMF imaging closer to practical deployment in real-world clinical environments." This implies a future direction focused on further clinical translation, validation in vivo, and integration into practical medical devices, though no specific research steps are detailed within the abstract.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Endoscopy</span>
                    
                    <span class="tag">Minimally Invasive Diagnostics</span>
                    
                    <span class="tag">Surgical Imaging</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">multimode fiber imaging</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">speckle reconstruction</span>
                    
                    <span class="tag tag-keyword">mutual information</span>
                    
                    <span class="tag tag-keyword">OrganAMNIST</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">fiber optics</span>
                    
                    <span class="tag tag-keyword">clinical deployment</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Existing deep learning methods in multimode fiber (MMF) imaging often focus on simpler datasets, limiting their applicability to complex, real-world imaging tasks. These models are typically data-intensive, a challenge that becomes more pronounced when dealing with diverse and complex images. In this work, we propose HistoSpeckle-Net, a deep learning architecture designed to reconstruct structurally rich medical images from MMF speckles. To build a clinically relevant dataset, we develop an optical setup that couples laser light through a spatial light modulator (SLM) into an MMF, capturing output speckle patterns corresponding to input OrganAMNIST images. Unlike previous MMF imaging approaches, which have not considered the underlying statistics of speckles and reconstructed images, we introduce a distribution-aware learning strategy. We employ a histogram-based mutual information loss to enhance model robustness and reduce reliance on large datasets. Our model includes a histogram computation unit that estimates smooth marginal and joint histograms for calculating mutual information loss. It also incorporates a unique Three-Scale Feature Refinement Module, which leads to multiscale Structural Similarity Index Measure (SSIM) loss computation. Together, these two loss functions enhance both the structural fidelity and statistical alignment of the reconstructed images. Our experiments on the complex OrganAMNIST dataset demonstrate that HistoSpeckle-Net achieves higher fidelity than baseline models such as U-Net and Pix2Pix. It gives superior performance even with limited training samples and across varying fiber bending conditions. By effectively reconstructing complex anatomical features with reduced data and under fiber perturbations, HistoSpeckle-Net brings MMF imaging closer to practical deployment in real-world clinical environments.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>