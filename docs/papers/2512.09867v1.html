<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI - Health AI Hub</title>
    <meta name="description" content="MedForget is a novel hierarchy-aware multimodal unlearning testbed designed for medical AI, specifically addressing critical privacy challenges like the "right ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.09867v1" target="_blank">2512.09867v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Fengli Wu, Vaidehi Patil, Jaehong Yoon, Yue Zhang, Mohit Bansal
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI, cs.CL
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.09867v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.09867v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MedForget is a novel hierarchy-aware multimodal unlearning testbed designed for medical AI, specifically addressing critical privacy challenges like the "right to be forgotten" for sensitive patient data under regulations such as HIPAA and GDPR. The research demonstrates that current state-of-the-art unlearning methods struggle to achieve complete, fine-grained hierarchical forgetting without compromising diagnostic performance, and can leave models vulnerable to reconstruction attacks via contextual cues.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critical for developing HIPAA and GDPR-compliant medical AI systems by providing a framework to rigorously test and improve unlearning capabilities for sensitive patient data. It ensures the ethical and legal deployment of MLLMs in clinical settings for tasks such as diagnosis support and report generation, safeguarding patient privacy.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development and ethical deployment of privacy-preserving medical AI systems. Specifically, it enables the study and improvement of machine unlearning techniques for Multimodal Large Language Models (MLLMs) used in clinical reasoning, diagnosis support, and report generation, ensuring compliance with patient data privacy regulations like HIPAA and GDPR while maintaining diagnostic performance.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>**Problem Addressed:** MLLMs in medical AI face significant privacy and compliance issues (HIPAA, GDPR) due to training on sensitive patient data, necessitating robust unlearning capabilities to enforce the "right to be forgotten."</li>
                    
                    <li>**Novel Testbed:** Introduction of MedForget, a Hierarchy-Aware Multimodal Unlearning Testbed with explicit retain/forget data splits and evaluation sets containing rephrased variants to thoroughly assess forgetting.</li>
                    
                    <li>**Hierarchical Data Modeling:** MedForget models hospital data as a nested hierarchy (Institution -> Patient -> Study -> Section), enabling fine-grained assessment of unlearning effectiveness across eight distinct organizational levels.</li>
                    
                    <li>**Benchmark Composition:** The testbed comprises 3840 multimodal instances (image, question, answer), with each hierarchy level having a dedicated unlearning target to reflect diverse unlearning challenges.</li>
                    
                    <li>**SOTA Unlearning Limitations:** Experiments using four state-of-the-art unlearning methods on three tasks (generation, classification, cloze) reveal that existing techniques struggle to achieve complete, hierarchy-aware forgetting without reducing diagnostic performance.</li>
                    
                    <li>**Reconstruction Attack:** A novel reconstruction attack is introduced, which progressively adds hierarchical level context to prompts to test the true deletion of forgotten information.</li>
                    
                    <li>**Vulnerability of Fine-Grained Unlearning:** The reconstruction attack showed that models unlearned at a coarse granularity exhibit strong resistance, while fine-grained unlearning leaves models vulnerable, indicating incomplete erasure of hierarchical pathways and potential for information recovery.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved creating MedForget, a hierarchy-aware multimodal unlearning testbed based on hospital data organized into a nested structure (Institution -> Patient -> Study -> Section). It contains 3840 multimodal instances (image, question, answer) with dedicated unlearning targets for each of its eight hierarchical levels. Four state-of-the-art unlearning methods were evaluated on three distinct AI tasks (generation, classification, cloze). A novel reconstruction attack was also devised, progressively adding hierarchical context to prompts, to assess the completeness and robustness of unlearning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Existing state-of-the-art unlearning methods are currently insufficient, as they fail to achieve complete, hierarchy-aware forgetting without compromising the model's diagnostic performance. Furthermore, the effectiveness of unlearning is highly dependent on granularity; fine-grained unlearning leaves models susceptible to reconstruction attacks that leverage hierarchical context, indicating that critical information pathways are not fully erased.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MedForget serves as an essential, HIPAA-aligned testbed for advancing the development of privacy-preserving medical AI systems. It provides the tools to rigorously evaluate unlearning techniques, paving the way for trustworthy MLLMs that respect patient rights under strict regulations. The findings highlight the urgent need for more robust unlearning algorithms to enable the safe and compliant deployment of AI in sensitive clinical environments.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract explicitly states that existing state-of-the-art unlearning methods struggle to achieve complete, hierarchy-aware forgetting without reducing diagnostic performance. Additionally, a significant limitation identified is that fine-grained unlearning leaves models vulnerable to reconstruction attacks, indicating current methods are not robust enough for complete data deletion at granular levels.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated as 'future directions,' the paper implicitly calls for the development of new, more effective unlearning methods that can achieve complete, fine-grained, and robust hierarchical forgetting without performance degradation. MedForget itself is presented as a practical testbed to guide future research in building truly compliant medical AI systems.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Reasoning</span>
                    
                    <span class="tag">Diagnosis Support</span>
                    
                    <span class="tag">Medical Report Generation</span>
                    
                    <span class="tag">Medical Imaging Analysis</span>
                    
                    <span class="tag">Healthcare Informatics</span>
                    
                    <span class="tag">Medical Ethics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                    <span class="tag tag-keyword">Multimodal LLMs</span>
                    
                    <span class="tag tag-keyword">Machine Unlearning</span>
                    
                    <span class="tag tag-keyword">Patient Privacy</span>
                    
                    <span class="tag tag-keyword">HIPAA</span>
                    
                    <span class="tag tag-keyword">GDPR</span>
                    
                    <span class="tag tag-keyword">Right to be forgotten</span>
                    
                    <span class="tag tag-keyword">Hierarchical data</span>
                    
                    <span class="tag tag-keyword">Reconstruction attack</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Pretrained Multimodal Large Language Models (MLLMs) are increasingly deployed in medical AI systems for clinical reasoning, diagnosis support, and report generation. However, their training on sensitive patient data raises critical privacy and compliance challenges under regulations such as HIPAA and GDPR, which enforce the "right to be forgotten". Unlearning, the process of tuning models to selectively remove the influence of specific training data points, offers a potential solution, yet its effectiveness in complex medical settings remains underexplored. To systematically study this, we introduce MedForget, a Hierarchy-Aware Multimodal Unlearning Testbed with explicit retain and forget splits and evaluation sets containing rephrased variants. MedForget models hospital data as a nested hierarchy (Institution -> Patient -> Study -> Section), enabling fine-grained assessment across eight organizational levels. The benchmark contains 3840 multimodal (image, question, answer) instances, each hierarchy level having a dedicated unlearning target, reflecting distinct unlearning challenges. Experiments with four SOTA unlearning methods on three tasks (generation, classification, cloze) show that existing methods struggle to achieve complete, hierarchy-aware forgetting without reducing diagnostic performance. To test whether unlearning truly deletes hierarchical pathways, we introduce a reconstruction attack that progressively adds hierarchical level context to prompts. Models unlearned at a coarse granularity show strong resistance, while fine-grained unlearning leaves models vulnerable to such reconstruction. MedForget provides a practical, HIPAA-aligned testbed for building compliant medical AI systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Dataset and Code: https://github.com/fengli-wu/MedForget</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>