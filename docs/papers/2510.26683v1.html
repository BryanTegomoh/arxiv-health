<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models - Health AI Hub</title>
    <meta name="description" content="Evontree proposes a novel framework for Large Language Models (LLMs) to self-evolve their domain knowledge in data-sensitive fields like healthcare, leveraging ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26683v1" target="_blank">2510.26683v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Mingchen Tu, Zhiqiang Liu, Juan Li, Liangyurui Liu, Junjie Wang, Lei Liang, Wen Zhang
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26683v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26683v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">Evontree proposes a novel framework for Large Language Models (LLMs) to self-evolve their domain knowledge in data-sensitive fields like healthcare, leveraging a small set of high-quality ontology rules. It systematically extracts, validates, and enhances domain knowledge within LLMs without extensive external datasets, achieving up to a 3.7% accuracy improvement on medical QA benchmarks through self-distilled fine-tuning.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is critically important for healthcare as it enables LLMs to acquire and maintain accurate, consistent, and specialized medical knowledge, vital for reliable AI applications in clinical settings where data sensitivity and trustworthiness are paramount, without needing prohibitively large, curated datasets.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops a framework (Evontree) to enhance the accuracy and domain-specific knowledge of Large Language Models (LLMs) for medical applications. Specifically, it aims to improve LLMs' ability to process and answer medical questions, support clinical decision-making, and manage medical knowledge in low-resource settings by leveraging ontology rules for self-evolution and refinement of domain understanding.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenge of LLM adaptation in data-sensitive domains (e.g., healthcare) due to the lack of high-quality, domain-specific training data.</li>
                    
                    <li>Introduces Evontree, a framework that utilizes a small set of pre-defined ontology rules to guide LLM self-evolution, reducing reliance on extensive external datasets.</li>
                    
                    <li>The framework involves a three-step process: extracting domain ontology from raw LLMs, detecting inconsistencies using two core ontology rules, and reinforcing refined knowledge.</li>
                    
                    <li>Knowledge reinforcement is performed via self-distilled fine-tuning, allowing the LLM to internalize validated domain-specific information.</li>
                    
                    <li>Extensive experiments were conducted on medical QA benchmarks using Llama3-8B-Instruct and Med42-v2 foundational models.</li>
                    
                    <li>Evontree consistently outperformed both unmodified base models and leading supervised baselines, achieving up to a 3.7% improvement in accuracy.</li>
                    
                    <li>The results confirm the effectiveness, efficiency, and robustness of the approach for low-resource domain adaptation, particularly relevant for specialized medical applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>Evontree operates by first extracting implicit domain ontology from an existing LLM. It then identifies inconsistencies within this extracted knowledge using two core, predefined ontology rules, which formalize relationships and constraints among concepts. Finally, the refined and validated knowledge is reinforced back into the LLM via a self-distilled fine-tuning process, enabling the model to learn from its corrected and enhanced internal representation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The Evontree framework consistently improved the performance of LLMs on medical QA benchmarks. Specifically, it achieved up to a 3.7% increase in accuracy when applied to Llama3-8B-Instruct and Med42-v2 models, significantly outperforming both the original models and leading supervised baselines. This demonstrates the approach's effectiveness, efficiency, and robustness for domain adaptation in low-resource environments.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By enhancing LLM accuracy and reliability in medical domains, Evontree can lead to more precise diagnostic aids, intelligent clinical decision support systems, improved patient education materials, and more dependable medical information retrieval. This capability to adapt LLMs with minimal specialized data has the potential to accelerate the deployment of trustworthy AI tools in diverse clinical settings, ultimately supporting healthcare professionals and improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed Evontree framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state any future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Healthcare</span>
                    
                    <span class="tag">Medical Question Answering</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Medical Knowledge Management</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">LLMs</span>
                    
                    <span class="tag tag-keyword">Ontology</span>
                    
                    <span class="tag tag-keyword">Healthcare AI</span>
                    
                    <span class="tag tag-keyword">Domain Adaptation</span>
                    
                    <span class="tag tag-keyword">Self-Evolution</span>
                    
                    <span class="tag tag-keyword">Medical QA</span>
                    
                    <span class="tag tag-keyword">Fine-tuning</span>
                    
                    <span class="tag tag-keyword">Low-Resource Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Large language models (LLMs) have demonstrated exceptional capabilities
across multiple domains by leveraging massive pre-training and curated
fine-tuning data. However, in data-sensitive fields such as healthcare, the
lack of high-quality, domain-specific training corpus hinders LLMs' adaptation
for specialized applications. Meanwhile, domain experts have distilled domain
wisdom into ontology rules, which formalize relationships among concepts and
ensure the integrity of knowledge management repositories. Viewing LLMs as
implicit repositories of human knowledge, we propose Evontree, a novel
framework that leverages a small set of high-quality ontology rules to
systematically extract, validate, and enhance domain knowledge within LLMs,
without requiring extensive external datasets. Specifically, Evontree extracts
domain ontology from raw models, detects inconsistencies using two core
ontology rules, and reinforces the refined knowledge via self-distilled
fine-tuning. Extensive experiments on medical QA benchmarks with
Llama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both
unmodified models and leading supervised baselines, achieving up to a 3.7%
improvement in accuracy. These results confirm the effectiveness, efficiency,
and robustness of our approach for low-resource domain adaptation of LLMs.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>