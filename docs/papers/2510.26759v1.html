<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MORE: Multi-Organ Medical Image REconstruction Dataset - Health AI Hub</title>
    <meta name="description" content="This paper introduces the Multi-Organ Medical Image REconstruction (MORE) dataset, designed to overcome the poor generalization of current deep learning CT reco">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MORE: Multi-Organ Medical Image REconstruction Dataset</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26759v1" target="_blank">2510.26759v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shaokai Wu, Yapan Guo, Yanbiao Ji, Jing Tong, Yuxiang Lu, Mei Li, Suizhi Huang, Yue Ding, Hongtao Lu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.CV, cs.MM
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26759v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26759v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces the Multi-Organ Medical Image REconstruction (MORE) dataset, designed to overcome the poor generalization of current deep learning CT reconstruction methods to diverse anatomies and lesions. The dataset facilitates robust model training and rigorous generalization evaluation, demonstrating that comprehensive data and optimization-based methods significantly enhance model performance for unseen anatomical structures.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Improving the generalization of CT reconstruction models is critical for reliable clinical diagnosis and treatment planning, as it ensures high-quality images can be generated across diverse patient populations, organ systems, and pathologies without requiring specialized model retraining.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to enhance and generalize deep learning models used for CT reconstruction. By providing a diverse dataset of multi-organ CT scans with various lesion types, the research aims to enable more robust training and evaluation of AI models, ultimately leading to better quality diagnostic images for radiologists, aiding in patient diagnosis and treatment planning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the limitation of current deep learning CT reconstruction models, which struggle with generalization to unseen anatomies and lesion types.</li>
                    
                    <li>Introduces the MORE dataset, comprising CT scans from 9 diverse anatomies and 15 distinct lesion types.</li>
                    
                    <li>The dataset serves a dual purpose: enabling robust training of deep learning models on extensive, heterogeneous data and facilitating rigorous evaluation of model generalization.</li>
                    
                    <li>Establishes a strong baseline solution that outperforms prior approaches under challenging generalization conditions.</li>
                    
                    <li>Demonstrates that a comprehensive and diverse dataset significantly improves the generalization capability of deep learning models.</li>
                    
                    <li>Highlights that optimization-based methods offer enhanced robustness, particularly when applied to previously unseen anatomies.</li>
                    
                    <li>The MORE dataset is freely accessible under a CC-BY-NC 4.0 license to foster further research.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The primary methodology involves the creation and release of the MORE dataset, a large-scale collection of CT scans covering 9 distinct anatomies and 15 lesion types. Subsequently, a strong deep learning baseline solution was established and rigorously evaluated against prior methods using this heterogeneous dataset to demonstrate improved generalization and robustness, particularly for optimization-based reconstruction techniques.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The research found that (1) utilizing a comprehensive and diverse dataset significantly enhances the generalization capabilities of deep learning models for CT reconstruction, and (2) optimization-based deep learning methods provide superior robustness when dealing with unseen anatomical structures.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work has the potential to lead to the development of more versatile and reliable AI-powered CT reconstruction tools, reducing the need for highly specialized models for different body regions or patient conditions. This will enable radiologists to obtain higher-quality, more consistent diagnostic images across a broader spectrum of clinical scenarios, potentially leading to more accurate diagnoses and improved patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of *prior* deep learning methods (lack of generalization to unseen anatomies/lesions) which the MORE dataset aims to address. It does not explicitly state limitations inherent to the authors' own work or dataset within the provided abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention specific future research directions, but the release of the dataset implicitly encourages further research into robust and generalizable CT reconstruction models.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Medical Image Analysis</span>
                    
                    <span class="tag">Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">CT reconstruction</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">generalization</span>
                    
                    <span class="tag tag-keyword">multi-organ</span>
                    
                    <span class="tag tag-keyword">dataset</span>
                    
                    <span class="tag tag-keyword">robustness</span>
                    
                    <span class="tag tag-keyword">optimization-based methods</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">CT reconstruction provides radiologists with images for diagnosis and
treatment, yet current deep learning methods are typically limited to specific
anatomies and datasets, hindering generalization ability to unseen anatomies
and lesions. To address this, we introduce the Multi-Organ medical image
REconstruction (MORE) dataset, comprising CT scans across 9 diverse anatomies
with 15 lesion types. This dataset serves two key purposes: (1) enabling robust
training of deep learning models on extensive, heterogeneous data, and (2)
facilitating rigorous evaluation of model generalization for CT reconstruction.
We further establish a strong baseline solution that outperforms prior
approaches under these challenging conditions. Our results demonstrate that:
(1) a comprehensive dataset helps improve the generalization capability of
models, and (2) optimization-based methods offer enhanced robustness for unseen
anatomies. The MORE dataset is freely accessible under CC-BY-NC 4.0 at our
project page https://more-med.github.io/</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to ACMMM 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>