<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning - Health AI Hub</title>
    <meta name="description" content="This paper introduces WISE-MAE, a two-stage wavelet-driven masked autoencoder designed to improve histopathology representation learning from whole-slide images">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.06958v1" target="_blank">2511.06958v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Raneen Younis, Louay Hamdi, Lukas Chavez, Zahra Ahmadi
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.06958v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.06958v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces WISE-MAE, a two-stage wavelet-driven masked autoencoder designed to improve histopathology representation learning from whole-slide images. By selectively focusing on structurally rich regions, mirroring pathologists' workflow, WISE-MAE achieves competitive representation quality and downstream classification performance across various cancer datasets while maintaining computational efficiency.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing digital pathology by enabling more accurate and efficient analysis of whole-slide images. By improving the quality of learned representations, it can lead to more reliable AI-powered diagnostic and prognostic tools for various cancers, directly benefiting patient care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is to develop more effective and biologically relevant representation learning models for analyzing whole-slide images in digital pathology. This aims to improve the accuracy and efficiency of AI systems for tasks like cancer detection, classification, and grading from tissue biopsies, thereby assisting pathologists in diagnosis and research.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the challenges of extreme whole-slide image (WSI) size and scarce annotations, alongside the limitations of conventional random patch sampling in Masked Autoencoders (MAEs) for histopathology.</li>
                    
                    <li>Proposes WISE-MAE, a lightweight and domain-adapted framework that integrates structure and biological relevance into MAE-based learning.</li>
                    
                    <li>Employs a two-step coarse-to-fine patch selection strategy: wavelet-based screening at low magnification identifies structurally rich regions.</li>
                    
                    <li>High-resolution patches are subsequently extracted only from these identified regions for detailed modeling, reflecting a pathologist's diagnostic workflow.</li>
                    
                    <li>This targeted patch selection strategy significantly improves the quality of learned representations by focusing on meaningful tissue patterns and reducing noise.</li>
                    
                    <li>Evaluations were conducted across multiple cancer datasets, including lung, renal, and colorectal tissues.</li>
                    
                    <li>WISE-MAE demonstrates competitive representation quality and superior downstream classification performance while maintaining efficiency under weak supervision conditions.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>WISE-MAE utilizes a two-stage wavelet-driven patch selection strategy within a Vision Transformer-based Masked Autoencoder (MAE) framework. The first stage involves applying wavelet analysis to low-magnification whole-slide images to effectively screen and locate structurally rich, biologically relevant tissue regions. The second stage then extracts high-resolution patches exclusively from these identified regions, which are subsequently used for the MAE's self-supervised representation learning task, focusing computational effort on diagnostically valuable areas.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The WISE-MAE framework significantly improves the quality of learned representations for histopathology images. It achieves competitive representation quality and robust downstream classification performance across diverse cancer types (lung, renal, and colorectal tissues) compared to conventional MAE methods, all while operating efficiently and effectively under weak supervision conditions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The ability to learn more meaningful and accurate representations from histopathology images could directly translate to more reliable and precise AI-powered diagnostic and prognostic tools. This could accelerate the detection and characterization of various cancers, aid in personalized treatment selection, and potentially reduce the workload of pathologists by providing highly relevant and structured insights from vast digital slides, ultimately improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the WISE-MAE framework or its current evaluation. It focuses primarily on the improvements and benefits of the proposed method.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions. It focuses on presenting the current framework and its demonstrated benefits in improving histopathology representation learning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Histopathology</span>
                    
                    <span class="tag">Cancer Research</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Whole-slide Images</span>
                    
                    <span class="tag tag-keyword">Masked Autoencoders</span>
                    
                    <span class="tag tag-keyword">Representation Learning</span>
                    
                    <span class="tag tag-keyword">Wavelets</span>
                    
                    <span class="tag tag-keyword">Digital Pathology</span>
                    
                    <span class="tag tag-keyword">Cancer Diagnosis</span>
                    
                    <span class="tag tag-keyword">Self-supervised Learning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Whole-slide images are central to digital pathology, yet their extreme size
and scarce annotations make self-supervised learning essential. Masked
Autoencoders (MAEs) with Vision Transformer backbones have recently shown
strong potential for histopathology representation learning. However,
conventional random patch sampling during MAE pretraining often includes
irrelevant or noisy regions, limiting the model's ability to capture meaningful
tissue patterns. In this paper, we present a lightweight and domain-adapted
framework that brings structure and biological relevance into MAE-based
learning through a wavelet-informed patch selection strategy. WISE-MAE applies
a two-step coarse-to-fine process: wavelet-based screening at low magnification
to locate structurally rich regions, followed by high-resolution extraction for
detailed modeling. This approach mirrors the diagnostic workflow of
pathologists and improves the quality of learned representations. Evaluations
across multiple cancer datasets, including lung, renal, and colorectal tissues,
show that WISE-MAE achieves competitive representation quality and downstream
classification performance while maintaining efficiency under weak supervision.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>