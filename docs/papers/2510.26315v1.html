<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading - Health AI Hub</title>
    <meta name="description" content="This paper proposes a novel hybrid framework for diabetic retinopathy (DR) grading, combining CNN and Vision Transformer (ViT) architectures, to overcome the pe">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26315v1" target="_blank">2510.26315v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng, Yawen Huang, Yuexiang Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper proposes a novel hybrid framework for diabetic retinopathy (DR) grading, combining CNN and Vision Transformer (ViT) architectures, to overcome the performance limitations of single-backbone systems. Leveraging the theory of evidence, the framework adaptively fuses local and global features, demonstrating improved accuracy and enhanced interpretability in DR diagnosis.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research directly addresses the critical need for more efficient and accurate early detection of diabetic retinopathy, which is a leading cause of vision loss. By enhancing automated screening systems, it can significantly improve patient outcomes, reduce the burden on healthcare systems, and positively impact the quality of life for millions.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Development of an AI-powered system for the automated diagnosis, grading, and early detection of Diabetic Retinopathy from medical images (e.g., fundus images). This application aims to enhance the efficiency and accuracy of clinical screening processes, thereby assisting healthcare professionals in managing and preventing vision loss in patients with diabetes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Diabetic retinopathy (DR) is a leading cause of vision loss, necessitating efficient and early automated diagnosis.</li>
                    
                    <li>Existing automated DR diagnosis systems based on single CNN or ViT backbones have reached a performance bottleneck due to their inherent limitations (CNN for local, ViT for global features).</li>
                    
                    <li>A novel hybrid framework is introduced, integrating CNN and ViT backbones to fully leverage their complementary strengths for feature extraction.</li>
                    
                    <li>The core innovation is an evidential fusion paradigm based on the theory of evidence, which transforms features from different backbones into 'supporting evidences' via deep evidential networks.</li>
                    
                    <li>An 'aggregated opinion' is formed from these supporting evidences, which is then used to adaptively tune the fusion pattern between the CNN and ViT components.</li>
                    
                    <li>Evaluated on two publicly available DR grading datasets, the hybrid model demonstrates improved accuracy compared to state-of-the-art frameworks.</li>
                    
                    <li>Beyond performance gains, the proposed method provides excellent interpretability for both the feature fusion process and the final decision-making for DR grading.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed method employs a hybrid neural network architecture combining Convolutional Neural Networks (CNNs) for local feature extraction and Vision Transformers (ViTs) for global feature capturing. Features from these backbones are transformed into 'supporting evidences' using a set of deep evidential networks. The core innovation is an evidential fusion paradigm based on the theory of evidence, where an aggregated opinion adaptively tunes the fusion pattern between the CNN and ViT components to optimize performance.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The hybrid model demonstrated superior accuracy in diabetic retinopathy grading when compared to state-of-the-art frameworks. Crucially, beyond performance gains, the evidential fusion approach yielded excellent interpretability for how features from different backbones are combined and how final diagnostic decisions are reached.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This framework has the potential to significantly improve clinical screening efficiency for diabetic retinopathy, enabling earlier and more accurate diagnosis. Its enhanced accuracy could lead to more timely interventions, preventing irreversible vision loss. Furthermore, the improved interpretability of the decision-making process can foster greater trust among clinicians, facilitating wider adoption in real-world clinical settings for automated DR grading.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the proposed hybrid model. It primarily identifies the inherent shortcomings and performance bottlenecks of existing single-type backbone CNN/ViT models as the motivation for this work.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for this specific work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Endocrinology</span>
                    
                    <span class="tag">Diabetology</span>
                    
                    <span class="tag">Preventive Medicine</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Diabetic Retinopathy</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">Vision Transformer (ViT)</span>
                    
                    <span class="tag tag-keyword">Hybrid Model</span>
                    
                    <span class="tag tag-keyword">Theory of Evidence</span>
                    
                    <span class="tag tag-keyword">Feature Fusion</span>
                    
                    <span class="tag tag-keyword">Automated Diagnosis</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>