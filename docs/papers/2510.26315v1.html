<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading - Health AI Hub</title>
    <meta name="description" content="This paper introduces a novel hybrid framework combining Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for more accurate and interpretable">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26315v1" target="_blank">2510.26315v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng, Yawen Huang, Yuexiang Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces a novel hybrid framework combining Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for more accurate and interpretable Diabetic Retinopathy (DR) grading. It addresses the limitations of single-backbone systems by employing an evidential fusion paradigm, based on the theory of evidence, to adaptively integrate their complementary local and global features. The method demonstrates improved DR grading accuracy over state-of-the-art techniques and offers excellent interpretability on publicly available datasets.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Diabetic retinopathy is a leading cause of vision loss, and this research aims to significantly improve the efficiency and accuracy of its early detection and grading. More precise and reliable automated diagnosis can lead to timely clinical intervention, preserving vision and enhancing the quality of life for diabetic patients.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper proposes a hybrid deep learning framework (combining CNN and Vision Transformers with an evidential fusion paradigm) for the automated grading and early detection of Diabetic Retinopathy from medical images. This serves as an AI application for clinical diagnosis, improving screening efficiency, and decision-making interpretability in ophthalmology.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the performance bottleneck of single-backbone automated DR diagnosis systems (CNN or ViT) by leveraging their complementary strengths.</li>
                    
                    <li>Proposes a novel hybrid framework that integrates CNN's local feature extraction capability with ViT's global feature capturing ability.</li>
                    
                    <li>Introduces an 'evidential fusion paradigm' based on the Theory of Evidence to effectively combine features from different backbones.</li>
                    
                    <li>Features are transformed into 'supporting evidences' via deep evidential networks, which then form an 'aggregated opinion' to adaptively tune the fusion pattern.</li>
                    
                    <li>Evaluated on two publicly available Diabetic Retinopathy grading datasets.</li>
                    
                    <li>Achieves improved accuracy for DR grading, outperforming state-of-the-art frameworks.</li>
                    
                    <li>Provides excellent interpretability for the feature fusion process and subsequent decision-making, crucial for clinical acceptance.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a hybrid deep learning architecture that integrates a CNN backbone (for local feature extraction) and a ViT backbone (for global feature capturing). A core innovation is the 'evidential fusion paradigm,' which utilizes the Theory of Evidence. Features extracted by the individual backbones are transformed into 'supporting evidences' via dedicated deep evidential networks. These evidences are then combined to form an 'aggregated opinion' that adaptively tunes the fusion weights and patterns between the CNN and ViT features, optimizing the overall classification performance for DR grading.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The hybrid model demonstrated superior accuracy in Diabetic Retinopathy grading compared to existing state-of-the-art frameworks. A notable additional finding is the 'excellent interpretability' offered by the proposed evidential fusion approach, providing insights into feature combination and decision processes, which is highly valuable for clinical applications.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research holds significant potential for clinical impact by enabling more efficient, accurate, and reliable automated screening and grading of Diabetic Retinopathy. Improved accuracy could lead to earlier diagnosis and intervention, preventing severe vision loss. The enhanced interpretability is critical for fostering trust among clinicians and facilitating the adoption of such AI-powered diagnostic tools in routine clinical practice.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed framework.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Diabetology</span>
                    
                    <span class="tag">Medical Imaging Diagnostics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Diabetic Retinopathy</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">ViT</span>
                    
                    <span class="tag tag-keyword">Hybrid Model</span>
                    
                    <span class="tag tag-keyword">Theory of Evidence</span>
                    
                    <span class="tag tag-keyword">Feature Fusion</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Automated Diagnosis</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>