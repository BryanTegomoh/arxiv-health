<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading - Health AI Hub</title>
    <meta name="description" content="This research addresses the performance bottleneck of single-backbone automated Diabetic Retinopathy (DR) diagnosis systems by proposing a novel hybrid framewor">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2510.26315v1" target="_blank">2510.26315v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-10-30
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Junlai Qiu, Yunzhu Chen, Hao Zheng, Yawen Huang, Yuexiang Li
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2510.26315v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2510.26315v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This research addresses the performance bottleneck of single-backbone automated Diabetic Retinopathy (DR) diagnosis systems by proposing a novel hybrid framework that combines Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). It introduces an evidential fusion paradigm, based on the theory of evidence, to adaptively integrate local and global features from different backbones. The proposed model achieves improved DR grading accuracy and enhanced interpretability on public datasets, surpassing existing state-of-the-art methods.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Diabetic retinopathy is a leading cause of preventable blindness. Developing highly accurate, efficient, and interpretable automated grading systems is critical for early detection, enabling timely intervention and significantly improving patient outcomes by preventing vision loss and reducing the burden on healthcare systems.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper describes the development of a medical AI system designed for automated grading and early detection of Diabetic Retinopathy. This AI application leverages hybrid deep learning models (CNN and ViT) to analyze medical images, providing a tool to assist clinicians in more efficient and accurate diagnosis, thereby improving patient outcomes and healthcare delivery for vision-threatening diseases.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the performance limitations of existing automated DR diagnosis systems that rely solely on CNNs or ViTs.</li>
                    
                    <li>Proposes a hybrid framework that synergistically combines the local feature extraction capabilities of CNNs with the global feature capturing abilities of ViTs.</li>
                    
                    <li>Introduces a novel evidential fusion paradigm based on the theory of evidence for adaptive feature integration.</li>
                    
                    <li>Transforms features from individual CNN and ViT backbones into 'supporting evidences' using a set of deep evidential networks.</li>
                    
                    <li>Utilizes an 'aggregated opinion' derived from the supporting evidences to adaptively tune the fusion pattern between the different backbones.</li>
                    
                    <li>Demonstrates improved accuracy in DR grading compared to state-of-the-art frameworks on two publicly available datasets.</li>
                    
                    <li>Provides excellent interpretability for both the feature fusion process and the final decision-making, which is critical for clinical acceptance.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The proposed method is a hybrid deep learning framework integrating CNNs and ViTs. It employs a novel evidential fusion paradigm based on the theory of evidence, where features from distinct CNN and ViT backbones are transformed into 'supporting evidences' via dedicated deep evidential networks. An 'aggregated opinion' is then formed from these evidences, which adaptively tunes the fusion pattern between the backbones to optimize performance.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The hybrid model significantly improves the accuracy of diabetic retinopathy grading, outperforming current state-of-the-art frameworks on two publicly available datasets. Furthermore, it offers excellent interpretability, elucidating the feature fusion process and the basis of the diagnostic decisions.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research has the potential to enhance the efficiency and accuracy of clinical screening for DR, leading to earlier diagnosis and intervention. The improved accuracy could reduce misdiagnosis rates, while the high interpretability might increase clinician trust and facilitate broader adoption of AI-assisted diagnostic tools in ophthalmology, ultimately contributing to better patient care and reduced vision impairment.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state any limitations of the proposed method.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for this work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Ophthalmology</span>
                    
                    <span class="tag">Diabetic Retinopathy</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Diagnostic AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Diabetic Retinopathy</span>
                    
                    <span class="tag tag-keyword">CNN</span>
                    
                    <span class="tag tag-keyword">Vision Transformer</span>
                    
                    <span class="tag tag-keyword">Hybrid Model</span>
                    
                    <span class="tag tag-keyword">Feature Fusion</span>
                    
                    <span class="tag tag-keyword">Theory of Evidence</span>
                    
                    <span class="tag tag-keyword">Medical Image Analysis</span>
                    
                    <span class="tag tag-keyword">Interpretability</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>