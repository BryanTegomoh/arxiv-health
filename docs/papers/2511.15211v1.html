<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition - Health AI Hub</title>
    <meta name="description" content="OEMA is a novel zero-shot clinical Named Entity Recognition (NER) framework utilizing multi-agent collaboration and ontology-guided reasoning to overcome limita">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15211v1" target="_blank">2511.15211v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-19
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Xinli Tao, Xin Dong, Xuezhong Zhou
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CL, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15211v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15211v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">OEMA is a novel zero-shot clinical Named Entity Recognition (NER) framework utilizing multi-agent collaboration and ontology-guided reasoning to overcome limitations of existing large language model (LLM) approaches. By integrating a self-annotator, an SNOMED CT-enhanced discriminator, and a predictor, OEMA achieves state-of-the-art exact-match performance on clinical datasets. It demonstrates near-supervised performance under related-match, offering an efficient solution for clinical information extraction without extensive manual annotation.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances medical informatics by enabling highly efficient and accurate extraction of critical information from vast amounts of unstructured electronic health records (EHRs) without the prohibitive costs of manual data annotation. This capability is vital for accelerating clinical research, improving patient care through enhanced decision support, and streamlining public health surveillance.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>OEMA is an AI framework designed to automatically and accurately extract specific medical entities (e.g., diseases, symptoms, treatments) from unstructured clinical text within electronic health records and other clinical documents. This application is crucial for enhancing clinical decision support, streamlining medical research by structuring data, improving public health surveillance (e.g., adverse event tracking), and facilitating advanced analytics in healthcare by transforming free-text into actionable, structured information.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>OEMA is a multi-agent, zero-shot framework specifically designed for clinical Named Entity Recognition (NER) to reduce dependency on costly annotated data.</li>
                    
                    <li>It tackles key challenges in zero-shot NER with LLMs, such as example selection granularity and effective integration of self-improvement mechanisms with prompts.</li>
                    
                    <li>The framework comprises three core components: a self-annotator for generating examples, a discriminator that filters these examples using reasoning guided by the SNOMED CT clinical ontology, and a predictor leveraging entity descriptions for accurate inference.</li>
                    
                    <li>OEMA achieved state-of-the-art exact-match performance on the MTSamples and VAERS clinical datasets, showcasing its superior accuracy.</li>
                    
                    <li>Under a related-match evaluation metric, OEMA's performance was comparable to the supervised BioClinicalBERT model and significantly surpassed traditional CRF models.</li>
                    
                    <li>The integration of ontology-guided reasoning (via SNOMED CT) is a critical component for filtering generated examples, enhancing the clinical relevance and accuracy of the NER process.</li>
                    
                    <li>This approach offers a pathway to achieving near-supervised NER performance with the efficiency and reduced data dependency of zero-shot learning, vital for real-world clinical Natural Language Processing (NLP) applications.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>OEMA employs a multi-agent collaboration framework. A 'self-annotator' agent first generates candidate entity examples. These examples are then rigorously filtered by a 'discriminator' agent that leverages the SNOMED CT clinical ontology to ensure accuracy and clinical relevance. Finally, a 'predictor' agent performs the actual named entity recognition inference using refined entity descriptions. This zero-shot approach minimizes the need for labeled training data while maximizing accuracy through ontology-enhanced filtering and multi-agent synergy.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>OEMA achieved state-of-the-art exact-match performance on the MTSamples and VAERS clinical datasets. Notably, under a related-match metric, its performance matched that of the supervised BioClinicalBERT model and significantly surpassed CRF models. The framework successfully addressed key challenges in zero-shot NER, delivering performance comparable to supervised methods.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>OEMA can drastically reduce the time and resources required for extracting structured data from unstructured clinical text, directly translating to more efficient clinical research, improved patient safety through better data accessibility, and enhanced automated processes like clinical coding or disease surveillance. Its near-supervised performance without extensive annotation makes it highly practical for deploying advanced NLP in resource-constrained clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations. Potential considerations, however, could include the computational cost associated with a multi-agent system, the generalization capabilities to highly specialized or rare clinical entities not extensively covered by SNOMED CT, or the robustness against extremely noisy or colloquial clinical notes not represented in the evaluated datasets.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The paper suggests OEMA holds significant promise for broader clinical NLP applications. Future research could explore its integration into real-time clinical workflows, its adaptability to other specialized medical ontologies, or its extension to more complex information extraction tasks beyond NER, continually optimizing its computational efficiency for practical deployment.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Medical Natural Language Processing</span>
                    
                    <span class="tag">Electronic Health Record Management</span>
                    
                    <span class="tag">Biomedical Research</span>
                    
                    <span class="tag">Public Health</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Clinical Named Entity Recognition</span>
                    
                    <span class="tag tag-keyword">Zero-Shot Learning</span>
                    
                    <span class="tag tag-keyword">Multi-Agent Systems</span>
                    
                    <span class="tag tag-keyword">Ontology (SNOMED CT)</span>
                    
                    <span class="tag tag-keyword">Large Language Models (LLMs)</span>
                    
                    <span class="tag tag-keyword">Electronic Health Records (EHRs)</span>
                    
                    <span class="tag tag-keyword">Natural Language Processing (NLP)</span>
                    
                    <span class="tag tag-keyword">Medical Informatics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>12 pages, 4 figures, 4 tables</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>