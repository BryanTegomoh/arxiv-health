<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Continual Alignment for SAM: Rethinking Foundation Models for Medical Image Segmentation in Continual Learning - Health AI Hub</title>
    <meta name="description" content="This paper introduces CA-SAM, a continual learning strategy built upon the Segment Anything Model (SAM) and a novel lightweight Alignment Layer, to address the ">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Continual Alignment for SAM: Rethinking Foundation Models for Medical Image Segmentation in Continual Learning</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.17201v1" target="_blank">2511.17201v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-21
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Jiayi Wang, Wei Dai, Haoyu Wang, Sihan Yang, Haixia Bi, Jian Sun
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.17201v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.17201v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces CA-SAM, a continual learning strategy built upon the Segment Anything Model (SAM) and a novel lightweight Alignment Layer, to address the challenges of medical image segmentation under privacy-constrained, continual learning scenarios. CA-SAM effectively mitigates catastrophic forgetting and leverages SAM's zero-shot priors, demonstrating state-of-the-art performance across nine medical segmentation datasets while significantly improving computational efficiency.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research directly addresses the critical need for adapting powerful AI models like SAM for medical image analysis in scenarios where data privacy and ethical considerations preclude centralized training, enabling robust and efficient continual learning for diagnostic and surgical planning tools in clinical settings.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops advanced AI models for medical image segmentation, aiming to improve the accuracy and efficiency of analyzing medical scans (e.g., X-rays, CTs, MRIs) for diagnostic and clinical purposes. Specifically, it tackles the challenge of continually adapting AI models to new medical data streams without 'catastrophic forgetting,' which is critical given institutional privacy policies and the evolving nature of medical data. This allows for more effective and adaptable AI tools in clinical settings, potentially aiding radiologists, clinicians, and researchers in tasks like tumor detection, organ segmentation, and disease progression tracking.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical problem of continual medical image segmentation, necessitated by heterogeneous privacy policies that prevent joint training on pooled datasets and the need to mitigate catastrophic forgetting.</li>
                    
                    <li>Proposes the 'Alignment Layer,' a lightweight, plug-and-play module designed to efficiently adapt SAM by aligning encoder-decoder feature distributions to specific medical images.</li>
                    
                    <li>The Alignment Layer demonstrably improves segmentation accuracy and substantially reduces the computational overhead associated with fine-tuning SAM for medical tasks.</li>
                    
                    <li>Introduces 'CA-SAM' (Continual Alignment for SAM), a continual learning strategy that automatically adapts the appropriate Alignment Layer to new data streams, effectively mitigating catastrophic forgetting.</li>
                    
                    <li>CA-SAM leverages SAM's powerful zero-shot priors, allowing it to preserve strong segmentation performance even on unseen medical datasets.</li>
                    
                    <li>Experimented across nine diverse medical segmentation datasets under a continual-learning scenario, CA-SAM achieves state-of-the-art performance.</li>
                    
                    <li>The research aims to balance SAM's strong foundational capabilities with practical computational efficiency, making it viable for real-world medical deployment.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves developing an 'Alignment Layer,' a lightweight, plug-and-play module that aligns encoder-decoder feature distributions to efficiently fine-tune the Segment Anything Model (SAM) for specific medical images, improving accuracy and reducing computation. This layer is then integrated into 'CA-SAM,' a continual learning strategy that automatically adapts the appropriate Alignment Layer to new data streams, thereby mitigating catastrophic forgetting while exploiting SAM's strong zero-shot priors for robust performance.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that CA-SAM achieves state-of-the-art performance across nine diverse medical segmentation datasets under a continual learning scenario. It successfully balances SAM's strong foundational capabilities with improved computational efficiency and effectively mitigates catastrophic forgetting, preserving strong performance on unseen medical data.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This work has significant potential clinical impact by enabling the deployment of advanced medical image segmentation models that can continuously learn from new institutional data without requiring joint training, thus respecting privacy policies. This could lead to more accurate and up-to-date diagnostic tools, better surgical planning, and improved patient outcomes in diverse clinical settings, even with evolving data characteristics.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the proposed CA-SAM method or the experimental setup beyond the general challenges it aims to solve.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly mention future research directions for the proposed work.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Image-Guided Surgery (implied)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Medical Image Segmentation</span>
                    
                    <span class="tag tag-keyword">Continual Learning</span>
                    
                    <span class="tag tag-keyword">Catastrophic Forgetting</span>
                    
                    <span class="tag tag-keyword">Segment Anything Model (SAM)</span>
                    
                    <span class="tag tag-keyword">Alignment Layer</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Privacy-Preserving AI</span>
                    
                    <span class="tag tag-keyword">State-of-the-Art</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">In medical image segmentation, heterogeneous privacy policies across institutions often make joint training on pooled datasets infeasible, motivating continual image segmentation-learning from data streams without catastrophic forgetting. While the Segment Anything Model (SAM) offers strong zero-shot priors and has been widely fine-tuned across downstream tasks, its large parameter count and computational overhead challenge practical deployment. This paper demonstrates that the SAM paradigm is highly promising once its computational efficiency and performance can be balanced. To this end, we introduce the Alignment Layer, a lightweight, plug-and-play module which aligns encoder-decoder feature distributions to efficiently adapt SAM to specific medical images, improving accuracy while reducing computation. Building on SAM and the Alignment Layer, we then propose Continual Alignment for SAM (CA-SAM), a continual learning strategy that automatically adapts the appropriate Alignment Layer to mitigate catastrophic forgetting, while leveraging SAM's zero-shot priors to preserve strong performance on unseen medical datasets. Experimented across nine medical segmentation datasets under continual-learning scenario, CA-SAM achieves state-of-the-art performance. Our code, models and datasets will be released on \mbox{https://github.com/azzzzyo/Continual-Alignment-for-SAM.}</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>