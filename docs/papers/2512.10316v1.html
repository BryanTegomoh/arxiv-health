<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation - Health AI Hub</title>
    <meta name="description" content="ConStruct proposes a novel prototype learning framework for weakly supervised semantic segmentation (WSSS) in histopathology, integrating morphology-aware repre">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.10316v1" target="_blank">2512.10316v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-11
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Khang Le, Ha Thach, Anh M. Vu, Trang T. K. Vo, Han H. Huynh, David Yang, Minh H. N. Le, Thanh-Huy Nguyen, Akash Awasthi, Chandra Mohan, Zhu Han, Hien Van Nguyen
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.10316v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.10316v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">ConStruct proposes a novel prototype learning framework for weakly supervised semantic segmentation (WSSS) in histopathology, integrating morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment. This approach generates high-quality, semantically discriminative, and spatially coherent prototypes, leading to improved localization completeness and semantic consistency without pixel-level annotations. The framework outperforms existing WSSS methods while maintaining computational efficiency.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is profoundly relevant to medical diagnostics and computational pathology by enabling accurate segmentation of complex tissue structures from histopathological images with minimal annotation effort. It reduces the dependency on time-consuming and expensive pixel-level annotations by highly specialized pathologists, accelerating the development of AI-driven diagnostic tools.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI framework described is applicable to automated or semi-automated analysis of histopathology slides. This can assist pathologists in identifying and segmenting diseased tissue regions, such as cancerous cells or specific tissue structures, for more accurate and efficient disease diagnosis and prognosis. It can potentially reduce manual workload, improve diagnostic consistency, and enhance the completeness of abnormality detection in medical image analysis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical challenge in histopathology WSSS where models often localize only the most discriminative regions, failing to capture the full spatial extent of tissue structures.</li>
                    
                    <li>Introduces ConStruct, a prototype learning framework that synergistically combines morphology-aware representations from a vision-language model (CONCH) and multi-scale structural cues from a modern segmentation backbone (SegFormer).</li>
                    
                    <li>Leverages text-guided semantic alignment and prototype initialization, incorporating pathology descriptions to generate more complete and semantically accurate pseudo-masks under weak supervision.</li>
                    
                    <li>Implements a structural distillation mechanism to effectively transfer fine-grained spatial knowledge from SegFormer, ensuring the preservation of local tissue boundaries and morphological patterns during prototype learning.</li>
                    
                    <li>Achieves generation of high-quality pseudo-masks without requiring dense pixel-level annotations, significantly improving localization completeness and enhancing semantic consistency across various tissue types.</li>
                    
                    <li>Demonstrates superior performance against existing WSSS methods on BCSS-WSSS datasets, providing a robust solution for histopathology segmentation.</li>
                    
                    <li>Maintains computational efficiency through the use of frozen foundation model backbones (CONCH, SegFormer) and lightweight trainable adapters, making it practical for real-world application.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>ConStruct is a prototype learning framework for WSSS that integrates morphology-aware representations from the CONCH vision-language model, multi-scale structural cues from the SegFormer segmentation backbone, and text-guided semantic alignment. It employs text-guided prototype initialization using pathology descriptions to generate complete pseudo-masks. A structural distillation mechanism transfers spatial knowledge from SegFormer to preserve fine-grained morphological patterns and local tissue boundaries during prototype learning. The framework utilizes frozen foundation model backbones and lightweight trainable adapters for efficient computation.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The ConStruct framework successfully generates high-quality pseudo-masks without requiring pixel-level annotations, significantly improving localization completeness and enhancing semantic consistency across diverse tissue types. Experiments on BCSS-WSSS datasets demonstrate that ConStruct outperforms existing WSSS methods while being computationally efficient.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This method has the potential to revolutionize the development of AI-assisted diagnostic tools in histopathology by significantly lowering the barrier to entry, as it requires only weak supervision instead of costly pixel-level annotations. This could lead to faster, more accurate, and more standardized analysis of histopathological slides, aiding pathologists in cancer diagnosis, grading, and treatment planning, ultimately improving patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state limitations of the proposed method. Potential limitations not addressed in the abstract could include the generalizability to extremely rare or atypical tissue patterns not covered by the training data or text descriptions, and the performance ceiling compared to fully supervised methods in highly complex segmentation tasks.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions. Potential future work could involve exploring the framework's applicability to other challenging medical imaging modalities (e.g., 3D pathology), investigating its robustness across a wider range of disease types and tissue stains, or integrating additional modalities such as genomic data for even richer prototype learning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Digital Pathology</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                    <span class="tag">Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Weakly Supervised Segmentation</span>
                    
                    <span class="tag tag-keyword">Histopathology</span>
                    
                    <span class="tag tag-keyword">Prototype Learning</span>
                    
                    <span class="tag tag-keyword">Foundation Models</span>
                    
                    <span class="tag tag-keyword">Semantic Segmentation</span>
                    
                    <span class="tag tag-keyword">Structural Distillation</span>
                    
                    <span class="tag tag-keyword">Digital Pathology</span>
                    
                    <span class="tag tag-keyword">Computational Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Weakly supervised semantic segmentation (WSSS) in histopathology relies heavily on classification backbones, yet these models often localize only the most discriminative regions and struggle to capture the full spatial extent of tissue structures. Vision-language models such as CONCH offer rich semantic alignment and morphology-aware representations, while modern segmentation backbones like SegFormer preserve fine-grained spatial cues. However, combining these complementary strengths remains challenging, especially under weak supervision and without dense annotations. We propose a prototype learning framework for WSSS in histopathological images that integrates morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment to produce prototypes that are simultaneously semantically discriminative and spatially coherent. To effectively leverage these heterogeneous sources, we introduce text-guided prototype initialization that incorporates pathology descriptions to generate more complete and semantically accurate pseudo-masks. A structural distillation mechanism transfers spatial knowledge from SegFormer to preserve fine-grained morphological patterns and local tissue boundaries during prototype learning. Our approach produces high-quality pseudo masks without pixel-level annotations, improves localization completeness, and enhances semantic consistency across tissue types. Experiments on BCSS-WSSS datasets demonstrate that our prototype learning framework outperforms existing WSSS methods while remaining computationally efficient through frozen foundation model backbones and lightweight trainable adapters.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>