<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FunnyNodules: A Customizable Medical Dataset Tailored for Evaluating Explainable AI - Health AI Hub</title>
    <meta name="description" content="FunnyNodules introduces a novel, fully parameterized synthetic medical dataset designed to address the scarcity of reasoning-annotated datasets crucial for Expl">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>FunnyNodules: A Customizable Medical Dataset Tailored for Evaluating Explainable AI</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.15481v1" target="_blank">2511.15481v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-19
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Luisa Gall√©e, Yiheng Xiong, Meinrad Beer, Michael G√∂tz
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.15481v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.15481v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">FunnyNodules introduces a novel, fully parameterized synthetic medical dataset designed to address the scarcity of reasoning-annotated datasets crucial for Explainable AI (xAI). It generates customizable lung nodule-like shapes with controllable visual attributes and predefined decision rules linking these attributes to diagnostic classes. This dataset enables systematic evaluation of whether AI models learn correct attribute-target relations and align their attention with relevant regions, thereby fostering the development of more trustworthy medical AI systems.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This dataset is paramount for advancing medical AI by enabling the rigorous development and evaluation of explainable models that can articulate *why* they reach a particular diagnosis. Such transparency is crucial for clinicians to trust and adopt AI in diagnostic workflows, potentially leading to more accurate, consistent, and reliable patient care, particularly in areas like lung nodule assessment.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The research provides a customizable dataset and framework to develop, benchmark, and analyze explainable AI models specifically for medical image diagnosis, such as classifying lung nodules. This aims to improve the transparency, reliability, and clinical utility of AI tools used by healthcare professionals for disease detection and diagnosis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses the critical gap of densely annotated medical image datasets that capture not only diagnostic labels but also the underlying reasoning for diagnoses, essential for xAI development.</li>
                    
                    <li>Introduces FunnyNodules, a fully parameterized synthetic dataset for systematic analysis of attribute-based reasoning in medical AI models.</li>
                    
                    <li>Generates abstract, lung nodule-like shapes with fully controllable visual attributes such as roundness, margin sharpness, and spiculation.</li>
                    
                    <li>Provides complete ground truth information by deriving the target diagnostic class from a predefined, user-controlled attribute combination, allowing full control over the decision rule.</li>
                    
                    <li>Enables model-agnostic evaluations to assess if AI models learn correct attribute-target relations, interpret over- or underperformance in attribute prediction, and analyze attention alignment with attribute-specific regions of interest.</li>
                    
                    <li>The framework is highly customizable, supporting variations in dataset complexity, target definitions, and class balance to suit diverse research and evaluation needs.</li>
                    
                    <li>Aims to provide a versatile foundation for developing, benchmarking, and conducting in-depth analyses of explainable AI methods specifically in medical image analysis.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>FunnyNodules employs a generative approach to create synthetic images resembling lung nodules. It achieves this by defining abstract shapes with parameterizable visual attributes (e.g., roundness, spiculation, margin sharpness). A key methodological aspect is the user's ability to predefine a deterministic decision rule that links specific combinations of these visual attributes directly to a diagnostic target class. This ensures complete ground truth reasoning is embedded within each generated instance, allowing for precise control and evaluation of how AI models learn and utilize these attributes for classification.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The paper demonstrates FunnyNodules' utility in several key areas: firstly, it allows for assessing whether AI models accurately learn the ground truth attribute-target relations defined in the dataset. Secondly, it facilitates the interpretation of model prediction over- or underperformance by linking it back to specific attribute predictions. Lastly, it enables the analysis of how well a model's attention mechanisms align with the attribute-specific regions of interest within the generated images, providing insights into its 'reasoning' process.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>By facilitating the development of transparent and rigorously evaluated explainable AI, FunnyNodules can significantly enhance clinical trust and adoption of AI in diagnostic medicine. This will enable radiologists and other clinicians to understand the rationale behind AI recommendations, promoting shared decision-making, improving diagnostic accuracy for critical conditions like lung cancer, and potentially reducing medical errors. Ultimately, it aims to deliver more reliable and accountable AI tools that can directly benefit patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>While powerful for xAI evaluation, the synthetic nature of FunnyNodules inherently means it simplifies the immense variability, noise, and complex pathological nuances present in real-world medical images. The abstract nodule-like shapes, while excellent for isolating reasoning, may not fully capture the full spectrum of challenges AI faces with authentic patient data. The abstract doesn't explicitly state these as limitations, but they are general considerations for synthetic datasets.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The framework is envisioned as a versatile foundation for continuous research and development in xAI. Future directions include leveraging FunnyNodules for benchmarking new xAI methods, conducting in-depth comparative analyses of different explanation techniques, and exploring how various model architectures impact attribute learning and the generation of human-interpretable explanations in the context of medical image analysis.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Pulmonology</span>
                    
                    <span class="tag">Diagnostic Imaging</span>
                    
                    <span class="tag">Oncology (lung cancer screening/diagnosis)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Explainable AI</span>
                    
                    <span class="tag tag-keyword">xAI</span>
                    
                    <span class="tag tag-keyword">Medical Imaging</span>
                    
                    <span class="tag tag-keyword">Synthetic Data</span>
                    
                    <span class="tag tag-keyword">Lung Nodules</span>
                    
                    <span class="tag tag-keyword">Attribute-based Reasoning</span>
                    
                    <span class="tag tag-keyword">Diagnostic AI</span>
                    
                    <span class="tag tag-keyword">Model Evaluation</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Densely annotated medical image datasets that capture not only diagnostic labels but also the underlying reasoning behind these diagnoses are scarce. Such reasoning-related annotations are essential for developing and evaluating explainable AI (xAI) models that reason similarly to radiologists: making correct predictions for the right reasons. To address this gap, we introduce FunnyNodules, a fully parameterized synthetic dataset designed for systematic analysis of attribute-based reasoning in medical AI models. The dataset generates abstract, lung nodule-like shapes with controllable visual attributes such as roundness, margin sharpness, and spiculation. Target class is derived from a predefined attribute combination, allowing full control over the decision rule that links attributes to the diagnostic class. We demonstrate how FunnyNodules can be used in model-agnostic evaluations to assess whether models learn correct attribute-target relations, to interpret over- or underperformance in attribute prediction, and to analyze attention alignment with attribute-specific regions of interest. The framework is fully customizable, supporting variations in dataset complexity, target definitions, class balance, and beyond. With complete ground truth information, FunnyNodules provides a versatile foundation for developing, benchmarking, and conducting in-depth analyses of explainable AI methods in medical image analysis.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>