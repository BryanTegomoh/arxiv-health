<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision - Health AI Hub</title>
    <meta name="description" content="This paper proposes a privacy-preserving framework to train local Vision Large Language Models (VLMs) specifically for surgical scene understanding, focusing on">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2512.05740v1" target="_blank">2512.05740v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-12-05
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Lennart Maack, Julia-Kristin Gra√ü, Lisa-Marie Toscha, Nathaniel Melling, Alexander Schlaefer
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2512.05740v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2512.05740v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper proposes a privacy-preserving framework to train local Vision Large Language Models (VLMs) specifically for surgical scene understanding, focusing on anatomy explanation during Complete Mesocolic Excision (CME). By distilling expert knowledge from a general-purpose teacher LLM into an efficient local VLM, the authors demonstrate a significant increase in surgical domain knowledge while ensuring patient data privacy.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing computer-aided surgery by providing domain-specific intelligence for complex procedures like CME, while simultaneously upholding stringent patient data privacy standards, which is a major barrier to AI adoption in healthcare.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development of local, privacy-preserving Vision Large Language Models (VLMs) designed to assist surgeons by identifying and explaining anatomical landmarks during surgical procedures (specifically Complete Mesocolic Excision). This contributes to computer-aided surgical decision support, surgical scene understanding, and potentially surgical training.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Addresses current VLM deficits in specific surgical scene understanding, particularly identifying and explaining anatomical landmarks during Complete Mesocolic Excision (CME).</li>
                    
                    <li>Tackles the critical need for locally deployable AI models to prevent patient data leakage associated with cloud-hosted large VLMs.</li>
                    
                    <li>Proposes a novel privacy-preserving framework that distills knowledge from a large, general-purpose LLM (teacher) into an efficient, local VLM.</li>
                    
                    <li>Generates an expert-supervised dataset by prompting the teacher LLM using only textual context and binary segmentation masks, completely avoiding sensitive patient images.</li>
                    
                    <li>Utilizes Supervised Fine-Tuning (SFT) followed by Direct Preference Optimization (DPO) to train the locally deployable VLM on the generated dataset.</li>
                    
                    <li>Evaluation confirms that finetuning with the generated datasets substantially enhances the VLM's surgical domain knowledge compared to its base model.</li>
                    
                    <li>Validates a data-efficient and privacy-conforming methodology for developing specialized, local VLMs for complex surgical tasks like anatomy explanation.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The methodology involves a privacy-preserving knowledge distillation framework. First, an expert-supervised dataset is created by querying a large teacher LLM using only textual context and binary segmentation masks (without sensitive images) to generate surgical explanations. This generated dataset is then used for Supervised Fine-Tuning (SFT) of a smaller, locally deployable VLM, followed by Direct Preference Optimization (DPO) to further refine its responses based on expert-like preferences.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary finding is that finetuning VLMs using the proposed expert-supervised, privacy-preserving generated datasets significantly increases their surgical domain knowledge and ability to explain anatomy in complex procedures like Complete Mesocolic Excision, by a large margin compared to their base VLM counterparts.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The clinical impact is substantial, enabling the deployment of AI assistants for real-time intraoperative guidance and surgical training without compromising patient data privacy. This can lead to improved surgical outcomes, enhanced trainee education through expert-level explanations, and broader adoption of AI in surgical settings due to its privacy-compliant nature.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract does not explicitly state specific limitations of the developed framework or model.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The abstract does not explicitly state future research directions.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Surgery</span>
                    
                    <span class="tag">Colorectal Surgery</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Artificial Intelligence in Medicine</span>
                    
                    <span class="tag">Medical Education</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Vision-Language Models (VLMs)</span>
                    
                    <span class="tag tag-keyword">Surgical Scene Understanding</span>
                    
                    <span class="tag tag-keyword">Complete Mesocolic Excision (CME)</span>
                    
                    <span class="tag tag-keyword">Knowledge Distillation</span>
                    
                    <span class="tag tag-keyword">Privacy-Preserving AI</span>
                    
                    <span class="tag tag-keyword">Supervised Fine-Tuning (SFT)</span>
                    
                    <span class="tag tag-keyword">Direct Preference Optimization (DPO)</span>
                    
                    <span class="tag tag-keyword">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Recently, Vision Large Language Models (VLMs) have demonstrated high potential in computer-aided diagnosis and decision-support. However, current VLMs show deficits in domain specific surgical scene understanding, such as identifying and explaining anatomical landmarks during Complete Mesocolic Excision. Additionally, there is a need for locally deployable models to avoid patient data leakage to large VLMs, hosted outside the clinic. We propose a privacy-preserving framework to distill knowledge from large, general-purpose LLMs into an efficient, local VLM. We generate an expert-supervised dataset by prompting a teacher LLM without sensitive images, using only textual context and binary segmentation masks for spatial information. This dataset is used for Supervised Fine-Tuning (SFT) and subsequent Direct Preference Optimization (DPO) of the locally deployable VLM. Our evaluation confirms that finetuning VLMs with our generated datasets increases surgical domain knowledge compared to its base VLM by a large margin. Overall, this work validates a data-efficient and privacy-conforming way to train a surgical domain optimized, locally deployable VLM for surgical scene understanding.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>