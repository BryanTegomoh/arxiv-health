<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging - Health AI Hub</title>
    <meta name="description" content="MIRNet introduces a novel framework for automated interpretation of diagnostic medical images, integrating self-supervised pre-training with constrained graph-b">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MIRNet: Integrating Constrained Graph-Based Reasoning with Pre-training for Diagnostic Medical Imaging</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.10013v1" target="_blank">2511.10013v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-13
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Shufeng Kong, Zijie Wang, Nuan Cui, Hao Tang, Yihan Meng, Yuanyuan Wei, Feifan Chen, Yingheng Wang, Zhuo Cai, Yaonan Wang, Yulong Zhang, Yuzheng Li, Zibin Zheng, Caihua Liu
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.CV, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.10013v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.10013v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MIRNet introduces a novel framework for automated interpretation of diagnostic medical images, integrating self-supervised pre-training with constrained graph-based reasoning. It addresses critical challenges like annotation scarcity, label imbalance, and the need for clinical plausibility, achieving state-of-the-art performance in tongue image diagnosis while demonstrating broad generalizability.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research significantly advances automated diagnostic medical imaging by providing a robust, data-efficient, and clinically plausible interpretation framework, particularly valuable for complex and data-scarce domains like tongue diagnosis, which is critical in certain medical traditions and can indicate systemic health issues.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The paper presents MIRNet, an AI framework using self-supervised pre-training and graph-based reasoning for automated interpretation and diagnosis from medical images. It is specifically applied to tongue image diagnosis, aiming to provide AI-assisted diagnostic capabilities for clinicians and generalize to broader diagnostic medical imaging tasks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>MIRNet is a novel framework that combines self-supervised Masked Autoencoder (MAE) pre-training for learning transferable visual representations with constrained Graph Attention Networks (GAT) for reasoning.</li>
                    
                    <li>It leverages expert-defined structured graphs within GATs to model complex label correlations and enforce clinical plausibility in diagnostic interpretations.</li>
                    
                    <li>Clinical priors are integrated and enforced via constraint-aware optimization using KL divergence and regularization losses, ensuring clinically plausible outputs.</li>
                    
                    <li>The framework explicitly mitigates challenges of label imbalance and annotation scarcity using techniques like asymmetric loss (ASL), boosting ensembles, and MAE's ability to learn from unlabeled data.</li>
                    
                    <li>A new, comprehensive expert-curated benchmark dataset, TongueAtlas-4K (4,000 images with 22 diagnostic labels), is introduced, representing the largest public dataset for tongue analysis.</li>
                    
                    <li>MIRNet achieves state-of-the-art (SOTA) performance on the challenging task of tongue image diagnosis.</li>
                    
                    <li>The framework is designed to be generalizable, extending beyond tongue diagnosis to a broader range of diagnostic medical imaging tasks.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MIRNet employs a self-supervised Masked Autoencoder (MAE) for pre-training to learn robust visual representations from unlabeled data. It then integrates Graph Attention Networks (GAT) to model label correlations through expert-defined structured graphs. Clinical priors are incorporated through constraint-aware optimization, utilizing KL divergence and regularization losses. To address data challenges, asymmetric loss (ASL) and boosting ensembles are used to mitigate label imbalance and improve robustness.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The MIRNet framework achieved state-of-the-art performance in automated tongue image diagnosis. A significant contribution is also the introduction of TongueAtlas-4K, the largest public dataset for tongue analysis, comprising 4,000 images with 22 diagnostic labels, providing a valuable resource for future research in this specialized domain.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MIRNet has the potential to significantly enhance the accuracy and reliability of automated medical image diagnosis, particularly in challenging visual domains with limited annotated data. By incorporating clinical priors, it ensures clinically plausible interpretations, which can aid clinicians in making more informed diagnostic decisions, reduce diagnostic errors, and extend the reach of automated diagnostics to complex visual examination tasks like tongue diagnosis, potentially streamlining patient assessment.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>Not explicitly mentioned in the abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The framework's generalizability suggests its application to a wider array of diagnostic medical imaging tasks beyond tongue diagnosis. Future work could involve exploring its performance across various anatomical sites and disease contexts, and further refining expert-defined graph structures and clinical priors for different medical specialties.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Diagnostic Medical Imaging</span>
                    
                    <span class="tag">Traditional Chinese Medicine (specifically tongue diagnosis)</span>
                    
                    <span class="tag">General internal medicine (for systemic disease indicators)</span>
                    
                    <span class="tag">Dermatology (potential for skin conditions)</span>
                    
                    <span class="tag">Oncology (for specific visual markers)</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">medical imaging</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">self-supervised learning</span>
                    
                    <span class="tag tag-keyword">graph neural networks</span>
                    
                    <span class="tag tag-keyword">diagnostic AI</span>
                    
                    <span class="tag tag-keyword">tongue diagnosis</span>
                    
                    <span class="tag tag-keyword">clinical priors</span>
                    
                    <span class="tag tag-keyword">label imbalance</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Automated interpretation of medical images demands robust modeling of complex visual-semantic relationships while addressing annotation scarcity, label imbalance, and clinical plausibility constraints. We introduce MIRNet (Medical Image Reasoner Network), a novel framework that integrates self-supervised pre-training with constrained graph-based reasoning. Tongue image diagnosis is a particularly challenging domain that requires fine-grained visual and semantic understanding. Our approach leverages self-supervised masked autoencoder (MAE) to learn transferable visual representations from unlabeled data; employs graph attention networks (GAT) to model label correlations through expert-defined structured graphs; enforces clinical priors via constraint-aware optimization using KL divergence and regularization losses; and mitigates imbalance using asymmetric loss (ASL) and boosting ensembles. To address annotation scarcity, we also introduce TongueAtlas-4K, a comprehensive expert-curated benchmark comprising 4,000 images annotated with 22 diagnostic labels--representing the largest public dataset in tongue analysis. Validation shows our method achieves state-of-the-art performance. While optimized for tongue diagnosis, the framework readily generalizes to broader diagnostic medical imaging tasks.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>To appear at AAAI-26</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>