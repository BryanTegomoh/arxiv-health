<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT - Health AI Hub</title>
    <meta name="description" content="This study investigates the effect of integrating anatomical prior information, specifically organ segmentation masks, into deep learning models for lymphoma le">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.07047v1" target="_blank">2511.07047v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-10
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Simone Bendazzoli, Antonios Tzortzakakis, Andreas Abrahamsson, Bj√∂rn Engelbrekt Wahlin, √ñrjan Smedby, Maria Holstensson, Rodrigo Moreno
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> eess.IV, cs.LG
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 1.00 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.07047v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="http://arxiv.org/pdf/2511.07047v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This study investigates the effect of integrating anatomical prior information, specifically organ segmentation masks, into deep learning models for lymphoma lesion detection in whole-body PET/CT images. It found that anatomical context substantially improves detection performance in CNN-based models like nnDetection, but had minimal impact on vision transformers (Swin Transformer). The research highlights the critical role of anatomical priors, particularly for CNN-based cancer lesion detection.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>Accurate and early detection of lymphoma lesions from PET/CT scans is crucial for patient staging, treatment planning, and overall prognosis. This research offers a method to potentially enhance the precision of automated lesion detection, thereby aiding radiologists and improving patient outcomes through earlier and more reliable diagnoses.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application involves using deep learning models (nnDetection, Swin Transformer) enhanced with anatomical prior information (organ segmentation masks) to automatically detect lymphoma lesions in whole-body PET/CT scans. This aims to improve the accuracy and efficiency of cancer diagnosis, thereby assisting clinicians and potentially leading to earlier treatment and better patient outcomes.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>The research addresses the challenge of accurate, multi-lesion detection in 18F FDG PET/CT for early cancer diagnosis, especially for lymphoma.</li>
                    
                    <li>Methodology involves adding organ segmentation masks (derived from TotalSegmentator) as auxiliary anatomical inputs to nnDetection (state-of-the-art CNN) and Swin Transformer (vision transformer).</li>
                    
                    <li>The Swin Transformer was trained using a two-stage process: self-supervised pre-training followed by supervised fine-tuning.</li>
                    
                    <li>Evaluation was conducted on two specialized lymphoma datasets: AutoPET and Karolinska lymphoma datasets.</li>
                    
                    <li>Inclusion of anatomical priors significantly improved lesion detection performance within the nnDetection framework.</li>
                    
                    <li>Conversely, anatomical priors had almost no impact on the detection performance of the Swin Transformer.</li>
                    
                    <li>Swin Transformer did not demonstrate clear advantages over the conventional CNN encoders utilized in nnDetection for this specific task.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study incorporated organ segmentation masks, generated by the TotalSegmentator tool, as auxiliary anatomical inputs into two deep learning models: nnDetection (a state-of-the-art convolutional neural network-based framework) and Swin Transformer (a vision transformer trained via two stages combining self-supervised pre-training and supervised fine-tuning). The models were trained and tested on the AutoPET and Karolinska lymphoma datasets.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>The primary findings reveal that anatomical prior information substantially improves lesion detection performance for CNN-based models like nnDetection. However, the same anatomical priors had negligible effect on the performance of the Swin Transformer. Furthermore, the Swin Transformer did not exhibit any clear performance advantages over the conventional CNN encoders used in nnDetection for this specific application.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>The findings suggest that integrating anatomical context into CNN-based lesion detection systems can significantly enhance their accuracy, potentially leading to improved diagnostic reliability in clinical settings. This could assist clinicians in more precise lymphoma staging, better treatment planning, and ultimately contribute to earlier and more effective patient management by reducing missed lesions or false positives.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract implicitly notes a limitation concerning the Swin Transformer, as it did not benefit from anatomical priors or offer clear advantages over conventional CNNs for this task, suggesting that its applicability or integration method for anatomical context might be limited compared to CNNs.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>While not explicitly stated, the differential impact observed between CNNs and vision transformers regarding anatomical priors suggests future research could investigate the underlying reasons for this difference and explore alternative architectures or integration strategies for anatomical context in vision transformers to unlock their potential in medical imaging.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Radiology</span>
                    
                    <span class="tag">Nuclear Medicine</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">lymphoma</span>
                    
                    <span class="tag tag-keyword">lesion detection</span>
                    
                    <span class="tag tag-keyword">PET/CT</span>
                    
                    <span class="tag tag-keyword">deep learning</span>
                    
                    <span class="tag tag-keyword">anatomical priors</span>
                    
                    <span class="tag tag-keyword">nnDetection</span>
                    
                    <span class="tag tag-keyword">Swin Transformer</span>
                    
                    <span class="tag tag-keyword">cancer imaging</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Early cancer detection is crucial for improving patient outcomes, and 18F FDG
PET/CT imaging plays a vital role by combining metabolic and anatomical
information. Accurate lesion detection remains challenging due to the need to
identify multiple lesions of varying sizes. In this study, we investigate the
effect of adding anatomy prior information to deep learning-based lesion
detection models. In particular, we add organ segmentation masks from the
TotalSegmentator tool as auxiliary inputs to provide anatomical context to
nnDetection, which is the state-of-the-art for lesion detection, and Swin
Transformer. The latter is trained in two stages that combine self-supervised
pre-training and supervised fine-tuning. The method is tested in the AutoPET
and Karolinska lymphoma datasets. The results indicate that the inclusion of
anatomical priors substantially improves the detection performance within the
nnDetection framework, while it has almost no impact on the performance of the
vision transformer. Moreover, we observe that Swin Transformer does not offer
clear advantages over conventional convolutional neural network (CNN) encoders
used in nnDetection. These findings highlight the critical role of the
anatomical context in cancer lesion detection, especially in CNN-based models.</p>
            </section>

            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>