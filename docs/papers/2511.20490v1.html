<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology - Health AI Hub</title>
    <meta name="description" content="MTBBench introduces a novel agentic benchmark simulating complex, multimodal, and longitudinal oncology decision-making scenarios found in Molecular Tumor Board">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20490v1" target="_blank">2511.20490v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MTBBench introduces a novel agentic benchmark simulating complex, multimodal, and longitudinal oncology decision-making scenarios found in Molecular Tumor Boards (MTBs). It reveals that current LLMs struggle significantly with clinical reliability, reasoning from time-resolved data, and reconciling conflicting multimodal evidence, but an accompanying agentic framework with tools substantially improves performance in these critical areas.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work directly addresses the critical need for more realistic AI evaluation and development in oncology, enabling the creation of more reliable and clinically effective multimodal LLMs capable of supporting complex decision-making in precision medicine.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The AI application is the development, benchmarking, and enhancement of Multimodal Large Language Models (LLMs) and agentic AI frameworks to support and improve complex clinical decision-making processes in oncology, specifically within Molecular Tumor Boards. This involves integrating heterogeneous and longitudinal patient data to aid in diagnostic and prognostic tasks, thereby aiming to increase the reliability and reasoning capabilities of AI in a healthcare setting.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Existing LLM benchmarks for biomedical reasoning lack the complexity of real-world clinical workflows, failing to capture multimodal, longitudinal, and multi-agent decision-making.</li>
                    
                    <li>MTBBench is an agentic benchmark designed to simulate Molecular Tumor Board (MTB)-style decision-making using clinically challenging, multimodal, and longitudinal oncology questions.</li>
                    
                    <li>Ground truth annotations for MTBBench cases are rigorously validated by clinicians via a co-developed application, ensuring high clinical relevance and accuracy.</li>
                    
                    <li>Benchmarking of multiple open and closed-source LLMs demonstrated significant limitations, including frequent hallucinations, poor reasoning with time-resolved data, and an inability to reconcile conflicting evidence across different modalities.</li>
                    
                    <li>Beyond benchmarking, MTBBench provides an agentic framework equipped with foundation model-based tools specifically designed to enhance multimodal and longitudinal reasoning capabilities.</li>
                    
                    <li>This agentic framework achieved notable task-level performance gains, improving multimodal reasoning by up to 9.0% and longitudinal reasoning by up to 11.2%.</li>
                    
                    <li>MTBBench serves as a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use, with a specific focus on precision oncology and MTB environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MTBBench was developed as an agentic benchmark simulating complex, multimodal, and longitudinal oncology decision-making scenarios found in Molecular Tumor Boards (MTBs). Clinicians co-developed an app to validate ground truth annotations, ensuring clinical relevance. The study involved benchmarking multiple open and closed-source LLMs against these scenarios and subsequently introducing an agentic framework with foundation model-based tools to enhance multimodal and longitudinal reasoning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Current LLMs, even at scale, lack clinical reliability, frequently hallucinate, struggle with reasoning from time-resolved data, and fail to reconcile conflicting evidence or different modalities. However, the proposed agentic framework, utilizing foundation model-based tools, significantly improves performance, yielding task-level gains of up to 9.0% for multimodal reasoning and 11.2% for longitudinal reasoning.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MTBBench can accelerate the development of more reliable and robust AI tools for precision oncology by providing a realistic testing ground. Improved LLM capabilities in integrating diverse, time-evolving patient data and resolving conflicting information can enhance diagnostic accuracy, refine prognostic assessments, and optimize treatment recommendations within Molecular Tumor Boards, ultimately leading to better patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The primary limitations identified are inherent to current LLMs: their lack of reliability, propensity for hallucinations, struggle with reasoning from time-resolved data, and inability to reconcile conflicting evidence across different modalities in complex clinical contexts.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>MTBBench provides a testbed to advance multimodal LLM reasoning, reliability, and tool-use. Future research should focus on developing LLMs and agentic AI systems that overcome the identified limitations, specifically improving their capabilities in handling complex multimodal and longitudinal data, mitigating hallucinations, and enhancing clinical reasoning in real-world precision oncology settings.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Clinical Informatics</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multimodal LLM</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Molecular Tumor Board</span>
                    
                    <span class="tag tag-keyword">Clinical Decision-Making</span>
                    
                    <span class="tag tag-keyword">Agentic AI</span>
                    
                    <span class="tag tag-keyword">Precision Medicine</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                    <span class="tag tag-keyword">Biomedical Reasoning</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>