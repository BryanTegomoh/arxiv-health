<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology - Health AI Hub</title>
    <meta name="description" content="This paper introduces MTBBench, a novel agentic benchmark designed to simulate complex, multimodal, and longitudinal clinical decision-making in oncology, speci">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20490v1" target="_blank">2511.20490v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MTBBench, a novel agentic benchmark designed to simulate complex, multimodal, and longitudinal clinical decision-making in oncology, specifically within Molecular Tumor Boards (MTBs). It reveals that current LLMs demonstrate significant reliability issues, struggling with time-resolved data and conflicting evidence, but proposes an agentic framework within MTBBench that substantially improves reasoning performance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for bridging the gap between current LLM capabilities and the complex demands of real-world clinical decision-making, especially in precision oncology. It provides a robust framework to evaluate and advance AI tools that can effectively integrate diverse, evolving patient data for improved diagnostic and therapeutic strategies.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This research develops a benchmark and an agentic framework to advance multimodal Large Language Models (LLMs) for clinical decision-making, particularly in oncology. It aims to improve the reliability and reasoning capabilities of AI models in integrating heterogeneous and longitudinal patient data for diagnostic and prognostic tasks within settings like Molecular Tumor Boards, thereby supporting healthcare professionals in complex medical scenarios.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current LLM benchmarks for biomedical reasoning are inadequate, failing to capture the multimodal, longitudinal, and multi-agent complexity of real-world clinical workflows like Molecular Tumor Boards (MTBs).</li>
                    
                    <li>MTBBench is introduced as a new agentic benchmark that simulates MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions.</li>
                    
                    <li>The ground truth annotations for MTBBench are rigorously validated by clinicians via a co-developed application, ensuring high clinical relevance and fidelity.</li>
                    
                    <li>Benchmarking of various open and closed-source LLMs on MTBBench reveals their lack of reliability, frequent hallucinations, and difficulties in reasoning from time-resolved data or reconciling conflicting multimodal evidence.</li>
                    
                    <li>MTBBench goes beyond simple benchmarking by providing an agentic framework augmented with foundation model-based tools designed to enhance multimodal and longitudinal reasoning capabilities.</li>
                    
                    <li>This agentic framework achieved significant task-level performance gains, specifically up to 9.0% for multimodal reasoning and 11.2% for longitudinal reasoning.</li>
                    
                    <li>The overall goal of MTBBench is to serve as a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use, particularly in precision oncology within MTB environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved creating MTBBench, an agentic benchmark that simulates Molecular Tumor Board (MTB) clinical decision-making using multimodal, longitudinal oncology questions. Ground truth annotations were validated by clinicians via a custom application. Open and closed-source LLMs were benchmarked on MTBBench to assess their performance. Subsequently, an agentic framework with foundation model-based tools was developed and integrated into MTBBench to enhance multimodal and longitudinal reasoning, and its performance gains were measured.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>['Existing open and closed-source LLMs demonstrate significant unreliability in complex clinical scenarios, frequently generating hallucinatory content.', 'These LLMs struggle considerably with reasoning from time-resolved data and are inefficient at reconciling conflicting evidence across different modalities (e.g., genomic, pathology, radiology reports).', 'The MTBBench agentic framework, leveraging foundation model-based tools, successfully enhances reasoning capabilities, leading to performance improvements of up to 9.0% for multimodal tasks and 11.2% for longitudinal tasks.']</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MTBBench provides a more realistic and rigorous testbed for AI systems aiming to assist in intricate medical diagnoses and treatment planning, especially in precision oncology. It highlights critical deficiencies of current LLMs, guiding the development of more reliable AI tools capable of processing dynamic, heterogeneous patient data. This could lead to more accurate clinical decision support, potentially improving outcomes in settings like Molecular Tumor Boards by enabling AI to assist experts in complex multi-factor analyses over time.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights the limitations of *current LLMs* when applied to complex clinical reasoning, specifically their lack of reliability, frequent hallucinations, inability to effectively reason from time-resolved data, and struggle to reconcile conflicting evidence across different modalities. While MTBBench aims for realism, it is a simulation, and the challenges of full real-world clinical integration are implicitly not covered.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work suggests future research should focus on advancing multimodal LLM reasoning, improving reliability, and enhancing tool-use capabilities, directly addressing the identified limitations of current LLMs. This includes further developing and refining agentic frameworks and foundation model-based tools to handle temporal data, conflicting evidence, and reduce hallucinations in clinical contexts, potentially extending beyond oncology to other medical domains requiring complex multimodal sequential reasoning.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Computational Pathology</span>
                    
                    <span class="tag">Medical Imaging</span>
                    
                    <span class="tag">Digital Health</span>
                    
                    <span class="tag">Medical AI</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multimodal LLMs</span>
                    
                    <span class="tag tag-keyword">Clinical Decision-Making</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Molecular Tumor Boards</span>
                    
                    <span class="tag tag-keyword">Benchmarking</span>
                    
                    <span class="tag tag-keyword">Agentic Framework</span>
                    
                    <span class="tag tag-keyword">Precision Oncology</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>