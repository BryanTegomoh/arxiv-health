<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology - Health AI Hub</title>
    <meta name="description" content="This paper introduces MTBBench, a novel benchmark designed to simulate the complex, multimodal, and longitudinal decision-making processes of Molecular Tumor Bo">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20490v1" target="_blank">2511.20490v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MTBBench, a novel benchmark designed to simulate the complex, multimodal, and longitudinal decision-making processes of Molecular Tumor Boards (MTBs) in oncology. It reveals that current LLMs, despite their scale, consistently lack reliability, struggle with time-resolved data and conflicting evidence, but demonstrates that an agentic framework with foundation model-based tools can significantly enhance their multimodal and longitudinal reasoning capabilities.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is crucial for advancing AI in medicine as it addresses the critical gap between current LLM capabilities and the demands of complex clinical scenarios like Molecular Tumor Boards. By providing a realistic evaluation framework and a tool-enhanced agentic approach, it aims to develop more reliable and clinically useful AI systems for precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>This paper develops a benchmark (MTBBench) and an agentic framework with tool-use capabilities to evaluate and advance Multimodal Large Language Models (LLMs) for complex clinical decision-making. Specifically, it targets the challenging environment of Molecular Tumor Boards in oncology, aiming to improve AI's ability to integrate heterogeneous, multimodal, and longitudinal patient data for more reliable diagnostic and prognostic support in precision oncology.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current LLM benchmarks for biomedical reasoning are inadequate, failing to capture the multi-agent, multimodal, and longitudinal complexity of real-world clinical workflows like Molecular Tumor Boards (MTBs).</li>
                    
                    <li>MTBBench is introduced as an agentic benchmark that simulates MTB-style decision-making using clinically challenging, multimodal, and time-resolved oncology questions.</li>
                    
                    <li>Ground truth annotations for MTBBench are rigorously validated by clinicians via a co-developed application, ensuring high clinical relevance.</li>
                    
                    <li>Benchmarking of various open and closed-source LLMs on MTBBench revealed significant deficiencies, including frequent hallucinations, poor reasoning from time-resolved data, and inability to reconcile conflicting evidence or different data modalities.</li>
                    
                    <li>To address these limitations, MTBBench provides an agentic framework incorporating foundation model-based tools, designed to enhance LLM reasoning.</li>
                    
                    <li>The agentic framework with integrated tools led to notable performance gains, specifically up to 9.0% in multimodal reasoning and 11.2% in longitudinal reasoning tasks.</li>
                    
                    <li>MTBBench serves as a robust and realistic testbed for advancing the reliability, reasoning capabilities, and tool-use of multimodal LLMs in precision oncology.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The study involved developing MTBBench, a benchmark simulating Molecular Tumor Board (MTB) decision-making with clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations were validated by clinicians via a custom app. Multiple open and closed-source Large Language Models (LLMs) were benchmarked against MTBBench. An agentic framework was co-developed, integrating foundation model-based tools to improve LLM performance in multimodal and longitudinal reasoning.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Current LLMs lack reliability, frequently hallucinate, struggle with reasoning from time-resolved data, and fail to reconcile conflicting evidence across different modalities. The proposed agentic framework within MTBBench, equipped with foundation model-based tools, significantly improves LLM performance in multimodal (up to 9.0%) and longitudinal (up to 11.2%) reasoning tasks, demonstrating a viable path to enhance their clinical utility.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MTBBench provides a more accurate and challenging testbed for evaluating AI's readiness for complex clinical environments, particularly in precision oncology. The agentic framework offers a practical approach to building more reliable AI systems that can integrate diverse, evolving patient data, potentially assisting oncologists in making better diagnostic and prognostic decisions within real-world Molecular Tumor Boards.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract highlights the inherent limitations of current LLMs in handling complex clinical decision-making, specifically their unreliability, propensity for hallucination, and struggles with time-resolved and conflicting multimodal data. It does not explicitly mention limitations of the MTBBench framework itself, but the identified shortcomings of LLMs imply the significant challenge that remains in achieving robust AI for these tasks.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>MTBBench is presented as a testbed for advancing multimodal LLM reasoning, reliability, and tool-use. This implies future research will focus on developing more capable LLMs and AI agents, potentially expanding the scope of diseases or clinical workflows simulated, and further integrating advanced tool-use to improve performance on such complex, real-world tasks.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Clinical Decision Support</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Genomics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multimodal LLMs</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Molecular Tumor Boards</span>
                    
                    <span class="tag tag-keyword">Clinical Decision-Making</span>
                    
                    <span class="tag tag-keyword">AI Benchmarking</span>
                    
                    <span class="tag tag-keyword">Precision Oncology</span>
                    
                    <span class="tag tag-keyword">Agentic AI</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>