<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology - Health AI Hub</title>
    <meta name="description" content="This paper introduces MTBBench, a novel agentic benchmark designed to simulate complex, multimodal, and longitudinal clinical decision-making in oncology, speci">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20490v1" target="_blank">2511.20490v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.98 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">This paper introduces MTBBench, a novel agentic benchmark designed to simulate complex, multimodal, and longitudinal clinical decision-making in oncology, specifically within Molecular Tumor Board (MTB) environments. It reveals significant limitations in current LLMs regarding reliability, reasoning with time-resolved data, and reconciling conflicting evidence. Crucially, MTBBench also provides an agentic framework with foundation model-based tools that demonstrably enhance LLM performance on these challenging tasks.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This research is highly relevant for advancing AI in precision oncology by providing a realistic testing environment for LLMs. It directly addresses the need for AI systems capable of assisting complex diagnostic and prognostic tasks in Molecular Tumor Boards, crucial for personalized cancer care.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>The primary AI health application is the development, benchmarking, and enhancement of Multimodal Large Language Models (LLMs) and agentic AI frameworks to assist in complex, real-world clinical decision-making within Molecular Tumor Boards (MTBs) in oncology. This involves integrating heterogeneous, time-resolved patient data to improve diagnostic accuracy, prognostic assessments, and overall clinical reasoning in cancer care.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current LLM benchmarks are inadequate for real-world clinical workflows, failing to capture multimodal, longitudinal, and multi-agent complexity found in Molecular Tumor Boards (MTBs).</li>
                    
                    <li>MTBBench is an agentic benchmark that simulates MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions, with ground truth annotations validated by clinicians.</li>
                    
                    <li>Benchmarking of various open and closed-source LLMs on MTBBench revealed critical deficiencies: frequent hallucination, poor reasoning with time-resolved data, and inability to reconcile conflicting evidence across modalities.</li>
                    
                    <li>To address these limitations, MTBBench incorporates an agentic framework with foundation model-based tools designed to augment LLM capabilities.</li>
                    
                    <li>This tool-enhanced agentic framework demonstrated significant performance gains, achieving up to 9.0% improvement in multimodal reasoning and 11.2% in longitudinal reasoning tasks.</li>
                    
                    <li>The benchmark serves as a realistic and challenging testbed for advancing multimodal LLM reasoning, reliability, and tool-use in precision oncology, with a specific focus on MTB environments.</li>
                    
                    <li>The co-developed app for clinician validation of ground truth annotations ensures high clinical relevance and accuracy of the benchmark data.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>MTBBench is an agentic benchmark simulating Molecular Tumor Board decision-making using clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed application. The methodology involves benchmarking both open and closed-source LLMs on these tasks. Additionally, it integrates an agentic framework with foundation model-based tools to enhance multimodal and longitudinal reasoning, measuring performance gains compared to unaugmented LLMs.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>Existing large language models (LLMs) demonstrate significant unreliability in complex clinical scenarios, frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. However, an agentic framework within MTBBench, enhanced with foundation model-based tools, leads to substantial performance gains: up to 9.0% for multimodal reasoning and 11.2% for longitudinal reasoning tasks.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>MTBBench provides a critical infrastructure for developing and evaluating AI tools for precision oncology, particularly those intended to assist in Molecular Tumor Boards. By identifying current LLM weaknesses and demonstrating the effectiveness of tool-augmented agentic frameworks, it paves the way for more reliable AI systems that can accurately integrate heterogeneous, time-sensitive patient data for improved diagnosis, prognosis, and treatment recommendations in cancer care.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The abstract primarily highlights the limitations of current LLMs themselves (lack reliability, hallucination, poor reasoning with time-resolved/conflicting data) that MTBBench aims to expose and address. It does not explicitly state limitations or caveats regarding the MTBBench framework or the study design itself in the provided abstract.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>The work suggests future research should focus on advancing multimodal LLM reasoning, reliability, and effective tool-use, especially within complex clinical environments like Molecular Tumor Boards in precision oncology. Further development and integration of foundation model-based tools within agentic frameworks are implied as a key direction to overcome current LLM deficiencies.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Precision Medicine</span>
                    
                    <span class="tag">Medical Informatics</span>
                    
                    <span class="tag">Pathology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multimodal LLMs</span>
                    
                    <span class="tag tag-keyword">Clinical Decision-Making</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Molecular Tumor Boards</span>
                    
                    <span class="tag tag-keyword">Benchmark</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                    <span class="tag tag-keyword">Agentic AI</span>
                    
                    <span class="tag tag-keyword">Precision Oncology</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>