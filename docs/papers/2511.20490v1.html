<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology - Health AI Hub</title>
    <meta name="description" content="MTBBench introduces a novel agentic benchmark simulating Molecular Tumor Board (MTB)-style decision-making in oncology, featuring multimodal and longitudinal da">
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <div class="container">
            <div class="breadcrumb">
                <a href="../index.html">‚Üê Back to all papers</a>
                <a href="../index.html" class="home-btn">üè† Home</a>
            </div>
        </div>
    </header>

    <main class="container paper-detail">
        <article>
            <h1>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h1>

            <div class="paper-metadata">
                <div class="meta-row">
                    <strong>arXiv ID:</strong> <a href="http://arxiv.org/abs/2511.20490v1" target="_blank">2511.20490v1</a>
                </div>
                <div class="meta-row">
                    <strong>Published:</strong> 2025-11-25
                </div>
                <div class="meta-row">
                    <strong>Authors:</strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
                </div>
                <div class="meta-row">
                    <strong>Categories:</strong> cs.LG, cs.AI
                </div>
                <div class="meta-row">
                    <strong>Relevance Score:</strong> 0.95 / 1.00
                </div>
            </div>

            <div class="action-buttons">
                <a href="http://arxiv.org/abs/2511.20490v1" target="_blank" class="btn btn-primary">View on arXiv</a>
                <a href="https://arxiv.org/pdf/2511.20490v1" target="_blank" class="btn btn-primary">Download PDF</a>
            </div>

            <section class="paper-section">
                <h2>Summary</h2>
                <p class="summary-text">MTBBench introduces a novel agentic benchmark simulating Molecular Tumor Board (MTB)-style decision-making in oncology, featuring multimodal and longitudinal data, to address the shortcomings of current LLM evaluation. It reveals that state-of-the-art LLMs struggle with reliability, hallucination, and reasoning from complex, time-resolved data, but an integrated agentic framework with foundation model-based tools can significantly boost their multimodal and longitudinal reasoning performance.</p>
            </section>

            <section class="paper-section">
                <h2>Medical Relevance</h2>
                <p>This work is critical for developing trustworthy AI in healthcare by providing a realistic platform to evaluate and improve LLMs for complex oncology decision-making, directly addressing the need for reliable AI support in precision medicine and multidisciplinary tumor boards.</p>
            </section>

            
            <section class="paper-section">
                <h2>AI Health Application</h2>
                <p>Development and evaluation of Multimodal Large Language Models (LLMs) and agentic AI frameworks designed to assist with complex clinical decision-making in oncology. This involves simulating Molecular Tumor Board (MTB) environments to integrate heterogeneous and time-resolved patient data for improved diagnosis, prognosis, and treatment planning, thereby enhancing reliability and reasoning in a critical healthcare domain.</p>
            </section>
            

            <section class="paper-section">
                <h2>Key Points</h2>
                <ul class="key-points">
                    
                    <li>Current LLM benchmarks are insufficient for real-world clinical workflows, lacking multimodal, longitudinal, and multi-agent complexity, specifically in oncology settings like Molecular Tumor Boards (MTBs).</li>
                    
                    <li>MTBBench is an agentic benchmark that simulates complex, MTB-style clinical decision-making through challenging, multimodal, and longitudinal oncology questions.</li>
                    
                    <li>Ground truth annotations for the benchmark are rigorously validated by clinicians via a co-developed application, ensuring high clinical relevance and accuracy.</li>
                    
                    <li>Benchmarking of various open and closed-source LLMs revealed significant reliability issues, including frequent hallucinations, struggles with time-resolved data reasoning, and failure to reconcile conflicting evidence across different modalities.</li>
                    
                    <li>MTBBench provides an agentic framework equipped with foundation model-based tools, designed to enhance the multimodal and longitudinal reasoning capabilities of LLMs.</li>
                    
                    <li>This agentic framework demonstrates notable performance gains, leading to task-level improvements of up to 9.0% for multimodal reasoning and 11.2% for longitudinal reasoning tasks.</li>
                    
                    <li>The benchmark serves as a realistic and challenging testbed for advancing multimodal LLM reasoning, improving reliability, and fostering effective tool-use in precision oncology, particularly within MTB environments.</li>
                    
                </ul>
            </section>

            <div class="two-column">
                <section class="paper-section">
                    <h2>Methodology</h2>
                    <p>The authors developed MTBBench, an agentic benchmark simulating Molecular Tumor Board (MTB)-style decision-making using clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations were validated by clinicians via a co-developed application. Open and closed-source LLMs were benchmarked against this dataset. Furthermore, an agentic framework was designed, incorporating foundation model-based tools to enhance LLM reasoning, and its performance gains were measured.</p>
                </section>

                <section class="paper-section">
                    <h2>Key Findings</h2>
                    <p>1. Current LLMs (both open and closed-source) lack reliability in complex clinical scenarios, frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence across different modalities. 2. An agentic framework, integrated with foundation model-based tools, significantly enhances LLM performance in multimodal (up to 9.0% gain) and longitudinal (up to 11.2% gain) clinical reasoning tasks.</p>
                </section>
            </div>

            <section class="paper-section">
                <h2>Clinical Impact</h2>
                <p>This research provides a crucial tool for developing AI systems that can effectively assist multidisciplinary teams in precision oncology, such as Molecular Tumor Boards. By identifying current LLM limitations and offering a framework for improvement, it paves the way for more reliable AI that can integrate complex, heterogeneous, and time-evolving patient data, potentially leading to improved diagnostic accuracy, more personalized treatment plans, and better patient outcomes.</p>
            </section>

            
            <section class="paper-section">
                <h2>Limitations</h2>
                <p>The benchmark itself highlights significant limitations of current LLMs, noting their lack of reliability, frequent hallucinations, inability to reason effectively from time-resolved data, and failure to reconcile conflicting evidence or different modalities when applied to complex clinical tasks.</p>
            </section>
            

            
            <section class="paper-section">
                <h2>Future Directions</h2>
                <p>MTBBench serves as a testbed for advancing multimodal LLM reasoning, reliability, and tool-use. Future work will likely focus on leveraging this benchmark to develop more robust and context-aware LLMs capable of handling the intricacies of real-world clinical decision-making, particularly in precision oncology and multi-agent environments like Molecular Tumor Boards.</p>
            </section>
            

            <section class="paper-section">
                <h2>Medical Domains</h2>
                <div class="tags">
                    
                    <span class="tag">Oncology</span>
                    
                    <span class="tag">Precision Oncology</span>
                    
                    <span class="tag">Clinical Decision-Making</span>
                    
                    <span class="tag">Pathology</span>
                    
                    <span class="tag">Genomics</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Keywords</h2>
                <div class="tags">
                    
                    <span class="tag tag-keyword">Multimodal LLM</span>
                    
                    <span class="tag tag-keyword">Oncology</span>
                    
                    <span class="tag tag-keyword">Clinical Decision-Making</span>
                    
                    <span class="tag tag-keyword">Molecular Tumor Board</span>
                    
                    <span class="tag tag-keyword">Agentic AI</span>
                    
                    <span class="tag tag-keyword">Longitudinal Data</span>
                    
                    <span class="tag tag-keyword">Precision Oncology</span>
                    
                    <span class="tag tag-keyword">Benchmark</span>
                    
                </div>
            </section>

            <section class="paper-section">
                <h2>Abstract</h2>
                <p class="abstract">Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p>
            </section>

            
            <section class="paper-section">
                <h2>Comments</h2>
                <p>Accepted to NeurIPS 2025</p>
            </section>
            

            
        </article>
    </main>

    <footer class="container">
        <p><a href="../index.html">‚Üê Back to all papers</a></p>
    </footer>
</body>
</html>